# Comparing `tmp/dagster-1.6.9.tar.gz` & `tmp/dagster-1.7.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dagster-1.6.9.tar", last modified: Fri Mar  8 00:18:17 2024, max compression
+gzip compressed data, was "dagster-1.7.0.tar", last modified: Thu Apr  4 19:44:34 2024, max compression
```

## Comparing `dagster-1.6.9.tar` & `dagster-1.7.0.tar`

### file list

```diff
@@ -1,677 +1,691 @@
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.898550 dagster-1.6.9/
--rw-r--r--   0 root         (0) root         (0)      553 2024-03-08 00:17:46.000000 dagster-1.6.9/COPYING
--rw-r--r--   0 root         (0) root         (0)    11349 2024-03-08 00:17:46.000000 dagster-1.6.9/LICENSE
--rw-r--r--   0 root         (0) root         (0)      533 2024-03-08 00:17:46.000000 dagster-1.6.9/MANIFEST.in
--rw-r--r--   0 root         (0) root         (0)     8947 2024-03-08 00:18:17.898550 dagster-1.6.9/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)     7233 2024-03-08 00:17:46.000000 dagster-1.6.9/README.md
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.798551 dagster-1.6.9/dagster/
--rw-r--r--   0 root         (0) root         (0)    28915 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/__init__.py
--rw-r--r--   0 root         (0) root         (0)       31 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/__main__.py
--rw-r--r--   0 root         (0) root         (0)    20744 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_annotations.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.802551 dagster-1.6.9/dagster/_api/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/__init__.py
--rw-r--r--   0 root         (0) root         (0)      731 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/get_server_id.py
--rw-r--r--   0 root         (0) root         (0)     2147 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/list_repositories.py
--rw-r--r--   0 root         (0) root         (0)      531 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/notebook_data.py
--rw-r--r--   0 root         (0) root         (0)     3226 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/snapshot_execution_plan.py
--rw-r--r--   0 root         (0) root         (0)     1866 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/snapshot_job.py
--rw-r--r--   0 root         (0) root         (0)     5479 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/snapshot_partition.py
--rw-r--r--   0 root         (0) root         (0)     1668 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/snapshot_repository.py
--rw-r--r--   0 root         (0) root         (0)     3017 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/snapshot_schedule.py
--rw-r--r--   0 root         (0) root         (0)     3366 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_api/snapshot_sensor.py
--rw-r--r--   0 root         (0) root         (0)      478 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_builtins.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.802551 dagster-1.6.9/dagster/_check/
--rw-r--r--   0 root         (0) root         (0)     1352 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_check/README.md
--rw-r--r--   0 root         (0) root         (0)    51165 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_check/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.802551 dagster-1.6.9/dagster/_cli/
--rw-r--r--   0 root         (0) root         (0)     1182 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/__init__.py
--rw-r--r--   0 root         (0) root         (0)    26993 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/api.py
--rw-r--r--   0 root         (0) root         (0)     8229 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/asset.py
--rw-r--r--   0 root         (0) root         (0)     8302 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/code_server.py
--rw-r--r--   0 root         (0) root         (0)     2374 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/config_scaffolder.py
--rw-r--r--   0 root         (0) root         (0)     3513 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/debug.py
--rw-r--r--   0 root         (0) root         (0)     8134 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/dev.py
--rw-r--r--   0 root         (0) root         (0)     6651 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/instance.py
--rw-r--r--   0 root         (0) root         (0)    30649 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/job.py
--rw-r--r--   0 root         (0) root         (0)     1695 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/load_handle.py
--rw-r--r--   0 root         (0) root         (0)     9114 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/project.py
--rw-r--r--   0 root         (0) root         (0)     5129 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/run.py
--rw-r--r--   0 root         (0) root         (0)    19565 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/schedule.py
--rw-r--r--   0 root         (0) root         (0)    15749 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/sensor.py
--rw-r--r--   0 root         (0) root         (0)     4259 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.806551 dagster-1.6.9/dagster/_cli/workspace/
--rw-r--r--   0 root         (0) root         (0)      180 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/workspace/__init__.py
--rw-r--r--   0 root         (0) root         (0)    28028 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_cli/workspace/cli_target.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.806551 dagster-1.6.9/dagster/_config/
--rw-r--r--   0 root         (0) root         (0)     3186 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3403 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/config_schema.py
--rw-r--r--   0 root         (0) root         (0)    15870 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/config_type.py
--rw-r--r--   0 root         (0) root         (0)    19669 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/errors.py
--rw-r--r--   0 root         (0) root         (0)     1783 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/evaluate_value_result.py
--rw-r--r--   0 root         (0) root         (0)    14983 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/field.py
--rw-r--r--   0 root         (0) root         (0)    19812 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/field_utils.py
--rw-r--r--   0 root         (0) root         (0)     9536 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/post_process.py
--rw-r--r--   0 root         (0) root         (0)      855 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/primitive_mapping.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.810551 dagster-1.6.9/dagster/_config/pythonic_config/
--rw-r--r--   0 root         (0) root         (0)     1394 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/pythonic_config/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1641 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/pythonic_config/attach_other_object_to_context.py
--rw-r--r--   0 root         (0) root         (0)    18042 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/pythonic_config/config.py
--rw-r--r--   0 root         (0) root         (0)    11496 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/pythonic_config/conversion_utils.py
--rw-r--r--   0 root         (0) root         (0)    11583 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/pythonic_config/io_manager.py
--rw-r--r--   0 root         (0) root         (0)     3958 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/pythonic_config/pydantic_compat_layer.py
--rw-r--r--   0 root         (0) root         (0)    41365 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/pythonic_config/resource.py
--rw-r--r--   0 root         (0) root         (0)     1996 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/pythonic_config/type_check_utils.py
--rw-r--r--   0 root         (0) root         (0)     8377 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/pythonic_config/typing_utils.py
--rw-r--r--   0 root         (0) root         (0)    12532 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/snap.py
--rw-r--r--   0 root         (0) root         (0)     3153 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/source.py
--rw-r--r--   0 root         (0) root         (0)     3528 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/stack.py
--rw-r--r--   0 root         (0) root         (0)     7772 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/traversal_context.py
--rw-r--r--   0 root         (0) root         (0)     4167 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/type_printer.py
--rw-r--r--   0 root         (0) root         (0)    17239 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_config/validate.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.810551 dagster-1.6.9/dagster/_core/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/__init__.py
--rw-r--r--   0 root         (0) root         (0)      994 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/assets.py
--rw-r--r--   0 root         (0) root         (0)    13487 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/code_pointer.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.810551 dagster-1.6.9/dagster/_core/container_context/
--rw-r--r--   0 root         (0) root         (0)      184 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/container_context/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1278 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/container_context/config.py
--rw-r--r--   0 root         (0) root         (0)     2310 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/debug.py
--rw-r--r--   0 root         (0) root         (0)     9665 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/decorator_utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.826550 dagster-1.6.9/dagster/_core/definitions/
--rw-r--r--   0 root         (0) root         (0)     7755 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4239 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_check_evaluation.py
--rw-r--r--   0 root         (0) root         (0)     6948 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_check_result.py
--rw-r--r--   0 root         (0) root         (0)     5233 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_check_spec.py
--rw-r--r--   0 root         (0) root         (0)    10009 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_checks.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.830550 dagster-1.6.9/dagster/_core/definitions/asset_condition/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_condition/__init__.py
--rw-r--r--   0 root         (0) root         (0)    20543 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_condition/asset_condition.py
--rw-r--r--   0 root         (0) root         (0)    16433 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_condition/asset_condition_evaluation_context.py
--rw-r--r--   0 root         (0) root         (0)    26139 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_daemon_context.py
--rw-r--r--   0 root         (0) root         (0)    10555 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_daemon_cursor.py
--rw-r--r--   0 root         (0) root         (0)     4628 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_dep.py
--rw-r--r--   0 root         (0) root         (0)    32123 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_graph.py
--rw-r--r--   0 root         (0) root         (0)     7640 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_graph_differ.py
--rw-r--r--   0 root         (0) root         (0)    16428 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_graph_subset.py
--rw-r--r--   0 root         (0) root         (0)     3644 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_in.py
--rw-r--r--   0 root         (0) root         (0)    45363 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_layer.py
--rw-r--r--   0 root         (0) root         (0)     6617 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_out.py
--rw-r--r--   0 root         (0) root         (0)    33077 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_selection.py
--rw-r--r--   0 root         (0) root         (0)     7444 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)     6412 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_spec.py
--rw-r--r--   0 root         (0) root         (0)     9530 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/asset_subset.py
--rw-r--r--   0 root         (0) root         (0)    76072 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/assets.py
--rw-r--r--   0 root         (0) root         (0)    27001 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/assets_job.py
--rw-r--r--   0 root         (0) root         (0)    13536 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/auto_materialize_policy.py
--rw-r--r--   0 root         (0) root         (0)    51781 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/auto_materialize_rule.py
--rw-r--r--   0 root         (0) root         (0)    21600 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/auto_materialize_rule_evaluation.py
--rw-r--r--   0 root         (0) root         (0)     2761 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/auto_materialize_sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)     2939 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/backfill_policy.py
--rw-r--r--   0 root         (0) root         (0)    16772 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/cacheable_assets.py
--rw-r--r--   0 root         (0) root         (0)    43280 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/composition.py
--rw-r--r--   0 root         (0) root         (0)     4278 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/config.py
--rw-r--r--   0 root         (0) root         (0)    14811 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/configurable.py
--rw-r--r--   0 root         (0) root         (0)    22935 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/data_time.py
--rw-r--r--   0 root         (0) root         (0)    29872 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/data_version.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.830550 dagster-1.6.9/dagster/_core/definitions/decorators/
--rw-r--r--   0 root         (0) root         (0)      620 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/__init__.py
--rw-r--r--   0 root         (0) root         (0)    11372 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/asset_check_decorator.py
--rw-r--r--   0 root         (0) root         (0)    67827 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/asset_decorator.py
--rw-r--r--   0 root         (0) root         (0)     4907 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/config_mapping_decorator.py
--rw-r--r--   0 root         (0) root         (0)     9113 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/graph_decorator.py
--rw-r--r--   0 root         (0) root         (0)     9353 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/hook_decorator.py
--rw-r--r--   0 root         (0) root         (0)    10778 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/job_decorator.py
--rw-r--r--   0 root         (0) root         (0)    19011 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/op_decorator.py
--rw-r--r--   0 root         (0) root         (0)    15767 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/repository_decorator.py
--rw-r--r--   0 root         (0) root         (0)     8693 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/schedule_decorator.py
--rw-r--r--   0 root         (0) root         (0)    12463 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/sensor_decorator.py
--rw-r--r--   0 root         (0) root         (0)    12227 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/decorators/source_asset_decorator.py
--rw-r--r--   0 root         (0) root         (0)     5275 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/definition_config_schema.py
--rw-r--r--   0 root         (0) root         (0)    23570 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/definitions_class.py
--rw-r--r--   0 root         (0) root         (0)    42240 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/dependency.py
--rw-r--r--   0 root         (0) root         (0)    33081 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/events.py
--rw-r--r--   0 root         (0) root         (0)    21182 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/executor_definition.py
--rw-r--r--   0 root         (0) root         (0)     8872 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/external_asset.py
--rw-r--r--   0 root         (0) root         (0)    18371 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/external_asset_graph.py
--rw-r--r--   0 root         (0) root         (0)     9738 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/freshness_based_auto_materialize.py
--rw-r--r--   0 root         (0) root         (0)     8523 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/freshness_policy.py
--rw-r--r--   0 root         (0) root         (0)    16401 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/freshness_policy_sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)    46248 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/graph_definition.py
--rw-r--r--   0 root         (0) root         (0)     6546 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/hook_definition.py
--rw-r--r--   0 root         (0) root         (0)     1524 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/hook_invocation.py
--rw-r--r--   0 root         (0) root         (0)     3537 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/inference.py
--rw-r--r--   0 root         (0) root         (0)    21052 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/input.py
--rw-r--r--   0 root         (0) root         (0)     6410 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/instigation_logger.py
--rw-r--r--   0 root         (0) root         (0)     8076 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/internal_asset_graph.py
--rw-r--r--   0 root         (0) root         (0)     2722 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/job_base.py
--rw-r--r--   0 root         (0) root         (0)    55454 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/job_definition.py
--rw-r--r--   0 root         (0) root         (0)     5391 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/load_asset_checks_from_modules.py
--rw-r--r--   0 root         (0) root         (0)    22157 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/load_assets_from_modules.py
--rw-r--r--   0 root         (0) root         (0)     7171 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/logger_definition.py
--rw-r--r--   0 root         (0) root         (0)      636 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/logger_invocation.py
--rw-r--r--   0 root         (0) root         (0)     8882 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/materialize.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.830550 dagster-1.6.9/dagster/_core/definitions/metadata/
--rw-r--r--   0 root         (0) root         (0)    35866 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/metadata/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8557 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/metadata/table.py
--rw-r--r--   0 root         (0) root         (0)    57172 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/multi_asset_sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)    20416 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/multi_dimensional_partitions.py
--rw-r--r--   0 root         (0) root         (0)      197 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/no_step_launcher.py
--rw-r--r--   0 root         (0) root         (0)    11892 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/node_container.py
--rw-r--r--   0 root         (0) root         (0)     7953 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/node_definition.py
--rw-r--r--   0 root         (0) root         (0)     2892 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/observe.py
--rw-r--r--   0 root         (0) root         (0)    22789 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/op_definition.py
--rw-r--r--   0 root         (0) root         (0)    22431 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/op_invocation.py
--rw-r--r--   0 root         (0) root         (0)     7551 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/op_selection.py
--rw-r--r--   0 root         (0) root         (0)    19237 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/output.py
--rw-r--r--   0 root         (0) root         (0)    49689 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/partition.py
--rw-r--r--   0 root         (0) root         (0)      630 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/partition_key_range.py
--rw-r--r--   0 root         (0) root         (0)    47543 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/partition_mapping.py
--rw-r--r--   0 root         (0) root         (0)    11087 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/partitioned_schedule.py
--rw-r--r--   0 root         (0) root         (0)     3779 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/policy.py
--rw-r--r--   0 root         (0) root         (0)    27594 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/reconstruct.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.830550 dagster-1.6.9/dagster/_core/definitions/repository_definition/
--rw-r--r--   0 root         (0) root         (0)      654 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/repository_definition/__init__.py
--rw-r--r--   0 root         (0) root         (0)     6024 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/repository_definition/caching_index.py
--rw-r--r--   0 root         (0) root         (0)    20681 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/repository_definition/repository_data.py
--rw-r--r--   0 root         (0) root         (0)    21676 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/repository_definition/repository_data_builder.py
--rw-r--r--   0 root         (0) root         (0)    18732 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/repository_definition/repository_definition.py
--rw-r--r--   0 root         (0) root         (0)     1479 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/repository_definition/valid_definitions.py
--rw-r--r--   0 root         (0) root         (0)     8301 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/resolved_asset_deps.py
--rw-r--r--   0 root         (0) root         (0)     1465 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/resource_annotation.py
--rw-r--r--   0 root         (0) root         (0)    17900 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/resource_definition.py
--rw-r--r--   0 root         (0) root         (0)     5382 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/resource_invocation.py
--rw-r--r--   0 root         (0) root         (0)    10320 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/resource_requirement.py
--rw-r--r--   0 root         (0) root         (0)     3383 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/result.py
--rw-r--r--   0 root         (0) root         (0)    23276 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/run_config.py
--rw-r--r--   0 root         (0) root         (0)     1445 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/run_config_schema.py
--rw-r--r--   0 root         (0) root         (0)    18539 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/run_request.py
--rw-r--r--   0 root         (0) root         (0)    43703 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/run_status_sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)    38694 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/schedule_definition.py
--rw-r--r--   0 root         (0) root         (0)     5134 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/scoped_resources_builder.py
--rw-r--r--   0 root         (0) root         (0)    14134 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/selector.py
--rw-r--r--   0 root         (0) root         (0)    53028 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)    18796 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/source_asset.py
--rw-r--r--   0 root         (0) root         (0)     2481 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/step_launcher.py
--rw-r--r--   0 root         (0) root         (0)     1530 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/target.py
--rw-r--r--   0 root         (0) root         (0)    21859 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/time_window_partition_mapping.py
--rw-r--r--   0 root         (0) root         (0)   101937 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/time_window_partitions.py
--rw-r--r--   0 root         (0) root         (0)    17364 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/unresolved_asset_job_definition.py
--rw-r--r--   0 root         (0) root         (0)     7997 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/utils.py
--rw-r--r--   0 root         (0) root         (0)     3982 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/definitions/version_strategy.py
--rw-r--r--   0 root         (0) root         (0)    26986 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/errors.py
--rw-r--r--   0 root         (0) root         (0)    17805 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/event_api.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.830550 dagster-1.6.9/dagster/_core/events/
--rw-r--r--   0 root         (0) root         (0)    71440 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/events/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7635 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/events/log.py
--rw-r--r--   0 root         (0) root         (0)     1614 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/events/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.834550 dagster-1.6.9/dagster/_core/execution/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/__init__.py
--rw-r--r--   0 root         (0) root         (0)    38447 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/api.py
--rw-r--r--   0 root         (0) root         (0)    64692 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/asset_backfill.py
--rw-r--r--   0 root         (0) root         (0)    17297 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/backfill.py
--rw-r--r--   0 root         (0) root         (0)     6296 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/build_resources.py
--rw-r--r--   0 root         (0) root         (0)      224 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/bulk_actions.py
--rw-r--r--   0 root         (0) root         (0)     5587 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/compute_logs.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.838550 dagster-1.6.9/dagster/_core/execution/context/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context/__init__.py
--rw-r--r--   0 root         (0) root         (0)    74674 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context/compute.py
--rw-r--r--   0 root         (0) root         (0)    16179 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context/hook.py
--rw-r--r--   0 root         (0) root         (0)     9613 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context/init.py
--rw-r--r--   0 root         (0) root         (0)    27297 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context/input.py
--rw-r--r--   0 root         (0) root         (0)    39887 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context/invocation.py
--rw-r--r--   0 root         (0) root         (0)     3164 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context/logger.py
--rw-r--r--   0 root         (0) root         (0)    34869 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context/output.py
--rw-r--r--   0 root         (0) root         (0)    54298 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context/system.py
--rw-r--r--   0 root         (0) root         (0)    18533 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/context_creation_job.py
--rw-r--r--   0 root         (0) root         (0)     5135 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/execute_in_process.py
--rw-r--r--   0 root         (0) root         (0)     5897 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/execute_in_process_result.py
--rw-r--r--   0 root         (0) root         (0)     9633 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/execution_result.py
--rw-r--r--   0 root         (0) root         (0)     8636 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/host_mode.py
--rw-r--r--   0 root         (0) root         (0)    14274 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/job_backfill.py
--rw-r--r--   0 root         (0) root         (0)     6712 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/job_execution_result.py
--rw-r--r--   0 root         (0) root         (0)      998 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/memoization.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.842550 dagster-1.6.9/dagster/_core/execution/plan/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/__init__.py
--rw-r--r--   0 root         (0) root         (0)    26496 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/active.py
--rw-r--r--   0 root         (0) root         (0)     9858 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/compute.py
--rw-r--r--   0 root         (0) root         (0)    16317 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/compute_generator.py
--rw-r--r--   0 root         (0) root         (0)    17106 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/execute_plan.py
--rw-r--r--   0 root         (0) root         (0)    40357 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/execute_step.py
--rw-r--r--   0 root         (0) root         (0)    11036 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/external_step.py
--rw-r--r--   0 root         (0) root         (0)     3664 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/handle.py
--rw-r--r--   0 root         (0) root         (0)    38742 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/inputs.py
--rw-r--r--   0 root         (0) root         (0)     6251 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/instance_concurrency_context.py
--rw-r--r--   0 root         (0) root         (0)     1197 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/local_external_step_main.py
--rw-r--r--   0 root         (0) root         (0)     5706 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/objects.py
--rw-r--r--   0 root         (0) root         (0)     7326 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/outputs.py
--rw-r--r--   0 root         (0) root         (0)    61458 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/plan.py
--rw-r--r--   0 root         (0) root         (0)      114 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/resume_retry.py
--rw-r--r--   0 root         (0) root         (0)    16164 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/state.py
--rw-r--r--   0 root         (0) root         (0)    15917 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/step.py
--rw-r--r--   0 root         (0) root         (0)     3796 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/plan/utils.py
--rw-r--r--   0 root         (0) root         (0)     1762 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/poll_compute_logs.py
--rw-r--r--   0 root         (0) root         (0)     8186 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/resolve_versions.py
--rw-r--r--   0 root         (0) root         (0)    19141 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/resources_init.py
--rw-r--r--   0 root         (0) root         (0)     2100 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/retries.py
--rw-r--r--   0 root         (0) root         (0)     1651 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/run_cancellation_thread.py
--rw-r--r--   0 root         (0) root         (0)     9950 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/stats.py
--rw-r--r--   0 root         (0) root         (0)    13755 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/submit_asset_runs.py
--rw-r--r--   0 root         (0) root         (0)     1125 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/tags.py
--rw-r--r--   0 root         (0) root         (0)     1172 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/validate_run_config.py
--rw-r--r--   0 root         (0) root         (0)     1282 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/watch_orphans.py
--rw-r--r--   0 root         (0) root         (0)     4311 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/execution/with_resources.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.842550 dagster-1.6.9/dagster/_core/executor/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1265 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/base.py
--rw-r--r--   0 root         (0) root         (0)     5989 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/child_process_executor.py
--rw-r--r--   0 root         (0) root         (0)     3436 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/in_process.py
--rw-r--r--   0 root         (0) root         (0)     1509 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/init.py
--rw-r--r--   0 root         (0) root         (0)    15569 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/multiprocess.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.842550 dagster-1.6.9/dagster/_core/executor/step_delegating/
--rw-r--r--   0 root         (0) root         (0)      247 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/step_delegating/__init__.py
--rw-r--r--   0 root         (0) root         (0)    16894 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/step_delegating/step_delegating_executor.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.842550 dagster-1.6.9/dagster/_core/executor/step_delegating/step_handler/
--rw-r--r--   0 root         (0) root         (0)      152 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/step_delegating/step_handler/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3078 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/executor/step_delegating/step_handler/base.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.846550 dagster-1.6.9/dagster/_core/host_representation/
--rw-r--r--   0 root         (0) root         (0)     2807 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/__init__.py
--rw-r--r--   0 root         (0) root         (0)    35856 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/code_location.py
--rw-r--r--   0 root         (0) root         (0)    36950 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/external.py
--rw-r--r--   0 root         (0) root         (0)    84692 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/external_data.py
--rw-r--r--   0 root         (0) root         (0)     1450 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/feature_flags.py
--rw-r--r--   0 root         (0) root         (0)    12427 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/grpc_server_registry.py
--rw-r--r--   0 root         (0) root         (0)     1487 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/grpc_server_state_subscriber.py
--rw-r--r--   0 root         (0) root         (0)     4354 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/handle.py
--rw-r--r--   0 root         (0) root         (0)     1581 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/historical.py
--rw-r--r--   0 root         (0) root         (0)     4850 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/job_index.py
--rw-r--r--   0 root         (0) root         (0)    19537 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/origin.py
--rw-r--r--   0 root         (0) root         (0)     3602 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/host_representation/represented.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.846550 dagster-1.6.9/dagster/_core/instance/
--rw-r--r--   0 root         (0) root         (0)   128989 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/instance/__init__.py
--rw-r--r--   0 root         (0) root         (0)    15788 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/instance/config.py
--rw-r--r--   0 root         (0) root         (0)    24141 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/instance/ref.py
--rw-r--r--   0 root         (0) root         (0)     3899 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/instance_for_test.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.846550 dagster-1.6.9/dagster/_core/launcher/
--rw-r--r--   0 root         (0) root         (0)      297 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/launcher/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3819 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/launcher/base.py
--rw-r--r--   0 root         (0) root         (0)     6652 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/launcher/default_run_launcher.py
--rw-r--r--   0 root         (0) root         (0)     1566 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/launcher/sync_in_memory_run_launcher.py
--rw-r--r--   0 root         (0) root         (0)      473 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/libraries.py
--rw-r--r--   0 root         (0) root         (0)    16603 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/log_manager.py
--rw-r--r--   0 root         (0) root         (0)     1029 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/nux.py
--rw-r--r--   0 root         (0) root         (0)     5736 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/op_concurrency_limits_counter.py
--rw-r--r--   0 root         (0) root         (0)     3691 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/origin.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.846550 dagster-1.6.9/dagster/_core/pipes/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/pipes/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8974 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/pipes/client.py
--rw-r--r--   0 root         (0) root         (0)    18318 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/pipes/context.py
--rw-r--r--   0 root         (0) root         (0)     5648 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/pipes/subprocess.py
--rw-r--r--   0 root         (0) root         (0)    25661 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/pipes/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.850550 dagster-1.6.9/dagster/_core/run_coordinator/
--rw-r--r--   0 root         (0) root         (0)      267 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/run_coordinator/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2005 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/run_coordinator/base.py
--rw-r--r--   0 root         (0) root         (0)     1922 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/run_coordinator/default_run_coordinator.py
--rw-r--r--   0 root         (0) root         (0)    13364 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/run_coordinator/queued_run_coordinator.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.850550 dagster-1.6.9/dagster/_core/scheduler/
--rw-r--r--   0 root         (0) root         (0)      534 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/scheduler/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1241 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/scheduler/execution.py
--rw-r--r--   0 root         (0) root         (0)    28860 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/scheduler/instigation.py
--rw-r--r--   0 root         (0) root         (0)    10929 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/scheduler/scheduler.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.850550 dagster-1.6.9/dagster/_core/secrets/
--rw-r--r--   0 root         (0) root         (0)       51 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/secrets/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1801 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/secrets/env_file.py
--rw-r--r--   0 root         (0) root         (0)      388 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/secrets/loader.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.850550 dagster-1.6.9/dagster/_core/selector/
--rw-r--r--   0 root         (0) root         (0)      295 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/selector/__init__.py
--rw-r--r--   0 root         (0) root         (0)    18189 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/selector/subset_selector.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.850550 dagster-1.6.9/dagster/_core/snap/
--rw-r--r--   0 root         (0) root         (0)     2842 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/snap/__init__.py
--rw-r--r--   0 root         (0) root         (0)      494 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/snap/config_types.py
--rw-r--r--   0 root         (0) root         (0)     3999 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/snap/dagster_types.py
--rw-r--r--   0 root         (0) root         (0)     9302 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/snap/dep_snapshot.py
--rw-r--r--   0 root         (0) root         (0)    12155 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/snap/execution_plan_snapshot.py
--rw-r--r--   0 root         (0) root         (0)    17054 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/snap/job_snapshot.py
--rw-r--r--   0 root         (0) root         (0)     4559 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/snap/mode.py
--rw-r--r--   0 root         (0) root         (0)    14185 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/snap/node.py
--rw-r--r--   0 root         (0) root         (0)     3183 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/snap/snap_to_yaml.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.858550 dagster-1.6.9/dagster/_core/storage/
--rw-r--r--   0 root         (0) root         (0)     3058 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/DEVELOPING.md
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.858550 dagster-1.6.9/dagster/_core/storage/alembic/
--rw-r--r--   0 root         (0) root         (0)     6686 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/README.md
--rw-r--r--   0 root         (0) root         (0)      687 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/env.py
--rw-r--r--   0 root         (0) root         (0)      494 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/script.py.mako
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.870550 dagster-1.6.9/dagster/_core/storage/alembic/versions/
--rw-r--r--   0 root         (0) root         (0)     3150 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/001_initial_1.py
--rw-r--r--   0 root         (0) root         (0)      312 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/001_initial_schedule.py
--rw-r--r--   0 root         (0) root         (0)     1486 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_postgres.py
--rw-r--r--   0 root         (0) root         (0)      599 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      973 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_postgres.py
--rw-r--r--   0 root         (0) root         (0)      973 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     2729 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/004_add_snapshots_to_run_storage.py
--rw-r--r--   0 root         (0) root         (0)     1406 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/005_add_asset_key_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1406 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/005_add_asset_key_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1131 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/006_scheduler_update_postgres.py
--rw-r--r--   0 root         (0) root         (0)      953 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/007_create_run_id_idx_postgres.py
--rw-r--r--   0 root         (0) root         (0)      953 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/007_create_run_id_idx_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      956 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/008_add_run_tags_index_postgres.py
--rw-r--r--   0 root         (0) root         (0)      956 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/008_add_run_tags_index_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1171 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/009_add_partition_column_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1171 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/009_add_partition_column_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1730 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1730 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1147 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1125 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_1.py
--rw-r--r--   0 root         (0) root         (0)     1143 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_2.py
--rw-r--r--   0 root         (0) root         (0)      417 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/012_0_10_0_create_new_run_tables_postgres.py
--rw-r--r--   0 root         (0) root         (0)      417 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/012_0_10_0_create_new_run_tables_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      435 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/013_0_10_0_create_new_event_log_tables_postgres.py
--rw-r--r--   0 root         (0) root         (0)      435 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/013_0_10_0_create_new_event_log_tables_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      432 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/014_0_10_0_create_new_schedule_tables_postgres.py
--rw-r--r--   0 root         (0) root         (0)      432 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/014_0_10_0_create_new_schedule_tables_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     3927 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_postgres.py
--rw-r--r--   0 root         (0) root         (0)     3927 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      409 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/016_add_bulk_actions_table_postgres.py
--rw-r--r--   0 root         (0) root         (0)      409 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/016_add_bulk_actions_table_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      936 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/017_add_run_status_index_postgres.py
--rw-r--r--   0 root         (0) root         (0)      936 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/017_add_run_status_index_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      325 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/017_initial_mysql.py
--rw-r--r--   0 root         (0) root         (0)      421 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/018_add_asset_tags_mysql.py
--rw-r--r--   0 root         (0) root         (0)      421 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/018_add_asset_tags_postgres.py
--rw-r--r--   0 root         (0) root         (0)      421 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/018_add_asset_tags_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1570 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1570 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      410 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/020_add_column_asset_body_mysql.py
--rw-r--r--   0 root         (0) root         (0)      410 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/020_add_column_asset_body_postgres.py
--rw-r--r--   0 root         (0) root         (0)      410 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/020_add_column_asset_body_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1034 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/021_add_column_mode_mysql.py
--rw-r--r--   0 root         (0) root         (0)     1032 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/021_add_column_mode_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1034 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/021_add_column_mode_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      433 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_mysql.py
--rw-r--r--   0 root         (0) root         (0)      433 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_postgres.py
--rw-r--r--   0 root         (0) root         (0)      433 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      421 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_mysql.py
--rw-r--r--   0 root         (0) root         (0)      421 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_postgres.py
--rw-r--r--   0 root         (0) root         (0)      421 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      531 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_mysql.py
--rw-r--r--   0 root         (0) root         (0)     1275 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1275 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      404 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/025_add_range_index_mysql.py
--rw-r--r--   0 root         (0) root         (0)      404 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/025_add_range_index_postgres.py
--rw-r--r--   0 root         (0) root         (0)      404 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/025_add_range_index_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      635 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/026_convert_start_end_times_format_mysql.py
--rw-r--r--   0 root         (0) root         (0)      434 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/027_add_migration_table_mysql.py
--rw-r--r--   0 root         (0) root         (0)      434 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/027_add_migration_table_postgres.py
--rw-r--r--   0 root         (0) root         (0)      434 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/027_add_migration_table_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      410 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/028_add_instigators_table_mysql.py
--rw-r--r--   0 root         (0) root         (0)      410 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/028_add_instigators_table_postgres.py
--rw-r--r--   0 root         (0) root         (0)      410 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/028_add_instigators_table_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      416 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_mysql.py
--rw-r--r--   0 root         (0) root         (0)      416 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_postgres.py
--rw-r--r--   0 root         (0) root         (0)      416 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1893 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/030_add_columns_action_type_and_selector_id_.py
--rw-r--r--   0 root         (0) root         (0)      958 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/031_add_kvs_table.py
--rw-r--r--   0 root         (0) root         (0)      499 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/032_rebuild_event_indexes.py
--rw-r--r--   0 root         (0) root         (0)     1951 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/033_add_asset_event_tags_table.py
--rw-r--r--   0 root         (0) root         (0)      428 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/034_add_cached_status_data_column.py
--rw-r--r--   0 root         (0) root         (0)      427 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/035_add_run_job_index.py
--rw-r--r--   0 root         (0) root         (0)     1537 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/036_add_dynamic_partitions_table.py
--rw-r--r--   0 root         (0) root         (0)     2481 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/037_d9092588866f_add_primary_key_cols.py
--rw-r--r--   0 root         (0) root         (0)     1177 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/038_701913684cb4_add_postgres_pks.py
--rw-r--r--   0 root         (0) root         (0)     2062 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/039_d3a4c9e87af3_add_asset_daemon_asset_evaluations_table.py
--rw-r--r--   0 root         (0) root         (0)     2359 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/040_add_in_progress_step_table.py
--rw-r--r--   0 root         (0) root         (0)     2898 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/041_add_asset_check_executions_table.py
--rw-r--r--   0 root         (0) root         (0)     1322 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/042_46b412388816_add_concurrency_limits_table.py
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/alembic/versions/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3887 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/asset_check_execution_record.py
--rw-r--r--   0 root         (0) root         (0)     6779 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/asset_value_loader.py
--rw-r--r--   0 root         (0) root         (0)     1227 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/base_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.870550 dagster-1.6.9/dagster/_core/storage/branching/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/branching/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5579 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/branching/branching_io_manager.py
--rw-r--r--   0 root         (0) root         (0)     8725 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/captured_log_manager.py
--rw-r--r--   0 root         (0) root         (0)    16223 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/cloud_storage_compute_log_manager.py
--rw-r--r--   0 root         (0) root         (0)     9557 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/compute_log_manager.py
--rw-r--r--   0 root         (0) root         (0)     1863 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/config.py
--rw-r--r--   0 root         (0) root         (0)      417 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/daemon_cursor.py
--rw-r--r--   0 root         (0) root         (0)    25502 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/dagster_run.py
--rw-r--r--   0 root         (0) root         (0)    11165 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/db_io_manager.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.874550 dagster-1.6.9/dagster/_core/storage/event_log/
--rw-r--r--   0 root         (0) root         (0)      742 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/__init__.py
--rw-r--r--   0 root         (0) root         (0)    18188 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/base.py
--rw-r--r--   0 root         (0) root         (0)     3801 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/in_memory.py
--rw-r--r--   0 root         (0) root         (0)     7289 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/migration.py
--rw-r--r--   0 root         (0) root         (0)     7911 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/polling_event_watcher.py
--rw-r--r--   0 root         (0) root         (0)     9250 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/schema.py
--rw-r--r--   0 root         (0) root         (0)   122186 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/sql_event_log.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.874550 dagster-1.6.9/dagster/_core/storage/event_log/sqlite/
--rw-r--r--   0 root         (0) root         (0)      200 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/sqlite/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.874550 dagster-1.6.9/dagster/_core/storage/event_log/sqlite/alembic/
--rw-r--r--   0 root         (0) root         (0)      986 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/sqlite/alembic/alembic.ini
--rw-r--r--   0 root         (0) root         (0)     7508 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/sqlite/consolidated_sqlite_event_log.py
--rw-r--r--   0 root         (0) root         (0)    22493 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/event_log/sqlite/sqlite_event_log.py
--rw-r--r--   0 root         (0) root         (0)    10983 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/file_manager.py
--rw-r--r--   0 root         (0) root         (0)    13540 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/fs_io_manager.py
--rw-r--r--   0 root         (0) root         (0)     8819 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/input_manager.py
--rw-r--r--   0 root         (0) root         (0)    10882 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/io_manager.py
--rw-r--r--   0 root         (0) root         (0)    32648 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/legacy_storage.py
--rw-r--r--   0 root         (0) root         (0)    17558 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/local_compute_log_manager.py
--rw-r--r--   0 root         (0) root         (0)     1167 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/mem_io_manager.py
--rw-r--r--   0 root         (0) root         (0)     4355 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/memoizable_io_manager.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.874550 dagster-1.6.9/dagster/_core/storage/migration/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/migration/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5964 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/migration/bigint_migration.py
--rw-r--r--   0 root         (0) root         (0)    15491 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/migration/utils.py
--rw-r--r--   0 root         (0) root         (0)     3270 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/noop_compute_log_manager.py
--rw-r--r--   0 root         (0) root         (0)     2361 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/output_manager.py
--rw-r--r--   0 root         (0) root         (0)    17131 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/partition_status_cache.py
--rw-r--r--   0 root         (0) root         (0)     2121 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/root.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.874550 dagster-1.6.9/dagster/_core/storage/runs/
--rw-r--r--   0 root         (0) root         (0)      386 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/runs/__init__.py
--rw-r--r--   0 root         (0) root         (0)    13932 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/runs/base.py
--rw-r--r--   0 root         (0) root         (0)     2452 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/runs/in_memory.py
--rw-r--r--   0 root         (0) root         (0)     8725 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/runs/migration.py
--rw-r--r--   0 root         (0) root         (0)     6391 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/runs/schema.py
--rw-r--r--   0 root         (0) root         (0)    37516 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/runs/sql_run_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.874550 dagster-1.6.9/dagster/_core/storage/runs/sqlite/
--rw-r--r--   0 root         (0) root         (0)       69 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/runs/sqlite/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.874550 dagster-1.6.9/dagster/_core/storage/runs/sqlite/alembic/
--rw-r--r--   0 root         (0) root         (0)      986 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/runs/sqlite/alembic/alembic.ini
--rw-r--r--   0 root         (0) root         (0)     6310 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/runs/sqlite/sqlite_run_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.874550 dagster-1.6.9/dagster/_core/storage/schedules/
--rw-r--r--   0 root         (0) root         (0)      272 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/schedules/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7236 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/schedules/base.py
--rw-r--r--   0 root         (0) root         (0)     4133 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/schedules/migration.py
--rw-r--r--   0 root         (0) root         (0)     4086 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/schedules/schema.py
--rw-r--r--   0 root         (0) root         (0)    25146 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/schedules/sql_schedule_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.878550 dagster-1.6.9/dagster/_core/storage/schedules/sqlite/
--rw-r--r--   0 root         (0) root         (0)       84 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/schedules/sqlite/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.878550 dagster-1.6.9/dagster/_core/storage/schedules/sqlite/alembic/
--rw-r--r--   0 root         (0) root         (0)      986 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/schedules/sqlite/alembic/alembic.ini
--rw-r--r--   0 root         (0) root         (0)     3684 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/schedules/sqlite/sqlite_schedule_storage.py
--rw-r--r--   0 root         (0) root         (0)     7691 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/sql.py
--rw-r--r--   0 root         (0) root         (0)     1391 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/sqlalchemy_compat.py
--rw-r--r--   0 root         (0) root         (0)      926 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/sqlite.py
--rw-r--r--   0 root         (0) root         (0)     4875 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/sqlite_storage.py
--rw-r--r--   0 root         (0) root         (0)     3546 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/tags.py
--rw-r--r--   0 root         (0) root         (0)     1186 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/temp_file_manager.py
--rw-r--r--   0 root         (0) root         (0)    19311 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/storage/upath_io_manager.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.878550 dagster-1.6.9/dagster/_core/system_config/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/system_config/__init__.py
--rw-r--r--   0 root         (0) root         (0)    14010 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/system_config/composite_descent.py
--rw-r--r--   0 root         (0) root         (0)    15178 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/system_config/objects.py
--rw-r--r--   0 root         (0) root         (0)    30070 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/telemetry.py
--rw-r--r--   0 root         (0) root         (0)     4824 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/telemetry_upload.py
--rw-r--r--   0 root         (0) root         (0)    22479 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/test_utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.878550 dagster-1.6.9/dagster/_core/types/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3084 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/builtin_config_schemas.py
--rw-r--r--   0 root         (0) root         (0)     7042 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/config_schema.py
--rw-r--r--   0 root         (0) root         (0)    36611 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/dagster_type.py
--rw-r--r--   0 root         (0) root         (0)     3571 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/decorator.py
--rw-r--r--   0 root         (0) root         (0)     1846 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/loadable_target_origin.py
--rw-r--r--   0 root         (0) root         (0)     1027 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/primitive_mapping.py
--rw-r--r--   0 root         (0) root         (0)     4764 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/python_dict.py
--rw-r--r--   0 root         (0) root         (0)     2769 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/python_set.py
--rw-r--r--   0 root         (0) root         (0)     3645 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/python_tuple.py
--rw-r--r--   0 root         (0) root         (0)     1772 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/types/transform_typing.py
--rw-r--r--   0 root         (0) root         (0)     1441 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/utility_ops.py
--rw-r--r--   0 root         (0) root         (0)     6657 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.882550 dagster-1.6.9/dagster/_core/workspace/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/workspace/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4722 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/workspace/autodiscovery.py
--rw-r--r--   0 root         (0) root         (0)     3422 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/workspace/config_schema.py
--rw-r--r--   0 root         (0) root         (0)    28832 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/workspace/context.py
--rw-r--r--   0 root         (0) root         (0)    11925 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/workspace/load.py
--rw-r--r--   0 root         (0) root         (0)     4719 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/workspace/load_target.py
--rw-r--r--   0 root         (0) root         (0)     4311 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/workspace/permissions.py
--rw-r--r--   0 root         (0) root         (0)     1903 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_core/workspace/workspace.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.882550 dagster-1.6.9/dagster/_daemon/
--rw-r--r--   0 root         (0) root         (0)     1971 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/__init__.py
--rw-r--r--   0 root         (0) root         (0)       30 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/__main__.py
--rw-r--r--   0 root         (0) root         (0)    41757 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/asset_daemon.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.882550 dagster-1.6.9/dagster/_daemon/auto_run_reexecution/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/auto_run_reexecution/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7426 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/auto_run_reexecution/auto_run_reexecution.py
--rw-r--r--   0 root         (0) root         (0)     9036 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/auto_run_reexecution/event_log_consumer.py
--rw-r--r--   0 root         (0) root         (0)     2618 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/backfill.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.882550 dagster-1.6.9/dagster/_daemon/cli/
--rw-r--r--   0 root         (0) root         (0)     5118 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/cli/__init__.py
--rw-r--r--   0 root         (0) root         (0)    18853 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/controller.py
--rw-r--r--   0 root         (0) root         (0)    11973 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/daemon.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.882550 dagster-1.6.9/dagster/_daemon/monitoring/
--rw-r--r--   0 root         (0) root         (0)      320 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/monitoring/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1792 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/monitoring/concurrency.py
--rw-r--r--   0 root         (0) root         (0)     9863 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/monitoring/run_monitoring.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.882550 dagster-1.6.9/dagster/_daemon/run_coordinator/
--rw-r--r--   0 root         (0) root         (0)      100 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/run_coordinator/__init__.py
--rw-r--r--   0 root         (0) root         (0)    18440 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/run_coordinator/queued_run_coordinator_daemon.py
--rw-r--r--   0 root         (0) root         (0)    39638 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/sensor.py
--rw-r--r--   0 root         (0) root         (0)     2860 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/types.py
--rw-r--r--   0 root         (0) root         (0)     4112 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_daemon/workspace.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.882550 dagster-1.6.9/dagster/_experimental/
--rw-r--r--   0 root         (0) root         (0)      300 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_experimental/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.882550 dagster-1.6.9/dagster/_generate/
--rw-r--r--   0 root         (0) root         (0)      253 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2978 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/download.py
--rw-r--r--   0 root         (0) root         (0)     4805 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/generate.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.798551 dagster-1.6.9/dagster/_generate/templates/
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.882550 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/
--rw-r--r--   0 root         (0) root         (0)      175 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/__init__.py
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/assets.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/__init__.py
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/test_assets.py.tmpl
--rw-r--r--   0 root         (0) root         (0)      137 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/pyproject.toml.tmpl
--rw-r--r--   0 root         (0) root         (0)       43 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/setup.cfg.tmpl
--rw-r--r--   0 root         (0) root         (0)      297 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/setup.py.tmpl
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/
--rw-r--r--   0 root         (0) root         (0)     1753 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/README.md
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/
--rw-r--r--   0 root         (0) root         (0)       40 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/__init__.py.tmpl
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/assets.py
--rw-r--r--   0 root         (0) root         (0)      164 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/repository.py.tmpl
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/__init__.py
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/test_assets.py.tmpl
--rw-r--r--   0 root         (0) root         (0)       80 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/pyproject.toml
--rw-r--r--   0 root         (0) root         (0)       34 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/setup.cfg.tmpl
--rw-r--r--   0 root         (0) root         (0)      279 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/setup.py.tmpl
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_grpc/
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_grpc/__generated__/
--rw-r--r--   0 root         (0) root         (0)      178 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/__generated__/__init__.py
--rw-r--r--   0 root         (0) root         (0)    13462 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/__generated__/api_pb2.py
--rw-r--r--   0 root         (0) root         (0)    27262 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/__generated__/api_pb2.pyi
--rw-r--r--   0 root         (0) root         (0)    43164 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/__generated__/api_pb2_grpc.py
--rw-r--r--   0 root         (0) root         (0)     2060 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/__init__.py
--rw-r--r--   0 root         (0) root         (0)       89 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/__main__.py
--rw-r--r--   0 root         (0) root         (0)    22749 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/client.py
--rw-r--r--   0 root         (0) root         (0)     3584 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/compile.py
--rw-r--r--   0 root         (0) root         (0)    22955 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/impl.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_grpc/protos/
--rw-r--r--   0 root         (0) root         (0)     5993 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/protos/api.proto
--rw-r--r--   0 root         (0) root         (0)    13427 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/proxy_server.py
--rw-r--r--   0 root         (0) root         (0)    60750 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/server.py
--rw-r--r--   0 root         (0) root         (0)     5297 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/server_watcher.py
--rw-r--r--   0 root         (0) root         (0)    29100 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/types.py
--rw-r--r--   0 root         (0) root         (0)     3693 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_grpc/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_legacy/
--rw-r--r--   0 root         (0) root         (0)      180 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_legacy/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_loggers/
--rw-r--r--   0 root         (0) root         (0)     3781 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_loggers/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3269 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_module_alias_map.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.886550 dagster-1.6.9/dagster/_scheduler/
--rw-r--r--   0 root         (0) root         (0)        0 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_scheduler/__init__.py
--rw-r--r--   0 root         (0) root         (0)    35312 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_scheduler/scheduler.py
--rw-r--r--   0 root         (0) root         (0)     1361 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_scheduler/stale.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.890550 dagster-1.6.9/dagster/_serdes/
--rw-r--r--   0 root         (0) root         (0)      701 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_serdes/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8916 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_serdes/config_class.py
--rw-r--r--   0 root         (0) root         (0)      142 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_serdes/errors.py
--rw-r--r--   0 root         (0) root         (0)     7292 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_serdes/ipc.py
--rw-r--r--   0 root         (0) root         (0)    42444 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_serdes/serdes.py
--rw-r--r--   0 root         (0) root         (0)      674 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_serdes/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.890550 dagster-1.6.9/dagster/_seven/
--rw-r--r--   0 root         (0) root         (0)     5455 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_seven/__init__.py
--rw-r--r--   0 root         (0) root         (0)      553 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_seven/abc.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.890550 dagster-1.6.9/dagster/_seven/compat/
--rw-r--r--   0 root         (0) root         (0)      105 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_seven/compat/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3983 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_seven/compat/pendulum.py
--rw-r--r--   0 root         (0) root         (0)      383 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_seven/json.py
--rw-r--r--   0 root         (0) root         (0)      354 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_seven/temp_dir.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.894550 dagster-1.6.9/dagster/_utils/
--rw-r--r--   0 root         (0) root         (0)    24230 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     9312 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/alert.py
--rw-r--r--   0 root         (0) root         (0)     2250 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/backoff.py
--rw-r--r--   0 root         (0) root         (0)     4076 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/cached_method.py
--rw-r--r--   0 root         (0) root         (0)    42568 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/caching_instance_queryer.py
--rw-r--r--   0 root         (0) root         (0)     5865 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/concurrency.py
--rw-r--r--   0 root         (0) root         (0)    12887 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/container.py
--rw-r--r--   0 root         (0) root         (0)     2494 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/dagster_type.py
--rw-r--r--   0 root         (0) root         (0)      799 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/env.py
--rw-r--r--   0 root         (0) root         (0)     5477 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/error.py
--rw-r--r--   0 root         (0) root         (0)     1264 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/external.py
--rw-r--r--   0 root         (0) root         (0)      891 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/forked_pdb.py
--rw-r--r--   0 root         (0) root         (0)     1836 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/hosted_user_process.py
--rw-r--r--   0 root         (0) root         (0)     2796 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/indenting_printer.py
--rw-r--r--   0 root         (0) root         (0)      745 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/internal_init.py
--rw-r--r--   0 root         (0) root         (0)     3227 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/interrupts.py
--rw-r--r--   0 root         (0) root         (0)    11214 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/log.py
--rw-r--r--   0 root         (0) root         (0)     2313 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/merger.py
--rw-r--r--   0 root         (0) root         (0)     1507 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/net.py
--rw-r--r--   0 root         (0) root         (0)      208 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/partitions.py
--rw-r--r--   0 root         (0) root         (0)    30558 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/schedules.py
--rw-r--r--   0 root         (0) root         (0)      477 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/security.py
--rw-r--r--   0 root         (0) root         (0)     3289 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/tags.py
--rw-r--r--   0 root         (0) root         (0)     1820 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/temp_file.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.894550 dagster-1.6.9/dagster/_utils/test/
--rw-r--r--   0 root         (0) root         (0)    13678 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7647 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/data_versions.py
--rw-r--r--   0 root         (0) root         (0)      119 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/hello_world_defs.py
--rw-r--r--   0 root         (0) root         (0)      214 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/hello_world_repository.py
--rw-r--r--   0 root         (0) root         (0)     8622 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/mysql_instance.py
--rw-r--r--   0 root         (0) root         (0)      256 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/named_hello_world_repository.py
--rw-r--r--   0 root         (0) root         (0)     8959 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/postgres_instance.py
--rw-r--r--   0 root         (0) root         (0)    35722 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/schedule_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.894550 dagster-1.6.9/dagster/_utils/test/toys/
--rw-r--r--   0 root         (0) root         (0)       83 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/toys/__init__.py
--rw-r--r--   0 root         (0) root         (0)       84 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/test/toys/single_repository.py
--rw-r--r--   0 root         (0) root         (0)     2004 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/timing.py
--rw-r--r--   0 root         (0) root         (0)     1032 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/typed_dict.py
--rw-r--r--   0 root         (0) root         (0)      170 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/types.py
--rw-r--r--   0 root         (0) root         (0)     3334 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/typing_api.py
--rw-r--r--   0 root         (0) root         (0)     4740 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/warnings.py
--rw-r--r--   0 root         (0) root         (0)     4902 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/_utils/yaml_utils.py
--rw-r--r--   0 root         (0) root         (0)        8 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/py.typed
--rw-r--r--   0 root         (0) root         (0)       22 2024-03-08 00:17:46.000000 dagster-1.6.9/dagster/version.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-03-08 00:18:17.798551 dagster-1.6.9/dagster.egg-info/
--rw-r--r--   0 root         (0) root         (0)     8947 2024-03-08 00:18:17.000000 dagster-1.6.9/dagster.egg-info/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)    27396 2024-03-08 00:18:17.000000 dagster-1.6.9/dagster.egg-info/SOURCES.txt
--rw-r--r--   0 root         (0) root         (0)        1 2024-03-08 00:18:17.000000 dagster-1.6.9/dagster.egg-info/dependency_links.txt
--rw-r--r--   0 root         (0) root         (0)       86 2024-03-08 00:18:17.000000 dagster-1.6.9/dagster.egg-info/entry_points.txt
--rw-r--r--   0 root         (0) root         (0)     1534 2024-03-08 00:18:17.000000 dagster-1.6.9/dagster.egg-info/requires.txt
--rw-r--r--   0 root         (0) root         (0)        8 2024-03-08 00:18:17.000000 dagster-1.6.9/dagster.egg-info/top_level.txt
--rw-r--r--   0 root         (0) root         (0)      154 2024-03-08 00:18:17.898550 dagster-1.6.9/setup.cfg
--rw-r--r--   0 root         (0) root         (0)     6948 2024-03-08 00:17:46.000000 dagster-1.6.9/setup.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.235781 dagster-1.7.0/
+-rw-r--r--   0 root         (0) root         (0)      553 2024-04-04 19:44:07.000000 dagster-1.7.0/COPYING
+-rw-r--r--   0 root         (0) root         (0)    11349 2024-04-04 19:44:07.000000 dagster-1.7.0/LICENSE
+-rw-r--r--   0 root         (0) root         (0)      533 2024-04-04 19:44:07.000000 dagster-1.7.0/MANIFEST.in
+-rw-r--r--   0 root         (0) root         (0)     8934 2024-04-04 19:44:34.235781 dagster-1.7.0/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)     7220 2024-04-04 19:44:07.000000 dagster-1.7.0/README.md
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.143781 dagster-1.7.0/dagster/
+-rw-r--r--   0 root         (0) root         (0)    29822 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/__init__.py
+-rw-r--r--   0 root         (0) root         (0)       31 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/__main__.py
+-rw-r--r--   0 root         (0) root         (0)    20744 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_annotations.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.143781 dagster-1.7.0/dagster/_api/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      731 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/get_server_id.py
+-rw-r--r--   0 root         (0) root         (0)     2147 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/list_repositories.py
+-rw-r--r--   0 root         (0) root         (0)      531 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/notebook_data.py
+-rw-r--r--   0 root         (0) root         (0)     3224 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/snapshot_execution_plan.py
+-rw-r--r--   0 root         (0) root         (0)     1964 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/snapshot_job.py
+-rw-r--r--   0 root         (0) root         (0)     5483 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/snapshot_partition.py
+-rw-r--r--   0 root         (0) root         (0)     1670 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/snapshot_repository.py
+-rw-r--r--   0 root         (0) root         (0)     3021 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/snapshot_schedule.py
+-rw-r--r--   0 root         (0) root         (0)     3370 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_api/snapshot_sensor.py
+-rw-r--r--   0 root         (0) root         (0)      478 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_builtins.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.143781 dagster-1.7.0/dagster/_check/
+-rw-r--r--   0 root         (0) root         (0)     1352 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_check/README.md
+-rw-r--r--   0 root         (0) root         (0)    52040 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_check/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.147781 dagster-1.7.0/dagster/_cli/
+-rw-r--r--   0 root         (0) root         (0)     1182 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26898 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/api.py
+-rw-r--r--   0 root         (0) root         (0)     8030 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/asset.py
+-rw-r--r--   0 root         (0) root         (0)     8302 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/code_server.py
+-rw-r--r--   0 root         (0) root         (0)     2374 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/config_scaffolder.py
+-rw-r--r--   0 root         (0) root         (0)     3513 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/debug.py
+-rw-r--r--   0 root         (0) root         (0)     8134 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/dev.py
+-rw-r--r--   0 root         (0) root         (0)     6651 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/instance.py
+-rw-r--r--   0 root         (0) root         (0)    30542 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/job.py
+-rw-r--r--   0 root         (0) root         (0)     1695 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/load_handle.py
+-rw-r--r--   0 root         (0) root         (0)     9114 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/project.py
+-rw-r--r--   0 root         (0) root         (0)     5120 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/run.py
+-rw-r--r--   0 root         (0) root         (0)    19351 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/schedule.py
+-rw-r--r--   0 root         (0) root         (0)    15461 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/sensor.py
+-rw-r--r--   0 root         (0) root         (0)     4259 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.147781 dagster-1.7.0/dagster/_cli/workspace/
+-rw-r--r--   0 root         (0) root         (0)      180 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/workspace/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    27910 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_cli/workspace/cli_target.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.147781 dagster-1.7.0/dagster/_config/
+-rw-r--r--   0 root         (0) root         (0)     3186 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3403 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    15830 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/config_type.py
+-rw-r--r--   0 root         (0) root         (0)    18787 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/errors.py
+-rw-r--r--   0 root         (0) root         (0)     1783 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/evaluate_value_result.py
+-rw-r--r--   0 root         (0) root         (0)    14918 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/field.py
+-rw-r--r--   0 root         (0) root         (0)    19728 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/field_utils.py
+-rw-r--r--   0 root         (0) root         (0)     9536 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/post_process.py
+-rw-r--r--   0 root         (0) root         (0)      855 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/primitive_mapping.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.147781 dagster-1.7.0/dagster/_config/pythonic_config/
+-rw-r--r--   0 root         (0) root         (0)     1394 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/pythonic_config/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1641 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/pythonic_config/attach_other_object_to_context.py
+-rw-r--r--   0 root         (0) root         (0)    18042 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/pythonic_config/config.py
+-rw-r--r--   0 root         (0) root         (0)    11496 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/pythonic_config/conversion_utils.py
+-rw-r--r--   0 root         (0) root         (0)    11583 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/pythonic_config/io_manager.py
+-rw-r--r--   0 root         (0) root         (0)     4022 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/pythonic_config/pydantic_compat_layer.py
+-rw-r--r--   0 root         (0) root         (0)    41251 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/pythonic_config/resource.py
+-rw-r--r--   0 root         (0) root         (0)     1996 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/pythonic_config/type_check_utils.py
+-rw-r--r--   0 root         (0) root         (0)     8375 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/pythonic_config/typing_utils.py
+-rw-r--r--   0 root         (0) root         (0)    12532 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/snap.py
+-rw-r--r--   0 root         (0) root         (0)     3087 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/source.py
+-rw-r--r--   0 root         (0) root         (0)     3528 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/stack.py
+-rw-r--r--   0 root         (0) root         (0)     7772 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/traversal_context.py
+-rw-r--r--   0 root         (0) root         (0)     4167 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/type_printer.py
+-rw-r--r--   0 root         (0) root         (0)    17137 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_config/validate.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.151781 dagster-1.7.0/dagster/_core/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.151781 dagster-1.7.0/dagster/_core/asset_graph_view/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/asset_graph_view/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21047 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/asset_graph_view/asset_graph_view.py
+-rw-r--r--   0 root         (0) root         (0)      994 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/assets.py
+-rw-r--r--   0 root         (0) root         (0)    13427 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/code_pointer.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.151781 dagster-1.7.0/dagster/_core/container_context/
+-rw-r--r--   0 root         (0) root         (0)      184 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/container_context/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1278 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/container_context/config.py
+-rw-r--r--   0 root         (0) root         (0)     2310 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/debug.py
+-rw-r--r--   0 root         (0) root         (0)     9665 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/decorator_utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.171781 dagster-1.7.0/dagster/_core/definitions/
+-rw-r--r--   0 root         (0) root         (0)     7827 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4506 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_check_evaluation.py
+-rw-r--r--   0 root         (0) root         (0)     7409 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_check_result.py
+-rw-r--r--   0 root         (0) root         (0)     5426 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_check_spec.py
+-rw-r--r--   0 root         (0) root         (0)     6073 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_checks.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.171781 dagster-1.7.0/dagster/_core/definitions/asset_condition/
+-rw-r--r--   0 root         (0) root         (0)       62 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_condition/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21345 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_condition/asset_condition.py
+-rw-r--r--   0 root         (0) root         (0)    16484 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_condition/asset_condition_evaluation_context.py
+-rw-r--r--   0 root         (0) root         (0)    26160 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_daemon_context.py
+-rw-r--r--   0 root         (0) root         (0)    10572 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_daemon_cursor.py
+-rw-r--r--   0 root         (0) root         (0)     4628 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_dep.py
+-rw-r--r--   0 root         (0) root         (0)    10251 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_graph.py
+-rw-r--r--   0 root         (0) root         (0)     7570 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_graph_differ.py
+-rw-r--r--   0 root         (0) root         (0)    16483 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_graph_subset.py
+-rw-r--r--   0 root         (0) root         (0)     3644 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_in.py
+-rw-r--r--   0 root         (0) root         (0)    29917 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_job.py
+-rw-r--r--   0 root         (0) root         (0)     6060 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_key.py
+-rw-r--r--   0 root         (0) root         (0)    30355 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_layer.py
+-rw-r--r--   0 root         (0) root         (0)     6945 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_out.py
+-rw-r--r--   0 root         (0) root         (0)    39535 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_selection.py
+-rw-r--r--   0 root         (0) root         (0)     7444 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)     6764 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_spec.py
+-rw-r--r--   0 root         (0) root         (0)     9802 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/asset_subset.py
+-rw-r--r--   0 root         (0) root         (0)    79547 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/assets.py
+-rw-r--r--   0 root         (0) root         (0)    13884 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/auto_materialize_policy.py
+-rw-r--r--   0 root         (0) root         (0)    54395 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/auto_materialize_rule.py
+-rw-r--r--   0 root         (0) root         (0)    21660 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/auto_materialize_rule_evaluation.py
+-rw-r--r--   0 root         (0) root         (0)     2768 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/auto_materialize_sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)     2939 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/backfill_policy.py
+-rw-r--r--   0 root         (0) root         (0)    34626 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/base_asset_graph.py
+-rw-r--r--   0 root         (0) root         (0)    16772 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/cacheable_assets.py
+-rw-r--r--   0 root         (0) root         (0)    40623 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/composition.py
+-rw-r--r--   0 root         (0) root         (0)     4278 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/config.py
+-rw-r--r--   0 root         (0) root         (0)    14811 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/configurable.py
+-rw-r--r--   0 root         (0) root         (0)    22990 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/data_time.py
+-rw-r--r--   0 root         (0) root         (0)    29993 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/data_version.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.175781 dagster-1.7.0/dagster/_core/definitions/decorators/
+-rw-r--r--   0 root         (0) root         (0)      620 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    16572 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/asset_check_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    68510 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/asset_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     4907 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/config_mapping_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     9077 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/graph_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     9353 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/hook_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    10815 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/job_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    19011 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/op_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    15668 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/repository_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     8718 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/schedule_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    12463 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/sensor_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    12664 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/decorators/source_asset_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     5267 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/definition_config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    23545 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/definitions_class.py
+-rw-r--r--   0 root         (0) root         (0)    42247 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/dependency.py
+-rw-r--r--   0 root         (0) root         (0)    26888 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/events.py
+-rw-r--r--   0 root         (0) root         (0)    21182 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/executor_definition.py
+-rw-r--r--   0 root         (0) root         (0)     9379 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/external_asset.py
+-rw-r--r--   0 root         (0) root         (0)     9750 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/freshness_based_auto_materialize.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.175781 dagster-1.7.0/dagster/_core/definitions/freshness_checks/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/freshness_checks/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5166 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/freshness_checks/last_update.py
+-rw-r--r--   0 root         (0) root         (0)     7677 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/freshness_checks/sensor.py
+-rw-r--r--   0 root         (0) root         (0)     4029 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/freshness_checks/time_partition.py
+-rw-r--r--   0 root         (0) root         (0)    15650 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/freshness_checks/utils.py
+-rw-r--r--   0 root         (0) root         (0)     8801 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/freshness_policy.py
+-rw-r--r--   0 root         (0) root         (0)    16401 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/freshness_policy_sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    47569 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/graph_definition.py
+-rw-r--r--   0 root         (0) root         (0)     6546 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/hook_definition.py
+-rw-r--r--   0 root         (0) root         (0)     1524 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/hook_invocation.py
+-rw-r--r--   0 root         (0) root         (0)     3537 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/inference.py
+-rw-r--r--   0 root         (0) root         (0)    21027 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/input.py
+-rw-r--r--   0 root         (0) root         (0)     6410 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/instigation_logger.py
+-rw-r--r--   0 root         (0) root         (0)     2722 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/job_base.py
+-rw-r--r--   0 root         (0) root         (0)    53689 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/job_definition.py
+-rw-r--r--   0 root         (0) root         (0)     5610 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/load_asset_checks_from_modules.py
+-rw-r--r--   0 root         (0) root         (0)    22306 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/load_assets_from_modules.py
+-rw-r--r--   0 root         (0) root         (0)     7171 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/logger_definition.py
+-rw-r--r--   0 root         (0) root         (0)      636 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/logger_invocation.py
+-rw-r--r--   0 root         (0) root         (0)     8959 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/materialize.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.175781 dagster-1.7.0/dagster/_core/definitions/metadata/
+-rw-r--r--   0 root         (0) root         (0)    42305 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/metadata/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    10371 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/metadata/table.py
+-rw-r--r--   0 root         (0) root         (0)    57203 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/multi_asset_sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    22029 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/multi_dimensional_partitions.py
+-rw-r--r--   0 root         (0) root         (0)      197 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/no_step_launcher.py
+-rw-r--r--   0 root         (0) root         (0)    11892 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/node_container.py
+-rw-r--r--   0 root         (0) root         (0)     8016 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/node_definition.py
+-rw-r--r--   0 root         (0) root         (0)     2892 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/observe.py
+-rw-r--r--   0 root         (0) root         (0)    23078 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/op_definition.py
+-rw-r--r--   0 root         (0) root         (0)    22439 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/op_invocation.py
+-rw-r--r--   0 root         (0) root         (0)     7551 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/op_selection.py
+-rw-r--r--   0 root         (0) root         (0)    19237 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/output.py
+-rw-r--r--   0 root         (0) root         (0)    50520 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/partition.py
+-rw-r--r--   0 root         (0) root         (0)      630 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/partition_key_range.py
+-rw-r--r--   0 root         (0) root         (0)    47665 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/partition_mapping.py
+-rw-r--r--   0 root         (0) root         (0)    11087 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/partitioned_schedule.py
+-rw-r--r--   0 root         (0) root         (0)     3779 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/policy.py
+-rw-r--r--   0 root         (0) root         (0)    27569 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/reconstruct.py
+-rw-r--r--   0 root         (0) root         (0)    21602 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/remote_asset_graph.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.175781 dagster-1.7.0/dagster/_core/definitions/repository_definition/
+-rw-r--r--   0 root         (0) root         (0)      654 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/repository_definition/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6024 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/repository_definition/caching_index.py
+-rw-r--r--   0 root         (0) root         (0)    21698 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/repository_definition/repository_data.py
+-rw-r--r--   0 root         (0) root         (0)    20892 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/repository_definition/repository_data_builder.py
+-rw-r--r--   0 root         (0) root         (0)    20432 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/repository_definition/repository_definition.py
+-rw-r--r--   0 root         (0) root         (0)     1479 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/repository_definition/valid_definitions.py
+-rw-r--r--   0 root         (0) root         (0)     8858 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/resolved_asset_deps.py
+-rw-r--r--   0 root         (0) root         (0)     1465 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/resource_annotation.py
+-rw-r--r--   0 root         (0) root         (0)    17900 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/resource_definition.py
+-rw-r--r--   0 root         (0) root         (0)     5382 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/resource_invocation.py
+-rw-r--r--   0 root         (0) root         (0)    10320 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/resource_requirement.py
+-rw-r--r--   0 root         (0) root         (0)     3383 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/result.py
+-rw-r--r--   0 root         (0) root         (0)    23076 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/run_config.py
+-rw-r--r--   0 root         (0) root         (0)     1445 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/run_config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    19555 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/run_request.py
+-rw-r--r--   0 root         (0) root         (0)    44126 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/run_status_sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    39363 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/schedule_definition.py
+-rw-r--r--   0 root         (0) root         (0)     6225 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/schema_change_checks.py
+-rw-r--r--   0 root         (0) root         (0)     5134 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/scoped_resources_builder.py
+-rw-r--r--   0 root         (0) root         (0)    14134 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/selector.py
+-rw-r--r--   0 root         (0) root         (0)    53797 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    19244 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/source_asset.py
+-rw-r--r--   0 root         (0) root         (0)     2481 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/step_launcher.py
+-rw-r--r--   0 root         (0) root         (0)     1530 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/target.py
+-rw-r--r--   0 root         (0) root         (0)    21859 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/time_window_partition_mapping.py
+-rw-r--r--   0 root         (0) root         (0)   102142 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/time_window_partitions.py
+-rw-r--r--   0 root         (0) root         (0)    15160 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/unresolved_asset_job_definition.py
+-rw-r--r--   0 root         (0) root         (0)    11017 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/utils.py
+-rw-r--r--   0 root         (0) root         (0)     3982 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/definitions/version_strategy.py
+-rw-r--r--   0 root         (0) root         (0)    26986 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/errors.py
+-rw-r--r--   0 root         (0) root         (0)    17805 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/event_api.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.175781 dagster-1.7.0/dagster/_core/events/
+-rw-r--r--   0 root         (0) root         (0)    71913 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/events/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7635 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/events/log.py
+-rw-r--r--   0 root         (0) root         (0)     1614 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/events/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.183781 dagster-1.7.0/dagster/_core/execution/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    38363 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/api.py
+-rw-r--r--   0 root         (0) root         (0)    64654 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/asset_backfill.py
+-rw-r--r--   0 root         (0) root         (0)    17100 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/backfill.py
+-rw-r--r--   0 root         (0) root         (0)     6296 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/build_resources.py
+-rw-r--r--   0 root         (0) root         (0)      224 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/bulk_actions.py
+-rw-r--r--   0 root         (0) root         (0)     5587 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/compute_logs.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.187781 dagster-1.7.0/dagster/_core/execution/context/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    78765 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context/compute.py
+-rw-r--r--   0 root         (0) root         (0)    17598 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context/hook.py
+-rw-r--r--   0 root         (0) root         (0)     9613 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context/init.py
+-rw-r--r--   0 root         (0) root         (0)    29167 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context/input.py
+-rw-r--r--   0 root         (0) root         (0)    39887 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context/invocation.py
+-rw-r--r--   0 root         (0) root         (0)     3164 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context/logger.py
+-rw-r--r--   0 root         (0) root         (0)    37256 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context/output.py
+-rw-r--r--   0 root         (0) root         (0)    55076 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context/system.py
+-rw-r--r--   0 root         (0) root         (0)    18533 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/context_creation_job.py
+-rw-r--r--   0 root         (0) root         (0)     5135 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/execute_in_process.py
+-rw-r--r--   0 root         (0) root         (0)     5897 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/execute_in_process_result.py
+-rw-r--r--   0 root         (0) root         (0)     9633 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/execution_result.py
+-rw-r--r--   0 root         (0) root         (0)     8602 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/host_mode.py
+-rw-r--r--   0 root         (0) root         (0)    14247 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/job_backfill.py
+-rw-r--r--   0 root         (0) root         (0)     6723 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/job_execution_result.py
+-rw-r--r--   0 root         (0) root         (0)      998 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/memoization.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.191781 dagster-1.7.0/dagster/_core/execution/plan/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26460 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/active.py
+-rw-r--r--   0 root         (0) root         (0)     9850 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/compute.py
+-rw-r--r--   0 root         (0) root         (0)    16535 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/compute_generator.py
+-rw-r--r--   0 root         (0) root         (0)    16974 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/execute_plan.py
+-rw-r--r--   0 root         (0) root         (0)    40549 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/execute_step.py
+-rw-r--r--   0 root         (0) root         (0)    11036 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/external_step.py
+-rw-r--r--   0 root         (0) root         (0)     3664 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/handle.py
+-rw-r--r--   0 root         (0) root         (0)    39260 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/inputs.py
+-rw-r--r--   0 root         (0) root         (0)     6251 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/instance_concurrency_context.py
+-rw-r--r--   0 root         (0) root         (0)     1197 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/local_external_step_main.py
+-rw-r--r--   0 root         (0) root         (0)     5706 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/objects.py
+-rw-r--r--   0 root         (0) root         (0)     7326 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/outputs.py
+-rw-r--r--   0 root         (0) root         (0)    61075 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/plan.py
+-rw-r--r--   0 root         (0) root         (0)      114 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/resume_retry.py
+-rw-r--r--   0 root         (0) root         (0)    17174 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/state.py
+-rw-r--r--   0 root         (0) root         (0)    15985 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/step.py
+-rw-r--r--   0 root         (0) root         (0)     3796 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/plan/utils.py
+-rw-r--r--   0 root         (0) root         (0)     1762 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/poll_compute_logs.py
+-rw-r--r--   0 root         (0) root         (0)     8230 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/resolve_versions.py
+-rw-r--r--   0 root         (0) root         (0)    19141 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/resources_init.py
+-rw-r--r--   0 root         (0) root         (0)     2100 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/retries.py
+-rw-r--r--   0 root         (0) root         (0)     1564 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/run_cancellation_thread.py
+-rw-r--r--   0 root         (0) root         (0)     9950 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/stats.py
+-rw-r--r--   0 root         (0) root         (0)    14043 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/submit_asset_runs.py
+-rw-r--r--   0 root         (0) root         (0)     1125 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/tags.py
+-rw-r--r--   0 root         (0) root         (0)     1172 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/validate_run_config.py
+-rw-r--r--   0 root         (0) root         (0)     1282 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/watch_orphans.py
+-rw-r--r--   0 root         (0) root         (0)     4311 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/execution/with_resources.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.191781 dagster-1.7.0/dagster/_core/executor/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1265 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/base.py
+-rw-r--r--   0 root         (0) root         (0)     5989 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/child_process_executor.py
+-rw-r--r--   0 root         (0) root         (0)     3366 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/in_process.py
+-rw-r--r--   0 root         (0) root         (0)     1509 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/init.py
+-rw-r--r--   0 root         (0) root         (0)    15497 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/multiprocess.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.191781 dagster-1.7.0/dagster/_core/executor/step_delegating/
+-rw-r--r--   0 root         (0) root         (0)      247 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/step_delegating/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    16894 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/step_delegating/step_delegating_executor.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.191781 dagster-1.7.0/dagster/_core/executor/step_delegating/step_handler/
+-rw-r--r--   0 root         (0) root         (0)      152 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/step_delegating/step_handler/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3078 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/executor/step_delegating/step_handler/base.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.191781 dagster-1.7.0/dagster/_core/instance/
+-rw-r--r--   0 root         (0) root         (0)   131811 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/instance/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    15788 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/instance/config.py
+-rw-r--r--   0 root         (0) root         (0)    24141 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/instance/ref.py
+-rw-r--r--   0 root         (0) root         (0)     3899 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/instance_for_test.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.191781 dagster-1.7.0/dagster/_core/launcher/
+-rw-r--r--   0 root         (0) root         (0)      297 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/launcher/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3819 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/launcher/base.py
+-rw-r--r--   0 root         (0) root         (0)     6645 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/launcher/default_run_launcher.py
+-rw-r--r--   0 root         (0) root         (0)     1566 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/launcher/sync_in_memory_run_launcher.py
+-rw-r--r--   0 root         (0) root         (0)      473 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/libraries.py
+-rw-r--r--   0 root         (0) root         (0)    18041 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/log_manager.py
+-rw-r--r--   0 root         (0) root         (0)     1029 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/nux.py
+-rw-r--r--   0 root         (0) root         (0)     5736 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/op_concurrency_limits_counter.py
+-rw-r--r--   0 root         (0) root         (0)     3691 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/origin.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.191781 dagster-1.7.0/dagster/_core/pipes/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/pipes/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8974 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/pipes/client.py
+-rw-r--r--   0 root         (0) root         (0)    18318 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/pipes/context.py
+-rw-r--r--   0 root         (0) root         (0)     5648 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/pipes/subprocess.py
+-rw-r--r--   0 root         (0) root         (0)    25661 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/pipes/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.195781 dagster-1.7.0/dagster/_core/remote_representation/
+-rw-r--r--   0 root         (0) root         (0)     2793 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    36695 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/code_location.py
+-rw-r--r--   0 root         (0) root         (0)    37482 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/external.py
+-rw-r--r--   0 root         (0) root         (0)    82857 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/external_data.py
+-rw-r--r--   0 root         (0) root         (0)     1450 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/feature_flags.py
+-rw-r--r--   0 root         (0) root         (0)    12429 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/grpc_server_registry.py
+-rw-r--r--   0 root         (0) root         (0)     1487 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/grpc_server_state_subscriber.py
+-rw-r--r--   0 root         (0) root         (0)     4356 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/handle.py
+-rw-r--r--   0 root         (0) root         (0)     1581 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/historical.py
+-rw-r--r--   0 root         (0) root         (0)     4850 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/job_index.py
+-rw-r--r--   0 root         (0) root         (0)    19669 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/origin.py
+-rw-r--r--   0 root         (0) root         (0)     3602 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/remote_representation/represented.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.195781 dagster-1.7.0/dagster/_core/run_coordinator/
+-rw-r--r--   0 root         (0) root         (0)      267 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/run_coordinator/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2005 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/run_coordinator/base.py
+-rw-r--r--   0 root         (0) root         (0)     1922 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/run_coordinator/default_run_coordinator.py
+-rw-r--r--   0 root         (0) root         (0)    13364 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/run_coordinator/queued_run_coordinator.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.195781 dagster-1.7.0/dagster/_core/scheduler/
+-rw-r--r--   0 root         (0) root         (0)      534 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/scheduler/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1241 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/scheduler/execution.py
+-rw-r--r--   0 root         (0) root         (0)    28809 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/scheduler/instigation.py
+-rw-r--r--   0 root         (0) root         (0)    10931 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/scheduler/scheduler.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.195781 dagster-1.7.0/dagster/_core/secrets/
+-rw-r--r--   0 root         (0) root         (0)       51 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/secrets/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1801 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/secrets/env_file.py
+-rw-r--r--   0 root         (0) root         (0)      388 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/secrets/loader.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.195781 dagster-1.7.0/dagster/_core/selector/
+-rw-r--r--   0 root         (0) root         (0)      295 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/selector/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    18109 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/selector/subset_selector.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.195781 dagster-1.7.0/dagster/_core/snap/
+-rw-r--r--   0 root         (0) root         (0)     2842 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/snap/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      494 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/snap/config_types.py
+-rw-r--r--   0 root         (0) root         (0)     3999 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/snap/dagster_types.py
+-rw-r--r--   0 root         (0) root         (0)     9302 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/snap/dep_snapshot.py
+-rw-r--r--   0 root         (0) root         (0)    12155 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/snap/execution_plan_snapshot.py
+-rw-r--r--   0 root         (0) root         (0)    16934 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/snap/job_snapshot.py
+-rw-r--r--   0 root         (0) root         (0)     4561 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/snap/mode.py
+-rw-r--r--   0 root         (0) root         (0)    14185 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/snap/node.py
+-rw-r--r--   0 root         (0) root         (0)     3183 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/snap/snap_to_yaml.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.199781 dagster-1.7.0/dagster/_core/storage/
+-rw-r--r--   0 root         (0) root         (0)     3058 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/DEVELOPING.md
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.199781 dagster-1.7.0/dagster/_core/storage/alembic/
+-rw-r--r--   0 root         (0) root         (0)     6686 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/README.md
+-rw-r--r--   0 root         (0) root         (0)      687 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/env.py
+-rw-r--r--   0 root         (0) root         (0)      494 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/script.py.mako
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.211781 dagster-1.7.0/dagster/_core/storage/alembic/versions/
+-rw-r--r--   0 root         (0) root         (0)     3150 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/001_initial_1.py
+-rw-r--r--   0 root         (0) root         (0)      312 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/001_initial_schedule.py
+-rw-r--r--   0 root         (0) root         (0)     1486 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      599 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      973 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      973 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     2729 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/004_add_snapshots_to_run_storage.py
+-rw-r--r--   0 root         (0) root         (0)     1406 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/005_add_asset_key_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1406 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/005_add_asset_key_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1131 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/006_scheduler_update_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      953 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/007_create_run_id_idx_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      953 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/007_create_run_id_idx_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      956 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/008_add_run_tags_index_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      956 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/008_add_run_tags_index_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1171 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/009_add_partition_column_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1171 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/009_add_partition_column_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1730 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1730 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1147 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1125 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_1.py
+-rw-r--r--   0 root         (0) root         (0)     1143 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_2.py
+-rw-r--r--   0 root         (0) root         (0)      417 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/012_0_10_0_create_new_run_tables_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      417 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/012_0_10_0_create_new_run_tables_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      435 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/013_0_10_0_create_new_event_log_tables_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      435 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/013_0_10_0_create_new_event_log_tables_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      432 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/014_0_10_0_create_new_schedule_tables_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      432 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/014_0_10_0_create_new_schedule_tables_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     3927 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     3927 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      409 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/016_add_bulk_actions_table_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      409 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/016_add_bulk_actions_table_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      936 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/017_add_run_status_index_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      936 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/017_add_run_status_index_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      325 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/017_initial_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      421 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/018_add_asset_tags_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      421 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/018_add_asset_tags_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      421 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/018_add_asset_tags_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1570 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1570 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      410 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/020_add_column_asset_body_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      410 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/020_add_column_asset_body_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      410 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/020_add_column_asset_body_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1034 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/021_add_column_mode_mysql.py
+-rw-r--r--   0 root         (0) root         (0)     1032 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/021_add_column_mode_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1034 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/021_add_column_mode_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      433 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      433 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      433 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      421 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      421 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      421 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      531 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_mysql.py
+-rw-r--r--   0 root         (0) root         (0)     1275 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1275 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      404 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/025_add_range_index_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      404 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/025_add_range_index_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      404 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/025_add_range_index_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      635 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/026_convert_start_end_times_format_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      434 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/027_add_migration_table_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      434 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/027_add_migration_table_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      434 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/027_add_migration_table_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      410 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/028_add_instigators_table_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      410 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/028_add_instigators_table_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      410 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/028_add_instigators_table_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      416 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      416 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      416 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1893 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/030_add_columns_action_type_and_selector_id_.py
+-rw-r--r--   0 root         (0) root         (0)      958 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/031_add_kvs_table.py
+-rw-r--r--   0 root         (0) root         (0)      499 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/032_rebuild_event_indexes.py
+-rw-r--r--   0 root         (0) root         (0)     1951 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/033_add_asset_event_tags_table.py
+-rw-r--r--   0 root         (0) root         (0)      428 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/034_add_cached_status_data_column.py
+-rw-r--r--   0 root         (0) root         (0)      427 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/035_add_run_job_index.py
+-rw-r--r--   0 root         (0) root         (0)     1537 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/036_add_dynamic_partitions_table.py
+-rw-r--r--   0 root         (0) root         (0)     2481 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/037_d9092588866f_add_primary_key_cols.py
+-rw-r--r--   0 root         (0) root         (0)     1177 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/038_701913684cb4_add_postgres_pks.py
+-rw-r--r--   0 root         (0) root         (0)     2062 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/039_d3a4c9e87af3_add_asset_daemon_asset_evaluations_table.py
+-rw-r--r--   0 root         (0) root         (0)     2359 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/040_add_in_progress_step_table.py
+-rw-r--r--   0 root         (0) root         (0)     2898 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/041_add_asset_check_executions_table.py
+-rw-r--r--   0 root         (0) root         (0)     1322 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/042_46b412388816_add_concurrency_limits_table.py
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/alembic/versions/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3887 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/asset_check_execution_record.py
+-rw-r--r--   0 root         (0) root         (0)     7301 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/asset_value_loader.py
+-rw-r--r--   0 root         (0) root         (0)     1227 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/base_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.211781 dagster-1.7.0/dagster/_core/storage/branching/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/branching/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5579 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/branching/branching_io_manager.py
+-rw-r--r--   0 root         (0) root         (0)     8725 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/captured_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)    16223 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/cloud_storage_compute_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)     9557 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/compute_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)     1863 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/config.py
+-rw-r--r--   0 root         (0) root         (0)      417 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/daemon_cursor.py
+-rw-r--r--   0 root         (0) root         (0)    25656 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/dagster_run.py
+-rw-r--r--   0 root         (0) root         (0)    11187 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/db_io_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.215781 dagster-1.7.0/dagster/_core/storage/event_log/
+-rw-r--r--   0 root         (0) root         (0)      742 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    18330 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/base.py
+-rw-r--r--   0 root         (0) root         (0)     3801 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/in_memory.py
+-rw-r--r--   0 root         (0) root         (0)     7289 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/migration.py
+-rw-r--r--   0 root         (0) root         (0)     7911 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/polling_event_watcher.py
+-rw-r--r--   0 root         (0) root         (0)     9250 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/schema.py
+-rw-r--r--   0 root         (0) root         (0)   122582 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/sql_event_log.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.215781 dagster-1.7.0/dagster/_core/storage/event_log/sqlite/
+-rw-r--r--   0 root         (0) root         (0)      200 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/sqlite/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.215781 dagster-1.7.0/dagster/_core/storage/event_log/sqlite/alembic/
+-rw-r--r--   0 root         (0) root         (0)      986 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/sqlite/alembic/alembic.ini
+-rw-r--r--   0 root         (0) root         (0)     7508 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/sqlite/consolidated_sqlite_event_log.py
+-rw-r--r--   0 root         (0) root         (0)    22497 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/event_log/sqlite/sqlite_event_log.py
+-rw-r--r--   0 root         (0) root         (0)    10983 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/file_manager.py
+-rw-r--r--   0 root         (0) root         (0)    13492 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/fs_io_manager.py
+-rw-r--r--   0 root         (0) root         (0)     8819 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/input_manager.py
+-rw-r--r--   0 root         (0) root         (0)    10882 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/io_manager.py
+-rw-r--r--   0 root         (0) root         (0)    32629 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/legacy_storage.py
+-rw-r--r--   0 root         (0) root         (0)    17558 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/local_compute_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)     1167 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/mem_io_manager.py
+-rw-r--r--   0 root         (0) root         (0)     4355 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/memoizable_io_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.215781 dagster-1.7.0/dagster/_core/storage/migration/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/migration/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5964 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/migration/bigint_migration.py
+-rw-r--r--   0 root         (0) root         (0)    15491 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/migration/utils.py
+-rw-r--r--   0 root         (0) root         (0)     3270 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/noop_compute_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)     2361 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/output_manager.py
+-rw-r--r--   0 root         (0) root         (0)    17131 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/partition_status_cache.py
+-rw-r--r--   0 root         (0) root         (0)     2121 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/root.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.219781 dagster-1.7.0/dagster/_core/storage/runs/
+-rw-r--r--   0 root         (0) root         (0)      386 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/runs/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    13903 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/runs/base.py
+-rw-r--r--   0 root         (0) root         (0)     2452 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/runs/in_memory.py
+-rw-r--r--   0 root         (0) root         (0)     8716 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/runs/migration.py
+-rw-r--r--   0 root         (0) root         (0)     6391 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/runs/schema.py
+-rw-r--r--   0 root         (0) root         (0)    37454 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/runs/sql_run_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.219781 dagster-1.7.0/dagster/_core/storage/runs/sqlite/
+-rw-r--r--   0 root         (0) root         (0)       69 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/runs/sqlite/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.219781 dagster-1.7.0/dagster/_core/storage/runs/sqlite/alembic/
+-rw-r--r--   0 root         (0) root         (0)      986 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/runs/sqlite/alembic/alembic.ini
+-rw-r--r--   0 root         (0) root         (0)     6310 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/runs/sqlite/sqlite_run_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.219781 dagster-1.7.0/dagster/_core/storage/schedules/
+-rw-r--r--   0 root         (0) root         (0)      272 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/schedules/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7236 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/schedules/base.py
+-rw-r--r--   0 root         (0) root         (0)     4133 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/schedules/migration.py
+-rw-r--r--   0 root         (0) root         (0)     4086 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/schedules/schema.py
+-rw-r--r--   0 root         (0) root         (0)    25146 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/schedules/sql_schedule_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.219781 dagster-1.7.0/dagster/_core/storage/schedules/sqlite/
+-rw-r--r--   0 root         (0) root         (0)       84 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/schedules/sqlite/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.219781 dagster-1.7.0/dagster/_core/storage/schedules/sqlite/alembic/
+-rw-r--r--   0 root         (0) root         (0)      986 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/schedules/sqlite/alembic/alembic.ini
+-rw-r--r--   0 root         (0) root         (0)     3684 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/schedules/sqlite/sqlite_schedule_storage.py
+-rw-r--r--   0 root         (0) root         (0)     7691 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/sql.py
+-rw-r--r--   0 root         (0) root         (0)     1391 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/sqlalchemy_compat.py
+-rw-r--r--   0 root         (0) root         (0)      926 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     4875 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/sqlite_storage.py
+-rw-r--r--   0 root         (0) root         (0)     3546 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/tags.py
+-rw-r--r--   0 root         (0) root         (0)     1186 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/temp_file_manager.py
+-rw-r--r--   0 root         (0) root         (0)    19355 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/storage/upath_io_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.219781 dagster-1.7.0/dagster/_core/system_config/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/system_config/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    13962 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/system_config/composite_descent.py
+-rw-r--r--   0 root         (0) root         (0)    15178 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/system_config/objects.py
+-rw-r--r--   0 root         (0) root         (0)    29921 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/telemetry.py
+-rw-r--r--   0 root         (0) root         (0)     4824 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/telemetry_upload.py
+-rw-r--r--   0 root         (0) root         (0)    22361 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/test_utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.219781 dagster-1.7.0/dagster/_core/types/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3084 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/builtin_config_schemas.py
+-rw-r--r--   0 root         (0) root         (0)     7042 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    36504 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/dagster_type.py
+-rw-r--r--   0 root         (0) root         (0)     3571 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/decorator.py
+-rw-r--r--   0 root         (0) root         (0)     1846 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/loadable_target_origin.py
+-rw-r--r--   0 root         (0) root         (0)     1027 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/primitive_mapping.py
+-rw-r--r--   0 root         (0) root         (0)     4764 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/python_dict.py
+-rw-r--r--   0 root         (0) root         (0)     2769 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/python_set.py
+-rw-r--r--   0 root         (0) root         (0)     3620 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/python_tuple.py
+-rw-r--r--   0 root         (0) root         (0)     1772 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/types/transform_typing.py
+-rw-r--r--   0 root         (0) root         (0)     1441 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/utility_ops.py
+-rw-r--r--   0 root         (0) root         (0)     6652 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.219781 dagster-1.7.0/dagster/_core/workspace/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/workspace/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4457 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/workspace/autodiscovery.py
+-rw-r--r--   0 root         (0) root         (0)     3422 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/workspace/config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    28842 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/workspace/context.py
+-rw-r--r--   0 root         (0) root         (0)    11852 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/workspace/load.py
+-rw-r--r--   0 root         (0) root         (0)     4721 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/workspace/load_target.py
+-rw-r--r--   0 root         (0) root         (0)     4311 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/workspace/permissions.py
+-rw-r--r--   0 root         (0) root         (0)     3463 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_core/workspace/workspace.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_daemon/
+-rw-r--r--   0 root         (0) root         (0)     1971 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/__init__.py
+-rw-r--r--   0 root         (0) root         (0)       30 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/__main__.py
+-rw-r--r--   0 root         (0) root         (0)    41787 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/asset_daemon.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_daemon/auto_run_reexecution/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/auto_run_reexecution/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7402 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/auto_run_reexecution/auto_run_reexecution.py
+-rw-r--r--   0 root         (0) root         (0)     9036 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/auto_run_reexecution/event_log_consumer.py
+-rw-r--r--   0 root         (0) root         (0)     2665 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/backfill.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_daemon/cli/
+-rw-r--r--   0 root         (0) root         (0)     5118 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/cli/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19590 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/controller.py
+-rw-r--r--   0 root         (0) root         (0)    12112 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/daemon.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_daemon/monitoring/
+-rw-r--r--   0 root         (0) root         (0)      320 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/monitoring/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1792 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/monitoring/concurrency.py
+-rw-r--r--   0 root         (0) root         (0)     9904 2024-04-04 19:44:07.000000 dagster-1.7.0/dagster/_daemon/monitoring/run_monitoring.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_daemon/run_coordinator/
+-rw-r--r--   0 root         (0) root         (0)      100 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_daemon/run_coordinator/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    18369 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_daemon/run_coordinator/queued_run_coordinator_daemon.py
+-rw-r--r--   0 root         (0) root         (0)    39110 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_daemon/sensor.py
+-rw-r--r--   0 root         (0) root         (0)     2860 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_daemon/types.py
+-rw-r--r--   0 root         (0) root         (0)      678 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_daemon/utils.py
+-rw-r--r--   0 root         (0) root         (0)     4114 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_daemon/workspace.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_experimental/
+-rw-r--r--   0 root         (0) root         (0)      300 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_experimental/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_generate/
+-rw-r--r--   0 root         (0) root         (0)      253 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2997 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/download.py
+-rw-r--r--   0 root         (0) root         (0)     4805 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/generate.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.139781 dagster-1.7.0/dagster/_generate/templates/
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/
+-rw-r--r--   0 root         (0) root         (0)      175 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/__init__.py
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/assets.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/__init__.py
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/test_assets.py.tmpl
+-rw-r--r--   0 root         (0) root         (0)      137 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/pyproject.toml.tmpl
+-rw-r--r--   0 root         (0) root         (0)       43 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/setup.cfg.tmpl
+-rw-r--r--   0 root         (0) root         (0)      297 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/setup.py.tmpl
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.223781 dagster-1.7.0/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/
+-rw-r--r--   0 root         (0) root         (0)     1753 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/README.md
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/
+-rw-r--r--   0 root         (0) root         (0)       40 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/__init__.py.tmpl
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/assets.py
+-rw-r--r--   0 root         (0) root         (0)      164 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/repository.py.tmpl
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/__init__.py
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/test_assets.py.tmpl
+-rw-r--r--   0 root         (0) root         (0)       80 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/pyproject.toml
+-rw-r--r--   0 root         (0) root         (0)       34 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/setup.cfg.tmpl
+-rw-r--r--   0 root         (0) root         (0)      279 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/setup.py.tmpl
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_grpc/
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_grpc/__generated__/
+-rw-r--r--   0 root         (0) root         (0)      178 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/__generated__/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    13462 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/__generated__/api_pb2.py
+-rw-r--r--   0 root         (0) root         (0)    27262 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/__generated__/api_pb2.pyi
+-rw-r--r--   0 root         (0) root         (0)    43164 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/__generated__/api_pb2_grpc.py
+-rw-r--r--   0 root         (0) root         (0)     2060 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/__init__.py
+-rw-r--r--   0 root         (0) root         (0)       89 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/__main__.py
+-rw-r--r--   0 root         (0) root         (0)    22739 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/client.py
+-rw-r--r--   0 root         (0) root         (0)     3584 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/compile.py
+-rw-r--r--   0 root         (0) root         (0)    23173 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/impl.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_grpc/protos/
+-rw-r--r--   0 root         (0) root         (0)     5993 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/protos/api.proto
+-rw-r--r--   0 root         (0) root         (0)    13431 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/proxy_server.py
+-rw-r--r--   0 root         (0) root         (0)    60914 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/server.py
+-rw-r--r--   0 root         (0) root         (0)     5297 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/server_watcher.py
+-rw-r--r--   0 root         (0) root         (0)    29291 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/types.py
+-rw-r--r--   0 root         (0) root         (0)     3693 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_grpc/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_legacy/
+-rw-r--r--   0 root         (0) root         (0)      180 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_legacy/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_loggers/
+-rw-r--r--   0 root         (0) root         (0)     3781 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_loggers/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_model/
+-rw-r--r--   0 root         (0) root         (0)      919 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_model/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3269 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_module_alias_map.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.227781 dagster-1.7.0/dagster/_scheduler/
+-rw-r--r--   0 root         (0) root         (0)        0 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_scheduler/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    41378 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_scheduler/scheduler.py
+-rw-r--r--   0 root         (0) root         (0)     1262 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_scheduler/stale.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.231781 dagster-1.7.0/dagster/_serdes/
+-rw-r--r--   0 root         (0) root         (0)      701 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_serdes/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8916 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_serdes/config_class.py
+-rw-r--r--   0 root         (0) root         (0)      142 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_serdes/errors.py
+-rw-r--r--   0 root         (0) root         (0)     7292 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_serdes/ipc.py
+-rw-r--r--   0 root         (0) root         (0)    42415 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_serdes/serdes.py
+-rw-r--r--   0 root         (0) root         (0)      674 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_serdes/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.231781 dagster-1.7.0/dagster/_seven/
+-rw-r--r--   0 root         (0) root         (0)     5455 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_seven/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      553 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_seven/abc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.231781 dagster-1.7.0/dagster/_seven/compat/
+-rw-r--r--   0 root         (0) root         (0)      105 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_seven/compat/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3967 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_seven/compat/pendulum.py
+-rw-r--r--   0 root         (0) root         (0)      383 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_seven/json.py
+-rw-r--r--   0 root         (0) root         (0)      354 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_seven/temp_dir.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.235781 dagster-1.7.0/dagster/_utils/
+-rw-r--r--   0 root         (0) root         (0)    24377 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     9314 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/alert.py
+-rw-r--r--   0 root         (0) root         (0)     2250 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/backoff.py
+-rw-r--r--   0 root         (0) root         (0)     5404 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/cached_method.py
+-rw-r--r--   0 root         (0) root         (0)    42589 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/caching_instance_queryer.py
+-rw-r--r--   0 root         (0) root         (0)     5865 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/concurrency.py
+-rw-r--r--   0 root         (0) root         (0)    12887 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/container.py
+-rw-r--r--   0 root         (0) root         (0)     2412 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/dagster_type.py
+-rw-r--r--   0 root         (0) root         (0)      799 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/env.py
+-rw-r--r--   0 root         (0) root         (0)     5477 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/error.py
+-rw-r--r--   0 root         (0) root         (0)     1255 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/external.py
+-rw-r--r--   0 root         (0) root         (0)      891 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/forked_pdb.py
+-rw-r--r--   0 root         (0) root         (0)     1870 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/hosted_user_process.py
+-rw-r--r--   0 root         (0) root         (0)     2796 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/indenting_printer.py
+-rw-r--r--   0 root         (0) root         (0)      745 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/internal_init.py
+-rw-r--r--   0 root         (0) root         (0)     3227 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/interrupts.py
+-rw-r--r--   0 root         (0) root         (0)    11214 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/log.py
+-rw-r--r--   0 root         (0) root         (0)     2313 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/merger.py
+-rw-r--r--   0 root         (0) root         (0)     1507 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/net.py
+-rw-r--r--   0 root         (0) root         (0)      208 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/partitions.py
+-rw-r--r--   0 root         (0) root         (0)    33171 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/schedules.py
+-rw-r--r--   0 root         (0) root         (0)      477 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/security.py
+-rw-r--r--   0 root         (0) root         (0)     3289 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/tags.py
+-rw-r--r--   0 root         (0) root         (0)     1820 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/temp_file.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.235781 dagster-1.7.0/dagster/_utils/test/
+-rw-r--r--   0 root         (0) root         (0)    13678 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7622 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/data_versions.py
+-rw-r--r--   0 root         (0) root         (0)      119 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/hello_world_defs.py
+-rw-r--r--   0 root         (0) root         (0)      214 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/hello_world_repository.py
+-rw-r--r--   0 root         (0) root         (0)     8622 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/mysql_instance.py
+-rw-r--r--   0 root         (0) root         (0)      256 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/named_hello_world_repository.py
+-rw-r--r--   0 root         (0) root         (0)     8959 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/postgres_instance.py
+-rw-r--r--   0 root         (0) root         (0)    35720 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/schedule_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.235781 dagster-1.7.0/dagster/_utils/test/toys/
+-rw-r--r--   0 root         (0) root         (0)       83 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/toys/__init__.py
+-rw-r--r--   0 root         (0) root         (0)       84 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/test/toys/single_repository.py
+-rw-r--r--   0 root         (0) root         (0)     2004 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/timing.py
+-rw-r--r--   0 root         (0) root         (0)     1032 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/typed_dict.py
+-rw-r--r--   0 root         (0) root         (0)      170 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/types.py
+-rw-r--r--   0 root         (0) root         (0)     3334 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/typing_api.py
+-rw-r--r--   0 root         (0) root         (0)     4740 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/warnings.py
+-rw-r--r--   0 root         (0) root         (0)     4902 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/_utils/yaml_utils.py
+-rw-r--r--   0 root         (0) root         (0)        8 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/py.typed
+-rw-r--r--   0 root         (0) root         (0)       22 2024-04-04 19:44:08.000000 dagster-1.7.0/dagster/version.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-04 19:44:34.143781 dagster-1.7.0/dagster.egg-info/
+-rw-r--r--   0 root         (0) root         (0)     8934 2024-04-04 19:44:33.000000 dagster-1.7.0/dagster.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)    27927 2024-04-04 19:44:34.000000 dagster-1.7.0/dagster.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2024-04-04 19:44:33.000000 dagster-1.7.0/dagster.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0) root         (0)       86 2024-04-04 19:44:33.000000 dagster-1.7.0/dagster.egg-info/entry_points.txt
+-rw-r--r--   0 root         (0) root         (0)     1458 2024-04-04 19:44:33.000000 dagster-1.7.0/dagster.egg-info/requires.txt
+-rw-r--r--   0 root         (0) root         (0)        8 2024-04-04 19:44:33.000000 dagster-1.7.0/dagster.egg-info/top_level.txt
+-rw-r--r--   0 root         (0) root         (0)      154 2024-04-04 19:44:34.235781 dagster-1.7.0/setup.cfg
+-rw-r--r--   0 root         (0) root         (0)     6827 2024-04-04 19:44:08.000000 dagster-1.7.0/setup.py
```

### Comparing `dagster-1.6.9/COPYING` & `dagster-1.7.0/COPYING`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/LICENSE` & `dagster-1.7.0/LICENSE`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/MANIFEST.in` & `dagster-1.7.0/MANIFEST.in`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/PKG-INFO` & `dagster-1.7.0/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dagster
-Version: 1.6.9
+Version: 1.7.0
 Summary: Dagster is an orchestration platform for the development, production, and observation of data assets.
 Author: Dagster Labs
 Author-email: hello@dagsterlabs.com
 License: Apache-2.0
 Project-URL: Homepage, https://dagster.io
 Project-URL: GitHub, https://github.com/dagster-io/dagster
 Project-URL: Documentation, https://docs.dagster.io
@@ -78,15 +78,15 @@
 from dagster import asset
 from pandas import DataFrame, read_html, get_dummies
 from sklearn.linear_model import LinearRegression
 
 @asset
 def country_populations() -> DataFrame:
     df = read_html("https://tinyurl.com/mry64ebh")[0]
-    df.columns = ["country", "continent", "rg", "pop2018", "pop2019", "change"]
+    df.columns = ["country", "pop2022", "pop2023", "change", "continent", "region"]
     df["change"] = df["change"].str.rstrip("%").str.replace("", "-").astype("float")
     return df
 
 @asset
 def continent_change_model(country_populations: DataFrame) -> LinearRegression:
     data = country_populations.dropna(subset=["change"])
     return LinearRegression().fit(get_dummies(data[["continent"]]), data["change"])
@@ -97,35 +97,35 @@
     result["pop_change_factor"] = continent_change_model.coef_
     return result
 ```
 
 The graph loaded into Dagster's web UI:
 
 <p align="center">
-  <img width="432" alt="An example asset graph as rendered in the Dagster UI" src="https://github.com/dagster-io/dagster/assets/654855/5b302b1b-4cc9-49bf-8689-232f7de87d31">
+  <img width="100%" alt="An example asset graph as rendered in the Dagster UI" src="https://raw.githubusercontent.com/dagster-io/dagster/master/.github/example-lineage.png">
 </p>
 
 Dagster is built to be used at every stage of the data development lifecycle - local development, unit tests, integration tests, staging environments, all the way up to production.
 
 ## Quick Start:
 
 If you're new to Dagster, we recommend reading about its [core concepts](https://docs.dagster.io/concepts) or learning with the hands-on [tutorial](https://docs.dagster.io/tutorial).
 
-Dagster is available on PyPI and officially supports Python 3.8, Python 3.9, Python 3.10, and Python 3.11.
+Dagster is available on PyPI and officially supports Python 3.8 through Python 3.12.
 
 ```bash
 pip install dagster dagster-webserver
 ```
 
 This installs two packages:
 
 - `dagster`: The core programming model.
 - `dagster-webserver`: The server that hosts Dagster's web UI for developing and operating Dagster jobs and assets.
 
-Running on Using a Mac with an M1 or M2 chip? Check the [install details here](https://docs.dagster.io/getting-started/install#installing-dagster-into-an-existing-python-environment).
+Running on Using a Mac with an Apple silicon chip? Check the [install details here](https://docs.dagster.io/getting-started/install#installing-dagster-into-an-existing-python-environment).
 
 ## Documentation
 
 You can find the full Dagster documentation [here](https://docs.dagster.io), including the ['getting started' guide](https://docs.dagster.io/getting-started).
 
 <hr/>
```

### Comparing `dagster-1.6.9/README.md` & `dagster-1.7.0/README.md`

 * *Files 3% similar despite different names*

```diff
@@ -38,15 +38,15 @@
 from dagster import asset
 from pandas import DataFrame, read_html, get_dummies
 from sklearn.linear_model import LinearRegression
 
 @asset
 def country_populations() -> DataFrame:
     df = read_html("https://tinyurl.com/mry64ebh")[0]
-    df.columns = ["country", "continent", "rg", "pop2018", "pop2019", "change"]
+    df.columns = ["country", "pop2022", "pop2023", "change", "continent", "region"]
     df["change"] = df["change"].str.rstrip("%").str.replace("", "-").astype("float")
     return df
 
 @asset
 def continent_change_model(country_populations: DataFrame) -> LinearRegression:
     data = country_populations.dropna(subset=["change"])
     return LinearRegression().fit(get_dummies(data[["continent"]]), data["change"])
@@ -57,35 +57,35 @@
     result["pop_change_factor"] = continent_change_model.coef_
     return result
 ```
 
 The graph loaded into Dagster's web UI:
 
 <p align="center">
-  <img width="432" alt="An example asset graph as rendered in the Dagster UI" src="https://github.com/dagster-io/dagster/assets/654855/5b302b1b-4cc9-49bf-8689-232f7de87d31">
+  <img width="100%" alt="An example asset graph as rendered in the Dagster UI" src="https://raw.githubusercontent.com/dagster-io/dagster/master/.github/example-lineage.png">
 </p>
 
 Dagster is built to be used at every stage of the data development lifecycle - local development, unit tests, integration tests, staging environments, all the way up to production.
 
 ## Quick Start:
 
 If you're new to Dagster, we recommend reading about its [core concepts](https://docs.dagster.io/concepts) or learning with the hands-on [tutorial](https://docs.dagster.io/tutorial).
 
-Dagster is available on PyPI and officially supports Python 3.8, Python 3.9, Python 3.10, and Python 3.11.
+Dagster is available on PyPI and officially supports Python 3.8 through Python 3.12.
 
 ```bash
 pip install dagster dagster-webserver
 ```
 
 This installs two packages:
 
 - `dagster`: The core programming model.
 - `dagster-webserver`: The server that hosts Dagster's web UI for developing and operating Dagster jobs and assets.
 
-Running on Using a Mac with an M1 or M2 chip? Check the [install details here](https://docs.dagster.io/getting-started/install#installing-dagster-into-an-existing-python-environment).
+Running on Using a Mac with an Apple silicon chip? Check the [install details here](https://docs.dagster.io/getting-started/install#installing-dagster-into-an-existing-python-environment).
 
 ## Documentation
 
 You can find the full Dagster documentation [here](https://docs.dagster.io), including the ['getting started' guide](https://docs.dagster.io/getting-started).
 
 <hr/>
```

### Comparing `dagster-1.6.9/dagster/__init__.py` & `dagster-1.7.0/dagster/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -113,14 +113,15 @@
 from dagster._core.definitions import AssetCheckResult as AssetCheckResult
 from dagster._core.definitions.asset_check_spec import (
     AssetCheckKey as AssetCheckKey,
     AssetCheckSeverity as AssetCheckSeverity,
     AssetCheckSpec as AssetCheckSpec,
 )
 from dagster._core.definitions.asset_checks import AssetChecksDefinition as AssetChecksDefinition
+from dagster._core.definitions.asset_condition import AssetCondition as AssetCondition
 from dagster._core.definitions.asset_dep import AssetDep as AssetDep
 from dagster._core.definitions.asset_in import AssetIn as AssetIn
 from dagster._core.definitions.asset_out import AssetOut as AssetOut
 from dagster._core.definitions.asset_selection import AssetSelection as AssetSelection
 from dagster._core.definitions.asset_sensor_definition import (
     AssetSensorDefinition as AssetSensorDefinition,
 )
@@ -143,14 +144,15 @@
 from dagster._core.definitions.data_version import (
     DataProvenance as DataProvenance,
     DataVersion as DataVersion,
     DataVersionsByPartition as DataVersionsByPartition,
 )
 from dagster._core.definitions.decorators.asset_check_decorator import (
     asset_check as asset_check,
+    multi_asset_check as multi_asset_check,
 )
 from dagster._core.definitions.decorators.asset_decorator import (
     asset as asset,
     graph_asset as graph_asset,
     graph_multi_asset as graph_multi_asset,
     multi_asset as multi_asset,
 )
@@ -205,14 +207,23 @@
     multiple_process_executor_requirements as multiple_process_executor_requirements,
     multiprocess_executor as multiprocess_executor,
 )
 from dagster._core.definitions.external_asset import (
     external_asset_from_spec as external_asset_from_spec,
     external_assets_from_specs as external_assets_from_specs,
 )
+from dagster._core.definitions.freshness_checks.last_update import (
+    build_last_update_freshness_checks as build_last_update_freshness_checks,
+)
+from dagster._core.definitions.freshness_checks.sensor import (
+    build_sensor_for_freshness_checks as build_sensor_for_freshness_checks,
+)
+from dagster._core.definitions.freshness_checks.time_partition import (
+    build_time_partition_freshness_checks as build_time_partition_freshness_checks,
+)
 from dagster._core.definitions.freshness_policy import FreshnessPolicy as FreshnessPolicy
 from dagster._core.definitions.freshness_policy_sensor_definition import (
     FreshnessPolicySensorContext as FreshnessPolicySensorContext,
     FreshnessPolicySensorDefinition as FreshnessPolicySensorDefinition,
     build_freshness_policy_sensor_context as build_freshness_policy_sensor_context,
     freshness_policy_sensor as freshness_policy_sensor,
 )
@@ -256,17 +267,19 @@
     MarkdownMetadataValue as MarkdownMetadataValue,
     MetadataEntry as MetadataEntry,
     MetadataValue as MetadataValue,
     NotebookMetadataValue as NotebookMetadataValue,
     NullMetadataValue as NullMetadataValue,
     PathMetadataValue as PathMetadataValue,
     PythonArtifactMetadataValue as PythonArtifactMetadataValue,
+    TableColumnLineageMetadataValue as TableColumnLineageMetadataValue,
     TableMetadataValue as TableMetadataValue,
     TableSchemaMetadataValue as TableSchemaMetadataValue,
     TextMetadataValue as TextMetadataValue,
+    TimestampMetadataValue as TimestampMetadataValue,
     UrlMetadataValue as UrlMetadataValue,
 )
 from dagster._core.definitions.metadata.table import (
     TableColumn as TableColumn,
     TableColumnConstraints as TableColumnConstraints,
     TableConstraints as TableConstraints,
     TableRecord as TableRecord,
@@ -356,14 +369,17 @@
 )
 from dagster._core.definitions.schedule_definition import (
     DefaultScheduleStatus as DefaultScheduleStatus,
     ScheduleDefinition as ScheduleDefinition,
     ScheduleEvaluationContext as ScheduleEvaluationContext,
     build_schedule_context as build_schedule_context,
 )
+from dagster._core.definitions.schema_change_checks import (
+    build_column_schema_change_checks as build_column_schema_change_checks,
+)
 from dagster._core.definitions.selector import (
     CodeLocationSelector as CodeLocationSelector,
     JobSelector as JobSelector,
     RepositorySelector as RepositorySelector,
 )
 from dagster._core.definitions.sensor_definition import (
     DefaultSensorStatus as DefaultSensorStatus,
@@ -445,14 +461,15 @@
 from dagster._core.events.log import EventLogEntry as EventLogEntry
 from dagster._core.execution.api import (
     ReexecutionOptions as ReexecutionOptions,
     execute_job as execute_job,
 )
 from dagster._core.execution.build_resources import build_resources as build_resources
 from dagster._core.execution.context.compute import (
+    AssetCheckExecutionContext as AssetCheckExecutionContext,
     AssetExecutionContext as AssetExecutionContext,
     OpExecutionContext as OpExecutionContext,
 )
 from dagster._core.execution.context.hook import (
     HookContext as HookContext,
     build_hook_context as build_hook_context,
 )
```

### Comparing `dagster-1.6.9/dagster/_annotations.py` & `dagster-1.7.0/dagster/_annotations.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_api/get_server_id.py` & `dagster-1.7.0/dagster/_api/get_server_id.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_api/list_repositories.py` & `dagster-1.7.0/dagster/_api/list_repositories.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_api/notebook_data.py` & `dagster-1.7.0/dagster/_api/notebook_data.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_api/snapshot_execution_plan.py` & `dagster-1.7.0/dagster/_api/snapshot_execution_plan.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,44 +1,44 @@
 from typing import TYPE_CHECKING, AbstractSet, Any, Mapping, Optional, Sequence
 
 import dagster._check as check
 from dagster._core.definitions.asset_check_spec import AssetCheckKey
 from dagster._core.definitions.events import AssetKey
 from dagster._core.errors import DagsterUserCodeProcessError
 from dagster._core.execution.plan.state import KnownExecutionState
-from dagster._core.host_representation.external_data import DEFAULT_MODE_NAME
-from dagster._core.host_representation.origin import ExternalJobOrigin
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.external_data import DEFAULT_MODE_NAME
+from dagster._core.remote_representation.origin import RemoteJobOrigin
 from dagster._core.snap.execution_plan_snapshot import (
     ExecutionPlanSnapshot,
     ExecutionPlanSnapshotErrorData,
 )
 from dagster._grpc.types import ExecutionPlanSnapshotArgs
 from dagster._serdes import deserialize_value
 
 if TYPE_CHECKING:
     from dagster._grpc.client import DagsterGrpcClient
 
 
 def sync_get_external_execution_plan_grpc(
     api_client: "DagsterGrpcClient",
-    job_origin: ExternalJobOrigin,
+    job_origin: RemoteJobOrigin,
     run_config: Mapping[str, Any],
     job_snapshot_id: str,
     asset_selection: Optional[AbstractSet[AssetKey]] = None,
     asset_check_selection: Optional[AbstractSet[AssetCheckKey]] = None,
     op_selection: Optional[Sequence[str]] = None,
     step_keys_to_execute: Optional[Sequence[str]] = None,
     known_state: Optional[KnownExecutionState] = None,
     instance: Optional[DagsterInstance] = None,
 ) -> ExecutionPlanSnapshot:
     from dagster._grpc.client import DagsterGrpcClient
 
     check.inst_param(api_client, "api_client", DagsterGrpcClient)
-    check.inst_param(job_origin, "job_origin", ExternalJobOrigin)
+    check.inst_param(job_origin, "job_origin", RemoteJobOrigin)
     op_selection = check.opt_sequence_param(op_selection, "op_selection", of_type=str)
     asset_selection = check.opt_nullable_set_param(
         asset_selection, "asset_selection", of_type=AssetKey
     )
     asset_check_selection = check.opt_nullable_set_param(
         asset_check_selection, "asset_check_selection", of_type=AssetCheckKey
     )
```

### Comparing `dagster-1.6.9/dagster/_api/snapshot_job.py` & `dagster-1.7.0/dagster/_api/snapshot_job.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,45 +1,47 @@
 from typing import TYPE_CHECKING, AbstractSet, Optional, Sequence
 
 import dagster._check as check
 from dagster._core.definitions.asset_check_spec import AssetCheckKey
 from dagster._core.definitions.events import AssetKey
 from dagster._core.errors import DagsterUserCodeProcessError
-from dagster._core.host_representation.external_data import ExternalJobSubsetResult
-from dagster._core.host_representation.origin import ExternalJobOrigin
+from dagster._core.remote_representation.external_data import ExternalJobSubsetResult
+from dagster._core.remote_representation.origin import RemoteJobOrigin
 from dagster._grpc.types import JobSubsetSnapshotArgs
 from dagster._serdes import deserialize_value
 
 if TYPE_CHECKING:
     from dagster._grpc.client import DagsterGrpcClient
 
 
 def sync_get_external_job_subset_grpc(
     api_client: "DagsterGrpcClient",
-    job_origin: ExternalJobOrigin,
+    job_origin: RemoteJobOrigin,
+    include_parent_snapshot: bool,
     op_selection: Optional[Sequence[str]] = None,
     asset_selection: Optional[AbstractSet[AssetKey]] = None,
     asset_check_selection: Optional[AbstractSet[AssetCheckKey]] = None,
 ) -> ExternalJobSubsetResult:
     from dagster._grpc.client import DagsterGrpcClient
 
     check.inst_param(api_client, "api_client", DagsterGrpcClient)
-    job_origin = check.inst_param(job_origin, "job_origin", ExternalJobOrigin)
+    job_origin = check.inst_param(job_origin, "job_origin", RemoteJobOrigin)
     op_selection = check.opt_nullable_sequence_param(op_selection, "op_selection", of_type=str)
     asset_selection = check.opt_nullable_set_param(
         asset_selection, "asset_selection", of_type=AssetKey
     )
 
     result = deserialize_value(
         api_client.external_pipeline_subset(
             pipeline_subset_snapshot_args=JobSubsetSnapshotArgs(
                 job_origin=job_origin,
                 op_selection=op_selection,
                 asset_selection=asset_selection,
                 asset_check_selection=asset_check_selection,
+                include_parent_snapshot=include_parent_snapshot,
             ),
         ),
         ExternalJobSubsetResult,
     )
 
     if result.error:
         raise DagsterUserCodeProcessError.from_error_info(result.error)
```

### Comparing `dagster-1.6.9/dagster/_api/snapshot_partition.py` & `dagster-1.7.0/dagster/_api/snapshot_partition.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from typing import TYPE_CHECKING, Sequence
 
 import dagster._check as check
 from dagster._core.errors import DagsterUserCodeProcessError
-from dagster._core.host_representation.external_data import (
+from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.external_data import (
     ExternalPartitionConfigData,
     ExternalPartitionExecutionErrorData,
     ExternalPartitionNamesData,
     ExternalPartitionSetExecutionParamData,
     ExternalPartitionTagsData,
 )
-from dagster._core.host_representation.handle import RepositoryHandle
-from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.handle import RepositoryHandle
 from dagster._grpc.types import PartitionArgs, PartitionNamesArgs, PartitionSetExecutionParamArgs
 from dagster._serdes import deserialize_value
 
 if TYPE_CHECKING:
     from dagster._grpc.client import DagsterGrpcClient
```

### Comparing `dagster-1.6.9/dagster/_api/snapshot_repository.py` & `dagster-1.7.0/dagster/_api/snapshot_repository.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,34 +1,34 @@
 from typing import TYPE_CHECKING, Mapping
 
 import dagster._check as check
 from dagster._core.errors import DagsterUserCodeProcessError
-from dagster._core.host_representation.external_data import (
+from dagster._core.remote_representation.external_data import (
     ExternalRepositoryData,
     ExternalRepositoryErrorData,
 )
 from dagster._serdes import deserialize_value
 
 if TYPE_CHECKING:
-    from dagster._core.host_representation import CodeLocation
+    from dagster._core.remote_representation import CodeLocation
     from dagster._grpc.client import DagsterGrpcClient
 
 
 def sync_get_streaming_external_repositories_data_grpc(
     api_client: "DagsterGrpcClient", code_location: "CodeLocation"
 ) -> Mapping[str, ExternalRepositoryData]:
-    from dagster._core.host_representation import CodeLocation, ExternalRepositoryOrigin
+    from dagster._core.remote_representation import CodeLocation, RemoteRepositoryOrigin
 
     check.inst_param(code_location, "code_location", CodeLocation)
 
     repo_datas = {}
     for repository_name in code_location.repository_names:  # type: ignore
         external_repository_chunks = list(
             api_client.streaming_external_repository(
-                external_repository_origin=ExternalRepositoryOrigin(
+                external_repository_origin=RemoteRepositoryOrigin(
                     code_location.origin,
                     repository_name,
                 )
             )
         )
 
         result = deserialize_value(
```

### Comparing `dagster-1.6.9/dagster/_api/snapshot_schedule.py` & `dagster-1.7.0/dagster/_api/snapshot_schedule.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import TYPE_CHECKING, Any, Optional, Sequence
 
 import dagster._check as check
 from dagster._core.definitions.schedule_definition import ScheduleExecutionData
 from dagster._core.errors import DagsterUserCodeProcessError
-from dagster._core.host_representation.external_data import ExternalScheduleExecutionErrorData
-from dagster._core.host_representation.handle import RepositoryHandle
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.external_data import ExternalScheduleExecutionErrorData
+from dagster._core.remote_representation.handle import RepositoryHandle
 from dagster._grpc.types import ExternalScheduleExecutionArgs
 from dagster._serdes import deserialize_value
 from dagster._seven.compat.pendulum import PendulumDateTime
 
 if TYPE_CHECKING:
     from dagster._grpc.client import DagsterGrpcClient
```

### Comparing `dagster-1.6.9/dagster/_api/snapshot_sensor.py` & `dagster-1.7.0/dagster/_api/snapshot_sensor.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import TYPE_CHECKING, Optional, Sequence
 
 import dagster._check as check
 from dagster._core.definitions.sensor_definition import SensorExecutionData
 from dagster._core.errors import DagsterUserCodeProcessError
-from dagster._core.host_representation.external_data import ExternalSensorExecutionErrorData
-from dagster._core.host_representation.handle import RepositoryHandle
+from dagster._core.remote_representation.external_data import ExternalSensorExecutionErrorData
+from dagster._core.remote_representation.handle import RepositoryHandle
 from dagster._grpc.client import DEFAULT_GRPC_TIMEOUT
 from dagster._grpc.types import SensorExecutionArgs
 from dagster._serdes import deserialize_value
 
 if TYPE_CHECKING:
     from dagster._core.instance import DagsterInstance
     from dagster._grpc.client import DagsterGrpcClient
```

### Comparing `dagster-1.6.9/dagster/_check/README.md` & `dagster-1.7.0/dagster/_check/README.md`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_check/__init__.py` & `dagster-1.7.0/dagster/_check/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -609,17 +609,30 @@
     return value
 
 
 # ########################
 # ##### INST
 # ########################
 
-# type-checking note: Attempting to use the passed type (Type[T] -> T) to infer the output type has
-# issues with abstract classes, so here we count on the incoming object to be typed before
-# this runtime validation check.
+# NOTE: inst() and opt_inst() perform narrowing, while inst_param() and opt_inst_param() do not. The
+# reason for this is that there is a trade-off between narrowing and passing type information
+# through untouched. The only working narrowing implementation will sometimes lose type information.
+# This is because not every static type can be expressed as a runtime-checkable type:
+#
+#     foo = Foo(Bar())  # type is Foo[Bar]
+#     inst(foo, Foo[Bar])  # illegal, can't pass parameterized types to inst()
+#     inst(foo, Foo)  # type is Foo; because we couldn't pass parameterized type, we lost info
+#
+# In contrast, we don't lose type information when we pass the type of the checked argument through
+# without modification.
+#
+# Because of this trade-off, it makes sense for inst() to perform narrowing but not inst_param().
+# With inst(), we rarely have rich type information at the callsite (if we did we wouldn't be
+# calling inst()). With inst_param(), on the other hand, we should always have rich type information
+# at the callsite from the type annotation, so we should never need to narrow.
 
 
 def inst_param(
     obj: T, param_name: str, ttype: TypeOrTupleOfTypes, additional_message: Optional[str] = None
 ) -> T:
     if not isinstance(obj, ttype):
         raise _param_type_mismatch_exception(
@@ -666,29 +679,32 @@
     additional_message: Optional[str] = None,
 ) -> Optional[T]:
     if obj is not None and not isinstance(obj, ttype):
         raise _param_type_mismatch_exception(obj, ttype, param_name, additional_message)
     return default if obj is None else obj
 
 
-def inst(obj: T, ttype: TypeOrTupleOfTypes, additional_message: Optional[str] = None) -> T:
+def inst(
+    obj: object,
+    ttype: Union[Type[T], Tuple[Type[T], ...]],
+    additional_message: Optional[str] = None,
+) -> T:
     if not isinstance(obj, ttype):
         raise _type_mismatch_error(obj, ttype, additional_message)
     return obj
 
 
 def opt_inst(
-    obj: T,
-    ttype: TypeOrTupleOfTypes,
+    obj: object,
+    ttype: Union[Type[T], Tuple[Type[T], ...]],
     additional_message: Optional[str] = None,
-    default: Optional[T] = None,
 ) -> Optional[T]:
     if obj is not None and not isinstance(obj, ttype):
         raise _type_mismatch_error(obj, ttype, additional_message)
-    return default if obj is None else obj
+    return obj
 
 
 # ########################
 # ##### ITERATOR
 # ########################
```

### Comparing `dagster-1.6.9/dagster/_cli/__init__.py` & `dagster-1.7.0/dagster/_cli/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_cli/api.py` & `dagster-1.7.0/dagster/_cli/api.py`

 * *Files 2% similar despite different names*

```diff
@@ -93,17 +93,16 @@
         cancellation_thread, cancellation_thread_shutdown_event = None, None
 
     dagster_run = check.not_none(
         instance.get_run_by_id(run_id),
         f"Run with id '{run_id}' not found for run execution.",
     )
 
-    check.inst(
+    check.not_none(
         dagster_run.job_code_origin,
-        JobPythonOrigin,
         f"Run with id '{run_id}' does not include an origin.",
     )
 
     recon_job = recon_job_from_origin(cast(JobPythonOrigin, dagster_run.job_code_origin))
 
     pid = os.getpid()
     instance.report_engine_event(
@@ -189,17 +188,16 @@
         )
     else:
         cancellation_thread, cancellation_thread_shutdown_event = None, None
     dagster_run = check.not_none(
         instance.get_run_by_id(run_id),  # type: ignore
         f"Run with id '{run_id}' not found for run execution.",
     )
-    check.inst(
+    check.not_none(
         dagster_run.job_code_origin,
-        JobPythonOrigin,
         f"Run with id '{run_id}' does not include an origin.",
     )
 
     recon_job = recon_job_from_origin(cast(JobPythonOrigin, dagster_run.job_code_origin))
 
     pid = os.getpid()
     instance.report_engine_event(
@@ -324,15 +322,18 @@
 
         if compressed_input_json:
             input_json = zlib.decompress(base64.b64decode(compressed_input_json.encode())).decode()
 
         args = deserialize_value(input_json, ExecuteStepArgs)
 
         with get_instance_for_cli(instance_ref=args.instance_ref) as instance:
-            dagster_run = instance.get_run_by_id(args.run_id)
+            dagster_run = check.not_none(
+                instance.get_run_by_id(args.run_id),
+                f"Run with id '{args.run_id}' not found for step execution",
+            )
 
             buff = []
 
             for event in _execute_step_command_body(
                 args,
                 instance,
                 dagster_run,
@@ -349,22 +350,16 @@
 ):
     single_step_key = (
         args.step_keys_to_execute[0]
         if args.step_keys_to_execute and len(args.step_keys_to_execute) == 1
         else None
     )
     try:
-        check.inst(
-            dagster_run,
-            DagsterRun,
-            f"Run with id '{args.run_id}' not found for step execution",
-        )
-        check.inst(
+        check.not_none(
             dagster_run.job_code_origin,
-            JobPythonOrigin,
             f"Run with id '{args.run_id}' does not include an origin.",
         )
 
         location_name = (
             dagster_run.external_job_origin.location_name
             if dagster_run.external_job_origin
             else None
```

### Comparing `dagster-1.6.9/dagster/_cli/asset.py` & `dagster-1.7.0/dagster/_cli/asset.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,20 +3,20 @@
 import click
 
 import dagster._check as check
 from dagster._cli.workspace.cli_target import (
     get_repository_python_origin_from_kwargs,
     python_origin_target_argument,
 )
+from dagster._core.definitions.asset_selection import AssetSelection
 from dagster._core.definitions.events import AssetKey
 from dagster._core.errors import DagsterInvalidSubsetError
 from dagster._core.execution.api import execute_job
 from dagster._core.instance import DagsterInstance
 from dagster._core.origin import JobPythonOrigin
-from dagster._core.selector.subset_selector import parse_asset_selection
 from dagster._core.telemetry import telemetry_wrapper
 from dagster._utils.hosted_user_process import (
     recon_job_from_origin,
     recon_repository_from_origin,
 )
 from dagster._utils.interrupts import capture_interrupts
 
@@ -43,18 +43,16 @@
 @telemetry_wrapper
 def execute_materialize_command(instance: DagsterInstance, kwargs: Mapping[str, str]) -> None:
     repository_origin = get_repository_python_origin_from_kwargs(kwargs)
 
     recon_repo = recon_repository_from_origin(repository_origin)
     repo_def = recon_repo.get_definition()
 
-    asset_keys = parse_asset_selection(
-        assets_defs=list(repo_def.assets_defs_by_key.values()),
-        asset_selection=kwargs["select"].split(","),
-    )
+    asset_selection = AssetSelection.from_coercible(kwargs["select"].split(","))
+    asset_keys = asset_selection.resolve(repo_def.asset_graph)
 
     implicit_job_def = repo_def.get_implicit_job_def_for_assets(asset_keys)
     # If we can't find an implicit job with all the given assets, it's because they couldn't be
     # placed into the same implicit job, because of their conflicting PartitionsDefinitions.
     if implicit_job_def is None:
         raise DagsterInvalidSubsetError(
             "All selected assets must share the same PartitionsDefinition or have no"
@@ -64,15 +62,15 @@
     reconstructable_job = recon_job_from_origin(
         JobPythonOrigin(implicit_job_def.name, repository_origin=repository_origin)
     )
     partition = kwargs.get("partition")
     if partition:
         partitions_def = implicit_job_def.partitions_def
         if partitions_def is None or all(
-            implicit_job_def.asset_layer.partitions_def_for_asset(asset_key) is None
+            implicit_job_def.asset_layer.get(asset_key).partitions_def is None
             for asset_key in asset_keys
         ):
             check.failed("Provided '--partition' option, but none of the assets are partitioned")
 
         tags = partitions_def.get_tags_for_partition_key(partition)
     else:
         tags = {}
@@ -90,25 +88,19 @@
 def asset_list_command(**kwargs):
     repository_origin = get_repository_python_origin_from_kwargs(kwargs)
     recon_repo = recon_repository_from_origin(repository_origin)
     repo_def = recon_repo.get_definition()
 
     select = kwargs.get("select")
     if select is not None:
-        asset_keys = parse_asset_selection(
-            assets_defs=list(repo_def.assets_defs_by_key.values()),
-            asset_selection=select.split(","),
-            raise_on_clause_has_no_matches=False,
-        )
+        asset_selection = AssetSelection.from_coercible(kwargs["select"].split(","))
     else:
-        asset_keys = [
-            asset_key
-            for assets_def in repo_def.assets_defs_by_key.values()
-            for asset_key in assets_def.keys
-        ]
+        asset_selection = AssetSelection.all()
+
+    asset_keys = asset_selection.resolve(repo_def.asset_graph, allow_missing=True)
 
     for asset_key in sorted(asset_keys):
         print(asset_key.to_user_string())  # noqa: T201
 
 
 @asset_cli.command(name="wipe")
 @click.argument("key", nargs=-1)
```

### Comparing `dagster-1.6.9/dagster/_cli/code_server.py` & `dagster-1.7.0/dagster/_cli/code_server.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_cli/config_scaffolder.py` & `dagster-1.7.0/dagster/_cli/config_scaffolder.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_cli/debug.py` & `dagster-1.7.0/dagster/_cli/debug.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_cli/dev.py` & `dagster-1.7.0/dagster/_cli/dev.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_cli/instance.py` & `dagster-1.7.0/dagster/_cli/instance.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_cli/job.py` & `dagster-1.7.0/dagster/_cli/job.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,31 +26,31 @@
     job_target_argument,
     python_job_config_argument,
     python_job_target_argument,
 )
 from dagster._core.definitions import JobDefinition
 from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.definitions.selector import JobSubsetSelector
-from dagster._core.definitions.utils import validate_tags
+from dagster._core.definitions.utils import normalize_tags
 from dagster._core.errors import DagsterBackfillFailedError
 from dagster._core.execution.api import create_execution_plan, execute_job
 from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
 from dagster._core.execution.execution_result import ExecutionResult
 from dagster._core.execution.job_backfill import create_backfill_run
-from dagster._core.host_representation import (
+from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation import (
     CodeLocation,
     ExternalJob,
     ExternalRepository,
     RepositoryHandle,
 )
-from dagster._core.host_representation.external_data import (
+from dagster._core.remote_representation.external_data import (
     ExternalPartitionNamesData,
     ExternalPartitionSetExecutionParamData,
 )
-from dagster._core.instance import DagsterInstance
 from dagster._core.snap import JobSnapshot, NodeInvocationSnap
 from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.storage.tags import MEMOIZED_RUN_TAG
 from dagster._core.telemetry import log_external_repo_stats, telemetry_wrapper
 from dagster._core.utils import make_new_backfill_id
 from dagster._core.workspace.workspace import IWorkspace
 from dagster._seven import IS_WINDOWS, JSONDecodeError, json
@@ -123,21 +123,21 @@
         " -m a_module.submodule -a define_some_repo -j <<job_name>>"
     )
 
 
 def get_job_instructions(command_name):
     return (
         "This commands targets a job. The job can be specified in a number of ways:\n\n1. dagster"
-        " job {command_name} -j <<job_name>> (works if .{default_filename} exists)\n\n2. dagster"
-        " job {command_name} -j <<job_name>> -w path/to/{default_filename}\n\n3. dagster job"
-        " {command_name} -f /path/to/file.py -a define_some_job\n\n4. dagster job {command_name} -m"
-        " a_module.submodule -a define_some_job\n\n5. dagster job {command_name} -f"
-        " /path/to/file.py -a define_some_repo -j <<job_name>>\n\n6. dagster job {command_name} -m"
+        f" job {command_name} -j <<job_name>> (works if .{DEFAULT_WORKSPACE_YAML_FILENAME} exists)\n\n2. dagster"
+        f" job {command_name} -j <<job_name>> -w path/to/{DEFAULT_WORKSPACE_YAML_FILENAME}\n\n3. dagster job"
+        f" {command_name} -f /path/to/file.py -a define_some_job\n\n4. dagster job {command_name} -m"
+        f" a_module.submodule -a define_some_job\n\n5. dagster job {command_name} -f"
+        f" /path/to/file.py -a define_some_repo -j <<job_name>>\n\n6. dagster job {command_name} -m"
         " a_module.submodule -a define_some_repo -j <<job_name>>"
-    ).format(command_name=command_name, default_filename=DEFAULT_WORKSPACE_YAML_FILENAME)
+    )
 
 
 @job_cli.command(
     name="print",
     help="Print a job.\n\n{instructions}".format(instructions=get_job_instructions("print")),
 )
 @click.option("--verbose", is_flag=True)
@@ -382,18 +382,15 @@
     elif config_json:
         config_json = cast(str, config_json)
         try:
             return json.loads(config_json)
 
         except JSONDecodeError:
             raise click.UsageError(
-                "Invalid JSON-string given for `--config-json`: {}\n\n{}".format(
-                    config_json,
-                    serializable_error_info_from_exc_info(sys.exc_info()).to_string(),
-                )
+                f"Invalid JSON-string given for `--config-json`: {config_json}\n\n{serializable_error_info_from_exc_info(sys.exc_info()).to_string()}"
             )
     else:
         check.failed("Unhandled case getting config from kwargs")
 
 
 def get_op_selection_from_args(kwargs: ClickArgMapping) -> Optional[Sequence[str]]:
     op_selection_str = kwargs.get("op_selection")
@@ -573,15 +570,15 @@
 
     tags = check.opt_mapping_param(tags, "tags", key_type=str)
     check.opt_sequence_param(op_selection, "op_selection", of_type=str)
     tags = merge_dicts(external_job.tags, tags)
 
     return (
         run_config,
-        validate_tags(tags),
+        normalize_tags(tags).tags,
         op_selection,
     )
 
 
 @job_cli.command(
     name="scaffold_config",
     help="Scaffold the config for a job.\n\n{instructions}".format(
```

### Comparing `dagster-1.6.9/dagster/_cli/load_handle.py` & `dagster-1.7.0/dagster/_cli/load_handle.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_cli/project.py` & `dagster-1.7.0/dagster/_cli/project.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_cli/run.py` & `dagster-1.7.0/dagster/_cli/run.py`

 * *Files 1% similar despite different names*

```diff
@@ -100,15 +100,15 @@
 
     with get_instance_for_cli() as instance:
         with get_external_job_from_kwargs(
             instance, version=dagster_version, kwargs=kwargs
         ) as external_job:
             new_job_origin = external_job.get_external_origin()
             job_name = external_job.name
-            to_label = new_job_origin.external_repository_origin.get_label()
+            to_label = new_job_origin.repository_origin.get_label()
 
         if not to_label:
             raise click.UsageError("Must specify valid job targets to migrate history to.")
 
         if to_label == from_label:
             click.echo(f"Migrating runs from {from_label} to {to_label} is a no-op.")
             return
```

### Comparing `dagster-1.6.9/dagster/_cli/schedule.py` & `dagster-1.7.0/dagster/_cli/schedule.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,16 +10,16 @@
     __version__ as dagster_version,
 )
 from dagster._cli.workspace.cli_target import (
     get_external_repository_from_kwargs,
     repository_target_argument,
 )
 from dagster._core.definitions.run_request import InstigatorType
-from dagster._core.host_representation import ExternalRepository
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation import ExternalRepository
 from dagster._core.scheduler.instigation import InstigatorStatus
 from dagster._core.scheduler.scheduler import DagsterDaemonScheduler
 
 from .utils import get_instance_for_cli
 
 
 @click.group(name="schedule")
@@ -75,17 +75,15 @@
                 "Planned Schedule Changes:" if preview else "Changes:", fg="magenta", bold=True
             )
         )
 
     for schedule_origin_id in added_schedules:
         print_fn(
             click.style(
-                "  + {name} (add) [{id}]".format(
-                    name=external_schedules_dict[schedule_origin_id].name, id=schedule_origin_id
-                ),
+                f"  + {external_schedules_dict[schedule_origin_id].name} (add) [{schedule_origin_id}]",
                 fg="green",
             )
         )
 
     for schedule_origin_id in changed_schedules:
         schedule_state = schedule_states_dict[schedule_origin_id]
         external_schedule = external_schedules_dict[schedule_origin_id]
@@ -102,18 +100,15 @@
             + " => "
             + click.style(external_schedule.cron_schedule, fg="green")
         )
 
     for schedule_origin_id in removed_schedules:
         print_fn(
             click.style(
-                "  - {name} (delete) [{id}]".format(
-                    name=schedule_states_dict[schedule_origin_id].instigator_name,
-                    id=schedule_origin_id,
-                ),
+                f"  - {schedule_states_dict[schedule_origin_id].instigator_name} (delete) [{schedule_origin_id}]",
                 fg="red",
             )
         )
 
 
 def check_repo_and_scheduler(repository: ExternalRepository, instance: DagsterInstance) -> None:
     check.inst_param(repository, "repository", ExternalRepository)
@@ -410,17 +405,15 @@
                 external_schedule = external_repo.get_external_schedule(schedule_name)
                 schedule_state = instance.get_instigator_state(
                     external_schedule.get_external_origin_id(),
                     external_schedule.selector_id,
                 )
                 if schedule_state is not None and schedule_state.status != InstigatorStatus.RUNNING:
                     click.UsageError(
-                        "Cannot restart a schedule {name} because is not currently running".format(
-                            name=schedule_state.instigator_name
-                        )
+                        f"Cannot restart a schedule {schedule_state.instigator_name} because is not currently running"
                     )
 
                 try:
                     instance.stop_schedule(
                         schedule_state.instigator_origin_id,
                         external_schedule.selector_id,
                         external_schedule,
```

### Comparing `dagster-1.6.9/dagster/_cli/sensor.py` & `dagster-1.7.0/dagster/_cli/sensor.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 from dagster._cli.workspace.cli_target import (
     get_code_location_from_kwargs,
     get_external_repository_from_code_location,
     get_external_repository_from_kwargs,
     repository_target_argument,
 )
 from dagster._core.definitions.run_request import InstigatorType
-from dagster._core.host_representation import ExternalRepository
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation import ExternalRepository
 from dagster._core.scheduler.instigation import (
     InstigatorState,
     InstigatorStatus,
     SensorInstigatorData,
 )
 from dagster._utils.error import serializable_error_info_from_exc_info
 from dagster._utils.yaml_utils import dump_run_config_yaml
@@ -285,28 +285,22 @@
                         cursor,
                         log_key=None,
                         last_sensor_start_time=None,
                     )
                 except Exception:
                     error_info = serializable_error_info_from_exc_info(sys.exc_info())
                     print_fn(
-                        "Failed to resolve sensor for {sensor_name} : {error_info}".format(
-                            sensor_name=external_sensor.name,
-                            error_info=error_info.to_string(),
-                        )
+                        f"Failed to resolve sensor for {external_sensor.name} : {error_info.to_string()}"
                     )
                     return
 
                 if not sensor_runtime_data.run_requests:
                     if sensor_runtime_data.skip_message:
                         print_fn(
-                            "Sensor returned false for {sensor_name}, skipping: {skip_message}".format(
-                                sensor_name=external_sensor.name,
-                                skip_message=sensor_runtime_data.skip_message,
-                            )
+                            f"Sensor returned false for {external_sensor.name}, skipping: {sensor_runtime_data.skip_message}"
                         )
                     else:
                         print_fn(f"Sensor returned false for {external_sensor.name}, skipping")
                 else:
                     print_fn(
                         "Sensor returning run requests for {num} run(s):\n\n{run_requests}".format(
                             num=len(sensor_runtime_data.run_requests),
```

### Comparing `dagster-1.6.9/dagster/_cli/utils.py` & `dagster-1.7.0/dagster/_cli/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_cli/workspace/cli_target.py` & `dagster-1.7.0/dagster/_cli/workspace/cli_target.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,22 +22,22 @@
 from click import UsageError
 from typing_extensions import Never, TypeAlias
 
 import dagster._check as check
 from dagster._core.code_pointer import CodePointer
 from dagster._core.definitions.reconstruct import repository_def_from_target_def
 from dagster._core.definitions.repository_definition import RepositoryDefinition
-from dagster._core.host_representation.code_location import CodeLocation
-from dagster._core.host_representation.external import ExternalRepository
 from dagster._core.instance import DagsterInstance
 from dagster._core.origin import (
     DEFAULT_DAGSTER_ENTRY_POINT,
     JobPythonOrigin,
     RepositoryPythonOrigin,
 )
+from dagster._core.remote_representation.code_location import CodeLocation
+from dagster._core.remote_representation.external import ExternalRepository
 from dagster._core.workspace.context import WorkspaceRequestContext
 from dagster._core.workspace.load_target import (
     CompositeTarget,
     EmptyWorkspaceTarget,
     GrpcServerTarget,
     ModuleTarget,
     PackageTarget,
@@ -48,15 +48,15 @@
 )
 from dagster._grpc.utils import get_loadable_targets
 from dagster._utils.hosted_user_process import recon_repository_from_origin
 
 if TYPE_CHECKING:
     from dagster._core.workspace.context import WorkspaceProcessContext
 
-from dagster._core.host_representation.external import ExternalJob
+from dagster._core.remote_representation.external import ExternalJob
 
 WORKSPACE_TARGET_WARNING = (
     "Can only use ONE of --workspace/-w, --python-file/-f, --module-name/-m, --grpc-port,"
     " --grpc-socket."
 )
 
 T_Callable = TypeVar("T_Callable", bound=Callable[..., Any])
@@ -705,18 +705,15 @@
         raise click.UsageError(
             f'Location "{provided_location_name}" not found in workspace. '
             f"Found {_sorted_quoted(workspace.code_location_names)} instead."
         )
 
     if workspace.has_code_location_error(provided_location_name):
         raise click.UsageError(
-            'Error loading location "{provided_location_name}": {error_str}'.format(
-                provided_location_name=provided_location_name,
-                error_str=str(workspace.get_code_location_error(provided_location_name)),
-            )
+            f'Error loading location "{provided_location_name}": {workspace.get_code_location_error(provided_location_name)!s}'
         )
 
     return workspace.get_code_location(provided_location_name)
 
 
 def get_external_repository_from_code_location(
     code_location: CodeLocation, provided_repo_name: Optional[str]
```

### Comparing `dagster-1.6.9/dagster/_config/__init__.py` & `dagster-1.7.0/dagster/_config/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/config_schema.py` & `dagster-1.7.0/dagster/_config/config_schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/config_type.py` & `dagster-1.7.0/dagster/_config/config_type.py`

 * *Files 2% similar despite different names*

```diff
@@ -427,17 +427,15 @@
         self,
         scalar_type: typing.Any,
         non_scalar_schema: UserConfigSchema,
         _key: Optional[str] = None,
     ):
         from .field import resolve_to_config_type
 
-        self.scalar_type = check.inst(
-            cast(ConfigType, resolve_to_config_type(scalar_type)), ConfigType
-        )
+        self.scalar_type = check.inst(resolve_to_config_type(scalar_type), ConfigType)
         self.non_scalar_type = resolve_to_config_type(non_scalar_schema)
 
         check.param_invariant(self.scalar_type.kind == ConfigTypeKind.SCALAR, "scalar_type")
         check.param_invariant(
             self.non_scalar_type.kind
             in {ConfigTypeKind.STRICT_SHAPE, ConfigTypeKind.SELECTOR, ConfigTypeKind.ARRAY},
             "non_scalar_type",
```

### Comparing `dagster-1.6.9/dagster/_config/errors.py` & `dagster-1.7.0/dagster/_config/errors.py`

 * *Files 6% similar despite different names*

```diff
@@ -193,50 +193,39 @@
     available_fields = sorted(context.config_type_snap.field_names)
     undefined_fields = sorted(undefined_fields)
 
     return EvaluationError(
         stack=context.stack,
         reason=DagsterEvaluationErrorReason.FIELDS_NOT_DEFINED,
         message=(
-            'Received unexpected config entries "{undefined_fields}" {path_msg}. '
-            'Expected: "{available_fields}."'
-        ).format(
-            undefined_fields=undefined_fields,
-            path_msg=get_friendly_path_msg(context.stack),
-            available_fields=available_fields,
+            f'Received unexpected config entries "{undefined_fields}" {get_friendly_path_msg(context.stack)}. '
+            f'Expected: "{available_fields}."'
         ),
         error_data=FieldsNotDefinedErrorData(field_names=undefined_fields),
     )
 
 
 def create_enum_type_mismatch_error(context: ContextData, config_value: object) -> EvaluationError:
     check.inst_param(context, "context", ContextData)
 
     return EvaluationError(
         stack=context.stack,
         reason=DagsterEvaluationErrorReason.RUNTIME_TYPE_MISMATCH,
-        message="Value {path_msg} for enum type {type_name} must be a string".format(
-            type_name=context.config_type_snap.given_name,
-            path_msg=get_friendly_path_msg(context.stack),
-        ),
+        message=f"Value {get_friendly_path_msg(context.stack)} for enum type {context.config_type_snap.given_name} must be a string",
         error_data=RuntimeMismatchErrorData(context.config_type_snap, repr(config_value)),
     )
 
 
 def create_enum_value_missing_error(context: ContextData, config_value: object) -> EvaluationError:
     check.inst_param(context, "context", ContextData)
 
     return EvaluationError(
         stack=context.stack,
         reason=DagsterEvaluationErrorReason.RUNTIME_TYPE_MISMATCH,
-        message="Value {path_msg} not in enum type {type_name} got {config_value}".format(
-            config_value=config_value,
-            type_name=context.config_type_snap.given_name,
-            path_msg=get_friendly_path_msg(context.stack),
-        ),
+        message=f"Value {get_friendly_path_msg(context.stack)} not in enum type {context.config_type_snap.given_name} got {config_value}",
         error_data=RuntimeMismatchErrorData(context.config_type_snap, repr(config_value)),
     )
 
 
 def check_config_type_in_context_has_fields(context: ContextData, param_name: str) -> None:
     check.param_invariant(ConfigTypeKind.has_fields(context.config_type_snap.kind), param_name)
 
@@ -362,21 +351,16 @@
 def create_scalar_error(context: ContextData, config_value: object) -> EvaluationError:
     check.inst_param(context, "context", ContextData)
 
     return EvaluationError(
         stack=context.stack,
         reason=DagsterEvaluationErrorReason.RUNTIME_TYPE_MISMATCH,
         message=(
-            'Invalid scalar {path_msg}. Value "{config_value}" of type '
-            '"{type}" is not valid for expected type "{type_name}".'.format(
-                path_msg=get_friendly_path_msg(context.stack),
-                type_name=context.config_type_snap.given_name,
-                config_value=config_value,
-                type=type(config_value),
-            )
+            f'Invalid scalar {get_friendly_path_msg(context.stack)}. Value "{config_value}" of type '
+            f'"{type(config_value)}" is not valid for expected type "{context.config_type_snap.given_name}".'
         ),
         error_data=RuntimeMismatchErrorData(context.config_type_snap, repr(config_value)),
     )
 
 
 def create_pydantic_env_var_error(
     context: ContextData, config_value: Union[EnvVar, IntEnvVar]
@@ -406,20 +390,16 @@
     defined_fields = sorted(context.config_type_snap.field_names)
     incoming_fields = sorted(list(config_value.keys()))
 
     return EvaluationError(
         stack=context.stack,
         reason=DagsterEvaluationErrorReason.SELECTOR_FIELD_ERROR,
         message=(
-            "You can only specify a single field {path_msg}. You specified {incoming_fields}. "
-            "The available fields are {defined_fields}"
-        ).format(
-            incoming_fields=incoming_fields,
-            defined_fields=defined_fields,
-            path_msg=get_friendly_path_msg(context.stack),
+            f"You can only specify a single field {get_friendly_path_msg(context.stack)}. You specified {incoming_fields}. "
+            f"The available fields are {defined_fields}"
         ),
         error_data=SelectorTypeErrorData(
             config_type_snap=context.config_type_snap, incoming_fields=incoming_fields
         ),
     )
 
 
@@ -430,17 +410,17 @@
 
     defined_fields = sorted(context.config_type_snap.field_names)
 
     return EvaluationError(
         stack=context.stack,
         reason=DagsterEvaluationErrorReason.SELECTOR_FIELD_ERROR,
         message=(
-            "Must specify a field {path_msg} if more than one field is defined. "
-            "Defined fields: {defined_fields}"
-        ).format(defined_fields=defined_fields, path_msg=get_friendly_path_msg(context.stack)),
+            f"Must specify a field {get_friendly_path_msg(context.stack)} if more than one field is defined. "
+            f"Defined fields: {defined_fields}"
+        ),
         error_data=SelectorTypeErrorData(
             config_type_snap=context.config_type_snap, incoming_fields=[]
         ),
     )
 
 
 def create_selector_type_error(context: ContextData, config_value: object) -> EvaluationError:
@@ -461,16 +441,16 @@
 
     defined_fields = sorted(context.config_type_snap.field_names)
 
     return EvaluationError(
         stack=context.stack,
         reason=DagsterEvaluationErrorReason.SELECTOR_FIELD_ERROR,
         message=(
-            "Must specify the required field {path_msg}. Defined fields: {defined_fields}"
-        ).format(defined_fields=defined_fields, path_msg=get_friendly_path_msg(context.stack)),
+            f"Must specify the required field {get_friendly_path_msg(context.stack)}. Defined fields: {defined_fields}"
+        ),
         error_data=SelectorTypeErrorData(
             config_type_snap=context.config_type_snap, incoming_fields=[]
         ),
     )
 
 
 def create_none_not_allowed_error(context: ContextData) -> EvaluationError:
@@ -495,19 +475,15 @@
     check.inst_param(context, "context", ContextData)
     check.inst_param(error_data, "error_data", SerializableErrorInfo)
 
     return EvaluationError(
         stack=context.stack,
         reason=DagsterEvaluationErrorReason.FAILED_POST_PROCESSING,
         message=(
-            "Post processing {path_msg} of original value {original_value} failed:\n{error}".format(
-                path_msg=get_friendly_path_msg(context.stack),
-                original_value=original_value,
-                error=error_data.to_string(),
-            )
+            f"Post processing {get_friendly_path_msg(context.stack)} of original value {original_value} failed:\n{error_data.to_string()}"
         ),
         error_data=error_data,
     )
 
 
 class PostProcessingError(Exception):
     """This is part of the formal API for implementing post_process
```

### Comparing `dagster-1.6.9/dagster/_config/evaluate_value_result.py` & `dagster-1.7.0/dagster/_config/evaluate_value_result.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/field.py` & `dagster-1.7.0/dagster/_config/field.py`

 * *Files 0% similar despite different names*

```diff
@@ -298,19 +298,17 @@
 
         # check explicit default value
         if self.default_provided:
             if self.config_type.kind == ConfigTypeKind.ENUM and is_enum_value(default_value):
                 raise DagsterInvalidDefinitionError(
                     (
                         "You have passed into a python enum value as the default value "
-                        "into of a config enum type {name}. You must pass in the underlying "
-                        "string represention as the default value. One of {value_set}."
-                    ).format(
-                        value_set=[ev.config_value for ev in self.config_type.enum_values],
-                        name=self.config_type.given_name,
+                        f"into of a config enum type {self.config_type.given_name}. You must pass in the underlying "
+                        "string represention as the default value. "
+                        f"One of {[ev.config_value for ev in self.config_type.enum_values]}."  # type: ignore
                     )
                 )
 
             evr = validate_config(self.config_type, default_value)
             if not evr.success:
                 raise DagsterInvalidConfigError(
                     "Invalid default_value for Field.",
```

### Comparing `dagster-1.6.9/dagster/_config/field_utils.py` & `dagster-1.7.0/dagster/_config/field_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -391,17 +391,15 @@
 
     inner_type = _convert_potential_type(original_root, the_list[0], stack)
     if not inner_type:
         raise DagsterInvalidConfigDefinitionError(
             original_root,
             the_list,
             stack,
-            "List have a single item and contain a valid type i.e. [int]. Got item {}".format(
-                repr(the_list[0])
-            ),
+            f"List have a single item and contain a valid type i.e. [int]. Got item {the_list[0]!r}",
         )
 
     return Array(inner_type)
 
 
 def expand_map(original_root: object, the_dict: Mapping[object, object], stack: List[str]) -> Map:
     if len(the_dict) != 1:
@@ -421,17 +419,15 @@
 
     inner_type = _convert_potential_type(original_root, the_dict[key], stack)
     if not inner_type:
         raise DagsterInvalidConfigDefinitionError(
             original_root,
             the_dict,
             stack,
-            "Map must have a single value and contain a valid type i.e. {{str: int}}. Got item {}".format(
-                repr(the_dict[key])
-            ),
+            f"Map must have a single value and contain a valid type i.e. {{str: int}}. Got item {the_dict[key]!r}",
         )
 
     return Map(key_type, inner_type)
 
 
 def convert_potential_field(potential_field: object) -> "Field":
     return _convert_potential_field(potential_field, potential_field, [])
```

### Comparing `dagster-1.6.9/dagster/_config/post_process.py` & `dagster-1.7.0/dagster/_config/post_process.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/primitive_mapping.py` & `dagster-1.7.0/dagster/_config/primitive_mapping.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/pythonic_config/__init__.py` & `dagster-1.7.0/dagster/_config/pythonic_config/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/pythonic_config/attach_other_object_to_context.py` & `dagster-1.7.0/dagster/_config/pythonic_config/attach_other_object_to_context.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/pythonic_config/config.py` & `dagster-1.7.0/dagster/_config/pythonic_config/config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/pythonic_config/conversion_utils.py` & `dagster-1.7.0/dagster/_config/pythonic_config/conversion_utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/pythonic_config/io_manager.py` & `dagster-1.7.0/dagster/_config/pythonic_config/io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/pythonic_config/pydantic_compat_layer.py` & `dagster-1.7.0/dagster/_config/pythonic_config/pydantic_compat_layer.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 import pydantic
 from pydantic import BaseModel
 
 from .attach_other_object_to_context import (
     IAttachDifferentObjectToOpContext as IAttachDifferentObjectToOpContext,
 )
 
+USING_PYDANTIC_1 = int(pydantic.__version__.split(".")[0]) == 1
 USING_PYDANTIC_2 = int(pydantic.__version__.split(".")[0]) >= 2
 
 PydanticUndefined = None
 if USING_PYDANTIC_2:
     from pydantic_core import PydanticUndefined as _PydanticUndefined  # type: ignore
 
     PydanticUndefined = _PydanticUndefined
```

### Comparing `dagster-1.6.9/dagster/_config/pythonic_config/resource.py` & `dagster-1.7.0/dagster/_config/pythonic_config/resource.py`

 * *Files 1% similar despite different names*

```diff
@@ -474,23 +474,20 @@
 
         Returns a new instance of the resource.
         """
         from dagster._core.execution.build_resources import wrap_resource_for_execution
 
         partial_resources_to_update: Dict[str, Any] = {}
         if self._nested_partial_resources:
-            context_with_mapping = cast(
+            context_with_mapping = check.inst(
+                context,
                 InitResourceContextWithKeyMapping,
-                check.inst(
-                    context,
-                    InitResourceContextWithKeyMapping,
-                    "This ConfiguredResource contains unresolved partially-specified nested"
-                    " resources, and so can only be initialized using a"
-                    " InitResourceContextWithKeyMapping",
-                ),
+                "This ConfiguredResource contains unresolved partially-specified nested"
+                " resources, and so can only be initialized using a"
+                " InitResourceContextWithKeyMapping",
             )
             partial_resources_to_update = {
                 attr_name: context_with_mapping.resources_by_id[id(resource)]
                 for attr_name, resource in self._nested_partial_resources.items()
             }
 
         # Also evaluate any resources that are not partial
@@ -830,15 +827,15 @@
 V = TypeVar("V")
 
 
 class ResourceDependency(Generic[V]):
     def __set_name__(self, _owner, name):
         self._name = name
 
-    def __get__(self, obj: "ConfigurableResourceFactory", __owner: Any) -> V:
+    def __get__(self, obj: "ConfigurableResourceFactory", owner: Any) -> V:
         return getattr(obj, self._name)
 
     def __set__(self, obj: Optional[object], value: ResourceOrPartialOrValue[V]) -> None:
         setattr(obj, self._name, value)
 
 
 class ConfigurableLegacyResourceAdapter(ConfigurableResource, ABC):
```

### Comparing `dagster-1.6.9/dagster/_config/pythonic_config/type_check_utils.py` & `dagster-1.7.0/dagster/_config/pythonic_config/type_check_utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/pythonic_config/typing_utils.py` & `dagster-1.7.0/dagster/_config/pythonic_config/typing_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -170,15 +170,15 @@
 
     Very similar to https://github.com/pydantic/pydantic/discussions/4262.
     """
 
     def __set_name__(self, _owner, name):
         self._assigned_name = name
 
-    def __get__(self: Self, obj: Any, __owner: Any) -> Self:
+    def __get__(self: Self, obj: Any, owner: Any) -> Self:
         # no-op implementation (only used to affect type signature)
         return cast(Self, getattr(obj, self._assigned_name))
 
     # The annotation her has been temporarily changed from:
     #     value: Union[Self, "PartialResource[Self]"]
     # to:
     #     value: Union[Any, "PartialResource[Any]"]
```

### Comparing `dagster-1.6.9/dagster/_config/snap.py` & `dagster-1.7.0/dagster/_config/snap.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/source.py` & `dagster-1.7.0/dagster/_config/source.py`

 * *Files 2% similar despite different names*

```diff
@@ -86,16 +86,14 @@
         key, cfg = next(iter(value.items()))
         check.invariant(key == "env", "Only valid key is env")
         value = _ensure_env_variable(cfg)
         try:
             return bool(value)
         except ValueError as e:
             raise PostProcessingError(
-                (
-                    'Value "{value}" stored in env variable "{var}" cannot be coerced into an bool.'
-                ).format(value=value, var=cfg)
+                (f'Value "{value}" stored in env variable "{cfg}" cannot be coerced into an bool.')
             ) from e
 
 
 StringSource: StringSourceType = StringSourceType()
 IntSource: IntSourceType = IntSourceType()
 BoolSource: BoolSourceType = BoolSourceType()
```

### Comparing `dagster-1.6.9/dagster/_config/stack.py` & `dagster-1.7.0/dagster/_config/stack.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/traversal_context.py` & `dagster-1.7.0/dagster/_config/traversal_context.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/type_printer.py` & `dagster-1.7.0/dagster/_config/type_printer.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_config/validate.py` & `dagster-1.7.0/dagster/_config/validate.py`

 * *Files 0% similar despite different names*

```diff
@@ -51,16 +51,15 @@
         # historical snapshot without scalar kind. do no validation
         return True
     else:
         check.failed(f"Not a supported scalar {config_type_snap}")
 
 
 def validate_config(config_schema: object, config_value: T) -> EvaluateValueResult[T]:
-    config_type = resolve_to_config_type(config_schema)
-    config_type = check.inst(cast(ConfigType, config_type), ConfigType)
+    config_type = check.inst(resolve_to_config_type(config_schema), ConfigType)
 
     return validate_config_from_snap(
         config_schema_snapshot=config_type.get_schema_snapshot(),
         config_type_key=config_type.key,
         config_value=config_value,
     )
 
@@ -217,17 +216,15 @@
                 context.config_schema_snapshot.get_config_snap(field_snap.type_key).kind
             )
             else field_value
         ),
     )
 
     if child_evaluate_value_result.success:
-        return EvaluateValueResult.for_value(  # type: ignore
-            {field_name: child_evaluate_value_result.value}
-        )
+        return EvaluateValueResult.for_value({field_name: child_evaluate_value_result.value})
     else:
         return child_evaluate_value_result
 
 
 def _validate_shape_config(
     context: ValidationContext, config_value: object, check_for_extra_incoming_fields: bool
 ) -> EvaluateValueResult[Mapping[str, object]]:
@@ -297,15 +294,15 @@
 
     if field_errors:
         errors += field_errors
 
     if errors:
         return EvaluateValueResult.for_errors(errors)
     else:
-        return EvaluateValueResult.for_value(config_value)  # type: ignore
+        return EvaluateValueResult.for_value(config_value)
 
 
 def validate_permissive_shape_config(
     context: ValidationContext, config_value: object
 ) -> EvaluateValueResult[Mapping[str, object]]:
     check.inst_param(context, "context", ValidationContext)
     check.invariant(context.config_type_snap.kind == ConfigTypeKind.PERMISSIVE_SHAPE)
```

### Comparing `dagster-1.6.9/dagster/_core/assets.py` & `dagster-1.7.0/dagster/_core/assets.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/code_pointer.py` & `dagster-1.7.0/dagster/_core/code_pointer.py`

 * *Files 1% similar despite different names*

```diff
@@ -305,17 +305,15 @@
         reconstructor = cast(Callable, self.reconstructor_pointer.load_target())
 
         return reconstructor(
             *self.reconstructable_args, **{key: value for key, value in self.reconstructable_kwargs}
         )
 
     def describe(self) -> str:
-        return "reconstructable using {module}.{fn_name}".format(
-            module=self.reconstructor_pointer.module, fn_name=self.reconstructor_pointer.fn_name
-        )
+        return f"reconstructable using {self.reconstructor_pointer.module}.{self.reconstructor_pointer.fn_name}"
 
     # Allow this to be hashed for use in `lru_cache`. This is needed because:
     # - `ReconstructableJob` uses `lru_cache`
     # - `ReconstructableJob` has a `ReconstructableRepository` attribute
     # - `ReconstructableRepository` has a `CodePointer` attribute
     # - `CustomCodePointer` has collection attributes that are unhashable by default
     def __hash__(self) -> int:
```

### Comparing `dagster-1.6.9/dagster/_core/container_context/config.py` & `dagster-1.7.0/dagster/_core/container_context/config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/debug.py` & `dagster-1.7.0/dagster/_core/debug.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/decorator_utils.py` & `dagster-1.7.0/dagster/_core/decorator_utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/__init__.py` & `dagster-1.7.0/dagster/_core/definitions/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -58,14 +58,15 @@
     MarkdownMetadataValue as MarkdownMetadataValue,
     MetadataEntry as MetadataEntry,
     MetadataValue as MetadataValue,
     PathMetadataValue as PathMetadataValue,
     PythonArtifactMetadataValue as PythonArtifactMetadataValue,
     TableColumn as TableColumn,
     TableColumnConstraints as TableColumnConstraints,
+    TableColumnLineageMetadataValue as TableColumnLineageMetadataValue,
     TableConstraints as TableConstraints,
     TableMetadataValue as TableMetadataValue,
     TableRecord as TableRecord,
     TableSchema as TableSchema,
     TableSchemaMetadataValue as TableSchemaMetadataValue,
     TextMetadataValue as TextMetadataValue,
     UrlMetadataValue as UrlMetadataValue,
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_check_evaluation.py` & `dagster-1.7.0/dagster/_core/definitions/asset_check_evaluation.py`

 * *Files 4% similar despite different names*

```diff
@@ -62,14 +62,15 @@
             ("passed", bool),
             ("metadata", Mapping[str, MetadataValue]),
             (
                 "target_materialization_data",
                 Optional[AssetCheckEvaluationTargetMaterializationData],
             ),
             ("severity", AssetCheckSeverity),
+            ("description", Optional[str]),
         ],
     )
 ):
     """Represents the outcome of a evaluating an asset check.
 
     Attributes:
         asset_key (AssetKey):
@@ -82,35 +83,39 @@
             Arbitrary user-provided metadata about the asset.  Keys are displayed string labels, and
             values are one of the following: string, float, int, JSON-serializable dict, JSON-serializable
             list, and one of the data classes returned by a MetadataValue static method.
         target_materialization_data (Optional[AssetCheckEvaluationTargetMaterializationData]):
             The latest materialization at execution time of the check.
         severity (AssetCheckSeverity):
             Severity of the check result.
+        description (Optional[str]):
+            A text description of the result of the check evaluation.
     """
 
     def __new__(
         cls,
         asset_key: AssetKey,
         check_name: str,
         passed: bool,
         metadata: Mapping[str, MetadataValue],
         target_materialization_data: Optional[AssetCheckEvaluationTargetMaterializationData] = None,
         severity: AssetCheckSeverity = AssetCheckSeverity.ERROR,
+        description: Optional[str] = None,
     ):
         return super(AssetCheckEvaluation, cls).__new__(
             cls,
             asset_key=check.inst_param(asset_key, "asset_key", AssetKey),
             check_name=check.str_param(check_name, "check_name"),
             passed=check.bool_param(passed, "passed"),
             metadata=check.dict_param(metadata, "metadata", key_type=str),
             target_materialization_data=check.opt_inst_param(
                 target_materialization_data,
                 "target_materialization_data",
                 AssetCheckEvaluationTargetMaterializationData,
             ),
             severity=check.inst_param(severity, "severity", AssetCheckSeverity),
+            description=check.opt_str_param(description, "description"),
         )
 
     @property
     def asset_check_key(self) -> AssetCheckKey:
         return AssetCheckKey(self.asset_key, self.check_name)
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_check_result.py` & `dagster-1.7.0/dagster/_core/definitions/asset_check_result.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import TYPE_CHECKING, Mapping, NamedTuple, Optional
 
 import dagster._check as check
-from dagster._annotations import PublicAttr, experimental
+from dagster._annotations import PublicAttr
 from dagster._core.definitions.asset_check_evaluation import (
     AssetCheckEvaluation,
     AssetCheckEvaluationTargetMaterializationData,
 )
 from dagster._core.definitions.asset_check_spec import AssetCheckSeverity
 from dagster._core.definitions.events import (
     AssetKey,
@@ -16,24 +16,24 @@
 )
 from dagster._core.errors import DagsterInvariantViolationError
 
 if TYPE_CHECKING:
     from dagster._core.execution.context.compute import StepExecutionContext
 
 
-@experimental
 class AssetCheckResult(
     NamedTuple(
         "_AssetCheckResult",
         [
             ("passed", PublicAttr[bool]),
             ("asset_key", PublicAttr[Optional[AssetKey]]),
             ("check_name", PublicAttr[Optional[str]]),
             ("metadata", PublicAttr[Mapping[str, MetadataValue]]),
             ("severity", PublicAttr[AssetCheckSeverity]),
+            ("description", PublicAttr[Optional[str]]),
         ],
     )
 ):
     """The result of an asset check.
 
     Attributes:
         asset_key (Optional[AssetKey]):
@@ -44,36 +44,39 @@
             The pass/fail result of the check.
         metadata (Optional[Dict[str, RawMetadataValue]]):
             Arbitrary metadata about the asset.  Keys are displayed string labels, and values are
             one of the following: string, float, int, JSON-serializable dict, JSON-serializable
             list, and one of the data classes returned by a MetadataValue static method.
         severity (AssetCheckSeverity):
             Severity of the check. Defaults to ERROR.
-
+        description (Optional[str]):
+            A text description of the result of the check evaluation.
     """
 
     def __new__(
         cls,
         *,
         passed: bool,
         asset_key: Optional[CoercibleToAssetKey] = None,
         check_name: Optional[str] = None,
         metadata: Optional[Mapping[str, RawMetadataValue]] = None,
         severity: AssetCheckSeverity = AssetCheckSeverity.ERROR,
+        description: Optional[str] = None,
     ):
         normalized_metadata = normalize_metadata(
             check.opt_mapping_param(metadata, "metadata", key_type=str),
         )
         return super().__new__(
             cls,
             asset_key=AssetKey.from_coercible(asset_key) if asset_key is not None else None,
             check_name=check.opt_str_param(check_name, "check_name"),
             passed=check.bool_param(passed, "passed"),
             metadata=normalized_metadata,
             severity=check.inst_param(severity, "severity", AssetCheckSeverity),
+            description=check.opt_str_param(description, "description"),
         )
 
     def to_asset_check_evaluation(
         self, step_context: "StepExecutionContext"
     ) -> AssetCheckEvaluation:
         spec_check_names_by_asset_key = (
             step_context.job_def.asset_layer.check_names_by_asset_key_by_node_handle.get(
@@ -129,15 +132,20 @@
                     " checks to choose from for the this asset key:"
                     f" {check_names_with_specs}"
                 )
 
             resolved_check_name = next(iter(check_names_with_specs))
 
         input_asset_info = step_context.get_input_asset_version_info(resolved_asset_key)
-        if input_asset_info is not None:
+        from dagster._core.events import DagsterEventType
+
+        if (
+            input_asset_info is not None
+            and input_asset_info.event_type == DagsterEventType.ASSET_MATERIALIZATION
+        ):
             target_materialization_data = AssetCheckEvaluationTargetMaterializationData(
                 run_id=input_asset_info.run_id,
                 storage_id=input_asset_info.storage_id,
                 timestamp=input_asset_info.timestamp,
             )
         else:
             target_materialization_data = None
@@ -145,14 +153,15 @@
         return AssetCheckEvaluation(
             check_name=resolved_check_name,
             asset_key=resolved_asset_key,
             passed=self.passed,
             metadata=self.metadata,
             target_materialization_data=target_materialization_data,
             severity=self.severity,
+            description=self.description,
         )
 
     def get_spec_python_identifier(
         self, *, asset_key: Optional[AssetKey] = None, check_name: Optional[str] = None
     ) -> str:
         """Returns a string uniquely identifying the asset check spec associated with this result.
         This is used for the output name associated with an `AssetCheckResult`.
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_check_spec.py` & `dagster-1.7.0/dagster/_core/definitions/asset_check_spec.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,41 +1,40 @@
 from enum import Enum
 from typing import TYPE_CHECKING, Any, Iterable, Mapping, NamedTuple, Optional, Union
 
 import dagster._check as check
-from dagster._annotations import PublicAttr, experimental
-from dagster._core.definitions.events import (
+from dagster._annotations import PublicAttr
+from dagster._core.definitions.asset_key import (
     AssetKey,
     CoercibleToAssetKey,
     CoercibleToAssetKeyPrefix,
 )
+from dagster._core.definitions.metadata import RawMetadataMapping
 from dagster._serdes.serdes import whitelist_for_serdes
 
 if TYPE_CHECKING:
     from dagster._core.definitions.asset_dep import AssetDep, CoercibleToAssetDep
     from dagster._core.definitions.assets import AssetsDefinition
     from dagster._core.definitions.source_asset import SourceAsset
 
 
-@experimental
 @whitelist_for_serdes
 class AssetCheckSeverity(Enum):
     """Severity level for an AssetCheckResult.
 
     - WARN: a potential issue with the asset
     - ERROR: a definite issue with the asset
 
     Severity does not impact execution of the asset or downstream assets.
     """
 
     WARN = "WARN"
     ERROR = "ERROR"
 
 
-@experimental(emit_runtime_warning=False)
 @whitelist_for_serdes(old_storage_names={"AssetCheckHandle"})
 class AssetCheckKey(NamedTuple):
     """Check names are expected to be unique per-asset. Thus, this combination of asset key and
     check name uniquely identifies an asset check within a deployment.
     """
 
     asset_key: PublicAttr[AssetKey]
@@ -47,25 +46,31 @@
             asset_key=AssetKey.from_graphql_input(graphql_input["assetKey"]),
             name=graphql_input["name"],
         )
 
     def with_asset_key_prefix(self, prefix: CoercibleToAssetKeyPrefix) -> "AssetCheckKey":
         return self._replace(asset_key=self.asset_key.with_prefix(prefix))
 
+    def to_user_string(self) -> str:
+        return f"{self.asset_key.to_user_string()}:{self.name}"
+
 
-@experimental
 class AssetCheckSpec(
     NamedTuple(
         "_AssetCheckSpec",
         [
             ("name", PublicAttr[str]),
             ("asset_key", PublicAttr[AssetKey]),
             ("description", PublicAttr[Optional[str]]),
             ("additional_deps", PublicAttr[Optional[Iterable["AssetDep"]]]),
-            ("blocking", PublicAttr[bool]),
+            (
+                "blocking",  # intentionally not public, see https://github.com/dagster-io/dagster/issues/20659
+                bool,
+            ),
+            ("metadata", PublicAttr[Optional[Mapping[str, Any]]]),
         ],
     )
 ):
     """Defines information about an asset check, except how to execute it.
 
     AssetCheckSpec is often used as an argument to decorators that decorator a function that can
     execute multiple checks - e.g. `@asset`, and `@multi_asset`. It defines one of the checks that
@@ -77,28 +82,26 @@
             the check applies to.
         description (Optional[str]): Description for the check.
         additional_deps (Optional[Iterable[AssetDep]]): Additional dependencies for the check. The
             check relies on these assets in some way, but the result of the check only applies to
             the asset specified by `asset`. For example, the check may test that `asset` has
             matching data with an asset in `additional_deps`. This field holds both `additional_deps`
             and `additional_ins` passed to @asset_check.
-        blocking (bool): When enabled, runs that include this check and any downstream assets that
-            depend on `asset` will wait for this check to complete before starting the downstream
-            assets. If the check fails with severity `AssetCheckSeverity.ERROR`, then the downstream
-            assets won't execute.
+        metadata (Optional[Mapping[str, Any]]):  A dict of static metadata for this asset check.
     """
 
     def __new__(
         cls,
         name: str,
         *,
         asset: Union[CoercibleToAssetKey, "AssetsDefinition", "SourceAsset"],
         description: Optional[str] = None,
         additional_deps: Optional[Iterable["CoercibleToAssetDep"]] = None,
         blocking: bool = False,
+        metadata: Optional[RawMetadataMapping] = None,
     ):
         from dagster._core.definitions.asset_dep import coerce_to_deps_and_check_duplicates
 
         asset_key = AssetKey.from_coercible_or_definition(asset)
 
         additional_asset_deps = coerce_to_deps_and_check_duplicates(
             additional_deps, AssetCheckKey(asset_key, name)
@@ -114,21 +117,22 @@
         return super().__new__(
             cls,
             name=check.str_param(name, "name"),
             asset_key=asset_key,
             description=check.opt_str_param(description, "description"),
             additional_deps=additional_asset_deps,
             blocking=check.bool_param(blocking, "blocking"),
+            metadata=check.opt_mapping_param(metadata, "metadata", key_type=str),
         )
 
     def get_python_identifier(self) -> str:
         """Returns a string uniquely identifying the asset check, that uses only the characters
         allowed in a Python identifier.
         """
-        return f"{self.asset_key.to_python_identifier()}_{self.name}"
+        return f"{self.asset_key.to_python_identifier()}_{self.name}".replace(".", "_")
 
     @property
     def key(self) -> AssetCheckKey:
         return AssetCheckKey(self.asset_key, self.name)
 
     def with_asset_key_prefix(self, prefix: CoercibleToAssetKeyPrefix) -> "AssetCheckSpec":
         return self._replace(asset_key=self.asset_key.with_prefix(prefix))
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_checks.py` & `dagster-1.7.0/dagster/_core/execution/plan/compute.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,262 +1,258 @@
+import asyncio
+import inspect
 from typing import (
-    TYPE_CHECKING,
     Any,
-    Dict,
-    Iterable,
+    AsyncIterator,
     Iterator,
+    List,
     Mapping,
-    NamedTuple,
-    Optional,
     Sequence,
     Set,
+    TypeVar,
+    Union,
 )
 
-from dagster import _check as check
-from dagster._annotations import experimental, public
-from dagster._core.definitions.asset_check_spec import AssetCheckKey, AssetCheckSpec
-from dagster._core.definitions.events import (
-    AssetKey,
-    CoercibleToAssetKeyPrefix,
+from typing_extensions import TypeAlias
+
+import dagster._check as check
+from dagster._core.definitions import (
+    AssetCheckEvaluation,
+    AssetCheckResult,
+    AssetMaterialization,
+    AssetObservation,
+    DynamicOutput,
+    ExpectationResult,
+    Node,
+    NodeHandle,
+    Output,
 )
-from dagster._core.definitions.node_definition import NodeDefinition
-from dagster._core.definitions.resource_definition import ResourceDefinition
-from dagster._core.definitions.resource_requirement import (
-    RequiresResources,
-    ResourceAddable,
-    ResourceRequirement,
-    merge_resource_defs,
+from dagster._core.definitions.asset_check_spec import AssetCheckKey
+from dagster._core.definitions.asset_layer import AssetLayer
+from dagster._core.definitions.op_definition import OpComputeFunction
+from dagster._core.definitions.result import AssetResult, MaterializeResult, ObserveResult
+from dagster._core.errors import (
+    DagsterExecutionStepExecutionError,
+    DagsterInvariantViolationError,
 )
-from dagster._core.errors import DagsterAssetCheckFailedError
-from dagster._core.types.dagster_type import Nothing
-
-if TYPE_CHECKING:
-    from dagster._core.definitions.assets import AssetsDefinition
-
-
-@experimental
-class AssetChecksDefinitionInputOutputProps(NamedTuple):
-    asset_check_keys_by_output_name: Mapping[str, AssetCheckKey]
-    asset_keys_by_input_name: Mapping[str, AssetKey]
-
-    def with_asset_key_prefix(
-        self, prefix: CoercibleToAssetKeyPrefix
-    ) -> "AssetChecksDefinitionInputOutputProps":
-        return self._replace(
-            asset_check_keys_by_output_name={
-                output_name: check_key.with_asset_key_prefix(prefix)
-                for output_name, check_key in self.asset_check_keys_by_output_name.items()
-            },
-            asset_keys_by_input_name={
-                input_name: asset_key.with_prefix(prefix)
-                for input_name, asset_key in self.asset_keys_by_input_name.items()
-            },
+from dagster._core.events import DagsterEvent
+from dagster._core.execution.context.compute import (
+    AssetCheckExecutionContext,
+    AssetExecutionContext,
+    OpExecutionContext,
+)
+from dagster._core.execution.context.system import StepExecutionContext
+from dagster._core.system_config.objects import ResolvedRunConfig
+from dagster._utils import iterate_with_context
+
+from .outputs import StepOutput, StepOutputProperties
+from .utils import op_execution_error_boundary
+
+T = TypeVar("T")
+
+OpOutputUnion: TypeAlias = Union[
+    DynamicOutput[Any],
+    Output[Any],
+    AssetMaterialization,
+    ExpectationResult,
+    AssetObservation,
+    DagsterEvent,
+    AssetCheckEvaluation,
+    AssetCheckResult,
+    MaterializeResult,
+    ObserveResult,
+]
+
+
+def create_step_outputs(
+    node: Node,
+    handle: NodeHandle,
+    resolved_run_config: ResolvedRunConfig,
+    asset_layer: AssetLayer,
+) -> Sequence[StepOutput]:
+    check.inst_param(node, "node", Node)
+    check.inst_param(handle, "handle", NodeHandle)
+
+    # the run config has the node output name configured
+    config_output_names: Set[str] = set()
+    current_handle = handle
+    while current_handle:
+        op_config = resolved_run_config.ops[current_handle.to_string()]
+        current_handle = current_handle.parent
+        config_output_names = config_output_names.union(op_config.outputs.output_names)
+
+    step_outputs: List[StepOutput] = []
+    for name, output_def in node.definition.output_dict.items():
+        asset_info = asset_layer.asset_info_for_output(handle, name)
+
+        step_outputs.append(
+            StepOutput(
+                node_handle=handle,
+                name=output_def.name,
+                dagster_type_key=output_def.dagster_type.key,
+                properties=StepOutputProperties(
+                    is_required=output_def.is_required,
+                    is_dynamic=output_def.is_dynamic,
+                    is_asset=asset_info is not None,
+                    should_materialize=output_def.name in config_output_names,
+                    asset_key=asset_info.key if asset_info and asset_info.is_required else None,
+                    is_asset_partitioned=bool(asset_info.partitions_def) if asset_info else False,
+                    asset_check_key=asset_layer.asset_check_key_for_output(handle, name),
+                ),
+            )
         )
+    return step_outputs
 
 
-@experimental
-class AssetChecksDefinition(ResourceAddable, RequiresResources):
-    """Defines a set of checks that are produced by the same op or op graph.
-
-    AssetChecksDefinition are typically not instantiated directly, but rather produced using a
-    decorator like :py:func:`@asset_check <asset>`.
-    """
-
-    def __init__(
-        self,
-        *,
-        node_def: NodeDefinition,
-        resource_defs: Mapping[str, ResourceDefinition],
-        specs: Sequence[AssetCheckSpec],
-        input_output_props: AssetChecksDefinitionInputOutputProps,
-        # if adding new fields, make sure to handle them in the get_attributes_dict method
+def _validate_event(event: Any, step_context: StepExecutionContext) -> OpOutputUnion:
+    if not isinstance(
+        event,
+        (
+            DynamicOutput,
+            Output,
+            AssetMaterialization,
+            ExpectationResult,
+            AssetObservation,
+            DagsterEvent,
+            AssetCheckResult,
+            AssetCheckEvaluation,
+            MaterializeResult,
+            ObserveResult,
+        ),
     ):
-        self._node_def = node_def
-        self._resource_defs = resource_defs
-        self._specs = check.sequence_param(specs, "specs", of_type=AssetCheckSpec)
-        self._input_output_props = check.inst_param(
-            input_output_props, "input_output_props", AssetChecksDefinitionInputOutputProps
-        )
-        self._specs_by_handle = {spec.key: spec for spec in specs}
-        self._specs_by_output_name = {
-            output_name: self._specs_by_handle[check_key]
-            for output_name, check_key in input_output_props.asset_check_keys_by_output_name.items()
-        }
-
-    @public
-    @property
-    def node_def(self) -> NodeDefinition:
-        """The op or op graph that can be executed to check the assets."""
-        return self._node_def
-
-    @public
-    @property
-    def name(self) -> str:
-        return self.spec.name
-
-    @public
-    @property
-    def description(self) -> Optional[str]:
-        return self.spec.description
-
-    @public
-    @property
-    def asset_key(self) -> AssetKey:
-        return self.spec.asset_key
-
-    @public
-    @property
-    def spec(self) -> AssetCheckSpec:
-        if len(self._specs_by_output_name) > 1:
-            check.failed(
-                "Tried to retrieve single-check property from a checks definition with multiple"
-                " checks: " + ", ".join(spec.name for spec in self._specs_by_output_name.values()),
+        raise DagsterInvariantViolationError(
+            (
+                f"Compute function for {step_context.describe_op()} yielded a value of type {type(event)} "
+                "rather than an instance of Output, AssetMaterialization, or ExpectationResult."
+                f" Values yielded by {step_context.op_def.node_type_str}s must be wrapped in one of these types. If your "
+                f"{step_context.op_def.node_type_str} has a single output and yields no other events, you may want to use "
+                f"`return` instead of `yield` in the body of your {step_context.op_def.node_type_str} compute function. If "
+                "you are already using `return`, and you expected to return a value of type "
+                f"{type(event)}, you may be inadvertently returning a generator rather than the value "
+                # f"you expected. Value is {str(event[0])}"
             )
+        )
 
-        return next(iter(self.specs))
+    return event
 
-    @public
-    @property
-    def specs(self) -> Iterable[AssetCheckSpec]:
-        return self._specs_by_output_name.values()
-
-    @property
-    def keys(self) -> Iterable[AssetCheckKey]:
-        return self._specs_by_handle.keys()
-
-    @property
-    def specs_by_output_name(self) -> Mapping[str, AssetCheckSpec]:
-        return self._specs_by_output_name
-
-    @property
-    def asset_keys_by_input_name(self) -> Mapping[str, AssetKey]:
-        return self._input_output_props.asset_keys_by_input_name
-
-    def get_resource_requirements(self) -> Iterator[ResourceRequirement]:
-        yield from self.node_def.get_resource_requirements()  # type: ignore[attr-defined]
-        for source_key, resource_def in self._resource_defs.items():
-            yield from resource_def.get_resource_requirements(outer_context=source_key)
-
-    def get_spec_for_check_key(self, asset_check_key: AssetCheckKey) -> AssetCheckSpec:
-        return self._specs_by_handle[asset_check_key]
-
-    @public
-    @property
-    def required_resource_keys(self) -> Set[str]:
-        """Set[str]: The set of keys for resources that must be provided to this AssetsDefinition."""
-        return {requirement.key for requirement in self.get_resource_requirements()}
-
-    @property
-    def resource_defs(self) -> Mapping[str, ResourceDefinition]:
-        return self._resource_defs
-
-    def with_resources(
-        self, resource_defs: Mapping[str, ResourceDefinition]
-    ) -> "AssetChecksDefinition":
-        attributes_dict = self.get_attributes_dict()
-        attributes_dict["resource_defs"] = merge_resource_defs(
-            old_resource_defs=self._resource_defs,
-            resource_defs_to_merge_in=resource_defs,
-            requires_resources=self,
-        )
-        return self.__class__(**attributes_dict)
 
-    def get_attributes_dict(self) -> Dict[str, Any]:
-        return dict(
-            node_def=self._node_def,
-            resource_defs=self._resource_defs,
-            specs=self._specs,
-            input_output_props=self._input_output_props,
+def gen_from_async_gen(async_gen: AsyncIterator[T]) -> Iterator[T]:
+    # prime use for asyncio.Runner, but new in 3.11 and did not find appealing backport
+    loop = asyncio.new_event_loop()
+    try:
+        while True:
+            try:
+                yield loop.run_until_complete(async_gen.__anext__())
+            except StopAsyncIteration:
+                return
+    finally:
+        loop.run_until_complete(loop.shutdown_asyncgens())
+        loop.close()
+
+
+def _yield_compute_results(
+    step_context: StepExecutionContext,
+    inputs: Mapping[str, Any],
+    compute_fn: OpComputeFunction,
+    compute_context: Union[OpExecutionContext, AssetExecutionContext, AssetCheckExecutionContext],
+) -> Iterator[OpOutputUnion]:
+    user_event_generator = compute_fn(compute_context, inputs)
+
+    if isinstance(user_event_generator, Output):
+        raise DagsterInvariantViolationError(
+            (
+                f"Compute function for {step_context.describe_op()} returned an Output rather than "
+                f"yielding it. The compute_fn of the {step_context.op_def.node_type_str} must yield "
+                "its results"
+            )
         )
 
-    def with_attributes(
-        self,
-        asset_key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
-    ) -> "AssetChecksDefinition":
-        attributes_dict = self.get_attributes_dict()
-        if asset_key_prefix is not None:
-            attributes_dict["specs"] = [
-                spec.with_asset_key_prefix(asset_key_prefix) for spec in self._specs
-            ]
-            attributes_dict["input_output_props"] = self._input_output_props.with_asset_key_prefix(
-                asset_key_prefix
-            )
+    if user_event_generator is None:
+        return
 
-        return AssetChecksDefinition(**attributes_dict)
+    if inspect.isasyncgen(user_event_generator):
+        user_event_generator = gen_from_async_gen(user_event_generator)
 
+    op_label = step_context.describe_op()
 
-@experimental
-def build_asset_with_blocking_check(
-    asset_def: "AssetsDefinition",
-    checks: Sequence[AssetChecksDefinition],
-) -> "AssetsDefinition":
-    from dagster import AssetIn, In, OpExecutionContext, Output, op
-    from dagster._core.definitions.decorators.asset_decorator import graph_asset_no_defaults
-    from dagster._core.storage.asset_check_execution_record import AssetCheckExecutionRecordStatus
-
-    check_specs = []
-    for c in checks:
-        check_specs.extend(c.specs)
-
-    check_output_names = [c.get_python_identifier() for c in check_specs]
-
-    check.invariant(len(asset_def.op.output_defs) == 1)
-    asset_out_type = asset_def.op.output_defs[0].dagster_type
-
-    @op(
-        name=f"{asset_def.op.name}_asset_and_checks",
-        ins={"asset_return_value": In(asset_out_type), "check_evaluations": In(Nothing)},
-    )
-    def fan_in_checks_and_asset_return_value(context: OpExecutionContext, asset_return_value: Any):
-        # we pass the asset_return_value through and store it again so that downstream assets can load it.
-        # This is a little silly- we only do this because this op has the asset key in its StepOutputProperties
-        # so the output is written to the right path. We could probably get the asset_def.op to write to the
-        # asset path (and make sure we don't override it here) to avoid the double write.
-        yield Output(asset_return_value)
-
-        for check_spec in check_specs:
-            executions = context.instance.event_log_storage.get_asset_check_execution_history(
-                check_key=check_spec.key, limit=1
+    for event in iterate_with_context(
+        lambda: op_execution_error_boundary(
+            DagsterExecutionStepExecutionError,
+            msg_fn=lambda: f"Error occurred while executing {op_label}:",
+            step_context=step_context,
+            step_key=step_context.step.key,
+            op_def_name=step_context.op_def.name,
+            op_name=step_context.op.name,
+        ),
+        user_event_generator,
+    ):
+        if compute_context.op_execution_context.has_events():
+            yield from compute_context.op_execution_context.consume_events()
+        yield _validate_event(event, step_context)
+
+    if compute_context.op_execution_context.has_events():
+        yield from compute_context.op_execution_context.consume_events()
+
+
+def execute_core_compute(
+    step_context: StepExecutionContext,
+    inputs: Mapping[str, Any],
+    compute_fn: OpComputeFunction,
+    compute_context: Union[OpExecutionContext, AssetExecutionContext, AssetCheckExecutionContext],
+) -> Iterator[OpOutputUnion]:
+    """Execute the user-specified compute for the op. Wrap in an error boundary and do
+    all relevant logging and metrics tracking.
+    """
+    step = step_context.step
+
+    emitted_result_names = set()
+    for step_output in _yield_compute_results(step_context, inputs, compute_fn, compute_context):
+        yield step_output
+        if isinstance(step_output, (DynamicOutput, Output)):
+            emitted_result_names.add(step_output.output_name)
+        elif isinstance(step_output, AssetResult):
+            asset_key = (
+                step_output.asset_key
+                or step_context.job_def.asset_layer.asset_key_for_node(step_context.node_handle)
             )
-            check.invariant(
-                len(executions) == 1, "Expected asset check {check_spec.name} to execute"
+            emitted_result_names.add(
+                step_context.job_def.asset_layer.node_output_handle_for_asset(asset_key).output_name
             )
-            execution = executions[0]
-            check.invariant(
-                execution.run_id == context.run_id,
-                "Expected asset check {check_spec.name} to execute in the current run",
+            # Check results embedded in MaterializeResult are counted
+            for check_result in step_output.check_results or []:
+                handle = check_result.to_asset_check_evaluation(step_context).asset_check_key
+                output_name = step_context.job_def.asset_layer.get_output_name_for_asset_check(
+                    handle
+                )
+                emitted_result_names.add(output_name)
+        elif isinstance(step_output, AssetCheckEvaluation):
+            output_name = step_context.job_def.asset_layer.get_output_name_for_asset_check(
+                step_output.asset_check_key
             )
-            if execution.status != AssetCheckExecutionRecordStatus.SUCCEEDED:
-                raise DagsterAssetCheckFailedError()
+            emitted_result_names.add(output_name)
+        elif isinstance(step_output, AssetCheckResult):
+            if step_output.asset_key and step_output.check_name:
+                handle = AssetCheckKey(step_output.asset_key, step_output.check_name)
+            else:
+                handle = step_output.to_asset_check_evaluation(step_context).asset_check_key
+            output_name = step_context.job_def.asset_layer.get_output_name_for_asset_check(handle)
+            emitted_result_names.add(output_name)
+
+    expected_op_output_names = {
+        output.name
+        for output in step.step_outputs
+        # checks are required if we're in requires_typed_event_stream mode
+        if step_context.requires_typed_event_stream or output.properties.asset_check_key
+    }
+    omitted_outputs = expected_op_output_names.difference(emitted_result_names)
+    if omitted_outputs:
+        message = (
+            f"{step_context.op_def.node_type_str} '{step.node_handle}' did not yield or return "
+            f"expected outputs {omitted_outputs!r}."
+        )
 
-    # kwargs are the inputs to the asset_def.op that we are wrapping
-    def blocking_asset(**kwargs):
-        asset_return_value = asset_def.op.with_replaced_properties(
-            name=f"{asset_def.op.name}_graph_asset_op"
-        )(**kwargs)
-        check_evaluations = [check.node_def(asset_return_value) for check in checks]
-
-        return {
-            "result": fan_in_checks_and_asset_return_value(asset_return_value, check_evaluations),
-            **{
-                check_output_name: check_result
-                for check_output_name, check_result in zip(check_output_names, check_evaluations)
-            },
-        }
-
-    return graph_asset_no_defaults(
-        compose_fn=blocking_asset,
-        name=None,
-        key_prefix=None,
-        key=asset_def.key,
-        group_name=asset_def.group_names_by_key.get(asset_def.key),
-        partitions_def=asset_def.partitions_def,
-        check_specs=check_specs,
-        description=asset_def.descriptions_by_key.get(asset_def.key),
-        ins={name: AssetIn(key) for name, key in asset_def.keys_by_input_name.items()},
-        resource_defs=asset_def.resource_defs,
-        metadata=asset_def.metadata_by_key.get(asset_def.key),
-        freshness_policy=asset_def.freshness_policies_by_key.get(asset_def.key),
-        auto_materialize_policy=asset_def.auto_materialize_policies_by_key.get(asset_def.key),
-        backfill_policy=asset_def.backfill_policy,
-        config=None,  # gets config from asset_def.op
-    )
+        if step_context.requires_typed_event_stream:
+            if step_context.typed_event_stream_error_message:
+                message += " " + step_context.typed_event_stream_error_message
+            raise DagsterInvariantViolationError(message)
+        else:
+            step_context.log.info(message)
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_condition/asset_condition.py` & `dagster-1.7.0/dagster/_core/definitions/asset_condition/asset_condition.py`

 * *Files 3% similar despite different names*

```diff
@@ -16,14 +16,15 @@
     TypeVar,
     Union,
 )
 
 import pendulum
 
 import dagster._check as check
+from dagster._annotations import experimental
 from dagster._core.definitions.events import AssetKey
 from dagster._core.definitions.metadata import MetadataMapping, MetadataValue
 from dagster._core.definitions.partition import AllPartitionsSubset
 from dagster._serdes.serdes import PackableValue, whitelist_for_serdes
 
 from ..asset_subset import AssetSubset, ValidAssetSubset
 
@@ -302,18 +303,30 @@
         return self.evaluation.asset_key
 
     @property
     def num_requested(self) -> int:
         return self.evaluation.true_subset.size
 
 
-class AssetCondition(ABC):
+# Adding the NamedTuple inheritance to avoid bugs with the experimental decorator and subclasses.
+@experimental
+class AssetCondition(NamedTuple("_AssetCondition", []), ABC):
     """An AssetCondition represents some state of the world that can influence if an asset
-    partition should be materialized or not. AutomationConditions can be combined together to create
+    partition should be materialized or not. AssetConditions can be combined to create
     new conditions using the `&` (and), `|` (or), and `~` (not) operators.
+
+    Examples:
+        .. code-block:: python
+
+            from dagster import AssetCondition, AutoMaterializePolicy
+
+            # At least one parent is newer and no parent is missing.
+            my_policy = AutoMaterializePolicy(
+                asset_condition = AssetCondition.parent_newer() & ~AssetCondition.parent_missing()
+            )
     """
 
     @property
     def unique_id(self) -> str:
         parts = [
             self.__class__.__name__,
             *[child.unique_id for child in self.children],
@@ -325,21 +338,21 @@
         raise NotImplementedError()
 
     @abstractproperty
     def description(self) -> str:
         raise NotImplementedError()
 
     def __and__(self, other: "AssetCondition") -> "AssetCondition":
-        # group AndAutomationConditions together
+        # group AndAssetConditions together
         if isinstance(self, AndAssetCondition):
             return AndAssetCondition(children=[*self.children, other])
         return AndAssetCondition(children=[self, other])
 
     def __or__(self, other: "AssetCondition") -> "AssetCondition":
-        # group OrAutomationConditions together
+        # group OrAssetConditions together
         if isinstance(self, OrAssetCondition):
             return OrAssetCondition(children=[*self.children, other])
         return OrAssetCondition(children=[self, other])
 
     def __invert__(self) -> "AssetCondition":
         return NotAssetCondition(children=[self])
 
@@ -427,15 +440,16 @@
         from ..auto_materialize_rule import AutoMaterializeRule
 
         return ~RuleCondition(
             AutoMaterializeRule.skip_on_not_all_parents_updated_since_cron(cron_schedule, timezone)
         )
 
 
-class RuleCondition(
+@experimental
+class RuleCondition(  # type: ignore # related to AssetCondition being experimental
     NamedTuple("_RuleCondition", [("rule", "AutoMaterializeRule")]),
     AssetCondition,
 ):
     """This class represents the condition that a particular AutoMaterializeRule is satisfied."""
 
     @property
     def unique_id(self) -> str:
@@ -443,26 +457,27 @@
         return hashlib.md5("".join(parts).encode()).hexdigest()
 
     @property
     def description(self) -> str:
         return self.rule.description
 
     def evaluate(self, context: "AssetConditionEvaluationContext") -> AssetConditionResult:
-        context.root_context.daemon_context._verbose_log_fn(  # noqa
+        context.root_context.daemon_context.logger.debug(
             f"Evaluating rule: {self.rule.to_snapshot()}"
         )
         evaluation_result = self.rule.evaluate_for_asset(context)
-        context.root_context.daemon_context._verbose_log_fn(  # noqa
+        context.root_context.daemon_context.logger.debug(
             f"Rule returned {evaluation_result.true_subset.size} partitions "
             f"({evaluation_result.end_timestamp - evaluation_result.start_timestamp:.2f} seconds)"
         )
         return evaluation_result
 
 
-class AndAssetCondition(
+@experimental
+class AndAssetCondition(  # type: ignore # related to AssetCondition being experimental
     NamedTuple("_AndAssetCondition", [("children", Sequence[AssetCondition])]),
     AssetCondition,
 ):
     """This class represents the condition that all of its children evaluate to true."""
 
     @property
     def description(self) -> str:
@@ -475,15 +490,16 @@
             child_context = context.for_child(condition=child, candidate_subset=true_subset)
             child_result = child.evaluate(child_context)
             child_results.append(child_result)
             true_subset &= child_result.true_subset
         return AssetConditionResult.create_from_children(context, true_subset, child_results)
 
 
-class OrAssetCondition(
+@experimental
+class OrAssetCondition(  # type: ignore # related to AssetCondition being experimental
     NamedTuple("_OrAssetCondition", [("children", Sequence[AssetCondition])]),
     AssetCondition,
 ):
     """This class represents the condition that any of its children evaluate to true."""
 
     @property
     def description(self) -> str:
@@ -498,15 +514,16 @@
             )
             child_result = child.evaluate(child_context)
             child_results.append(child_result)
             true_subset |= child_result.true_subset
         return AssetConditionResult.create_from_children(context, true_subset, child_results)
 
 
-class NotAssetCondition(
+@experimental
+class NotAssetCondition(  # type: ignore # related to AssetCondition being experimental
     NamedTuple("_NotAssetCondition", [("children", Sequence[AssetCondition])]),
     AssetCondition,
 ):
     """This class represents the condition that none of its children evaluate to true."""
 
     def __new__(cls, children: Sequence[AssetCondition]):
         check.invariant(len(children) == 1)
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_condition/asset_condition_evaluation_context.py` & `dagster-1.7.0/dagster/_core/definitions/asset_condition/asset_condition_evaluation_context.py`

 * *Files 5% similar despite different names*

```diff
@@ -25,16 +25,16 @@
 from dagster._core.definitions.events import AssetKey, AssetKeyPartitionKey
 from dagster._core.definitions.metadata import MetadataValue
 from dagster._core.definitions.partition import PartitionsDefinition
 from dagster._core.definitions.partition_mapping import IdentityPartitionMapping
 from dagster._core.definitions.time_window_partition_mapping import TimeWindowPartitionMapping
 from dagster._utils.caching_instance_queryer import CachingInstanceQueryer
 
-from ..asset_graph import AssetGraph
 from ..asset_subset import AssetSubset, ValidAssetSubset
+from ..base_asset_graph import BaseAssetGraph
 
 if TYPE_CHECKING:
     from ..asset_daemon_context import AssetDaemonContext
     from .asset_condition import (
         AssetCondition,
         AssetConditionEvaluation,
         AssetConditionEvaluationState,
@@ -84,15 +84,15 @@
         previous_evaluation_state: Optional["AssetConditionEvaluationState"],
         instance_queryer: CachingInstanceQueryer,
         data_time_resolver: CachingDataTimeResolver,
         daemon_context: "AssetDaemonContext",
         evaluation_state_by_key: Mapping[AssetKey, "AssetConditionEvaluationState"],
         expected_data_time_mapping: Mapping[AssetKey, Optional[datetime.datetime]],
     ) -> "AssetConditionEvaluationContext":
-        partitions_def = instance_queryer.asset_graph.get_partitions_def(asset_key)
+        partitions_def = instance_queryer.asset_graph.get(asset_key).partitions_def
 
         return AssetConditionEvaluationContext(
             asset_key=asset_key,
             condition=condition,
             previous_evaluation_state=previous_evaluation_state,
             previous_evaluation=previous_evaluation_state.previous_evaluation
             if previous_evaluation_state
@@ -127,20 +127,20 @@
 
     @property
     def root_context(self) -> "AssetConditionEvaluationContext":
         """A reference to the context of the root condition for this evaluation."""
         return self.root_ref or self
 
     @property
-    def asset_graph(self) -> AssetGraph:
+    def asset_graph(self) -> BaseAssetGraph:
         return self.instance_queryer.asset_graph
 
     @property
     def partitions_def(self) -> Optional[PartitionsDefinition]:
-        return self.asset_graph.get_partitions_def(self.asset_key)
+        return self.asset_graph.get(self.asset_key).partitions_def
 
     @property
     def evaluation_time(self) -> datetime.datetime:
         """Returns the time at which this rule is being evaluated."""
         return self.instance_queryer.evaluation_time
 
     @property
@@ -186,15 +186,15 @@
     @functools.cached_property
     @root_property
     def parent_will_update_subset(self) -> ValidAssetSubset:
         """Returns the set of asset partitions whose parents will be updated on this tick, and which
         can be materialized in the same run as this asset.
         """
         subset = self.empty_subset()
-        for parent_key in self.asset_graph.get_parents(self.asset_key):
+        for parent_key in self.asset_graph.get(self.asset_key).parent_keys:
             if not self.materializable_in_same_run(self.asset_key, parent_key):
                 continue
             parent_info = self.evaluation_state_by_key.get(parent_key)
             if not parent_info:
                 continue
             parent_subset = parent_info.true_subset.as_valid(self.partitions_def)
             subset |= parent_subset._replace(asset_key=self.asset_key)
@@ -296,33 +296,35 @@
             self.previous_evaluation.candidate_subset, HistoricalAllPartitionsSubsetSentinel
         ):
             return self.empty_subset()
         return self.candidate_subset - self.previous_evaluation.candidate_subset
 
     def materializable_in_same_run(self, child_key: AssetKey, parent_key: AssetKey) -> bool:
         """Returns whether a child asset can be materialized in the same run as a parent asset."""
-        from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
+        from dagster._core.definitions.remote_asset_graph import RemoteAssetGraph
 
+        child_node = self.asset_graph.get(child_key)
+        parent_node = self.asset_graph.get(parent_key)
         return (
             # both assets must be materializable
-            child_key in self.asset_graph.materializable_asset_keys
-            and parent_key in self.asset_graph.materializable_asset_keys
+            child_node.is_materializable
+            and parent_node.is_materializable
             # the parent must have the same partitioning
-            and self.asset_graph.have_same_partitioning(child_key, parent_key)
+            and child_node.partitions_def == parent_node.partitions_def
             # the parent must have a simple partition mapping to the child
             and (
-                not self.asset_graph.is_partitioned(parent_key)
+                not parent_node.is_partitioned
                 or isinstance(
-                    self.asset_graph.get_partition_mapping(child_key, parent_key),
+                    self.asset_graph.get_partition_mapping(child_node.key, parent_node.key),
                     (TimeWindowPartitionMapping, IdentityPartitionMapping),
                 )
             )
             # the parent must be in the same repository to be materialized alongside the candidate
             and (
-                not isinstance(self.asset_graph, ExternalAssetGraph)
+                not isinstance(self.asset_graph, RemoteAssetGraph)
                 or self.asset_graph.get_repository_handle(child_key)
                 == self.asset_graph.get_repository_handle(parent_key)
             )
         )
 
     def get_parents_that_will_not_be_materialized_on_current_tick(
         self, *, asset_partition: AssetKeyPartitionKey
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_daemon_context.py` & `dagster-1.7.0/dagster/_core/definitions/asset_daemon_context.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 import datetime
 import logging
-import os
 import time
 from collections import defaultdict
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Any,
     Dict,
@@ -34,32 +33,32 @@
 from ... import PartitionKeyRange
 from ..storage.tags import ASSET_PARTITION_RANGE_END_TAG, ASSET_PARTITION_RANGE_START_TAG
 from .asset_condition.asset_condition import AssetConditionEvaluation, AssetConditionEvaluationState
 from .asset_condition.asset_condition_evaluation_context import (
     AssetConditionEvaluationContext,
 )
 from .asset_daemon_cursor import AssetDaemonCursor
-from .asset_graph import AssetGraph
 from .auto_materialize_rule import AutoMaterializeRule
 from .backfill_policy import BackfillPolicy, BackfillPolicyType
+from .base_asset_graph import BaseAssetGraph
 from .freshness_based_auto_materialize import get_expected_data_time_for_asset_key
 from .partition import PartitionsDefinition, ScheduleType
 
 if TYPE_CHECKING:
     from dagster._core.instance import DagsterInstance
     from dagster._utils.caching_instance_queryer import CachingInstanceQueryer  # expensive import
 
 
 def get_implicit_auto_materialize_policy(
-    asset_key: AssetKey, asset_graph: AssetGraph
+    asset_key: AssetKey, asset_graph: BaseAssetGraph
 ) -> Optional[AutoMaterializePolicy]:
     """For backcompat with pre-auto materialize policy graphs, assume a default scope of 1 day."""
-    auto_materialize_policy = asset_graph.get_auto_materialize_policy(asset_key)
+    auto_materialize_policy = asset_graph.get(asset_key).auto_materialize_policy
     if auto_materialize_policy is None:
-        time_partitions_def = get_time_partitions_def(asset_graph.get_partitions_def(asset_key))
+        time_partitions_def = get_time_partitions_def(asset_graph.get(asset_key).partitions_def)
         if time_partitions_def is None:
             max_materializations_per_minute = None
         elif time_partitions_def.schedule_type == ScheduleType.HOURLY:
             max_materializations_per_minute = 24
         else:
             max_materializations_per_minute = 1
         rules = {
@@ -80,15 +79,15 @@
 
 
 class AssetDaemonContext:
     def __init__(
         self,
         evaluation_id: int,
         instance: "DagsterInstance",
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         cursor: AssetDaemonCursor,
         materialize_run_tags: Optional[Mapping[str, str]],
         observe_run_tags: Optional[Mapping[str, str]],
         auto_observe_asset_keys: Optional[AbstractSet[AssetKey]],
         auto_materialize_asset_keys: Optional[AbstractSet[AssetKey]],
         respect_materialization_data_versions: bool,
         logger: logging.Logger,
@@ -105,55 +104,53 @@
         self._auto_materialize_asset_keys = auto_materialize_asset_keys or set()
         self._materialize_run_tags = materialize_run_tags
         self._observe_run_tags = observe_run_tags
         self._auto_observe_asset_keys = auto_observe_asset_keys or set()
         self._respect_materialization_data_versions = respect_materialization_data_versions
         self._logger = logger
 
-        self._verbose_log_fn = (
-            self._logger.info if os.getenv("ASSET_DAEMON_VERBOSE_LOGS") else self._logger.debug
-        )
-
         # cache data before the tick starts
         self.prefetch()
 
     @property
+    def logger(self) -> logging.Logger:
+        return self._logger
+
+    @property
     def instance_queryer(self) -> "CachingInstanceQueryer":
         return self._instance_queryer
 
     @property
     def data_time_resolver(self) -> CachingDataTimeResolver:
         return self._data_time_resolver
 
     @property
     def cursor(self) -> AssetDaemonCursor:
         return self._cursor
 
     @property
-    def asset_graph(self) -> AssetGraph:
+    def asset_graph(self) -> BaseAssetGraph:
         return self.instance_queryer.asset_graph
 
     @property
     def auto_materialize_asset_keys(self) -> AbstractSet[AssetKey]:
         return self._auto_materialize_asset_keys
 
     @property
     def auto_materialize_asset_keys_and_parents(self) -> AbstractSet[AssetKey]:
         return {
             parent
             for asset_key in self.auto_materialize_asset_keys
-            for parent in self.asset_graph.get_parents(asset_key)
+            for parent in self.asset_graph.get(asset_key).parent_keys
         } | self.auto_materialize_asset_keys
 
     @property
     def asset_records_to_prefetch(self) -> Sequence[AssetKey]:
         return [
-            key
-            for key in self.auto_materialize_asset_keys_and_parents
-            if self.asset_graph.has_asset(key)
+            key for key in self.auto_materialize_asset_keys_and_parents if self.asset_graph.has(key)
         ]
 
     @property
     def respect_materialization_data_versions(self) -> bool:
         return self._respect_materialization_data_versions
 
     @property
@@ -188,15 +185,15 @@
             - expected_data_time_mapping: A mapping of AssetKey to the expected data time of the
                 asset after this tick. As this function is called in topological order, this mapping
                 will contain the expected data times of all upstream assets.
 
         """
         # convert the legacy AutoMaterializePolicy to an Evaluator
         asset_condition = check.not_none(
-            self.asset_graph.get_auto_materialize_policy(asset_key)
+            self.asset_graph.get(asset_key).auto_materialize_policy
         ).to_asset_condition()
 
         asset_cursor = self.cursor.get_previous_evaluation_state(asset_key)
 
         context = AssetConditionEvaluationContext.create(
             asset_key=asset_key,
             previous_evaluation_state=asset_cursor,
@@ -232,15 +229,15 @@
         for asset_key in self.asset_graph.toposorted_asset_keys:
             # an asset may have already been visited if it was part of a non-subsettable multi-asset
             if asset_key not in self.auto_materialize_asset_keys:
                 continue
 
             num_checked_assets = num_checked_assets + 1
             start_time = time.time()
-            self._verbose_log_fn(
+            self._logger.debug(
                 "Evaluating asset"
                 f" {asset_key.to_user_string()} ({num_checked_assets}/{num_auto_materialize_asset_keys})"
             )
 
             try:
                 (evaluation_state, expected_data_time) = self.evaluate_asset(
                     asset_key, evaluation_state_by_key, expected_data_time_mapping
@@ -265,16 +262,17 @@
             )
 
             evaluation_state_by_key[asset_key] = evaluation_state
             expected_data_time_mapping[asset_key] = expected_data_time
 
             # if we need to materialize any partitions of a non-subsettable multi-asset, we need to
             # materialize all of them
-            if num_requested > 0:
-                for neighbor_key in self.asset_graph.get_required_multi_asset_keys(asset_key):
+            execution_set_keys = self.asset_graph.get(asset_key).execution_set_asset_keys
+            if len(execution_set_keys) > 1 and num_requested > 0:
+                for neighbor_key in execution_set_keys:
                     expected_data_time_mapping[neighbor_key] = expected_data_time
 
                     # make sure that the true_subset of the neighbor is accurate -- when it was
                     # evaluated it may have had a different requested AssetSubset. however, because
                     # all these neighbors must be executed as a unit, we need to union together
                     # the subset of all required neighbors
                     if neighbor_key in evaluation_state_by_key:
@@ -341,24 +339,24 @@
                 )
             ],
         )
 
 
 def build_run_requests(
     asset_partitions: Iterable[AssetKeyPartitionKey],
-    asset_graph: AssetGraph,
+    asset_graph: BaseAssetGraph,
     run_tags: Optional[Mapping[str, str]],
 ) -> Sequence[RunRequest]:
     assets_to_reconcile_by_partitions_def_partition_key: Mapping[
         Tuple[Optional[PartitionsDefinition], Optional[str]], Set[AssetKey]
     ] = defaultdict(set)
 
     for asset_partition in asset_partitions:
         assets_to_reconcile_by_partitions_def_partition_key[
-            asset_graph.get_partitions_def(asset_partition.asset_key), asset_partition.partition_key
+            asset_graph.get(asset_partition.asset_key).partitions_def, asset_partition.partition_key
         ].add(asset_partition.asset_key)
 
     run_requests = []
 
     for (
         partitions_def,
         partition_key,
@@ -388,15 +386,15 @@
     # to time windows seemed more risky from a perf perspective, so we didn't include it here, but
     # it could make sense to actually benchmark that in the future.
     return sorted(run_requests, key=lambda x: x.partition_key if x.partition_key else "")
 
 
 def build_run_requests_with_backfill_policies(
     asset_partitions: Iterable[AssetKeyPartitionKey],
-    asset_graph: AssetGraph,
+    asset_graph: BaseAssetGraph,
     run_tags: Optional[Mapping[str, str]],
     dynamic_partitions_store: DynamicPartitionsStore,
 ) -> Sequence[RunRequest]:
     """If all assets have backfill policies, we should respect them and materialize them according
     to their backfill policies.
     """
     run_requests = []
@@ -411,15 +409,15 @@
     assets_to_reconcile_by_partitions_def_partition_keys: Mapping[
         Tuple[Optional[PartitionsDefinition], Optional[FrozenSet[str]]], Set[AssetKey]
     ] = defaultdict(set)
 
     # here we are grouping assets by their partitions def and partition keys selected.
     for asset_key, partition_keys in asset_partition_keys.items():
         assets_to_reconcile_by_partitions_def_partition_keys[
-            asset_graph.get_partitions_def(asset_key),
+            asset_graph.get(asset_key).partitions_def,
             frozenset(partition_keys) if partition_keys else None,
         ].add(asset_key)
 
     for (
         partitions_def,
         partition_keys,
     ), asset_keys in assets_to_reconcile_by_partitions_def_partition_keys.items():
@@ -429,15 +427,15 @@
         if partitions_def is not None and partition_keys is None:
             check.failed("Partition key missing for partitioned asset")
         if partitions_def is None and partition_keys is None:
             # non partitioned assets will be backfilled in a single run
             run_requests.append(RunRequest(asset_selection=list(asset_keys), tags=tags))
         else:
             backfill_policies = {
-                check.not_none(asset_graph.get_backfill_policy(asset_key))
+                check.not_none(asset_graph.get(asset_key).backfill_policy)
                 for asset_key in asset_keys
             }
             if len(backfill_policies) == 1:
                 # if all backfill policies are the same, we can backfill them together
                 backfill_policy = backfill_policies.pop()
                 run_requests.extend(
                     _build_run_requests_with_backfill_policy(
@@ -448,15 +446,15 @@
                         tags,
                         dynamic_partitions_store=dynamic_partitions_store,
                     )
                 )
             else:
                 # if backfill policies are different, we need to backfill them separately
                 for asset_key in asset_keys:
-                    backfill_policy = asset_graph.get_backfill_policy(asset_key)
+                    backfill_policy = asset_graph.get(asset_key).backfill_policy
                     run_requests.extend(
                         _build_run_requests_with_backfill_policy(
                             [asset_key],
                             check.not_none(backfill_policy),
                             check.not_none(partition_keys),
                             check.not_none(partitions_def),
                             tags,
@@ -555,22 +553,22 @@
     }
     return RunRequest(asset_selection=asset_keys, tags=tags)
 
 
 def get_auto_observe_run_requests(
     last_observe_request_timestamp_by_asset_key: Mapping[AssetKey, float],
     current_timestamp: float,
-    asset_graph: AssetGraph,
+    asset_graph: BaseAssetGraph,
     run_tags: Optional[Mapping[str, str]],
     auto_observe_asset_keys: AbstractSet[AssetKey],
 ) -> Sequence[RunRequest]:
     assets_to_auto_observe: Set[AssetKey] = set()
     for asset_key in auto_observe_asset_keys:
         last_observe_request_timestamp = last_observe_request_timestamp_by_asset_key.get(asset_key)
-        auto_observe_interval_minutes = asset_graph.get_auto_observe_interval_minutes(asset_key)
+        auto_observe_interval_minutes = asset_graph.get(asset_key).auto_observe_interval_minutes
 
         if auto_observe_interval_minutes and (
             last_observe_request_timestamp is None
             or (
                 last_observe_request_timestamp + auto_observe_interval_minutes * 60
                 < current_timestamp
             )
@@ -578,15 +576,15 @@
             assets_to_auto_observe.add(asset_key)
 
     # create groups of asset keys that share the same repository AND the same partitions definition
     partitions_def_and_asset_key_groups: List[Sequence[AssetKey]] = []
     for repository_asset_keys in asset_graph.split_asset_keys_by_repository(assets_to_auto_observe):
         asset_keys_by_partitions_def = defaultdict(list)
         for asset_key in repository_asset_keys:
-            partitions_def = asset_graph.get_partitions_def(asset_key)
+            partitions_def = asset_graph.get(asset_key).partitions_def
             asset_keys_by_partitions_def[partitions_def].append(asset_key)
         partitions_def_and_asset_key_groups.extend(asset_keys_by_partitions_def.values())
 
     return [
         RunRequest(asset_selection=list(asset_keys), tags=run_tags)
         for asset_keys in partitions_def_and_asset_key_groups
         if len(asset_keys) > 0
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_daemon_cursor.py` & `dagster-1.7.0/dagster/_core/definitions/asset_daemon_cursor.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,15 +21,15 @@
     UnpackContext,
     WhitelistMap,
     pack_value,
     unpack_value,
     whitelist_for_serdes,
 )
 
-from .asset_graph import AssetGraph
+from .base_asset_graph import BaseAssetGraph
 
 if TYPE_CHECKING:
     from .asset_condition.asset_condition import (
         AssetConditionEvaluation,
         AssetConditionEvaluationState,
         AssetConditionSnapshot,
     )
@@ -164,15 +164,15 @@
         }
         if handled_root_subset and handled_root_subset.size > 0
         else {},
     )
 
 
 def backcompat_deserialize_asset_daemon_cursor_str(
-    cursor_str: str, asset_graph: Optional[AssetGraph], default_evaluation_id: int
+    cursor_str: str, asset_graph: Optional[BaseAssetGraph], default_evaluation_id: int
 ) -> AssetDaemonCursor:
     """This serves as a backcompat layer for deserializing the old cursor format. Some information
     is impossible to fully recover, this will recover enough to continue operating as normal.
     """
     from .asset_condition.asset_condition import AssetConditionEvaluation, AssetConditionSnapshot
     from .auto_materialize_rule_evaluation import (
         deserialize_auto_materialize_asset_evaluation_to_asset_condition_evaluation_with_run_ids,
@@ -195,15 +195,15 @@
         AssetKey.from_user_string(key_str): timestamp
         for key_str, timestamp in serialized_last_observe_request_timestamp_by_asset_key.items()
     }
 
     partition_subsets_by_asset_key = {}
     for key_str, serialized_str in data.get("handled_root_partitions_by_asset_key", {}).items():
         asset_key = AssetKey.from_user_string(key_str)
-        partitions_def = asset_graph.get_partitions_def(asset_key) if asset_graph else None
+        partitions_def = asset_graph.get(asset_key).partitions_def if asset_graph else None
         if not partitions_def:
             continue
         try:
             partition_subsets_by_asset_key[asset_key] = partitions_def.deserialize_subset(
                 serialized_str
             )
         except:
@@ -217,15 +217,15 @@
         partitions_subsets_by_asset_key=partition_subsets_by_asset_key,
     )
 
     serialized_latest_evaluation_by_asset_key = data.get("latest_evaluation_by_asset_key", {})
     latest_evaluation_by_asset_key = {}
     for key_str, serialized_evaluation in serialized_latest_evaluation_by_asset_key.items():
         key = AssetKey.from_user_string(key_str)
-        partitions_def = asset_graph.get_partitions_def(key) if asset_graph else None
+        partitions_def = asset_graph.get(key).partitions_def if asset_graph else None
 
         evaluation = deserialize_auto_materialize_asset_evaluation_to_asset_condition_evaluation_with_run_ids(
             serialized_evaluation, partitions_def
         ).evaluation
 
         latest_evaluation_by_asset_key[key] = evaluation
 
@@ -235,15 +235,15 @@
         if asset_graph
         else latest_evaluation_by_asset_key.keys()
     )
     for asset_key in cursor_keys:
         latest_evaluation_result = latest_evaluation_by_asset_key.get(asset_key)
         # create a placeholder evaluation result if we don't have one
         if not latest_evaluation_result:
-            partitions_def = asset_graph.get_partitions_def(asset_key) if asset_graph else None
+            partitions_def = asset_graph.get(asset_key).partitions_def if asset_graph else None
             latest_evaluation_result = AssetConditionEvaluation(
                 condition_snapshot=AssetConditionSnapshot("", "", ""),
                 true_subset=AssetSubset.empty(asset_key, partitions_def),
                 candidate_subset=AssetSubset.empty(asset_key, partitions_def),
                 start_timestamp=None,
                 end_timestamp=None,
                 subsets_with_metadata=[],
@@ -268,11 +268,11 @@
 
 @whitelist_for_serdes
 class LegacyAssetDaemonCursorWrapper(NamedTuple):
     """Wrapper class for the legacy AssetDaemonCursor object, which is not a serializable NamedTuple."""
 
     serialized_cursor: str
 
-    def get_asset_daemon_cursor(self, asset_graph: Optional[AssetGraph]) -> AssetDaemonCursor:
+    def get_asset_daemon_cursor(self, asset_graph: Optional[BaseAssetGraph]) -> AssetDaemonCursor:
         return backcompat_deserialize_asset_daemon_cursor_str(
             self.serialized_cursor, asset_graph, 0
         )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_dep.py` & `dagster-1.7.0/dagster/_core/definitions/asset_dep.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_graph.py` & `dagster-1.7.0/dagster/_core/definitions/base_asset_graph.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,49 +1,54 @@
-import functools
 from abc import ABC, abstractmethod
 from collections import deque
 from datetime import datetime
+from functools import cached_property, total_ordering
 from heapq import heapify, heappop, heappush
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Callable,
     Dict,
+    Generic,
     Iterable,
     Iterator,
     Mapping,
     NamedTuple,
     Optional,
     Sequence,
     Set,
+    TypeVar,
     Union,
     cast,
 )
 
 import toposort
 
 import dagster._check as check
+from dagster._core.definitions.asset_check_spec import AssetCheckKey
 from dagster._core.definitions.asset_subset import ValidAssetSubset
 from dagster._core.definitions.auto_materialize_policy import AutoMaterializePolicy
+from dagster._core.definitions.backfill_policy import BackfillPolicy
+from dagster._core.definitions.events import AssetKey
+from dagster._core.definitions.freshness_policy import FreshnessPolicy
+from dagster._core.definitions.metadata import ArbitraryMetadataMapping
+from dagster._core.definitions.partition import PartitionsDefinition
+from dagster._core.definitions.partition_mapping import PartitionMapping
 from dagster._core.errors import DagsterInvalidInvocationError
 from dagster._core.instance import DynamicPartitionsStore
 from dagster._core.selector.subset_selector import (
     DependencyGraph,
     fetch_sources,
 )
 from dagster._utils.cached_method import cached_method
 
-from .asset_check_spec import AssetCheckKey
-from .backfill_policy import BackfillPolicy
-from .events import AssetKey, AssetKeyPartitionKey
-from .freshness_policy import FreshnessPolicy
-from .partition import PartitionsDefinition, PartitionsSubset
+from .events import AssetKeyPartitionKey
+from .partition import PartitionsSubset
 from .partition_key_range import PartitionKeyRange
 from .partition_mapping import (
-    PartitionMapping,
     UpstreamPartitionsResult,
     infer_partition_mapping,
 )
 from .time_window_partitions import (
     get_time_partition_key,
     get_time_partitions_def,
 )
@@ -63,209 +68,291 @@
         upstream asset partitions that were mapped to but do not exist.
     """
 
     parent_partitions: AbstractSet[AssetKeyPartitionKey]
     required_but_nonexistent_parents_partitions: AbstractSet[AssetKeyPartitionKey]
 
 
-class AssetGraph(ABC):
+class BaseAssetNode(ABC):
+    key: AssetKey
+    parent_keys: AbstractSet[AssetKey]
+    child_keys: AbstractSet[AssetKey]
+
+    @property
+    def has_self_dependency(self) -> bool:
+        return self.key in self.parent_keys
+
     @property
     @abstractmethod
-    def asset_dep_graph(self) -> DependencyGraph[AssetKey]: ...
+    def description(self) -> Optional[str]: ...
 
+    @property
     @abstractmethod
-    def has_asset(self, asset_key: AssetKey) -> bool: ...
+    def group_name(self) -> str: ...
 
     @property
     @abstractmethod
-    def all_asset_keys(self) -> AbstractSet[AssetKey]: ...
+    def is_materializable(self) -> bool: ...
 
     @property
     @abstractmethod
-    def materializable_asset_keys(self) -> AbstractSet[AssetKey]: ...
+    def is_observable(self) -> bool: ...
 
+    @property
     @abstractmethod
-    def is_materializable(self, asset_key: AssetKey) -> bool: ...
+    def is_external(self) -> bool: ...
 
     @property
     @abstractmethod
-    def observable_asset_keys(self) -> AbstractSet[AssetKey]: ...
+    def is_executable(self) -> bool: ...
 
+    @property
     @abstractmethod
-    def is_observable(self, asset_key: AssetKey) -> bool: ...
+    def metadata(self) -> ArbitraryMetadataMapping: ...
 
     @property
     @abstractmethod
-    def external_asset_keys(self) -> AbstractSet[AssetKey]: ...
+    def tags(self) -> Mapping[str, str]: ...
 
+    @property
     @abstractmethod
-    def is_external(self, asset_key: AssetKey) -> bool: ...
+    def owners(self) -> Sequence[str]: ...
 
     @property
     @abstractmethod
-    def executable_asset_keys(self) -> AbstractSet[AssetKey]: ...
+    def is_partitioned(self) -> bool: ...
 
+    @property
     @abstractmethod
-    def is_executable(self, asset_key: AssetKey) -> bool: ...
+    def partitions_def(self) -> Optional[PartitionsDefinition]: ...
 
     @property
-    @cached_method
+    @abstractmethod
+    def partition_mappings(self) -> Mapping[AssetKey, PartitionMapping]: ...
+
+    @property
+    @abstractmethod
+    def freshness_policy(self) -> Optional[FreshnessPolicy]: ...
+
+    @property
+    @abstractmethod
+    def auto_materialize_policy(self) -> Optional[AutoMaterializePolicy]: ...
+
+    @property
+    @abstractmethod
+    def auto_observe_interval_minutes(self) -> Optional[float]: ...
+
+    @property
+    @abstractmethod
+    def backfill_policy(self) -> Optional[BackfillPolicy]: ...
+
+    @property
+    @abstractmethod
+    def code_version(self) -> Optional[str]: ...
+
+    @property
+    @abstractmethod
+    def check_keys(self) -> AbstractSet[AssetCheckKey]: ...
+
+    @property
+    @abstractmethod
+    def execution_set_asset_keys(self) -> AbstractSet[AssetKey]: ...
+
+    @property
+    @abstractmethod
+    def execution_set_asset_and_check_keys(
+        self,
+    ) -> AbstractSet[Union[AssetKey, AssetCheckKey]]: ...
+
+    def __str__(self) -> str:
+        return f"{self.__class__.__name__}<{self.key.to_user_string()}>"
+
+
+T_AssetNode = TypeVar("T_AssetNode", bound=BaseAssetNode)
+
+
+class BaseAssetGraph(ABC, Generic[T_AssetNode]):
+    _asset_nodes_by_key: Mapping[AssetKey, T_AssetNode]
+    _asset_nodes_by_check_key: Mapping[AssetCheckKey, T_AssetNode]
+
+    @property
+    def asset_nodes(self) -> Iterable[T_AssetNode]:
+        return self._asset_nodes_by_key.values()
+
+    def has(self, asset_key: AssetKey) -> bool:
+        return asset_key in self._asset_nodes_by_key
+
+    def get(self, asset_key: AssetKey) -> T_AssetNode:
+        return self._asset_nodes_by_key[asset_key]
+
+    @cached_property
+    def asset_dep_graph(self) -> DependencyGraph[AssetKey]:
+        return {
+            "upstream": {node.key: node.parent_keys for node in self.asset_nodes},
+            "downstream": {node.key: node.child_keys for node in self.asset_nodes},
+        }
+
+    @cached_property
+    def all_asset_keys(self) -> AbstractSet[AssetKey]:
+        return {node.key for node in self.asset_nodes}
+
+    @cached_property
+    def materializable_asset_keys(self) -> AbstractSet[AssetKey]:
+        return {node.key for node in self.asset_nodes if node.is_materializable}
+
+    @cached_property
+    def observable_asset_keys(self) -> AbstractSet[AssetKey]:
+        return {node.key for node in self.asset_nodes if node.is_observable}
+
+    @cached_property
+    def external_asset_keys(self) -> AbstractSet[AssetKey]:
+        return {node.key for node in self.asset_nodes if node.is_external}
+
+    @cached_property
+    def executable_asset_keys(self) -> AbstractSet[AssetKey]:
+        return {node.key for node in self.asset_nodes if node.is_executable}
+
+    @cached_property
+    def unexecutable_asset_keys(self) -> AbstractSet[AssetKey]:
+        return {node.key for node in self.asset_nodes if not node.is_executable}
+
+    @cached_property
     def toposorted_asset_keys(self) -> Sequence[AssetKey]:
         """Return topologically sorted asset keys in graph. Keys with the same topological level are
         sorted alphabetically to provide stability.
         """
         return [
-            key
-            for keys_in_level in self.toposorted_asset_keys_by_level
-            for key in sorted(keys_in_level)
+            item
+            for items_in_level in toposort.toposort(self.asset_dep_graph["upstream"])
+            for item in sorted(items_in_level)
         ]
 
-    @property
-    @cached_method
+    @cached_property
     def toposorted_asset_keys_by_level(self) -> Sequence[AbstractSet[AssetKey]]:
         """Return topologically sorted asset keys grouped into sets containing keys of the same
         topological level.
         """
-        return [
-            {key for key in level} for level in toposort.toposort(self.asset_dep_graph["upstream"])
-        ]
+        return [set(level) for level in toposort.toposort(self.asset_dep_graph["upstream"])]
 
-    @abstractmethod
-    def asset_keys_for_group(self, group_name: str) -> AbstractSet[AssetKey]: ...
+    @cached_property
+    def unpartitioned_asset_keys(self) -> AbstractSet[AssetKey]:
+        return {node.key for node in self.asset_nodes if not node.is_partitioned}
 
-    @functools.cached_property
+    def asset_keys_for_group(self, group_name: str) -> AbstractSet[AssetKey]:
+        return {node.key for node in self.asset_nodes if node.group_name == group_name}
+
+    @cached_method
+    def asset_keys_for_partitions_def(
+        self, partitions_def: PartitionsDefinition
+    ) -> AbstractSet[AssetKey]:
+        return {node.key for node in self.asset_nodes if node.partitions_def == partitions_def}
+
+    @cached_property
     def root_materializable_asset_keys(self) -> AbstractSet[AssetKey]:
         """Materializable asset keys that have no materializable parents."""
-        from .asset_selection import AssetSelection
+        from .asset_selection import KeysAssetSelection
 
-        return AssetSelection.keys(*self.materializable_asset_keys).roots().resolve(self)
+        return (
+            KeysAssetSelection(selected_keys=list(self.materializable_asset_keys))
+            .roots()
+            .resolve(self)
+        )
 
-    @functools.cached_property
+    @cached_property
     def root_executable_asset_keys(self) -> AbstractSet[AssetKey]:
         """Executable asset keys that have no executable parents."""
         return fetch_sources(
             self.asset_dep_graph, self.observable_asset_keys | self.materializable_asset_keys
         )
 
     @property
     @abstractmethod
-    def all_group_names(self) -> AbstractSet[str]: ...
-
-    @abstractmethod
-    def get_partitions_def(self, asset_key: AssetKey) -> Optional[PartitionsDefinition]: ...
+    def asset_check_keys(self) -> AbstractSet[AssetCheckKey]: ...
 
-    @abstractmethod
-    def get_partition_mappings(
-        self, asset_key: AssetKey
-    ) -> Mapping[AssetKey, PartitionMapping]: ...
+    @cached_property
+    def orphan_asset_check_keys(self) -> AbstractSet[AssetCheckKey]:
+        """Asset check keys that target an asset with no corresponding executable definition in the graph."""
+        return {k for k in self.asset_check_keys if k.asset_key not in self.executable_asset_keys}
+
+    @cached_property
+    def all_partitions_defs(self) -> Sequence[PartitionsDefinition]:
+        return sorted(
+            set(node.partitions_def for node in self.asset_nodes if node.partitions_def), key=repr
+        )
+
+    @cached_property
+    def all_group_names(self) -> AbstractSet[str]:
+        return {a.group_name for a in self.asset_nodes if a.group_name is not None}
 
     def get_partition_mapping(
-        self, asset_key: AssetKey, in_asset_key: AssetKey
+        self, asset_key: AssetKey, parent_asset_key: AssetKey
     ) -> PartitionMapping:
-        partition_mappings = self.get_partition_mappings(asset_key)
+        node = self.get(asset_key)
         return infer_partition_mapping(
-            partition_mappings.get(in_asset_key),
-            self.get_partitions_def(asset_key),
-            self.get_partitions_def(in_asset_key),
+            node.partition_mappings.get(parent_asset_key),
+            node.partitions_def,
+            self.get(parent_asset_key).partitions_def,
         )
 
-    def get_partitions_in_range(
-        self,
-        asset_key: AssetKey,
-        partition_key_range: PartitionKeyRange,
-        dynamic_partitions_store: DynamicPartitionsStore,
-    ) -> Sequence[AssetKeyPartitionKey]:
-        partition_def = self.get_partitions_def(asset_key)
-        partition_keys_in_range = check.not_none(partition_def).get_partition_keys_in_range(
-            partition_key_range, dynamic_partitions_store
-        )
-        return [
-            AssetKeyPartitionKey(asset_key, partition_key)
-            for partition_key in partition_keys_in_range
-        ]
-
-    def is_partitioned(self, asset_key: AssetKey) -> bool:
-        return self.get_partitions_def(asset_key) is not None
-
-    @abstractmethod
-    def get_group_name(self, asset_key: AssetKey) -> Optional[str]: ...
-
-    @abstractmethod
-    def get_freshness_policy(self, asset_key: AssetKey) -> Optional[FreshnessPolicy]: ...
-
-    @abstractmethod
-    def get_auto_materialize_policy(
-        self, asset_key: AssetKey
-    ) -> Optional[AutoMaterializePolicy]: ...
+    def get_children(self, node: T_AssetNode) -> AbstractSet[T_AssetNode]:
+        """Returns all asset nodes that directly depend on the given asset node."""
+        return {self._asset_nodes_by_key[key] for key in self.get(node.key).child_keys}
 
-    @abstractmethod
-    def get_auto_observe_interval_minutes(self, asset_key: AssetKey) -> Optional[float]: ...
+    def get_parents(self, node: T_AssetNode) -> AbstractSet[T_AssetNode]:
+        """Returns all asset nodes that are direct dependencies on the given asset node."""
+        return {self._asset_nodes_by_key[key] for key in self.get(node.key).parent_keys}
 
-    @abstractmethod
-    def get_backfill_policy(self, asset_key: AssetKey) -> Optional[BackfillPolicy]: ...
-
-    @abstractmethod
-    def get_code_version(self, asset_key: AssetKey) -> Optional[str]: ...
-
-    def have_same_partitioning(self, asset_key1: AssetKey, asset_key2: AssetKey) -> bool:
-        """Returns whether the given assets have the same partitions definition."""
-        return self.get_partitions_def(asset_key1) == self.get_partitions_def(asset_key2)
-
-    def have_same_or_no_partitioning(self, asset_keys: Iterable[AssetKey]) -> bool:
-        partitions_defs = []
-        for asset_key in asset_keys:
-            partitions_def = self.get_partitions_def(asset_key)
-            if partitions_def:
-                partitions_defs.append(partitions_def)
-
-        return len(partitions_defs) <= 1 or all(
-            partitions_defs[i] == partitions_defs[0] for i in range(1, len(partitions_defs))
-        )
-
-    def get_children(self, asset_key: AssetKey) -> AbstractSet[AssetKey]:
-        """Returns all assets that depend on the given asset."""
-        return self.asset_dep_graph["downstream"][asset_key]
-
-    def get_parents(self, asset_key: AssetKey) -> AbstractSet[AssetKey]:
-        """Returns all first-order dependencies of an asset."""
-        return self.asset_dep_graph["upstream"].get(asset_key) or set()
-
-    def get_ancestors(
+    def get_ancestor_asset_keys(
         self, asset_key: AssetKey, include_self: bool = False
     ) -> AbstractSet[AssetKey]:
         """Returns all nth-order dependencies of an asset."""
         ancestors = set()
-        next_parents = self.get_parents(asset_key) - {asset_key}  # remove self-dependencies
+        next_parents = self.get(asset_key).parent_keys - {asset_key}  # remove self-dependencies
         while next_parents:
             pending_next_parents = set()
             for node_key in next_parents:
                 if node_key in ancestors:
                     continue
                 ancestors.add(node_key)
-                pending_next_parents.update(self.get_parents(node_key))
+                pending_next_parents.update(self.get(node_key).parent_keys)
 
             next_parents = pending_next_parents
 
         if include_self:
             ancestors.add(asset_key)
         return ancestors
 
+    def get_partitions_in_range(
+        self,
+        asset_key: AssetKey,
+        partition_key_range: PartitionKeyRange,
+        dynamic_partitions_store: DynamicPartitionsStore,
+    ) -> Sequence[AssetKeyPartitionKey]:
+        partition_def = self.get(asset_key).partitions_def
+        partition_keys_in_range = check.not_none(partition_def).get_partition_keys_in_range(
+            partition_key_range, dynamic_partitions_store
+        )
+        return [
+            AssetKeyPartitionKey(asset_key, partition_key)
+            for partition_key in partition_keys_in_range
+        ]
+
     def get_parent_asset_subset(
         self,
         child_asset_subset: ValidAssetSubset,
         parent_asset_key: AssetKey,
         dynamic_partitions_store: DynamicPartitionsStore,
         current_time: datetime,
     ) -> ValidAssetSubset:
         """Given a child AssetSubset, returns the corresponding parent AssetSubset, based on the
         relevant PartitionMapping.
         """
         child_asset_key = child_asset_subset.asset_key
-        child_partitions_def = self.get_partitions_def(child_asset_key)
-        parent_partitions_def = self.get_partitions_def(parent_asset_key)
+        child_partitions_def = self.get(child_asset_key).partitions_def
+        parent_partitions_def = self.get(parent_asset_key).partitions_def
 
         if parent_partitions_def is None:
             return ValidAssetSubset(parent_asset_key, value=child_asset_subset.size > 0)
 
         partition_mapping = self.get_partition_mapping(child_asset_key, parent_asset_key)
         parent_partitions_subset = (
             partition_mapping.get_upstream_mapped_partitions_result_for_partitions(
@@ -286,16 +373,16 @@
         dynamic_partitions_store: DynamicPartitionsStore,
         current_time: datetime,
     ) -> ValidAssetSubset:
         """Given a parent AssetSubset, returns the corresponding child AssetSubset, based on the
         relevant PartitionMapping.
         """
         parent_asset_key = parent_asset_subset.asset_key
-        parent_partitions_def = self.get_partitions_def(parent_asset_key)
-        child_partitions_def = self.get_partitions_def(child_asset_key)
+        parent_partitions_def = self.get(parent_asset_key).partitions_def
+        child_partitions_def = self.get(child_asset_key).partitions_def
 
         if parent_partitions_def is None:
             if parent_asset_subset.size > 0:
                 return ValidAssetSubset.all(
                     child_asset_key, child_partitions_def, dynamic_partitions_store, current_time
                 )
             else:
@@ -321,26 +408,26 @@
         asset_key: AssetKey,
         partition_key: Optional[str] = None,
     ) -> AbstractSet[AssetKeyPartitionKey]:
         """Returns every partition in every of the given asset's children that depends on the given
         partition of that asset.
         """
         result: Set[AssetKeyPartitionKey] = set()
-        for child_asset_key in self.get_children(asset_key):
-            if self.is_partitioned(child_asset_key):
+        for child in self.get_children(self.get(asset_key)):
+            if child.is_partitioned:
                 for child_partition_key in self.get_child_partition_keys_of_parent(
                     dynamic_partitions_store,
                     partition_key,
                     asset_key,
-                    child_asset_key,
+                    child.key,
                     current_time,
                 ):
-                    result.add(AssetKeyPartitionKey(child_asset_key, child_partition_key))
+                    result.add(AssetKeyPartitionKey(child.key, child_partition_key))
             else:
-                result.add(AssetKeyPartitionKey(child_asset_key))
+                result.add(AssetKeyPartitionKey(child.key))
         return result
 
     def get_child_partition_keys_of_parent(
         self,
         dynamic_partitions_store: DynamicPartitionsStore,
         parent_partition_key: Optional[str],
         parent_asset_key: AssetKey,
@@ -357,16 +444,16 @@
             child_asset_key (AssetKey): The asset key of the downstream asset. The provided partition
                 key will be mapped to partitions within this asset.
 
         Returns:
             Sequence[str]: A list of the corresponding downstream partitions in child_asset_key that
                 partition_key maps to.
         """
-        child_partitions_def = self.get_partitions_def(child_asset_key)
-        parent_partitions_def = self.get_partitions_def(parent_asset_key)
+        child_partitions_def = self.get(child_asset_key).partitions_def
+        parent_partitions_def = self.get(parent_asset_key).partitions_def
 
         if child_partitions_def is None:
             raise DagsterInvalidInvocationError(
                 f"Asset key {child_asset_key} is not partitioned. Cannot get partition keys."
             )
         if parent_partition_key is None:
             return child_partitions_def.get_partition_keys(
@@ -398,16 +485,16 @@
         partition_key: Optional[str] = None,
     ) -> ParentsPartitionsResult:
         """Returns every partition in every of the given asset's parents that the given partition of
         that asset depends on.
         """
         valid_parent_partitions: Set[AssetKeyPartitionKey] = set()
         required_but_nonexistent_parent_partitions: Set[AssetKeyPartitionKey] = set()
-        for parent_asset_key in self.get_parents(asset_key):
-            if self.has_asset(parent_asset_key) and self.is_partitioned(parent_asset_key):
+        for parent_asset_key in self.get(asset_key).parent_keys:
+            if self.has(parent_asset_key) and self.get(parent_asset_key).is_partitioned:
                 mapped_partitions_result = self.get_parent_partition_keys_for_child(
                     partition_key,
                     parent_asset_key,
                     asset_key,
                     dynamic_partitions_store=dynamic_partitions_store,
                     current_time=current_time,
                 )
@@ -452,16 +539,16 @@
 
         Returns:
             Sequence[str]: A list of the corresponding downstream partitions in child_asset_key that
                 partition_key maps to.
         """
         partition_key = check.opt_str_param(partition_key, "partition_key")
 
-        child_partitions_def = cast(PartitionsDefinition, self.get_partitions_def(child_asset_key))
-        parent_partitions_def = self.get_partitions_def(parent_asset_key)
+        child_partitions_def = cast(PartitionsDefinition, self.get(child_asset_key).partitions_def)
+        parent_partitions_def = self.get(parent_asset_key).partitions_def
 
         if parent_partitions_def is None:
             raise DagsterInvalidInvocationError(
                 f"Asset key {parent_asset_key} is not partitioned. Cannot get partition keys."
             )
 
         partition_mapping = self.get_partition_mapping(child_asset_key, parent_asset_key)
@@ -476,77 +563,73 @@
             upstream_partitions_def=parent_partitions_def,
             dynamic_partitions_store=dynamic_partitions_store,
             current_time=current_time,
         )
 
     def has_materializable_parents(self, asset_key: AssetKey) -> bool:
         """Determines if an asset has any parents which are materializable."""
-        if self.is_external(asset_key):
+        if self.get(asset_key).is_external:
             return False
         return any(
-            self.has_asset(parent_key) and self.is_materializable(parent_key)
-            for parent_key in self.get_parents(asset_key) - {asset_key}
+            self.has(parent_key) and self.get(parent_key).is_materializable
+            for parent_key in self.get(asset_key).parent_keys - {asset_key}
         )
 
     def get_materializable_roots(self, asset_key: AssetKey) -> AbstractSet[AssetKey]:
         """Returns all assets upstream of the given asset which do not consume any other
         materializable assets.
         """
         if not self.has_materializable_parents(asset_key):
             return {asset_key}
         return {
             key
             for key in self.upstream_key_iterator(asset_key)
-            if self.has_asset(key)
-            and self.is_materializable(key)
+            if self.has(key)
+            and self.get(key).is_materializable
             and not self.has_materializable_parents(key)
         }
 
     def upstream_key_iterator(self, asset_key: AssetKey) -> Iterator[AssetKey]:
         """Iterates through all asset keys which are upstream of the given key."""
         visited: Set[AssetKey] = set()
         queue = deque([asset_key])
         while queue:
             current_key = queue.popleft()
-            for parent_key in self.get_parents(current_key):
+            for parent_key in self.get(current_key).parent_keys:
                 if parent_key not in visited:
                     yield parent_key
                     queue.append(parent_key)
                     visited.add(parent_key)
 
     @abstractmethod
-    def get_required_multi_asset_keys(self, asset_key: AssetKey) -> AbstractSet[AssetKey]:
-        """For a given asset_key, return the set of asset keys that must be materialized at the same time."""
-        ...
-
-    @abstractmethod
-    def get_required_asset_and_check_keys(
+    def get_execution_set_asset_and_check_keys(
         self, asset_key_or_check_key: AssetKeyOrCheckKey
-    ) -> AbstractSet[AssetKeyOrCheckKey]: ...
+    ) -> AbstractSet[AssetKeyOrCheckKey]:
+        """For a given asset/check key, return the set of asset/check keys that must be
+        materialized/computed at the same time.
+        """
+        ...
 
     @cached_method
     def get_downstream_freshness_policies(
         self, *, asset_key: AssetKey
     ) -> AbstractSet[FreshnessPolicy]:
+        asset = self.get(asset_key)
         downstream_policies = set().union(
             *(
                 self.get_downstream_freshness_policies(asset_key=child_key)
-                for child_key in self.get_children(asset_key)
+                for child_key in self.get(asset_key).child_keys
                 if child_key != asset_key
             )
         )
-        current_policy = self.get_freshness_policy(asset_key)
-        if self.get_partitions_def(asset_key) is None and current_policy is not None:
-            downstream_policies.add(current_policy)
+        if asset.partitions_def is None and asset.freshness_policy is not None:
+            downstream_policies.add(asset.freshness_policy)
 
         return downstream_policies
 
-    def has_self_dependency(self, asset_key: AssetKey) -> bool:
-        return asset_key in self.get_parents(asset_key)
-
     def bfs_filter_subsets(
         self,
         dynamic_partitions_store: DynamicPartitionsStore,
         condition_fn: Callable[[AssetKey, Optional[PartitionsSubset]], bool],
         initial_subset: "AssetGraphSubset",
         current_time: datetime,
     ) -> "AssetGraphSubset":
@@ -566,15 +649,15 @@
         )
         initial_asset_key = next(iter(initial_subset.asset_keys))
         queue = deque([initial_asset_key])
 
         queued_subsets_by_asset_key: Dict[AssetKey, Optional[PartitionsSubset]] = {
             initial_asset_key: (
                 initial_subset.get_partitions_subset(initial_asset_key, self)
-                if self.get_partitions_def(initial_asset_key)
+                if self.get(initial_asset_key).is_partitioned
                 else None
             ),
         }
         result = AssetGraphSubset()
 
         while len(queue) > 0:
             asset_key = queue.popleft()
@@ -584,49 +667,51 @@
                 result |= AssetGraphSubset(
                     non_partitioned_asset_keys={asset_key} if partitions_subset is None else set(),
                     partitions_subsets_by_asset_key=(
                         {asset_key: partitions_subset} if partitions_subset is not None else {}
                     ),
                 )
 
-                for child in self.get_children(asset_key):
-                    partition_mapping = self.get_partition_mapping(child, asset_key)
-                    child_partitions_def = self.get_partitions_def(child)
+                for child_key in self.get(asset_key).child_keys:
+                    partition_mapping = self.get_partition_mapping(child_key, asset_key)
+                    child_partitions_def = self.get(child_key).partitions_def
 
                     if child_partitions_def:
                         if partitions_subset is None:
                             child_partitions_subset = (
                                 child_partitions_def.subset_with_all_partitions(
                                     current_time=current_time,
                                     dynamic_partitions_store=dynamic_partitions_store,
                                 )
                             )
-                            queued_subsets_by_asset_key[child] = child_partitions_subset
+                            queued_subsets_by_asset_key[child_key] = child_partitions_subset
                         else:
                             child_partitions_subset = (
                                 partition_mapping.get_downstream_partitions_for_partitions(
                                     partitions_subset,
-                                    check.not_none(self.get_partitions_def(asset_key)),
+                                    check.not_none(self.get(asset_key).partitions_def),
                                     downstream_partitions_def=child_partitions_def,
                                     dynamic_partitions_store=dynamic_partitions_store,
                                     current_time=current_time,
                                 )
                             )
-                            prior_child_partitions_subset = queued_subsets_by_asset_key.get(child)
-                            queued_subsets_by_asset_key[child] = (
+                            prior_child_partitions_subset = queued_subsets_by_asset_key.get(
+                                child_key
+                            )
+                            queued_subsets_by_asset_key[child_key] = (
                                 child_partitions_subset
                                 if not prior_child_partitions_subset
                                 else child_partitions_subset | prior_child_partitions_subset
                             )
                     else:
                         child_partitions_subset = None
 
-                    if child not in all_assets:
-                        queue.append(child)
-                        all_assets.add(child)
+                    if child_key not in all_assets:
+                        queue.append(child_key)
+                        all_assets.add(child_key)
 
         return result
 
     def bfs_filter_asset_partitions(
         self,
         dynamic_partitions_store: DynamicPartitionsStore,
         condition_fn: Callable[
@@ -639,21 +724,21 @@
 
         - Are >= initial_asset_partitions
         - Match the condition_fn
         - Any of their ancestors >= initial_asset_partitions match the condition_fn
 
         Visits parents before children.
 
-        When asset partitions are part of the same non-subsettable multi-asset, they're provided all
-        at once to the condition_fn.
+        When asset partitions are part of the same execution set (non-subsettable multi-asset),
+        they're provided all at once to the condition_fn.
         """
         all_nodes = set(initial_asset_partitions)
 
         # invariant: we never consider an asset partition before considering its ancestors
-        queue = ToposortedPriorityQueue(self, all_nodes, include_required_multi_assets=True)
+        queue = ToposortedPriorityQueue(self, all_nodes, include_full_execution_set=True)
 
         result: Set[AssetKeyPartitionKey] = set()
 
         while len(queue) > 0:
             candidates_unit = queue.dequeue()
 
             if condition_fn(candidates_unit, result):
@@ -681,46 +766,46 @@
         return id(self)
 
     def __eq__(self, other: object) -> bool:
         return self is other
 
 
 def sort_key_for_asset_partition(
-    asset_graph: AssetGraph, asset_partition: AssetKeyPartitionKey
+    asset_graph: BaseAssetGraph, asset_partition: AssetKeyPartitionKey
 ) -> float:
     """Returns an integer sort key such that asset partitions are sorted in the order in which they
     should be materialized. For assets without a time window partition dimension, this is always 0.
     Assets with a time window partition dimension will be sorted from newest to oldest, unless they
     have a self-dependency, in which case they are sorted from oldest to newest.
     """
-    partitions_def = asset_graph.get_partitions_def(asset_partition.asset_key)
+    partitions_def = asset_graph.get(asset_partition.asset_key).partitions_def
     time_partitions_def = get_time_partitions_def(partitions_def)
     if time_partitions_def is None:
         return 0
 
     # A sort key such that time window partitions are sorted from oldest to newest
     time_partition_key = get_time_partition_key(partitions_def, asset_partition.partition_key)
     partition_timestamp = time_partitions_def.start_time_for_partition_key(
         time_partition_key
     ).timestamp()
 
-    if asset_graph.has_self_dependency(asset_partition.asset_key):
+    if asset_graph.get(asset_partition.asset_key).has_self_dependency:
         # sort self dependencies from oldest to newest, as older partitions must exist before
         # new ones can execute
         return partition_timestamp
     else:
         # sort non-self dependencies from newest to oldest, as newer partitions are more relevant
         # than older ones
         return -1 * partition_timestamp
 
 
 class ToposortedPriorityQueue:
     """Queue that returns parents before their children."""
 
-    @functools.total_ordering
+    @total_ordering
     class QueueItem(NamedTuple):
         level: int
         partition_sort_key: Optional[float]
         asset_partitions: Iterable[AssetKeyPartitionKey]
 
         def __eq__(self, other: object) -> bool:
             if isinstance(other, ToposortedPriorityQueue.QueueItem):
@@ -738,58 +823,53 @@
                     and other.partition_sort_key is not None
                     and self.partition_sort_key < other.partition_sort_key
                 )
             raise TypeError()
 
     def __init__(
         self,
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         items: Iterable[AssetKeyPartitionKey],
-        include_required_multi_assets: bool,
+        include_full_execution_set: bool,
     ):
         self._asset_graph = asset_graph
-        self._include_required_multi_assets = include_required_multi_assets
+        self._include_full_execution_set = include_full_execution_set
 
         self._toposort_level_by_asset_key = {
             asset_key: i
             for i, asset_keys in enumerate(asset_graph.toposorted_asset_keys_by_level)
             for asset_key in asset_keys
         }
         self._heap = [self._queue_item(asset_partition) for asset_partition in items]
         heapify(self._heap)
 
     def enqueue(self, asset_partition: AssetKeyPartitionKey) -> None:
         heappush(self._heap, self._queue_item(asset_partition))
 
     def dequeue(self) -> Iterable[AssetKeyPartitionKey]:
-        # For multi-assets, will include all required multi-asset keys if include_required_multi_assets is set to
-        # True, or a list of size 1 with just the passed in asset key if it was not
+        # For multi-assets, will include all required multi-asset keys if
+        # include_full_execution_set is set to True, or a list of size 1 with just the passed in
+        # asset key if it was not.
         return heappop(self._heap).asset_partitions
 
     def _queue_item(
         self, asset_partition: AssetKeyPartitionKey
     ) -> "ToposortedPriorityQueue.QueueItem":
         asset_key = asset_partition.asset_key
 
-        if self._include_required_multi_assets:
-            required_multi_asset_keys = self._asset_graph.get_required_multi_asset_keys(
-                asset_key
-            ) | {asset_key}
+        if self._include_full_execution_set:
+            execution_set_keys = self._asset_graph.get(asset_key).execution_set_asset_keys
         else:
-            required_multi_asset_keys = {asset_key}
+            execution_set_keys = {asset_key}
 
         level = max(
-            self._toposort_level_by_asset_key[required_asset_key]
-            for required_asset_key in required_multi_asset_keys
+            self._toposort_level_by_asset_key[asset_key] for asset_key in execution_set_keys
         )
 
         return ToposortedPriorityQueue.QueueItem(
             level,
             sort_key_for_asset_partition(self._asset_graph, asset_partition),
-            [
-                AssetKeyPartitionKey(ak, asset_partition.partition_key)
-                for ak in required_multi_asset_keys
-            ],
+            [AssetKeyPartitionKey(ak, asset_partition.partition_key) for ak in execution_set_keys],
         )
 
     def __len__(self) -> int:
         return len(self._heap)
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_graph_differ.py` & `dagster-1.7.0/dagster/_core/definitions/asset_graph_differ.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from enum import Enum
 from typing import TYPE_CHECKING, Callable, Optional, Sequence, Union
 
 import dagster._check as check
-from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
+from dagster._core.definitions.remote_asset_graph import RemoteAssetGraph
 from dagster._core.errors import DagsterInvariantViolationError
-from dagster._core.host_representation import ExternalRepository
+from dagster._core.remote_representation import ExternalRepository
 from dagster._core.workspace.context import BaseWorkspaceRequestContext
 
 if TYPE_CHECKING:
     from dagster._core.definitions.events import (
         AssetKey,
     )
 
@@ -36,39 +36,39 @@
     """Given two asset graphs, base_asset_graph and branch_asset_graph, we can compute how the
     assets in branch_asset_graph have changed with respect to base_asset_graph. The ChangeReason
     enum contains the list of potential changes an asset can undergo. If the base_asset_graph is None,
     this indicates that the branch_asset_graph does not yet exist in the base deployment. In this case
     we will consider every asset New.
     """
 
-    _branch_asset_graph: Optional["ExternalAssetGraph"]
-    _branch_asset_graph_load_fn: Optional[Callable[[], "ExternalAssetGraph"]]
-    _base_asset_graph: Optional["ExternalAssetGraph"]
-    _base_asset_graph_load_fn: Optional[Callable[[], "ExternalAssetGraph"]]
+    _branch_asset_graph: Optional["RemoteAssetGraph"]
+    _branch_asset_graph_load_fn: Optional[Callable[[], "RemoteAssetGraph"]]
+    _base_asset_graph: Optional["RemoteAssetGraph"]
+    _base_asset_graph_load_fn: Optional[Callable[[], "RemoteAssetGraph"]]
 
     def __init__(
         self,
-        branch_asset_graph: Union["ExternalAssetGraph", Callable[[], "ExternalAssetGraph"]],
+        branch_asset_graph: Union["RemoteAssetGraph", Callable[[], "RemoteAssetGraph"]],
         base_asset_graph: Optional[
-            Union["ExternalAssetGraph", Callable[[], "ExternalAssetGraph"]]
+            Union["RemoteAssetGraph", Callable[[], "RemoteAssetGraph"]]
         ] = None,
     ):
         if base_asset_graph is None:
             # if base_asset_graph is None, then the asset graph in the branch deployment does not exist
             # in the base deployment
             self._base_asset_graph = None
             self._base_asset_graph_load_fn = None
-        elif isinstance(base_asset_graph, ExternalAssetGraph):
+        elif isinstance(base_asset_graph, RemoteAssetGraph):
             self._base_asset_graph = base_asset_graph
             self._base_asset_graph_load_fn = None
         else:
             self._base_asset_graph = None
             self._base_asset_graph_load_fn = base_asset_graph
 
-        if isinstance(branch_asset_graph, ExternalAssetGraph):
+        if isinstance(branch_asset_graph, RemoteAssetGraph):
             self._branch_asset_graph = branch_asset_graph
             self._branch_asset_graph_load_fn = None
         else:
             self._branch_asset_graph = None
             self._branch_asset_graph_load_fn = branch_asset_graph
 
     @classmethod
@@ -78,19 +78,19 @@
         repository_name: str,
         branch_workspace: BaseWorkspaceRequestContext,
         base_workspace: BaseWorkspaceRequestContext,
     ) -> "AssetGraphDiffer":
         """Constructs an AssetGraphDiffer for a particular repository in a code location for two
         deployment workspaces, the base deployment and the branch deployment.
 
-        We cannot make ExternalAssetGraphs directly from the workspaces because if multiple code locations
-        use the same asset key, those asset keys will override each other in the dictionaries the ExternalAssetGraph
-        creates (see from_repository_handles_and_external_asset_nodes in ExternalAssetGraph). We need to ensure
+        We cannot make RemoteAssetGraphs directly from the workspaces because if multiple code locations
+        use the same asset key, those asset keys will override each other in the dictionaries the RemoteAssetGraph
+        creates (see from_repository_handles_and_external_asset_nodes in RemoteAssetGraph). We need to ensure
         that we are comparing assets in the same code location and repository, so we need to make the
-        ExternalAssetGraph from an ExternalRepository to ensure that there are no duplicate asset keys
+        RemoteAssetGraph from an ExternalRepository to ensure that there are no duplicate asset keys
         that could override each other.
         """
         check.inst_param(branch_workspace, "branch_workspace", BaseWorkspaceRequestContext)
         check.inst_param(base_workspace, "base_workspace", BaseWorkspaceRequestContext)
 
         branch_repo = _get_external_repo_from_context(
             branch_workspace, code_location_name, repository_name
@@ -99,18 +99,16 @@
             raise DagsterInvariantViolationError(
                 f"Repository {repository_name} does not exist in code location {code_location_name} for the branch deployment."
             )
         base_repo = _get_external_repo_from_context(
             base_workspace, code_location_name, repository_name
         )
         return AssetGraphDiffer(
-            branch_asset_graph=lambda: ExternalAssetGraph.from_external_repository(branch_repo),
-            base_asset_graph=(lambda: ExternalAssetGraph.from_external_repository(base_repo))
-            if base_repo is not None
-            else None,
+            branch_asset_graph=lambda: branch_repo.asset_graph,
+            base_asset_graph=(lambda: base_repo.asset_graph) if base_repo is not None else None,
         )
 
     def _compare_base_and_branch_assets(self, asset_key: "AssetKey") -> Sequence[ChangeReason]:
         """Computes the diff between a branch deployment asset and the
         corresponding base deployment asset.
         """
         if self.base_asset_graph is None:
@@ -118,48 +116,51 @@
             # is new and doesn't exist in the base deployment. Thus all assets are new.
             return [ChangeReason.NEW]
 
         if asset_key not in self.base_asset_graph.all_asset_keys:
             return [ChangeReason.NEW]
 
         changes = []
-        if self.branch_asset_graph.get_code_version(
-            asset_key
-        ) != self.base_asset_graph.get_code_version(asset_key):
+        if (
+            self.branch_asset_graph.get(asset_key).code_version
+            != self.base_asset_graph.get(asset_key).code_version
+        ):
             changes.append(ChangeReason.CODE_VERSION)
 
-        if self.branch_asset_graph.get_parents(asset_key) != self.base_asset_graph.get_parents(
-            asset_key
+        if (
+            self.branch_asset_graph.get(asset_key).parent_keys
+            != self.base_asset_graph.get(asset_key).parent_keys
         ):
             changes.append(ChangeReason.INPUTS)
         else:
             # if the set of inputs is different, then we don't need to check if the partition mappings
             # for inputs have changed since ChangeReason.INPUTS is already in the list of changes
-            for upstream_asset in self.branch_asset_graph.get_parents(asset_key):
+            for upstream_asset in self.branch_asset_graph.get(asset_key).parent_keys:
                 if self.branch_asset_graph.get_partition_mapping(
                     asset_key, upstream_asset
                 ) != self.base_asset_graph.get_partition_mapping(asset_key, upstream_asset):
                     changes.append(ChangeReason.INPUTS)
                     break
 
-        if self.branch_asset_graph.get_partitions_def(
-            asset_key
-        ) != self.base_asset_graph.get_partitions_def(asset_key):
+        if (
+            self.branch_asset_graph.get(asset_key).partitions_def
+            != self.base_asset_graph.get(asset_key).partitions_def
+        ):
             changes.append(ChangeReason.PARTITIONS_DEFINITION)
 
         return changes
 
     def get_changes_for_asset(self, asset_key: "AssetKey") -> Sequence[ChangeReason]:
         """Returns list of ChangeReasons for asset_key as compared to the base deployment."""
         return self._compare_base_and_branch_assets(asset_key)
 
     @property
-    def branch_asset_graph(self) -> "ExternalAssetGraph":
+    def branch_asset_graph(self) -> "RemoteAssetGraph":
         if self._branch_asset_graph is None:
             self._branch_asset_graph = check.not_none(self._branch_asset_graph_load_fn)()
         return self._branch_asset_graph
 
     @property
-    def base_asset_graph(self) -> Optional["ExternalAssetGraph"]:
+    def base_asset_graph(self) -> Optional["RemoteAssetGraph"]:
         if self._base_asset_graph is None and self._base_asset_graph_load_fn is not None:
             self._base_asset_graph = self._base_asset_graph_load_fn()
         return self._base_asset_graph
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_graph_subset.py` & `dagster-1.7.0/dagster/_core/definitions/asset_graph_subset.py`

 * *Files 2% similar despite different names*

```diff
@@ -26,16 +26,16 @@
 from dagster._core.instance import DynamicPartitionsStore
 from dagster._serdes.serdes import (
     NamedTupleSerializer,
     SerializableNonScalarKeyMapping,
     whitelist_for_serdes,
 )
 
-from .asset_graph import AssetGraph
 from .asset_subset import AssetSubset
+from .base_asset_graph import BaseAssetGraph
 from .events import AssetKey, AssetKeyPartitionKey
 
 
 class PartitionsSubsetMappingNamedTupleSerializer(NamedTupleSerializer):
     """Serializes NamedTuples with fields that are mappings containing PartitionsSubsets.
 
     This is necessary because PartitionKeysTimeWindowPartitionsSubsets are not serializable,
@@ -75,36 +75,36 @@
 
     @property
     def num_partitions_and_non_partitioned_assets(self) -> int:
         return len(self.non_partitioned_asset_keys) + sum(
             len(subset) for subset in self.partitions_subsets_by_asset_key.values()
         )
 
-    def get_asset_subset(self, asset_key: AssetKey, asset_graph: AssetGraph) -> AssetSubset:
+    def get_asset_subset(self, asset_key: AssetKey, asset_graph: BaseAssetGraph) -> AssetSubset:
         """Returns an AssetSubset representing the subset of a specific asset that this
         AssetGraphSubset contains.
         """
-        partitions_def = asset_graph.get_partitions_def(asset_key)
+        partitions_def = asset_graph.get(asset_key).partitions_def
         if partitions_def is None:
             return AssetSubset(
                 asset_key=asset_key, value=asset_key in self.non_partitioned_asset_keys
             )
         else:
             return AssetSubset(
                 asset_key=asset_key,
                 value=self.partitions_subsets_by_asset_key.get(
                     asset_key, partitions_def.empty_subset()
                 ),
             )
 
     def get_partitions_subset(
-        self, asset_key: AssetKey, asset_graph: Optional[AssetGraph] = None
+        self, asset_key: AssetKey, asset_graph: Optional[BaseAssetGraph] = None
     ) -> PartitionsSubset:
         if asset_graph:
-            partitions_def = asset_graph.get_partitions_def(asset_key)
+            partitions_def = asset_graph.get(asset_key).partitions_def
             if partitions_def is None:
                 check.failed("Can only call get_partitions_subset on a partitioned asset")
 
             return self.partitions_subsets_by_asset_key.get(
                 asset_key, partitions_def.empty_subset()
             )
         else:
@@ -135,32 +135,32 @@
         elif asset.partition_key is None:
             return asset.asset_key in self.non_partitioned_asset_keys
         else:
             partitions_subset = self.partitions_subsets_by_asset_key.get(asset.asset_key)
             return partitions_subset is not None and asset.partition_key in partitions_subset
 
     def to_storage_dict(
-        self, dynamic_partitions_store: DynamicPartitionsStore, asset_graph: AssetGraph
+        self, dynamic_partitions_store: DynamicPartitionsStore, asset_graph: BaseAssetGraph
     ) -> Mapping[str, object]:
         return {
             "partitions_subsets_by_asset_key": {
                 key.to_user_string(): value.serialize()
                 for key, value in self.partitions_subsets_by_asset_key.items()
             },
             "serializable_partitions_def_ids_by_asset_key": {
                 key.to_user_string(): check.not_none(
-                    asset_graph.get_partitions_def(key)
+                    asset_graph.get(key).partitions_def
                 ).get_serializable_unique_identifier(
                     dynamic_partitions_store=dynamic_partitions_store
                 )
                 for key, _ in self.partitions_subsets_by_asset_key.items()
             },
             "partitions_def_class_names_by_asset_key": {
                 key.to_user_string(): check.not_none(
-                    asset_graph.get_partitions_def(key)
+                    asset_graph.get(key).partitions_def
                 ).__class__.__name__
                 for key, _ in self.partitions_subsets_by_asset_key.items()
             },
             "non_partitioned_asset_keys": [
                 key.to_user_string() for key in self.non_partitioned_asset_keys
             ],
         }
@@ -238,49 +238,51 @@
             ")"
         )
 
     @classmethod
     def from_asset_partition_set(
         cls,
         asset_partitions_set: AbstractSet[AssetKeyPartitionKey],
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
     ) -> "AssetGraphSubset":
         partitions_by_asset_key = defaultdict(set)
         non_partitioned_asset_keys = set()
         for asset_key, partition_key in asset_partitions_set:
             if partition_key is not None:
                 partitions_by_asset_key[asset_key].add(partition_key)
             else:
                 non_partitioned_asset_keys.add(asset_key)
 
         return AssetGraphSubset(
             partitions_subsets_by_asset_key={
                 asset_key: (
-                    cast(PartitionsDefinition, asset_graph.get_partitions_def(asset_key))
+                    cast(PartitionsDefinition, asset_graph.get(asset_key).partitions_def)
                     .empty_subset()
                     .with_partition_keys(partition_keys)
                 )
                 for asset_key, partition_keys in partitions_by_asset_key.items()
             },
             non_partitioned_asset_keys=non_partitioned_asset_keys,
         )
 
     @classmethod
-    def can_deserialize(cls, serialized_dict: Mapping[str, Any], asset_graph: AssetGraph) -> bool:
+    def can_deserialize(
+        cls, serialized_dict: Mapping[str, Any], asset_graph: BaseAssetGraph
+    ) -> bool:
         serializable_partitions_ids = serialized_dict.get(
             "serializable_partitions_def_ids_by_asset_key", {}
         )
 
         partitions_def_class_names_by_asset_key = serialized_dict.get(
             "partitions_def_class_names_by_asset_key", {}
         )
 
         for key, value in serialized_dict["partitions_subsets_by_asset_key"].items():
             asset_key = AssetKey.from_user_string(key)
-            partitions_def = asset_graph.get_partitions_def(asset_key)
+            partitions_def = asset_graph.get(asset_key).partitions_def
 
             if partitions_def is None:
                 # Asset had a partitions definition at storage time, but no longer does
                 return False
 
             if not partitions_def.can_deserialize_subset(
                 value,
@@ -293,15 +295,15 @@
 
         return True
 
     @classmethod
     def from_storage_dict(
         cls,
         serialized_dict: Mapping[str, Any],
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         allow_partial: bool = False,
     ) -> "AssetGraphSubset":
         serializable_partitions_ids = serialized_dict.get(
             "serializable_partitions_def_ids_by_asset_key", {}
         )
 
         partitions_def_class_names_by_asset_key = serialized_dict.get(
@@ -314,15 +316,15 @@
             if asset_key not in asset_graph.all_asset_keys:
                 if not allow_partial:
                     raise DagsterDefinitionChangedDeserializationError(
                         f"Asset {key} existed at storage-time, but no longer does"
                     )
                 continue
 
-            partitions_def = asset_graph.get_partitions_def(asset_key)
+            partitions_def = asset_graph.get(asset_key).partitions_def
 
             if partitions_def is None:
                 if not allow_partial:
                     raise DagsterDefinitionChangedDeserializationError(
                         f"Asset {key} had a PartitionsDefinition at storage-time, but no longer"
                         " does"
                     )
@@ -353,38 +355,38 @@
             partitions_subsets_by_asset_key=partitions_subsets_by_asset_key,
             non_partitioned_asset_keys=non_partitioned_asset_keys,
         )
 
     @classmethod
     def all(
         cls,
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         dynamic_partitions_store: DynamicPartitionsStore,
         current_time: datetime,
     ) -> "AssetGraphSubset":
         return cls.from_asset_keys(
             asset_graph.materializable_asset_keys,
             asset_graph,
             dynamic_partitions_store,
             current_time,
         )
 
     @classmethod
     def from_asset_keys(
         cls,
         asset_keys: Iterable[AssetKey],
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         dynamic_partitions_store: DynamicPartitionsStore,
         current_time: datetime,
     ) -> "AssetGraphSubset":
         partitions_subsets_by_asset_key: Dict[AssetKey, PartitionsSubset] = {}
         non_partitioned_asset_keys: Set[AssetKey] = set()
 
         for asset_key in asset_keys:
-            partitions_def = asset_graph.get_partitions_def(asset_key)
+            partitions_def = asset_graph.get(asset_key).partitions_def
             if partitions_def:
                 partitions_subsets_by_asset_key[asset_key] = (
                     partitions_def.empty_subset().with_partition_keys(
                         partitions_def.get_partition_keys(
                             dynamic_partitions_store=dynamic_partitions_store,
                             current_time=current_time,
                         )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_in.py` & `dagster-1.7.0/dagster/_core/definitions/asset_in.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_out.py` & `dagster-1.7.0/dagster/_core/definitions/asset_out.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,21 +7,23 @@
 from dagster._core.definitions.events import (
     AssetKey,
     CoercibleToAssetKey,
     CoercibleToAssetKeyPrefix,
 )
 from dagster._core.definitions.freshness_policy import FreshnessPolicy
 from dagster._core.definitions.input import NoValueSentinel
-from dagster._core.definitions.metadata import RawMetadataMapping
 from dagster._core.definitions.output import Out
 from dagster._core.definitions.utils import DEFAULT_IO_MANAGER_KEY
 from dagster._core.types.dagster_type import DagsterType, resolve_dagster_type
 
+from .utils import validate_definition_tags
+
 
 @experimental_param(param="owners")
+@experimental_param(param="tags")
 class AssetOut(
     NamedTuple(
         "_AssetOut",
         [
             ("key", PublicAttr[Optional[AssetKey]]),
             ("key_prefix", PublicAttr[Optional[Sequence[str]]]),
             ("metadata", PublicAttr[Optional[Mapping[str, Any]]]),
@@ -31,14 +33,15 @@
             ("dagster_type", PublicAttr[Union[DagsterType, Type[NoValueSentinel]]]),
             ("group_name", PublicAttr[Optional[str]]),
             ("code_version", PublicAttr[Optional[str]]),
             ("freshness_policy", PublicAttr[Optional[FreshnessPolicy]]),
             ("auto_materialize_policy", PublicAttr[Optional[AutoMaterializePolicy]]),
             ("backfill_policy", PublicAttr[Optional[BackfillPolicy]]),
             ("owners", PublicAttr[Optional[Sequence[str]]]),
+            ("tags", PublicAttr[Optional[Mapping[str, str]]]),
         ],
     )
 ):
     """Defines one of the assets produced by a :py:func:`@multi_asset <multi_asset>`.
 
     Attributes:
         key_prefix (Optional[Union[str, Sequence[str]]]): If provided, the asset's key is the
@@ -57,39 +60,42 @@
         metadata (Optional[Dict[str, Any]]): A dict of the metadata for the output.
             For example, users can provide a file path if the data object will be stored in a
             filesystem, or provide information of a database table when it is going to load the data
             into the table.
         group_name (Optional[str]): A string name used to organize multiple assets into groups. If
             not provided, the name "default" is used.
         code_version (Optional[str]): The version of the code that generates this asset.
-        freshness_policy (Optional[FreshnessPolicy]): A policy which indicates how up to date this
-            asset is intended to be.
+        freshness_policy (Optional[FreshnessPolicy]): (Deprecated) A policy which indicates how up
+            to date this asset is intended to be.
         auto_materialize_policy (Optional[AutoMaterializePolicy]): AutoMaterializePolicy to apply to
             the specified asset.
         backfill_policy (Optional[BackfillPolicy]): BackfillPolicy to apply to the specified asset.
         owners (Optional[Sequence[str]]): A list of strings representing owners of the asset. Each
             string can be a user's email address, or a team name prefixed with `team:`,
             e.g. `team:finops`.
+        tags (Optional[Mapping[str, str]]): Tags for filtering and organizing. These tags are not
+            attached to runs of the asset.
     """
 
     def __new__(
         cls,
         key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
         key: Optional[CoercibleToAssetKey] = None,
         dagster_type: Union[Type, DagsterType] = NoValueSentinel,
         description: Optional[str] = None,
         is_required: bool = True,
         io_manager_key: Optional[str] = None,
-        metadata: Optional[RawMetadataMapping] = None,
+        metadata: Optional[Mapping[str, Any]] = None,
         group_name: Optional[str] = None,
         code_version: Optional[str] = None,
         freshness_policy: Optional[FreshnessPolicy] = None,
         auto_materialize_policy: Optional[AutoMaterializePolicy] = None,
         backfill_policy: Optional[BackfillPolicy] = None,
         owners: Optional[Sequence[str]] = None,
+        tags: Optional[Mapping[str, str]] = None,
     ):
         if isinstance(key_prefix, str):
             key_prefix = [key_prefix]
 
         return super(AssetOut, cls).__new__(
             cls,
             key=AssetKey.from_coercible(key) if key is not None else None,
@@ -113,14 +119,15 @@
             auto_materialize_policy=check.opt_inst_param(
                 auto_materialize_policy, "auto_materialize_policy", AutoMaterializePolicy
             ),
             backfill_policy=check.opt_inst_param(
                 backfill_policy, "backfill_policy", BackfillPolicy
             ),
             owners=check.opt_sequence_param(owners, "owners", of_type=str),
+            tags=validate_definition_tags(tags),
         )
 
     def to_out(self) -> Out:
         return Out(
             dagster_type=self.dagster_type,
             description=self.description,
             metadata=self.metadata,
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_selection.py` & `dagster-1.7.0/dagster/_core/definitions/asset_selection.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,52 +1,50 @@
 import collections.abc
 import operator
 from abc import ABC, abstractmethod
 from functools import reduce
-from typing import AbstractSet, Iterable, Optional, Sequence, Union, cast
+from typing import AbstractSet, Iterable, List, Optional, Sequence, Union, cast
 
-import pydantic
-from pydantic import BaseModel
 from typing_extensions import TypeAlias
 
 import dagster._check as check
-from dagster._annotations import deprecated, experimental_param, public
-from dagster._core.definitions.asset_checks import AssetChecksDefinition
-from dagster._core.definitions.internal_asset_graph import InternalAssetGraph
+from dagster._annotations import deprecated, experimental, experimental_param, public
+from dagster._core.definitions.asset_graph import AssetGraph
 from dagster._core.definitions.resolved_asset_deps import resolve_similar_asset_names
 from dagster._core.errors import DagsterInvalidSubsetError
 from dagster._core.selector.subset_selector import (
     fetch_connected,
     fetch_sinks,
     fetch_sources,
     parse_clause,
 )
+from dagster._model import DagsterModel
 from dagster._serdes.serdes import whitelist_for_serdes
 
 from .asset_check_spec import AssetCheckKey
-from .asset_graph import AssetGraph
-from .assets import AssetsDefinition
-from .events import (
+from .asset_key import (
     AssetKey,
     CoercibleToAssetKey,
     CoercibleToAssetKeyPrefix,
     key_prefix_from_coercible,
 )
+from .assets import AssetsDefinition
+from .base_asset_graph import BaseAssetGraph
 from .source_asset import SourceAsset
 
 CoercibleToAssetSelection: TypeAlias = Union[
     str,
     Sequence[str],
     Sequence[AssetKey],
     Sequence[Union["AssetsDefinition", "SourceAsset"]],
     "AssetSelection",
 ]
 
 
-class AssetSelection(ABC, BaseModel, frozen=True):
+class AssetSelection(ABC, DagsterModel):
     """An AssetSelection defines a query over a set of assets and asset checks, normally all that are defined in a code location.
 
     You can use the "|", "&", and "-" operators to create unions, intersections, and differences of selections, respectively.
 
     AssetSelections are typically used with :py:func:`define_asset_job`.
 
     By default, selecting assets will also select all of the asset checks that target those assets.
@@ -54,27 +52,27 @@
     Examples:
         .. code-block:: python
 
             # Select all assets in group "marketing":
             AssetSelection.groups("marketing")
 
             # Select all assets in group "marketing", as well as the asset with key "promotion":
-            AssetSelection.groups("marketing") | AssetSelection.keys("promotion")
+            AssetSelection.groups("marketing") | AssetSelection.assets("promotion")
 
             # Select all assets in group "marketing" that are downstream of asset "leads":
-            AssetSelection.groups("marketing") & AssetSelection.keys("leads").downstream()
+            AssetSelection.groups("marketing") & AssetSelection.assets("leads").downstream()
 
             # Select a list of assets:
             AssetSelection.assets(*my_assets_list)
 
             # Select all assets except for those in group "marketing"
             AssetSelection.all() - AssetSelection.groups("marketing")
 
             # Select all assets which are materialized by the same op as "projections":
-            AssetSelection.keys("projections").required_multi_asset_neighbors()
+            AssetSelection.assets("projections").required_multi_asset_neighbors()
 
             # Select all assets in group "marketing" and exclude their asset checks:
             AssetSelection.groups("marketing") - AssetSelection.all_asset_checks()
 
             # Select all asset checks that target a list of assets:
             AssetSelection.checks_for_assets(*my_assets_list)
 
@@ -83,39 +81,78 @@
 
     """
 
     @public
     @experimental_param(param="include_sources")
     @staticmethod
     def all(include_sources: bool = False) -> "AllSelection":
-        """Returns a selection that includes all assets and asset checks.
+        """Returns a selection that includes all assets and their asset checks.
 
         Args:
             include_sources (bool): If True, then include all source assets.
         """
         return AllSelection(include_sources=include_sources)
 
     @public
     @staticmethod
     def all_asset_checks() -> "AllAssetCheckSelection":
         """Returns a selection that includes all asset checks."""
         return AllAssetCheckSelection()
 
     @public
     @staticmethod
-    def assets(*assets_defs: AssetsDefinition) -> "KeysAssetSelection":
-        """Returns a selection that includes all of the provided assets and asset checks that target them."""
-        return KeysAssetSelection(
-            selected_keys=[key for assets_def in assets_defs for key in assets_def.keys]
-        )
+    def assets(*assets_defs: Union[AssetsDefinition, CoercibleToAssetKey]) -> "KeysAssetSelection":
+        """Returns a selection that includes all of the provided assets and asset checks that target
+        them.
+
+        Args:
+            *assets_defs (Union[AssetsDefinition, str, Sequence[str], AssetKey]): The assets to
+                select.
+
+        Examples:
+            .. code-block:: python
+
+                AssetSelection.assets(AssetKey(["a"]))
+
+                AssetSelection.assets("a")
+
+                AssetSelection.assets(AssetKey(["a"]), AssetKey(["b"]))
+
+                AssetSelection.assets("a", "b")
+
+                @asset
+                def asset1():
+                    ...
+
+                AssetSelection.assets(asset1)
+
+                asset_key_list = [AssetKey(["a"]), AssetKey(["b"])]
+                AssetSelection.assets(*asset_key_list)
+        """
+        selected_keys: List[AssetKey] = []
+        for el in assets_defs:
+            if isinstance(el, AssetsDefinition):
+                selected_keys.extend(el.keys)
+            else:
+                selected_keys.append(
+                    AssetKey.from_user_string(el)
+                    if isinstance(el, str)
+                    else AssetKey.from_coercible(el)
+                )
+
+        return KeysAssetSelection(selected_keys=selected_keys)
 
     @public
     @staticmethod
+    @deprecated(breaking_version="2.0", additional_warn_text="Use AssetSelection.assets instead.")
     def keys(*asset_keys: CoercibleToAssetKey) -> "KeysAssetSelection":
-        """Returns a selection that includes assets with any of the provided keys and all asset checks that target them.
+        """Returns a selection that includes assets with any of the provided keys and all asset
+        checks that target them.
+
+        Deprecated: use AssetSelection.assets instead.
 
         Examples:
             .. code-block:: python
 
                 AssetSelection.keys(AssetKey(["a"]))
 
                 AssetSelection.keys("a")
@@ -170,29 +207,65 @@
                 selection.
         """
         check.tuple_param(group_strs, "group_strs", of_type=str)
         return GroupsAssetSelection(selected_groups=group_strs, include_sources=include_sources)
 
     @public
     @staticmethod
+    @experimental
+    def tag(key: str, value: str, include_sources: bool = False) -> "AssetSelection":
+        """Returns a selection that includes materializable assets that have the provided tag, and
+        all the asset checks that target them.
+
+
+        Args:
+            include_sources (bool): If True, then include source assets matching the group in the
+                selection.
+        """
+        return TagAssetSelection(key=key, value=value, include_sources=include_sources)
+
+    @staticmethod
+    def tag_string(string: str, include_sources: bool = False) -> "AssetSelection":
+        """Returns a selection that includes materializable assets that have the provided tag, and
+        all the asset checks that target them.
+
+
+        Args:
+            include_sources (bool): If True, then include source assets matching the group in the
+                selection.
+        """
+        split_by_equals_segments = string.split("=")
+        if len(split_by_equals_segments) == 1:
+            return TagAssetSelection(key=string, value="", include_sources=include_sources)
+        elif len(split_by_equals_segments) == 2:
+            key, value = split_by_equals_segments
+            return TagAssetSelection(key=key, value=value, include_sources=include_sources)
+        else:
+            check.failed(f"Invalid tag selection string: {string}. Must have no more than one '='.")
+
+    @public
+    @staticmethod
     def checks_for_assets(*assets_defs: AssetsDefinition) -> "AssetChecksForAssetKeysSelection":
         """Returns a selection with the asset checks that target the provided assets."""
         return AssetChecksForAssetKeysSelection(
             selected_asset_keys=[key for assets_def in assets_defs for key in assets_def.keys]
         )
 
     @public
     @staticmethod
-    def checks(*asset_checks: AssetChecksDefinition) -> "AssetCheckKeysSelection":
-        """Returns a selection that includes all of the provided asset checks."""
+    def checks(
+        *assets_defs_or_check_keys: Union[AssetsDefinition, AssetCheckKey],
+    ) -> "AssetCheckKeysSelection":
+        """Returns a selection that includes all of the provided asset checks or check keys."""
+        assets_defs = [ad for ad in assets_defs_or_check_keys if isinstance(ad, AssetsDefinition)]
+        check_keys = [key for key in assets_defs_or_check_keys if isinstance(key, AssetCheckKey)]
         return AssetCheckKeysSelection(
             selected_asset_check_keys=[
-                AssetCheckKey(asset_key=AssetKey.from_coercible(spec.asset_key), name=spec.name)
-                for checks_def in asset_checks
-                for spec in checks_def.specs
+                *(key for ad in assets_defs for key in ad.check_keys),
+                *check_keys,
             ]
         )
 
     @public
     def downstream(
         self, depth: Optional[int] = None, include_self: bool = True
     ) -> "DownstreamAssetSelection":
@@ -324,341 +397,405 @@
         return True
 
     def __sub__(self, other: "AssetSelection") -> "SubtractAssetSelection":
         check.inst_param(other, "other", AssetSelection)
         return SubtractAssetSelection(left=self, right=other)
 
     def resolve(
-        self, all_assets: Union[Iterable[Union[AssetsDefinition, SourceAsset]], AssetGraph]
+        self,
+        all_assets: Union[Iterable[Union[AssetsDefinition, SourceAsset]], BaseAssetGraph],
+        allow_missing: bool = False,
     ) -> AbstractSet[AssetKey]:
-        if isinstance(all_assets, AssetGraph):
+        """Returns the set of asset keys in all_assets that match this selection.
+
+        Args:
+            allow_missing (bool): If False, will raise an error if any of the leaf selections in the
+                asset selection target entities that don't exist in the set of provided assets.
+        """
+        if isinstance(all_assets, BaseAssetGraph):
             asset_graph = all_assets
         else:
             check.iterable_param(all_assets, "all_assets", (AssetsDefinition, SourceAsset))
-            asset_graph = InternalAssetGraph.from_assets(all_assets)
+            asset_graph = AssetGraph.from_assets(all_assets)
 
-        return self.resolve_inner(asset_graph)
+        return self.resolve_inner(asset_graph, allow_missing=allow_missing)
 
     @abstractmethod
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         raise NotImplementedError()
 
-    def resolve_checks(self, asset_graph: InternalAssetGraph) -> AbstractSet[AssetCheckKey]:
+    def resolve_checks(
+        self, asset_graph: AssetGraph, allow_missing: bool = False
+    ) -> AbstractSet[AssetCheckKey]:
         """We don't need this method currently, but it makes things consistent with resolve_inner. Currently
-        we don't store checks in the ExternalAssetGraph, so we only support InternalAssetGraph.
+        we don't store checks in the RemoteAssetGraph, so we only support AssetGraph.
         """
-        return self.resolve_checks_inner(asset_graph)
+        return self.resolve_checks_inner(asset_graph, allow_missing=allow_missing)
 
-    def resolve_checks_inner(self, asset_graph: InternalAssetGraph) -> AbstractSet[AssetCheckKey]:
+    def resolve_checks_inner(
+        self, asset_graph: AssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetCheckKey]:
         """By default, resolve to checks that target the selected assets. This is overriden for particular selections."""
         asset_keys = self.resolve(asset_graph)
         return {handle for handle in asset_graph.asset_check_keys if handle.asset_key in asset_keys}
 
-    @staticmethod
-    def _selection_from_string(string: str) -> "AssetSelection":
-        from dagster._core.definitions import AssetSelection
-
+    @classmethod
+    def from_string(cls, string: str) -> "AssetSelection":
         if string == "*":
-            return AssetSelection.all()
+            return cls.all()
 
         parts = parse_clause(string)
-        if not parts:
-            check.failed(f"Invalid selection string: {string}")
-        u, item, d = parts
-
-        selection: AssetSelection = AssetSelection.keys(item)
-        if u:
-            selection = selection.upstream(u)
-        if d:
-            selection = selection.downstream(d)
-        return selection
+        if parts is not None:
+            key_selection = cls.assets(parts.item_name)
+            if parts.up_depth and parts.down_depth:
+                selection = key_selection.upstream(parts.up_depth) | key_selection.downstream(
+                    parts.down_depth
+                )
+            elif parts.up_depth:
+                selection = key_selection.upstream(parts.up_depth)
+            elif parts.down_depth:
+                selection = key_selection.downstream(parts.down_depth)
+            else:
+                selection = key_selection
+            return selection
+
+        elif string.startswith("tag:"):
+            tag_str = string[len("tag:") :]
+            return cls.tag_string(tag_str)
+
+        check.failed(f"Invalid selection string: {string}")
 
     @classmethod
     def from_coercible(cls, selection: CoercibleToAssetSelection) -> "AssetSelection":
         if isinstance(selection, str):
-            return cls._selection_from_string(selection)
+            return cls.from_string(selection)
         elif isinstance(selection, AssetSelection):
             return selection
         elif isinstance(selection, collections.abc.Sequence) and all(
             isinstance(el, str) for el in selection
         ):
-            return reduce(
-                operator.or_, [cls._selection_from_string(cast(str, s)) for s in selection]
-            )
+            return reduce(operator.or_, [cls.from_string(cast(str, s)) for s in selection])
         elif isinstance(selection, collections.abc.Sequence) and all(
             isinstance(el, (AssetsDefinition, SourceAsset)) for el in selection
         ):
-            return AssetSelection.keys(
+            return AssetSelection.assets(
                 *(
                     key
                     for el in selection
                     for key in (
                         el.keys if isinstance(el, AssetsDefinition) else [cast(SourceAsset, el).key]
                     )
                 )
             )
         elif isinstance(selection, collections.abc.Sequence) and all(
             isinstance(el, AssetKey) for el in selection
         ):
-            return cls.keys(*cast(Sequence[AssetKey], selection))
+            return cls.assets(*cast(Sequence[AssetKey], selection))
         else:
             check.failed(
                 "selection argument must be one of str, Sequence[str], Sequence[AssetKey],"
                 " Sequence[AssetsDefinition], Sequence[SourceAsset], AssetSelection. Was"
                 f" {type(selection)}."
             )
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return AssetSelection.keys(*self.resolve(asset_graph))
-
-    def replace(self, **kwargs):
-        if pydantic.__version__ >= "2":
-            func = getattr(BaseModel, "model_copy")
-        else:
-            func = getattr(BaseModel, "copy")
-        return func(self, update=kwargs)
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return KeysAssetSelection(selected_keys=list(self.resolve(asset_graph)))
 
     def needs_parentheses_when_operand(self) -> bool:
         """When generating a string representation of an asset selection and this asset selection
         is an operand in a larger expression, whether it needs to be surrounded by parentheses.
         """
         return False
 
     def operand__str__(self) -> str:
         return f"({self})" if self.needs_parentheses_when_operand() else str(self)
 
 
 @whitelist_for_serdes
-class AllSelection(AssetSelection, frozen=True):
+class AllSelection(AssetSelection):
     include_sources: Optional[bool] = None
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         return (
             asset_graph.all_asset_keys
             if self.include_sources
             else asset_graph.materializable_asset_keys
         )
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
         return self
 
     def __str__(self) -> str:
         return "all materializable assets" + (" and source assets" if self.include_sources else "")
 
 
 @whitelist_for_serdes
-class AllAssetCheckSelection(AssetSelection, frozen=True):
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+class AllAssetCheckSelection(AssetSelection):
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         return set()
 
-    def resolve_checks_inner(self, asset_graph: InternalAssetGraph) -> AbstractSet[AssetCheckKey]:
+    def resolve_checks_inner(
+        self, asset_graph: AssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetCheckKey]:
         return asset_graph.asset_check_keys
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
         return self
 
     def __str__(self) -> str:
         return "all asset checks"
 
 
 @whitelist_for_serdes
-class AssetChecksForAssetKeysSelection(AssetSelection, frozen=True):
+class AssetChecksForAssetKeysSelection(AssetSelection):
     selected_asset_keys: Sequence[AssetKey]
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         return set()
 
-    def resolve_checks_inner(self, asset_graph: InternalAssetGraph) -> AbstractSet[AssetCheckKey]:
+    def resolve_checks_inner(
+        self, asset_graph: AssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetCheckKey]:
         return {
             handle
             for handle in asset_graph.asset_check_keys
             if handle.asset_key in self.selected_asset_keys
         }
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
         return self
 
+    def __str__(self) -> str:
+        if len(self.selected_asset_keys) == 1:
+            return f"asset_check:{self.selected_asset_keys[0].to_user_string()}"
+        return f"asset_check:({' or '.join(k.to_user_string() for k in self.selected_asset_keys)})"
+
 
 @whitelist_for_serdes
-class AssetCheckKeysSelection(AssetSelection, frozen=True):
+class AssetCheckKeysSelection(AssetSelection):
     selected_asset_check_keys: Sequence[AssetCheckKey]
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         return set()
 
-    def resolve_checks_inner(self, asset_graph: InternalAssetGraph) -> AbstractSet[AssetCheckKey]:
-        return {
-            handle
-            for handle in asset_graph.asset_check_keys
-            if handle in self.selected_asset_check_keys
-        }
+    def resolve_checks_inner(
+        self, asset_graph: AssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetCheckKey]:
+        specified_keys = set(self.selected_asset_check_keys)
+        missing_keys = {key for key in specified_keys if key not in asset_graph.asset_check_keys}
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
+        if not allow_missing and missing_keys:
+            raise DagsterInvalidSubsetError(
+                f"AssetCheckKey(s) {[k.to_user_string() for k in missing_keys]} were selected, but "
+                "no definitions supply these keys. Make sure all keys are spelled "
+                "correctly, and all definitions are correctly added to the "
+                f"`Definitions`."
+            )
+        return specified_keys & asset_graph.asset_check_keys
+
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
         return self
 
+    def __str__(self) -> str:
+        if len(self.selected_asset_check_keys) == 1:
+            return f"asset_check:{self.selected_asset_check_keys[0].to_user_string()}"
+        return f"asset_check:({' or '.join(k.to_user_string() for k in self.selected_asset_check_keys)})"
+
 
 @whitelist_for_serdes
-class AndAssetSelection(
-    AssetSelection,
-    frozen=True,
-    arbitrary_types_allowed=True,
-):
+class AndAssetSelection(AssetSelection):
     operands: Sequence[AssetSelection]
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         return reduce(
-            operator.and_, (selection.resolve_inner(asset_graph) for selection in self.operands)
+            operator.and_,
+            (
+                selection.resolve_inner(asset_graph, allow_missing=allow_missing)
+                for selection in self.operands
+            ),
         )
 
-    def resolve_checks_inner(self, asset_graph: InternalAssetGraph) -> AbstractSet[AssetCheckKey]:
+    def resolve_checks_inner(
+        self, asset_graph: AssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetCheckKey]:
         return reduce(
             operator.and_,
-            (selection.resolve_checks_inner(asset_graph) for selection in self.operands),
+            (
+                selection.resolve_checks_inner(asset_graph, allow_missing=allow_missing)
+                for selection in self.operands
+            ),
         )
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return self.replace(
-            operands=[
-                operand.to_serializable_asset_selection(asset_graph) for operand in self.operands
-            ]
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return self.model_copy(
+            update=dict(
+                operands=[
+                    operand.to_serializable_asset_selection(asset_graph)
+                    for operand in self.operands
+                ]
+            )
         )
 
     def needs_parentheses_when_operand(self) -> bool:
         return True
 
     def __str__(self) -> str:
         return " and ".join(operand.operand__str__() for operand in self.operands)
 
 
 @whitelist_for_serdes
-class OrAssetSelection(
-    AssetSelection,
-    frozen=True,
-    arbitrary_types_allowed=True,
-):
+class OrAssetSelection(AssetSelection):
     operands: Sequence[AssetSelection]
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         return reduce(
-            operator.or_, (selection.resolve_inner(asset_graph) for selection in self.operands)
+            operator.or_,
+            (
+                selection.resolve_inner(asset_graph, allow_missing=allow_missing)
+                for selection in self.operands
+            ),
         )
 
-    def resolve_checks_inner(self, asset_graph: InternalAssetGraph) -> AbstractSet[AssetCheckKey]:
+    def resolve_checks_inner(
+        self, asset_graph: AssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetCheckKey]:
         return reduce(
             operator.or_,
-            (selection.resolve_checks_inner(asset_graph) for selection in self.operands),
+            (
+                selection.resolve_checks_inner(asset_graph, allow_missing=allow_missing)
+                for selection in self.operands
+            ),
         )
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return self.replace(
-            operands=[
-                operand.to_serializable_asset_selection(asset_graph) for operand in self.operands
-            ]
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return self.model_copy(
+            update=dict(
+                operands=[
+                    operand.to_serializable_asset_selection(asset_graph)
+                    for operand in self.operands
+                ]
+            )
         )
 
     def needs_parentheses_when_operand(self) -> bool:
         return True
 
     def __str__(self) -> str:
         return " or ".join(operand.operand__str__() for operand in self.operands)
 
 
 @whitelist_for_serdes
-class SubtractAssetSelection(
-    AssetSelection,
-    frozen=True,
-    arbitrary_types_allowed=True,
-):
+class SubtractAssetSelection(AssetSelection):
     left: AssetSelection
     right: AssetSelection
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
-        return self.left.resolve_inner(asset_graph) - self.right.resolve_inner(asset_graph)
-
-    def resolve_checks_inner(self, asset_graph: InternalAssetGraph) -> AbstractSet[AssetCheckKey]:
-        return self.left.resolve_checks_inner(asset_graph) - self.right.resolve_checks_inner(
-            asset_graph
-        )
-
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return self.replace(
-            left=self.left.to_serializable_asset_selection(asset_graph),
-            right=self.right.to_serializable_asset_selection(asset_graph),
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
+        return self.left.resolve_inner(
+            asset_graph, allow_missing=allow_missing
+        ) - self.right.resolve_inner(asset_graph, allow_missing=allow_missing)
+
+    def resolve_checks_inner(
+        self, asset_graph: AssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetCheckKey]:
+        return self.left.resolve_checks_inner(
+            asset_graph, allow_missing=allow_missing
+        ) - self.right.resolve_checks_inner(asset_graph, allow_missing=allow_missing)
+
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return self.model_copy(
+            update=dict(
+                left=self.left.to_serializable_asset_selection(asset_graph),
+                right=self.right.to_serializable_asset_selection(asset_graph),
+            )
         )
 
     def needs_parentheses_when_operand(self) -> bool:
         return True
 
     def __str__(self) -> str:
         return f"{self.left.operand__str__()} - {self.right.operand__str__()}"
 
 
 @whitelist_for_serdes
-class SinksAssetSelection(
-    AssetSelection,
-    frozen=True,
-    arbitrary_types_allowed=True,
-):
+class SinksAssetSelection(AssetSelection):
     child: AssetSelection
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
-        selection = self.child.resolve_inner(asset_graph)
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
+        selection = self.child.resolve_inner(asset_graph, allow_missing=allow_missing)
         return fetch_sinks(asset_graph.asset_dep_graph, selection)
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return self.replace(child=self.child.to_serializable_asset_selection(asset_graph))
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return self.model_copy(
+            update=dict(child=self.child.to_serializable_asset_selection(asset_graph))
+        )
 
 
 @whitelist_for_serdes
-class RequiredNeighborsAssetSelection(
-    AssetSelection,
-    frozen=True,
-    arbitrary_types_allowed=True,
-):
+class RequiredNeighborsAssetSelection(AssetSelection):
     child: AssetSelection
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
-        selection = self.child.resolve_inner(asset_graph)
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
+        selection = self.child.resolve_inner(asset_graph, allow_missing=allow_missing)
         output = set(selection)
         for asset_key in selection:
-            output.update(asset_graph.get_required_multi_asset_keys(asset_key))
+            output.update(asset_graph.get(asset_key).execution_set_asset_keys)
         return output
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return self.replace(child=self.child.to_serializable_asset_selection(asset_graph))
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return self.model_copy(
+            update=dict(child=self.child.to_serializable_asset_selection(asset_graph))
+        )
 
 
 @whitelist_for_serdes
-class RootsAssetSelection(
-    AssetSelection,
-    frozen=True,
-    arbitrary_types_allowed=True,
-):
+class RootsAssetSelection(AssetSelection):
     child: AssetSelection
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
-        selection = self.child.resolve_inner(asset_graph)
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
+        selection = self.child.resolve_inner(asset_graph, allow_missing=allow_missing)
         return fetch_sources(asset_graph.asset_dep_graph, selection)
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return self.replace(child=self.child.to_serializable_asset_selection(asset_graph))
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return self.model_copy(
+            update=dict(child=self.child.to_serializable_asset_selection(asset_graph))
+        )
 
 
 @whitelist_for_serdes
-class DownstreamAssetSelection(
-    AssetSelection,
-    frozen=True,
-    arbitrary_types_allowed=True,
-):
+class DownstreamAssetSelection(AssetSelection):
     child: AssetSelection
     depth: Optional[int]
     include_self: bool
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
-        selection = self.child.resolve_inner(asset_graph)
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
+        selection = self.child.resolve_inner(asset_graph, allow_missing=allow_missing)
         return operator.sub(
             reduce(
                 operator.or_,
                 [
                     {asset_key}
                     | fetch_connected(
                         item=asset_key,
@@ -668,119 +805,154 @@
                     )
                     for asset_key in selection
                 ],
             ),
             selection if not self.include_self else set(),
         )
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return self.replace(child=self.child.to_serializable_asset_selection(asset_graph))
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return self.model_copy(
+            update=dict(child=self.child.to_serializable_asset_selection(asset_graph))
+        )
 
 
 @whitelist_for_serdes
-class GroupsAssetSelection(AssetSelection, frozen=True):
+class GroupsAssetSelection(AssetSelection):
     selected_groups: Sequence[str]
     include_sources: bool
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         base_set = (
             asset_graph.all_asset_keys
             if self.include_sources
             else asset_graph.materializable_asset_keys
         )
         return {
             key
             for group in self.selected_groups
             for key in asset_graph.asset_keys_for_group(group)
             if key in base_set
         }
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
         return self
 
     def __str__(self) -> str:
         if len(self.selected_groups) == 1:
             return f"group:{self.selected_groups[0]}"
         else:
             return f"group:({' or '.join(self.selected_groups)})"
 
 
 @whitelist_for_serdes
-class KeysAssetSelection(AssetSelection, frozen=True):
+class TagAssetSelection(AssetSelection):
+    key: str
+    value: str
+    include_sources: bool
+
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
+        base_set = (
+            asset_graph.all_asset_keys
+            if self.include_sources
+            else asset_graph.materializable_asset_keys
+        )
+
+        return {key for key in base_set if asset_graph.get(key).tags.get(self.key) == self.value}
+
+    def __str__(self) -> str:
+        return f"tag:{self.key}={self.value}"
+
+
+@whitelist_for_serdes
+class KeysAssetSelection(AssetSelection):
     selected_keys: Sequence[AssetKey]
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         specified_keys = set(self.selected_keys)
-        invalid_keys = {key for key in specified_keys if key not in asset_graph.all_asset_keys}
+        missing_keys = {key for key in specified_keys if key not in asset_graph.all_asset_keys}
+
+        if not allow_missing:
+            # Arbitrary limit to avoid huge error messages
+            keys_to_suggest = list(missing_keys)[:4]
+            suggestions = ""
+            for invalid_key in keys_to_suggest:
+                similar_names = resolve_similar_asset_names(invalid_key, asset_graph.all_asset_keys)
+                if similar_names:
+                    # Arbitrarily limit to 10 similar names to avoid a huge error message
+                    subset_similar_names = similar_names[:10]
+                    similar_to_string = ", ".join(
+                        (similar.to_string() for similar in subset_similar_names)
+                    )
+                    suggestions += (
+                        f"\n\nFor selected asset {invalid_key.to_string()}, did you mean one of "
+                        f"the following?\n\t{similar_to_string}"
+                    )
 
-        # Arbitrary limit to avoid huge error messages
-        keys_to_suggest = list(invalid_keys)[:4]
-        suggestions = ""
-        for invalid_key in keys_to_suggest:
-            similar_names = resolve_similar_asset_names(invalid_key, asset_graph.all_asset_keys)
-            if similar_names:
-                # Arbitrarily limit to 10 similar names to avoid a huge error message
-                subset_similar_names = similar_names[:10]
-                similar_to_string = ", ".join(
-                    (similar.to_string() for similar in subset_similar_names)
+            if missing_keys:
+                raise DagsterInvalidSubsetError(
+                    f"AssetKey(s) {[k.to_user_string() for k in missing_keys]} were selected, but "
+                    "no AssetsDefinition objects supply these keys. Make sure all keys are spelled "
+                    "correctly, and all AssetsDefinitions are correctly added to the "
+                    f"`Definitions`.{suggestions}"
                 )
-                suggestions += f"\n\nFor selected asset {invalid_key.to_string()}, did you mean one of the following?\n\t{similar_to_string}"
 
-        if invalid_keys:
-            raise DagsterInvalidSubsetError(
-                f"AssetKey(s) {invalid_keys} were selected, but no AssetsDefinition objects supply "
-                "these keys. Make sure all keys are spelled correctly, and all AssetsDefinitions "
-                f"are correctly added to the `Definitions`.{suggestions}"
-            )
-        return specified_keys
+        return specified_keys - missing_keys
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
         return self
 
     def needs_parentheses_when_operand(self) -> bool:
         return len(self.selected_keys) > 1
 
     def __str__(self) -> str:
         if len(self.selected_keys) <= 3:
             return f"{' or '.join(k.to_user_string() for k in self.selected_keys)}"
         else:
             return f"{len(self.selected_keys)} assets"
 
 
 @whitelist_for_serdes
-class KeyPrefixesAssetSelection(AssetSelection, frozen=True):
+class KeyPrefixesAssetSelection(AssetSelection):
     selected_key_prefixes: Sequence[Sequence[str]]
     include_sources: bool
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
         base_set = (
             asset_graph.all_asset_keys
             if self.include_sources
             else asset_graph.materializable_asset_keys
         )
         return {
             key
             for key in base_set
             if any(key.has_prefix(prefix) for prefix in self.selected_key_prefixes)
         }
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
         return self
 
     def __str__(self) -> str:
         key_prefix_strs = ["/".join(key_prefix) for key_prefix in self.selected_key_prefixes]
         if len(self.selected_key_prefixes) == 1:
             return f"key_prefix:{key_prefix_strs[0]}"
         else:
             return f"key_prefix:({' or '.join(key_prefix_strs)})"
 
 
 def _fetch_all_upstream(
     selection: AbstractSet[AssetKey],
-    asset_graph: AssetGraph,
+    asset_graph: BaseAssetGraph,
     depth: Optional[int] = None,
     include_self: bool = True,
 ) -> AbstractSet[AssetKey]:
     return operator.sub(
         reduce(
             operator.or_,
             [
@@ -796,32 +968,32 @@
             set(),
         ),
         selection if not include_self else set(),
     )
 
 
 @whitelist_for_serdes
-class UpstreamAssetSelection(
-    AssetSelection,
-    frozen=True,
-    arbitrary_types_allowed=True,
-):
+class UpstreamAssetSelection(AssetSelection):
     child: AssetSelection
     depth: Optional[int]
     include_self: bool
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
-        selection = self.child.resolve_inner(asset_graph)
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
+        selection = self.child.resolve_inner(asset_graph, allow_missing=allow_missing)
         if len(selection) == 0:
             return selection
         all_upstream = _fetch_all_upstream(selection, asset_graph, self.depth, self.include_self)
         return {key for key in all_upstream if key in asset_graph.materializable_asset_keys}
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return self.replace(child=self.child.to_serializable_asset_selection(asset_graph))
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return self.model_copy(
+            update=dict(child=self.child.to_serializable_asset_selection(asset_graph))
+        )
 
     def __str__(self) -> str:
         if self.depth is None:
             base = f"*({self.child})"
         elif self.depth == 0:
             base = str(self.child)
         else:
@@ -830,23 +1002,23 @@
         if self.include_self:
             return base
         else:
             return f"{base} - ({self.child})"
 
 
 @whitelist_for_serdes
-class ParentSourcesAssetSelection(
-    AssetSelection,
-    frozen=True,
-    arbitrary_types_allowed=True,
-):
+class ParentSourcesAssetSelection(AssetSelection):
     child: AssetSelection
 
-    def resolve_inner(self, asset_graph: AssetGraph) -> AbstractSet[AssetKey]:
-        selection = self.child.resolve_inner(asset_graph)
+    def resolve_inner(
+        self, asset_graph: BaseAssetGraph, allow_missing: bool
+    ) -> AbstractSet[AssetKey]:
+        selection = self.child.resolve_inner(asset_graph, allow_missing=allow_missing)
         if len(selection) == 0:
             return selection
         all_upstream = _fetch_all_upstream(selection, asset_graph)
         return {key for key in all_upstream if key in asset_graph.external_asset_keys}
 
-    def to_serializable_asset_selection(self, asset_graph: AssetGraph) -> "AssetSelection":
-        return self.replace(child=self.child.to_serializable_asset_selection(asset_graph))
+    def to_serializable_asset_selection(self, asset_graph: BaseAssetGraph) -> "AssetSelection":
+        return self.model_copy(
+            update=dict(child=self.child.to_serializable_asset_selection(asset_graph))
+        )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_sensor_definition.py` & `dagster-1.7.0/dagster/_core/definitions/asset_sensor_definition.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_spec.py` & `dagster-1.7.0/dagster/_core/definitions/asset_spec.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 
 from .auto_materialize_policy import AutoMaterializePolicy
 from .events import (
     AssetKey,
     CoercibleToAssetKey,
 )
 from .freshness_policy import FreshnessPolicy
-from .metadata import RawMetadataMapping
+from .utils import validate_definition_tags
 
 if TYPE_CHECKING:
     from dagster._core.definitions.asset_dep import AssetDep, CoercibleToAssetDep
 
 # SYSTEM_METADATA_KEY_ASSET_EXECUTION_TYPE lives on the metadata of an asset
 # (which currently ends up on the Output associated with the asset key)
 # whih encodes the execution type the of asset. "Unexecutable" assets are assets
@@ -51,28 +51,30 @@
 class AssetExecutionType(Enum):
     OBSERVATION = "OBSERVATION"
     UNEXECUTABLE = "UNEXECUTABLE"
     MATERIALIZATION = "MATERIALIZATION"
 
 
 @experimental_param(param="owners")
+@experimental_param(param="tags")
 class AssetSpec(
     NamedTuple(
         "_AssetSpec",
         [
             ("key", PublicAttr[AssetKey]),
             ("deps", PublicAttr[Iterable["AssetDep"]]),
             ("description", PublicAttr[Optional[str]]),
             ("metadata", PublicAttr[Optional[Mapping[str, Any]]]),
             ("group_name", PublicAttr[Optional[str]]),
             ("skippable", PublicAttr[bool]),
             ("code_version", PublicAttr[Optional[str]]),
             ("freshness_policy", PublicAttr[Optional[FreshnessPolicy]]),
             ("auto_materialize_policy", PublicAttr[Optional[AutoMaterializePolicy]]),
             ("owners", PublicAttr[Optional[Sequence[str]]]),
+            ("tags", PublicAttr[Optional[Mapping[str, str]]]),
         ],
     )
 ):
     """Specifies the core attributes of an asset. This object is attached to the decorated
     function that defines how it materialized.
 
     Attributes:
@@ -85,37 +87,40 @@
             asset corresponds to.
         skippable (bool): Whether this asset can be omitted during materialization, causing downstream
             dependencies to skip.
         group_name (Optional[str]): A string name used to organize multiple assets into groups. If
             not provided, the name "default" is used.
         code_version (Optional[str]): The version of the code for this specific asset,
             overriding the code version of the materialization function
-        freshness_policy (Optional[FreshnessPolicy]): A policy which indicates how up to date this
-            asset is intended to be.
+        freshness_policy (Optional[FreshnessPolicy]): (Deprecated) A policy which indicates how up
+            to date this asset is intended to be.
         auto_materialize_policy (Optional[AutoMaterializePolicy]): AutoMaterializePolicy to apply to
             the specified asset.
         backfill_policy (Optional[BackfillPolicy]): BackfillPolicy to apply to the specified asset.
         owners (Optional[Sequence[str]]): A list of strings representing owners of the asset. Each
             string can be a user's email address, or a team name prefixed with `team:`,
             e.g. `team:finops`.
+        tags (Optional[Mapping[str, str]]): Tags for filtering and organizing. These tags are not
+            attached to runs of the asset.
     """
 
     def __new__(
         cls,
         key: CoercibleToAssetKey,
         *,
         deps: Optional[Iterable["CoercibleToAssetDep"]] = None,
         description: Optional[str] = None,
-        metadata: Optional[RawMetadataMapping] = None,
+        metadata: Optional[Mapping[str, Any]] = None,
         skippable: bool = False,
         group_name: Optional[str] = None,
         code_version: Optional[str] = None,
         freshness_policy: Optional[FreshnessPolicy] = None,
         auto_materialize_policy: Optional[AutoMaterializePolicy] = None,
         owners: Optional[Sequence[str]] = None,
+        tags: Optional[Mapping[str, str]] = None,
     ):
         from dagster._core.definitions.asset_dep import coerce_to_deps_and_check_duplicates
 
         key = AssetKey.from_coercible(key)
         asset_deps = coerce_to_deps_and_check_duplicates(deps, key)
 
         return super().__new__(
@@ -134,8 +139,9 @@
             ),
             auto_materialize_policy=check.opt_inst_param(
                 auto_materialize_policy,
                 "auto_materialize_policy",
                 AutoMaterializePolicy,
             ),
             owners=check.opt_sequence_param(owners, "owners", of_type=str),
+            tags=validate_definition_tags(tags),
         )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/asset_subset.py` & `dagster-1.7.0/dagster/_core/definitions/asset_subset.py`

 * *Files 2% similar despite different names*

```diff
@@ -143,27 +143,35 @@
 
     @staticmethod
     def from_asset_partitions_set(
         asset_key: AssetKey,
         partitions_def: Optional[PartitionsDefinition],
         asset_partitions_set: AbstractSet[AssetKeyPartitionKey],
     ) -> "ValidAssetSubset":
-        if partitions_def is None:
-            return ValidAssetSubset(asset_key=asset_key, value=bool(asset_partitions_set))
-        else:
-            return ValidAssetSubset(
+        return (
+            ValidAssetSubset.from_partition_keys(
                 asset_key=asset_key,
-                value=partitions_def.subset_with_partition_keys(
-                    {
-                        ap.partition_key
-                        for ap in asset_partitions_set
-                        if ap.partition_key is not None
-                    }
-                ),
+                partitions_def=partitions_def,
+                partition_keys={
+                    ap.partition_key for ap in asset_partitions_set if ap.partition_key is not None
+                },
             )
+            if partitions_def
+            else ValidAssetSubset(asset_key=asset_key, value=bool(asset_partitions_set))
+        )
+
+    @staticmethod
+    def from_partition_keys(
+        asset_key: AssetKey,
+        partitions_def: PartitionsDefinition,
+        partition_keys: AbstractSet[str],
+    ) -> "ValidAssetSubset":
+        return ValidAssetSubset(
+            asset_key=asset_key, value=partitions_def.subset_with_partition_keys(partition_keys)
+        )
 
     def __contains__(self, item: AssetKeyPartitionKey) -> bool:
         if not self.is_partitioned:
             return (
                 item.asset_key == self.asset_key and item.partition_key is None and self.bool_value
             )
         else:
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/assets.py` & `dagster-1.7.0/dagster/_core/definitions/assets.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 import json
 import warnings
+from functools import cached_property
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Any,
     Dict,
     Iterable,
     Iterator,
@@ -26,14 +27,15 @@
     SYSTEM_METADATA_KEY_AUTO_CREATED_STUB_ASSET,
     SYSTEM_METADATA_KEY_AUTO_OBSERVE_INTERVAL_MINUTES,
     AssetExecutionType,
 )
 from dagster._core.definitions.auto_materialize_policy import AutoMaterializePolicy
 from dagster._core.definitions.backfill_policy import BackfillPolicy, BackfillPolicyType
 from dagster._core.definitions.freshness_policy import FreshnessPolicy
+from dagster._core.definitions.graph_definition import SubselectedGraphDefinition
 from dagster._core.definitions.metadata import ArbitraryMetadataMapping
 from dagster._core.definitions.multi_dimensional_partitions import MultiPartitionsDefinition
 from dagster._core.definitions.op_invocation import direct_invocation_result
 from dagster._core.definitions.op_selection import get_graph_subset
 from dagster._core.definitions.partition_mapping import MultiPartitionMapping
 from dagster._core.definitions.resource_requirement import (
     ExternalAssetIOManagerRequirement,
@@ -65,18 +67,18 @@
 from .partition_mapping import (
     PartitionMapping,
     get_builtin_partition_mapping_types,
     infer_partition_mapping,
 )
 from .resource_definition import ResourceDefinition
 from .source_asset import SourceAsset
-from .utils import DEFAULT_GROUP_NAME, validate_group_name
+from .utils import DEFAULT_GROUP_NAME, validate_definition_tags, validate_group_name
 
 if TYPE_CHECKING:
-    from .asset_graph import AssetKeyOrCheckKey
+    from .base_asset_graph import AssetKeyOrCheckKey
     from .graph_definition import GraphDefinition
 
 ASSET_SUBSET_INPUT_PREFIX = "__subset_input__"
 
 
 class UserAssetOwner(NamedTuple):
     email: str
@@ -85,14 +87,23 @@
 class TeamAssetOwner(NamedTuple):
     team: str
 
 
 AssetOwner = Union[UserAssetOwner, TeamAssetOwner]
 
 
+def asset_owner_to_str(owner: AssetOwner) -> str:
+    if isinstance(owner, UserAssetOwner):
+        return owner.email
+    elif isinstance(owner, TeamAssetOwner):
+        return owner.team
+    else:
+        check.failed(f"Unexpected owner type {type(owner)}")
+
+
 class AssetsDefinition(ResourceAddable, RequiresResources, IHasInternalInit):
     """Defines a set of assets that are produced by the same op or graph.
 
     AssetsDefinitions are typically not instantiated directly, but rather produced using the
     :py:func:`@asset <asset>` or :py:func:`@multi_asset <multi_asset>` decorators.
     """
 
@@ -103,14 +114,15 @@
     _partition_mappings: Mapping[AssetKey, PartitionMapping]
     _asset_deps: Mapping[AssetKey, AbstractSet[AssetKey]]
     _resource_defs: Mapping[str, ResourceDefinition]
     _group_names_by_key: Mapping[AssetKey, str]
     _selected_asset_keys: AbstractSet[AssetKey]
     _can_subset: bool
     _metadata_by_key: Mapping[AssetKey, ArbitraryMetadataMapping]
+    _tags_by_key: Mapping[AssetKey, Mapping[str, str]]
     _freshness_policies_by_key: Mapping[AssetKey, FreshnessPolicy]
     _auto_materialize_policies_by_key: Mapping[AssetKey, AutoMaterializePolicy]
     _backfill_policy: Optional[BackfillPolicy]
     _code_versions_by_key: Mapping[AssetKey, Optional[str]]
     _descriptions_by_key: Mapping[AssetKey, str]
     _selected_asset_check_keys: AbstractSet[AssetCheckKey]
     _is_subset: bool
@@ -126,24 +138,25 @@
         partition_mappings: Optional[Mapping[AssetKey, PartitionMapping]] = None,
         asset_deps: Optional[Mapping[AssetKey, AbstractSet[AssetKey]]] = None,
         selected_asset_keys: Optional[AbstractSet[AssetKey]] = None,
         can_subset: bool = False,
         resource_defs: Optional[Mapping[str, object]] = None,
         group_names_by_key: Optional[Mapping[AssetKey, str]] = None,
         metadata_by_key: Optional[Mapping[AssetKey, ArbitraryMetadataMapping]] = None,
+        tags_by_key: Optional[Mapping[AssetKey, Mapping[str, str]]] = None,
         freshness_policies_by_key: Optional[Mapping[AssetKey, FreshnessPolicy]] = None,
         auto_materialize_policies_by_key: Optional[Mapping[AssetKey, AutoMaterializePolicy]] = None,
         backfill_policy: Optional[BackfillPolicy] = None,
         descriptions_by_key: Optional[Mapping[AssetKey, str]] = None,
         check_specs_by_output_name: Optional[Mapping[str, AssetCheckSpec]] = None,
         selected_asset_check_keys: Optional[AbstractSet[AssetCheckKey]] = None,
         is_subset: bool = False,
         owners_by_key: Optional[Mapping[AssetKey, Sequence[Union[str, AssetOwner]]]] = None,
-        # if adding new fields, make sure to handle them in the with_attributes, from_graph, and
-        # get_attributes_dict methods
+        # if adding new fields, make sure to handle them in the with_attributes, from_graph,
+        # from_op, and get_attributes_dict methods
     ):
         from dagster._core.execution.build_resources import wrap_resources_for_execution
 
         from .graph_definition import GraphDefinition
 
         if isinstance(node_def, GraphDefinition):
             _validate_graph_def(node_def)
@@ -158,15 +171,15 @@
         self._keys_by_output_name = check.mapping_param(
             keys_by_output_name,
             "keys_by_output_name",
             key_type=str,
             value_type=AssetKey,
         )
 
-        check.opt_mapping_param(
+        self._check_specs_by_output_name = check.opt_mapping_param(
             check_specs_by_output_name,
             "check_specs_by_output_name",
             key_type=str,
             value_type=AssetCheckSpec,
         )
 
         # if not specified assume all output assets depend on all input assets
@@ -238,42 +251,44 @@
                 self._selected_asset_check_keys = {
                     key for key in all_check_keys if key.asset_key in self._selected_asset_keys
                 }
             else:
                 # otherwise, use the selected checks
                 self._selected_asset_check_keys = selected_asset_check_keys
 
-        self._check_specs_by_output_name = {
-            name: spec
-            for name, spec in (check_specs_by_output_name or {}).items()
-            if spec.key in self._selected_asset_check_keys
-        }
         self._check_specs_by_key = {
-            spec.key: spec for spec in self._check_specs_by_output_name.values()
+            spec.key: spec
+            for spec in self._check_specs_by_output_name.values()
+            if spec.key in self._selected_asset_check_keys
         }
 
         self._can_subset = can_subset
 
         self._code_versions_by_key = {}
         self._metadata_by_key = dict(
             check.opt_mapping_param(
                 metadata_by_key, "metadata_by_key", key_type=AssetKey, value_type=dict
             )
         )
+
+        for tags in (tags_by_key or {}).values():
+            validate_definition_tags(tags)
+        self._tags_by_key = tags_by_key or {}
+
         self._descriptions_by_key = dict(
             check.opt_mapping_param(
                 descriptions_by_key, "descriptions_by_key", key_type=AssetKey, value_type=str
             )
         )
         for output_name, asset_key in keys_by_output_name.items():
             output_def, _ = node_def.resolve_output_to_origin(output_name, None)
-            self._metadata_by_key[asset_key] = merge_dicts(
-                output_def.metadata,
-                self._metadata_by_key.get(asset_key, {}),
-            )
+            self._metadata_by_key[asset_key] = {
+                **output_def.metadata,
+                **self._metadata_by_key.get(asset_key, {}),
+            }
             # We construct description from three sources of truth here. This
             # highly unfortunate. See commentary in @multi_asset's call to dagster_internal_init.
             description = (
                 self._descriptions_by_key.get(asset_key, output_def.description)
                 or node_def.description
             )
             if description:
@@ -362,28 +377,28 @@
                     else TeamAssetOwner(team=owner[5:])
                 )
                 for owner in owners
             ]
             for key, owners in (owners_by_key or {}).items()
         }
 
-    @staticmethod
     def dagster_internal_init(
         *,
         keys_by_input_name: Mapping[str, AssetKey],
         keys_by_output_name: Mapping[str, AssetKey],
         node_def: NodeDefinition,
         partitions_def: Optional[PartitionsDefinition],
         partition_mappings: Optional[Mapping[AssetKey, PartitionMapping]],
         asset_deps: Optional[Mapping[AssetKey, AbstractSet[AssetKey]]],
         selected_asset_keys: Optional[AbstractSet[AssetKey]],
         can_subset: bool,
         resource_defs: Optional[Mapping[str, object]],
         group_names_by_key: Optional[Mapping[AssetKey, str]],
         metadata_by_key: Optional[Mapping[AssetKey, ArbitraryMetadataMapping]],
+        tags_by_key: Optional[Mapping[AssetKey, Mapping[str, str]]],
         freshness_policies_by_key: Optional[Mapping[AssetKey, FreshnessPolicy]],
         auto_materialize_policies_by_key: Optional[Mapping[AssetKey, AutoMaterializePolicy]],
         backfill_policy: Optional[BackfillPolicy],
         descriptions_by_key: Optional[Mapping[AssetKey, str]],
         check_specs_by_output_name: Optional[Mapping[str, AssetCheckSpec]],
         selected_asset_check_keys: Optional[AbstractSet[AssetCheckKey]],
         is_subset: bool,
@@ -397,14 +412,15 @@
             partition_mappings=partition_mappings,
             asset_deps=asset_deps,
             selected_asset_keys=selected_asset_keys,
             can_subset=can_subset,
             resource_defs=resource_defs,
             group_names_by_key=group_names_by_key,
             metadata_by_key=metadata_by_key,
+            tags_by_key=tags_by_key,
             freshness_policies_by_key=freshness_policies_by_key,
             auto_materialize_policies_by_key=auto_materialize_policies_by_key,
             backfill_policy=backfill_policy,
             descriptions_by_key=descriptions_by_key,
             check_specs_by_output_name=check_specs_by_output_name,
             selected_asset_check_keys=selected_asset_check_keys,
             is_subset=is_subset,
@@ -435,14 +451,15 @@
         partitions_def: Optional[PartitionsDefinition] = None,
         partition_mappings: Optional[Mapping[str, PartitionMapping]] = None,
         resource_defs: Optional[Mapping[str, ResourceDefinition]] = None,
         group_name: Optional[str] = None,
         group_names_by_output_name: Optional[Mapping[str, Optional[str]]] = None,
         descriptions_by_output_name: Optional[Mapping[str, str]] = None,
         metadata_by_output_name: Optional[Mapping[str, Optional[ArbitraryMetadataMapping]]] = None,
+        tags_by_output_name: Optional[Mapping[str, Optional[Mapping[str, str]]]] = None,
         freshness_policies_by_output_name: Optional[Mapping[str, Optional[FreshnessPolicy]]] = None,
         auto_materialize_policies_by_output_name: Optional[
             Mapping[str, Optional[AutoMaterializePolicy]]
         ] = None,
         backfill_policy: Optional[BackfillPolicy] = None,
         can_subset: bool = False,
         check_specs: Optional[Sequence[AssetCheckSpec]] = None,
@@ -485,14 +502,18 @@
                 outputs, and values are the group name. Cannot be used with the group_name argument.
             descriptions_by_output_name (Optional[Mapping[str, Optional[str]]]): Defines a description to be
                 associated with each of the output asstes for this graph.
             metadata_by_output_name (Optional[Mapping[str, Optional[RawMetadataMapping]]]): Defines metadata to
                 be associated with each of the output assets for this node. Keys are names of the
                 outputs, and values are dictionaries of metadata to be associated with the related
                 asset.
+            tags_by_output_name (Optional[Mapping[str, Optional[Mapping[str, str]]]]): Defines
+                tags to be associated with each othe output assets for this node. Keys are the names
+                of outputs, and values are dictionaries of tags to be associated with the related
+                asset.
             freshness_policies_by_output_name (Optional[Mapping[str, Optional[FreshnessPolicy]]]): Defines a
                 FreshnessPolicy to be associated with some or all of the output assets for this node.
                 Keys are the names of the outputs, and values are the FreshnessPolicies to be attached
                 to the associated asset.
             auto_materialize_policies_by_output_name (Optional[Mapping[str, Optional[AutoMaterializePolicy]]]): Defines an
                 AutoMaterializePolicy to be associated with some or all of the output assets for this node.
                 Keys are the names of the outputs, and values are the AutoMaterializePolicies to be attached
@@ -509,14 +530,15 @@
             partitions_def=partitions_def,
             partition_mappings=partition_mappings,
             resource_defs=resource_defs,
             group_name=group_name,
             group_names_by_output_name=group_names_by_output_name,
             descriptions_by_output_name=descriptions_by_output_name,
             metadata_by_output_name=metadata_by_output_name,
+            tags_by_output_name=tags_by_output_name,
             freshness_policies_by_output_name=freshness_policies_by_output_name,
             auto_materialize_policies_by_output_name=auto_materialize_policies_by_output_name,
             backfill_policy=backfill_policy,
             can_subset=can_subset,
             check_specs=check_specs,
         )
 
@@ -531,14 +553,15 @@
         internal_asset_deps: Optional[Mapping[str, Set[AssetKey]]] = None,
         partitions_def: Optional[PartitionsDefinition] = None,
         partition_mappings: Optional[Mapping[str, PartitionMapping]] = None,
         group_name: Optional[str] = None,
         group_names_by_output_name: Optional[Mapping[str, Optional[str]]] = None,
         descriptions_by_output_name: Optional[Mapping[str, str]] = None,
         metadata_by_output_name: Optional[Mapping[str, Optional[ArbitraryMetadataMapping]]] = None,
+        tags_by_output_name: Optional[Mapping[str, Optional[Mapping[str, str]]]] = None,
         freshness_policies_by_output_name: Optional[Mapping[str, Optional[FreshnessPolicy]]] = None,
         auto_materialize_policies_by_output_name: Optional[
             Mapping[str, Optional[AutoMaterializePolicy]]
         ] = None,
         backfill_policy: Optional[BackfillPolicy] = None,
         can_subset: bool = False,
     ) -> "AssetsDefinition":
@@ -576,14 +599,18 @@
                 outputs, and values are the group name. Cannot be used with the group_name argument.
             descriptions_by_output_name (Optional[Mapping[str, Optional[str]]]): Defines a description to be
                 associated with each of the output asstes for this graph.
             metadata_by_output_name (Optional[Mapping[str, Optional[RawMetadataMapping]]]): Defines metadata to
                 be associated with each of the output assets for this node. Keys are names of the
                 outputs, and values are dictionaries of metadata to be associated with the related
                 asset.
+            tags_by_output_name (Optional[Mapping[str, Optional[Mapping[str, str]]]]): Defines
+                tags to be associated with each othe output assets for this node. Keys are the names
+                of outputs, and values are dictionaries of tags to be associated with the related
+                asset.
             freshness_policies_by_output_name (Optional[Mapping[str, Optional[FreshnessPolicy]]]): Defines a
                 FreshnessPolicy to be associated with some or all of the output assets for this node.
                 Keys are the names of the outputs, and values are the FreshnessPolicies to be attached
                 to the associated asset.
             auto_materialize_policies_by_output_name (Optional[Mapping[str, Optional[AutoMaterializePolicy]]]): Defines an
                 AutoMaterializePolicy to be associated with some or all of the output assets for this node.
                 Keys are the names of the outputs, and values are the AutoMaterializePolicies to be attached
@@ -598,14 +625,15 @@
             internal_asset_deps=internal_asset_deps,
             partitions_def=partitions_def,
             partition_mappings=partition_mappings,
             group_name=group_name,
             group_names_by_output_name=group_names_by_output_name,
             descriptions_by_output_name=descriptions_by_output_name,
             metadata_by_output_name=metadata_by_output_name,
+            tags_by_output_name=tags_by_output_name,
             freshness_policies_by_output_name=freshness_policies_by_output_name,
             auto_materialize_policies_by_output_name=auto_materialize_policies_by_output_name,
             backfill_policy=backfill_policy,
             can_subset=can_subset,
         )
 
     @staticmethod
@@ -619,14 +647,15 @@
         partitions_def: Optional[PartitionsDefinition] = None,
         partition_mappings: Optional[Mapping[str, PartitionMapping]] = None,
         resource_defs: Optional[Mapping[str, ResourceDefinition]] = None,
         group_name: Optional[str] = None,
         group_names_by_output_name: Optional[Mapping[str, Optional[str]]] = None,
         descriptions_by_output_name: Optional[Mapping[str, str]] = None,
         metadata_by_output_name: Optional[Mapping[str, Optional[ArbitraryMetadataMapping]]] = None,
+        tags_by_output_name: Optional[Mapping[str, Optional[Mapping[str, str]]]] = None,
         freshness_policies_by_output_name: Optional[Mapping[str, Optional[FreshnessPolicy]]] = None,
         auto_materialize_policies_by_output_name: Optional[
             Mapping[str, Optional[AutoMaterializePolicy]]
         ] = None,
         backfill_policy: Optional[BackfillPolicy] = None,
         can_subset: bool = False,
         check_specs: Optional[Sequence[AssetCheckSpec]] = None,
@@ -729,14 +758,23 @@
                     keys_by_output_name_with_prefix[output_name]: metadata
                     for output_name, metadata in metadata_by_output_name.items()
                     if metadata is not None
                 }
                 if metadata_by_output_name
                 else None
             ),
+            tags_by_key=(
+                {
+                    keys_by_output_name_with_prefix[output_name]: tags
+                    for output_name, tags in tags_by_output_name.items()
+                    if tags is not None
+                }
+                if tags_by_output_name
+                else None
+            ),
             freshness_policies_by_key=(
                 {
                     keys_by_output_name_with_prefix[output_name]: freshness_policy
                     for output_name, freshness_policy in freshness_policies_by_output_name.items()
                     if freshness_policy is not None
                 }
                 if freshness_policies_by_output_name
@@ -863,14 +901,18 @@
         """AbstractSet[AssetKey]: The asset keys associated with this AssetsDefinition."""
         return self._selected_asset_keys
 
     @property
     def has_keys(self) -> bool:
         return len(self.keys) > 0
 
+    @property
+    def has_check_keys(self) -> bool:
+        return len(self.check_keys) > 0
+
     @public
     @property
     def dependency_keys(self) -> Iterable[AssetKey]:
         """Iterable[AssetKey]: The asset keys which are upstream of any asset included in this
         AssetsDefinition.
         """
         # the input asset keys that are directly upstream of a selected asset key
@@ -885,17 +927,26 @@
 
     @property
     def node_keys_by_input_name(self) -> Mapping[str, AssetKey]:
         """AssetKey for each input on the underlying NodeDefinition."""
         return self._keys_by_input_name
 
     @property
-    def check_specs_by_output_name(self) -> Mapping[str, AssetCheckSpec]:
+    def node_check_specs_by_output_name(self) -> Mapping[str, AssetCheckSpec]:
+        """AssetCheckSpec for each output on the underlying NodeDefinition."""
         return self._check_specs_by_output_name
 
+    @property
+    def check_specs_by_output_name(self) -> Mapping[str, AssetCheckSpec]:
+        return {
+            name: spec
+            for name, spec in self._check_specs_by_output_name.items()
+            if spec.key in self._selected_asset_check_keys
+        }
+
     def get_spec_for_check_key(self, asset_check_key: AssetCheckKey) -> AssetCheckSpec:
         return self._check_specs_by_key[asset_check_key]
 
     @property
     def keys_by_output_name(self) -> Mapping[str, AssetKey]:
         return {
             name: key for name, key in self.node_keys_by_output_name.items() if key in self.keys
@@ -908,16 +959,24 @@
             {
                 output_name: spec.key
                 for output_name, spec in self.check_specs_by_output_name.items()
             },
         )
 
     @property
+    def asset_and_check_keys(self) -> AbstractSet["AssetKeyOrCheckKey"]:
+        return set(self.keys).union(self.check_keys)
+
+    @property
     def keys_by_input_name(self) -> Mapping[str, AssetKey]:
-        upstream_keys = {dep_key for key in self.keys for dep_key in self.asset_deps[key]}
+        upstream_keys = {
+            *(dep_key for key in self.keys for dep_key in self.asset_deps[key]),
+            *(spec.asset_key for spec in self.check_specs if spec.asset_key not in self.keys),
+        }
+
         return {
             name: key for name, key in self.node_keys_by_input_name.items() if key in upstream_keys
         }
 
     @property
     def freshness_policies_by_key(self) -> Mapping[AssetKey, FreshnessPolicy]:
         return self._freshness_policies_by_key
@@ -963,14 +1022,18 @@
         return self._partitions_def
 
     @property
     def metadata_by_key(self) -> Mapping[AssetKey, ArbitraryMetadataMapping]:
         return self._metadata_by_key
 
     @property
+    def tags_by_key(self) -> Mapping[AssetKey, Mapping[str, str]]:
+        return self._tags_by_key
+
+    @property
     def code_versions_by_key(self) -> Mapping[AssetKey, Optional[str]]:
         return self._code_versions_by_key
 
     @property
     def partition_mappings(self) -> Mapping[AssetKey, PartitionMapping]:
         return self._partition_mappings
 
@@ -990,15 +1053,15 @@
     def check_specs(self) -> Iterable[AssetCheckSpec]:
         """Returns the asset check specs defined on this AssetsDefinition, i.e. the checks that can
         be executed while materializing the assets.
 
         Returns:
             Iterable[AssetsCheckSpec]:
         """
-        return self._check_specs_by_output_name.values()
+        return self.check_specs_by_output_name.values()
 
     @property
     def check_keys(self) -> AbstractSet[AssetCheckKey]:
         """Returns the selected asset checks associated by this AssetsDefinition.
 
         Returns:
             AbstractSet[Tuple[AssetKey, str]]: The selected asset checks. An asset check is
@@ -1064,22 +1127,22 @@
         self,
         *,
         output_asset_key_replacements: Optional[Mapping[AssetKey, AssetKey]] = None,
         input_asset_key_replacements: Optional[Mapping[AssetKey, AssetKey]] = None,
         group_names_by_key: Optional[Mapping[AssetKey, str]] = None,
         descriptions_by_key: Optional[Mapping[AssetKey, str]] = None,
         metadata_by_key: Optional[Mapping[AssetKey, ArbitraryMetadataMapping]] = None,
+        tags_by_key: Optional[Mapping[AssetKey, Mapping[str, str]]] = None,
         freshness_policy: Optional[
             Union[FreshnessPolicy, Mapping[AssetKey, FreshnessPolicy]]
         ] = None,
         auto_materialize_policy: Optional[
             Union[AutoMaterializePolicy, Mapping[AssetKey, AutoMaterializePolicy]]
         ] = None,
         backfill_policy: Optional[BackfillPolicy] = None,
-        is_subset: bool = False,
         check_specs_by_output_name: Optional[Mapping[str, AssetCheckSpec]] = None,
         selected_asset_check_keys: Optional[AbstractSet[AssetCheckKey]] = None,
     ) -> "AssetsDefinition":
         output_asset_key_replacements = check.opt_mapping_param(
             output_asset_key_replacements,
             "output_asset_key_replacements",
             key_type=AssetKey,
@@ -1182,14 +1245,24 @@
             metadata_by_key = self.metadata_by_key
 
         replaced_metadata_by_key = {
             output_asset_key_replacements.get(key, key): metadata
             for key, metadata in metadata_by_key.items()
         }
 
+        replaced_tags_by_key = {
+            output_asset_key_replacements.get(key, key): tags
+            for key, tags in self.tags_by_key.items()
+        }
+
+        replaced_owners_by_key = {
+            output_asset_key_replacements.get(key, key): owners
+            for key, owners in self.owners_by_key.items()
+        }
+
         replaced_attributes = dict(
             keys_by_input_name={
                 input_name: input_asset_key_replacements.get(key, key)
                 for input_name, key in self._keys_by_input_name.items()
             },
             keys_by_output_name={
                 output_name: output_asset_key_replacements.get(key, key)
@@ -1217,38 +1290,40 @@
                 **replaced_group_names_by_key,
                 **group_names_by_key,
             },
             metadata_by_key={
                 **self._metadata_by_key,
                 **replaced_metadata_by_key,
             },
+            tags_by_key=replaced_tags_by_key,
+            owners_by_key=replaced_owners_by_key,
             freshness_policies_by_key=replaced_freshness_policies_by_key,
             auto_materialize_policies_by_key=replaced_auto_materialize_policies_by_key,
             backfill_policy=backfill_policy if backfill_policy else self.backfill_policy,
             descriptions_by_key={
                 **self._descriptions_by_key,
                 **replaced_descriptions_by_key,
             },
-            is_subset=is_subset,
+            is_subset=self.is_subset,
             check_specs_by_output_name=check_specs_by_output_name
             if check_specs_by_output_name
-            else self.check_specs_by_output_name,
+            else self._check_specs_by_output_name,
             selected_asset_check_keys=selected_asset_check_keys
             if selected_asset_check_keys
             else self._selected_asset_check_keys,
         )
 
         merged_attrs = merge_dicts(self.get_attributes_dict(), replaced_attributes)
         return self.__class__.dagster_internal_init(**merged_attrs)
 
     def _subset_graph_backed_asset(
         self,
         selected_asset_keys: AbstractSet[AssetKey],
         selected_asset_check_keys: AbstractSet[AssetCheckKey],
-    ):
+    ) -> SubselectedGraphDefinition:
         from dagster._core.definitions.graph_definition import GraphDefinition
 
         if not isinstance(self.node_def, GraphDefinition):
             raise DagsterInvalidInvocationError(
                 "Method _subset_graph_backed_asset cannot subset an asset that is not a graph"
             )
 
@@ -1330,15 +1405,14 @@
             # keys_by_output_name and asset_deps so that the webserver can populate an warning when
             # this occurs. This is the same behavior as multi-asset subsetting.
 
             subsetted_asset_deps = {
                 out_asset_key: set(self._keys_by_input_name.values())
                 for out_asset_key in subsetted_keys_by_output_name.values()
             }
-
             replaced_attributes = dict(
                 keys_by_input_name=subsetted_keys_by_input_name,
                 keys_by_output_name=subsetted_keys_by_output_name,
                 node_def=subsetted_node,
                 asset_deps=subsetted_asset_deps,
                 selected_asset_keys=selected_asset_keys & self.keys,
                 selected_asset_check_keys=asset_check_subselection,
@@ -1419,14 +1493,15 @@
                 key=key,
                 metadata=output_def.metadata,
                 io_manager_key=output_def.io_manager_key,
                 description=output_def.description,
                 resource_defs=self.resource_defs,
                 partitions_def=self.partitions_def,
                 group_name=self.group_names_by_key[key],
+                tags=self.tags_by_key.get(key),
             )
 
     def get_io_manager_key_for_asset_key(self, key: AssetKey) -> str:
         output_name = self.get_output_name_for_asset_key(key)
         return self.node_def.resolve_output_to_origin(
             output_name, NodeHandle(self.node_def.name, parent=None)
         )[0].io_manager_key
@@ -1454,18 +1529,20 @@
     def __str__(self):
         if len(self.keys) == 1:
             return f"AssetsDefinition with key {self.key.to_string()}"
         else:
             asset_keys = ", ".join(sorted(([asset_key.to_string() for asset_key in self.keys])))
             return f"AssetsDefinition with keys {asset_keys}"
 
-    @property
+    @cached_property
     def unique_id(self) -> str:
         """A unique identifier for the AssetsDefinition that's stable across processes."""
-        return non_secure_md5_hash_str((json.dumps(sorted(self.keys))).encode("utf-8"))
+        return non_secure_md5_hash_str(
+            (json.dumps(sorted(self.keys) + sorted(self.check_keys))).encode("utf-8")
+        )
 
     def with_resources(self, resource_defs: Mapping[str, ResourceDefinition]) -> "AssetsDefinition":
         attributes_dict = self.get_attributes_dict()
         attributes_dict["resource_defs"] = merge_resource_defs(
             old_resource_defs=self.resource_defs,
             resource_defs_to_merge_in=resource_defs,
             requires_resources=self,
@@ -1488,14 +1565,15 @@
             freshness_policies_by_key=self._freshness_policies_by_key,
             auto_materialize_policies_by_key=self._auto_materialize_policies_by_key,
             backfill_policy=self._backfill_policy,
             descriptions_by_key=self._descriptions_by_key,
             check_specs_by_output_name=self._check_specs_by_output_name,
             selected_asset_check_keys=self._selected_asset_check_keys,
             owners_by_key=self._owners_by_key,
+            tags_by_key=self._tags_by_key,
         )
 
 
 def _infer_keys_by_input_names(
     node_def: Union["GraphDefinition", OpDefinition], keys_by_input_name: Mapping[str, AssetKey]
 ) -> Mapping[str, AssetKey]:
     all_input_names = [input_def.name for input_def in node_def.input_defs]
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/assets_job.py` & `dagster-1.7.0/dagster/_core/definitions/asset_job.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,33 +1,38 @@
 from collections import defaultdict
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Any,
+    Callable,
     Dict,
     Iterable,
     List,
     Mapping,
     Optional,
     Sequence,
     Set,
     Tuple,
     Union,
 )
 
 from toposort import CircularDependencyError, toposort
 
 import dagster._check as check
+from dagster._core.definitions.asset_check_spec import AssetCheckKey
+from dagster._core.definitions.asset_checks import has_only_asset_checks
+from dagster._core.definitions.asset_graph import AssetGraph
+from dagster._core.definitions.asset_selection import AssetSelection
 from dagster._core.definitions.hook_definition import HookDefinition
+from dagster._core.definitions.logger_definition import LoggerDefinition
 from dagster._core.definitions.policy import RetryPolicy
-from dagster._core.errors import DagsterInvalidDefinitionError
+from dagster._core.errors import DagsterInvalidDefinitionError, DagsterInvalidSubsetError
 from dagster._core.selector.subset_selector import AssetSelectionData
 from dagster._utils.merger import merge_dicts
 
-from .asset_checks import AssetChecksDefinition
 from .asset_layer import AssetLayer
 from .assets import AssetsDefinition
 from .config import ConfigMapping
 from .dependency import (
     BlockingAssetChecksDependencyDefinition,
     DependencyDefinition,
     DependencyMapping,
@@ -40,15 +45,14 @@
 from .executor_definition import ExecutorDefinition
 from .graph_definition import GraphDefinition
 from .job_definition import JobDefinition, default_job_io_manager
 from .metadata import RawMetadataValue
 from .partition import PartitionedConfig, PartitionsDefinition
 from .resource_definition import ResourceDefinition
 from .resource_requirement import ensure_requirements_satisfied
-from .source_asset import SourceAsset
 from .utils import DEFAULT_IO_MANAGER_KEY
 
 # Prefix for auto created jobs that are used to materialize assets
 ASSET_BASE_JOB_PREFIX = "__ASSET_JOB"
 
 if TYPE_CHECKING:
     from dagster._core.definitions.run_config import RunConfig
@@ -56,80 +60,98 @@
     from .asset_check_spec import AssetCheckSpec
 
 
 def is_base_asset_job_name(name: str) -> bool:
     return name.startswith(ASSET_BASE_JOB_PREFIX)
 
 
+def _build_partitioned_asset_job_lambda(
+    job_name: str,
+    asset_graph: AssetGraph,
+    partitions_def: PartitionsDefinition,
+    resource_defs: Optional[Mapping[str, ResourceDefinition]],
+    executor_def: Optional[ExecutorDefinition],
+    logger_defs: Optional[Mapping[str, LoggerDefinition]],
+) -> Callable[[], JobDefinition]:
+    def build_asset_job_lambda() -> JobDefinition:
+        executable_asset_keys = asset_graph.executable_asset_keys & {
+            *asset_graph.asset_keys_for_partitions_def(partitions_def=partitions_def),
+            *asset_graph.unpartitioned_asset_keys,
+        }
+        # For now, to preserve behavior keep all orphaned asset checks (where the target check
+        # has no corresponding executable definition) in all base jobs. When checks support
+        # partitions, they should only go in the corresponding partitioned job.
+        selection = AssetSelection.assets(*executable_asset_keys) | AssetSelection.checks(
+            *asset_graph.orphan_asset_check_keys
+        )
+        job_def = build_asset_job(
+            job_name,
+            asset_graph=get_asset_graph_for_job(asset_graph, selection),
+            resource_defs=resource_defs,
+            executor_def=executor_def,
+            partitions_def=partitions_def,
+        )
+        job_def.validate_resource_requirements_satisfied()
+
+        if logger_defs and not job_def.has_specified_loggers:
+            job_def = job_def.with_logger_defs(logger_defs)
+
+        return job_def
+
+    return build_asset_job_lambda
+
+
+def _build_global_asset_job_lambda(
+    asset_graph, executor_def, resource_defs, logger_defs
+) -> Callable[[], JobDefinition]:
+    def build_asset_job_lambda() -> JobDefinition:
+        job_def = build_asset_job(
+            name=ASSET_BASE_JOB_PREFIX,
+            asset_graph=asset_graph,
+            executor_def=executor_def,
+            resource_defs=resource_defs,
+        )
+        job_def.validate_resource_requirements_satisfied()
+        if logger_defs and not job_def.has_specified_loggers:
+            job_def = job_def.with_logger_defs(logger_defs)
+        return job_def
+
+    return build_asset_job_lambda
+
+
 def get_base_asset_jobs(
-    assets: Sequence[AssetsDefinition],
-    asset_checks: Sequence[AssetChecksDefinition],
+    asset_graph: AssetGraph,
     resource_defs: Optional[Mapping[str, ResourceDefinition]],
     executor_def: Optional[ExecutorDefinition],
-) -> Sequence[JobDefinition]:
-    executable_assets = [a for a in assets if a.is_executable]
-    unexecutable_assets = [a for a in assets if not a.is_executable]
-
-    executable_assets_by_partitions_def: Dict[
-        Optional[PartitionsDefinition], List[AssetsDefinition]
-    ] = defaultdict(list)
-    for asset in executable_assets:
-        executable_assets_by_partitions_def[asset.partitions_def].append(asset)
-    # sort to ensure some stability in the ordering
-    all_partitions_defs = sorted(
-        [p for p in executable_assets_by_partitions_def.keys() if p], key=repr
-    )
-
-    if len(all_partitions_defs) == 0:
-        return [
-            build_assets_job(
-                name=ASSET_BASE_JOB_PREFIX,
-                executable_assets=executable_assets,
-                loadable_assets=unexecutable_assets,
-                asset_checks=asset_checks,
-                executor_def=executor_def,
-                resource_defs=resource_defs,
+    logger_defs: Optional[Mapping[str, LoggerDefinition]],
+) -> Mapping[str, Callable[[], JobDefinition]]:
+    if len(asset_graph.all_partitions_defs) == 0:
+        return {
+            ASSET_BASE_JOB_PREFIX: _build_global_asset_job_lambda(
+                asset_graph, executor_def, resource_defs, logger_defs
             )
-        ]
+        }
     else:
-        unpartitioned_executable_assets = executable_assets_by_partitions_def.get(None, [])
-        jobs = []
-
-        for i, partitions_def in enumerate(all_partitions_defs):
-            # all base jobs contain all unpartitioned assets
-            executable_assets_for_job = [
-                *executable_assets_by_partitions_def[partitions_def],
-                *unpartitioned_executable_assets,
-            ]
-            jobs.append(
-                build_assets_job(
-                    f"{ASSET_BASE_JOB_PREFIX}_{i}",
-                    executable_assets=executable_assets_for_job,
-                    loadable_assets=[
-                        *(
-                            asset
-                            for asset in executable_assets
-                            if asset not in executable_assets_for_job
-                        ),
-                        *unexecutable_assets,
-                    ],
-                    asset_checks=asset_checks,
-                    resource_defs=resource_defs,
-                    executor_def=executor_def,
-                    partitions_def=partitions_def,
-                )
+        jobs = {}
+        for i, partitions_def in enumerate(asset_graph.all_partitions_defs):
+            job_name = f"{ASSET_BASE_JOB_PREFIX}_{i}"
+            jobs[job_name] = _build_partitioned_asset_job_lambda(
+                f"{ASSET_BASE_JOB_PREFIX}_{i}",
+                asset_graph,
+                partitions_def,
+                resource_defs,
+                executor_def,
+                logger_defs,
             )
         return jobs
 
 
-def build_assets_job(
+def build_asset_job(
     name: str,
-    executable_assets: Sequence[Union[AssetsDefinition, SourceAsset]],
-    loadable_assets: Optional[Sequence[Union[SourceAsset, AssetsDefinition]]] = None,
-    asset_checks: Optional[Sequence[AssetChecksDefinition]] = None,
+    asset_graph: AssetGraph,
     resource_defs: Optional[Mapping[str, object]] = None,
     description: Optional[str] = None,
     config: Optional[
         Union[ConfigMapping, Mapping[str, object], PartitionedConfig, "RunConfig"]
     ] = None,
     tags: Optional[Mapping[str, str]] = None,
     metadata: Optional[Mapping[str, RawMetadataValue]] = None,
@@ -143,19 +165,18 @@
     during resolution of jobs created with `define_asset_job`.
 
     The dependencies between the ops in the job are determined by the asset dependencies defined
     in the metadata on the provided asset nodes.
 
     Args:
         name (str): The name of the job.
-        executable_assets (Sequence[Union[AssetsDefinition, SourceAsset]]): A sequence of AssetsDefinitions or SourceAssets
-            to be executed by the job. SourceAssets must be observable.
-        loadable_assets (Optional[Sequence[Union[SourceAsset, AssetsDefinition]]]): A list of
-            AssetsDefinitions or SourceAssets that are not exectued by this job, but that are
-            available to be loaded as inputs by executable assets.
+        asset_graph (AssetGraph): The asset graph that contains the assets and checks to be
+            executed. Any assets in the graph that you do not wish to be executed must be
+            unexecutable. You can create an AssetGraph that selects the desired executable assets
+            using `get_asset_graph_job_subset`.
         resource_defs (Optional[Mapping[str, object]]): Resource defs to be included in
             this job.
         description (Optional[str]): A description of the job.
         op_retry_policy (Optional[RetryPolicy]): The default retry policy for all ops that compute assets in this job.
             Only used if retry policy is not defined on the asset definition.
 
     Examples:
@@ -172,100 +193,55 @@
             my_assets_job = build_assets_job("my_assets_job", assets=[asset1, asset2])
 
     Returns:
         JobDefinition: A job that materializes the given assets.
     """
     from dagster._core.execution.build_resources import wrap_resources_for_execution
 
-    check.str_param(name, "name")
-    check.iterable_param(executable_assets, "assets", of_type=(AssetsDefinition, SourceAsset))
-    for asset in executable_assets:
-        if not asset.is_executable:
-            keys = [asset.key] if isinstance(asset, SourceAsset) else asset.keys
-            check.failed(f"Passed unexecutable keys to executable_assets: {keys}")
-
-    loadable_assets = check.opt_sequence_param(
-        loadable_assets, "source_assets", of_type=(SourceAsset, AssetsDefinition)
-    )
-    asset_checks = check.opt_sequence_param(
-        asset_checks, "asset_checks", of_type=AssetChecksDefinition
-    )
-    check.opt_str_param(description, "description")
-    check.opt_inst_param(_asset_selection_data, "_asset_selection_data", AssetSelectionData)
-
     resource_defs = check.opt_mapping_param(resource_defs, "resource_defs")
     resource_defs = merge_dicts({DEFAULT_IO_MANAGER_KEY: default_job_io_manager}, resource_defs)
     wrapped_resource_defs = wrap_resources_for_execution(resource_defs)
-
-    assets = [asset for asset in executable_assets if isinstance(asset, AssetsDefinition)]
-    resolved_source_assets = [
-        asset for asset in executable_assets if isinstance(asset, SourceAsset)
-    ]
-    for asset in loadable_assets or []:
-        if isinstance(asset, AssetsDefinition):
-            resolved_source_assets += asset.to_source_assets()
-        elif isinstance(asset, SourceAsset):
-            resolved_source_assets.append(asset)
-
-    # figure out what partitions (if any) exist for this job
-    partitions_def = partitions_def or build_job_partitions_from_assets(assets)
-
-    deps, assets_defs_by_node_handle, asset_checks_defs_by_node_handle = build_node_deps(
-        assets, asset_checks
+    partitions_def = _infer_and_validate_common_partitions_def(
+        asset_graph, asset_graph.executable_asset_keys, partitions_def
     )
 
+    deps, assets_defs_by_node_handle = build_node_deps(asset_graph)
+
     # attempt to resolve cycles using multi-asset subsetting
     if _has_cycles(deps):
-        assets = _attempt_resolve_cycles(assets, resolved_source_assets)
+        asset_graph = _attempt_resolve_node_cycles(asset_graph)
+        deps, assets_defs_by_node_handle = build_node_deps(asset_graph)
 
-        deps, assets_defs_by_node_handle, asset_checks_defs_by_node_handle = build_node_deps(
-            assets,
-            asset_checks,
+    node_defs = [
+        asset.node_def
+        for asset in asset_graph.assets_defs_for_keys(
+            [
+                *asset_graph.executable_asset_keys,
+                *asset_graph.asset_check_keys,
+            ]
         )
-
-    if len(assets) > 0 or len(asset_checks) > 0:
-        node_defs = [
-            *(asset.node_def for asset in assets),
-            *(asset_check.node_def for asset_check in asset_checks),
-        ]
-        observable_source_assets_by_node_handle = {}
-    else:
-        node_defs = []
-        observable_source_assets_by_node_handle: Mapping[NodeHandle, SourceAsset] = {}
-        for asset in resolved_source_assets:
-            if (
-                isinstance(asset, SourceAsset)
-                and asset.is_observable
-                and asset.node_def is not None
-            ):
-                node_defs.append(asset.node_def)
-                node_handle = NodeHandle(asset.node_def.name, parent=None)
-                observable_source_assets_by_node_handle[node_handle] = asset
+    ]
 
     graph = GraphDefinition(
         name=name,
         node_defs=node_defs,
         dependencies=deps,
         description=description,
         input_mappings=None,
         output_mappings=None,
         config=None,
     )
 
     asset_layer = AssetLayer.from_graph_and_assets_node_mapping(
         graph_def=graph,
-        asset_checks_defs_by_node_handle=asset_checks_defs_by_node_handle,
-        source_assets=resolved_source_assets,
         assets_defs_by_outer_node_handle=assets_defs_by_node_handle,
-        observable_source_assets_by_node_handle=observable_source_assets_by_node_handle,
+        asset_graph=asset_graph,
     )
 
-    all_resource_defs = get_all_resource_defs(
-        assets, asset_checks, resolved_source_assets, wrapped_resource_defs
-    )
+    all_resource_defs = get_all_resource_defs(asset_graph, wrapped_resource_defs)
 
     if _asset_selection_data:
         original_job = _asset_selection_data.parent_job_def
         return graph.to_job(
             resource_defs=all_resource_defs,
             config=config,
             tags=tags,
@@ -290,143 +266,277 @@
         asset_layer=asset_layer,
         hooks=hooks,
         op_retry_policy=op_retry_policy,
         _asset_selection_data=_asset_selection_data,
     )
 
 
-def build_job_partitions_from_assets(
-    assets: Iterable[Union[AssetsDefinition, SourceAsset]],
-) -> Optional[PartitionsDefinition]:
-    assets_with_partitions_defs = [assets_def for assets_def in assets if assets_def.partitions_def]
+def get_asset_graph_for_job(
+    parent_asset_graph: AssetGraph, selection: AssetSelection
+) -> AssetGraph:
+    """Subset an AssetGraph to create an AssetGraph representing an asset job.
 
-    if len(assets_with_partitions_defs) == 0:
-        return None
+    The provided selection must satisfy certain constraints to comprise a valid asset job:
 
-    first_asset_with_partitions_def: Union[AssetsDefinition, SourceAsset] = (
-        assets_with_partitions_defs[0]
+    - The selected keys must be a subset of the existing executable asset keys.
+    - The selected keys must have at most one non-null partitions definition.
+
+    The returned AssetGraph will contain only the selected keys within executable AssetsDefinitions.
+    Any unselected dependencies will be included as unexecutable AssetsDefinitions.
+    """
+    from dagster._core.definitions.external_asset import (
+        create_unexecutable_external_assets_from_assets_def,
     )
-    for asset in assets_with_partitions_defs:
-        if asset.partitions_def != first_asset_with_partitions_def.partitions_def:
-            first_asset_key = _key_for_asset(asset).to_string()
-            second_asset_key = _key_for_asset(first_asset_with_partitions_def).to_string()
-            raise DagsterInvalidDefinitionError(
-                "When an assets job contains multiple partitioned assets, they must have the "
-                f"same partitions definitions, but asset '{first_asset_key}' and asset "
-                f"'{second_asset_key}' have different partitions definitions. "
+
+    selected_keys = selection.resolve(parent_asset_graph)
+    invalid_keys = selected_keys - parent_asset_graph.executable_asset_keys
+    if invalid_keys:
+        raise DagsterInvalidDefinitionError(
+            "Selected keys keys must be a subset of existing executable asset keys."
+            f" Invalid selected keys: {invalid_keys}",
+        )
+
+    _infer_and_validate_common_partitions_def(parent_asset_graph, selected_keys)
+
+    selected_check_keys = selection.resolve_checks(parent_asset_graph)
+
+    # _subset_assets_defs returns two lists of Assetsfinitions-- those included and those
+    # excluded by the selection. These collections retain their original execution type. We need
+    # to convert the excluded assets to unexecutable external assets.
+    executable_assets_defs, excluded_assets_defs = _subset_assets_defs(
+        parent_asset_graph.assets_defs, selected_keys, selected_check_keys
+    )
+
+    # Ideally we would include only the logical dependencies of our executable asset keys in our job
+    # asset graph. These could be obtained by calling `AssetsDefinition.dependency_keys` for each
+    # executable assets def.
+    #
+    # However, this is insufficient due to the way multi-asset subsetting works. Our execution
+    # machinery needs the AssetNodes for any input or output asset of a multi-asset that is touched
+    # by our selection, regardless of whether these assets are in our selection or their
+    # dependencies. Thus for now we retrieve all of these keys with `node_keys_by_{input,output}_name`.
+    # This is something we should probably fix in the future by appropriately adjusting multi-asset
+    # subsets.
+    other_keys = {
+        *(k for ad in executable_assets_defs for k in ad.node_keys_by_input_name.values()),
+        *(k for ad in executable_assets_defs for k in ad.node_keys_by_output_name.values()),
+    } - selected_keys
+    other_assets_defs, _ = _subset_assets_defs(
+        excluded_assets_defs, other_keys, None, allow_extraneous_asset_keys=True
+    )
+    unexecutable_assets_defs = [
+        unexecutable_ad
+        for ad in other_assets_defs
+        for unexecutable_ad in create_unexecutable_external_assets_from_assets_def(ad)
+    ]
+
+    return AssetGraph.from_assets([*executable_assets_defs, *unexecutable_assets_defs])
+
+
+def _subset_assets_defs(
+    assets: Iterable["AssetsDefinition"],
+    selected_asset_keys: AbstractSet[AssetKey],
+    selected_asset_check_keys: Optional[AbstractSet[AssetCheckKey]],
+    allow_extraneous_asset_keys: bool = False,
+) -> Tuple[
+    Sequence["AssetsDefinition"],
+    Sequence["AssetsDefinition"],
+]:
+    """Given a list of asset key selection queries, generate a set of AssetsDefinition objects
+    representing the included/excluded definitions.
+    """
+    included_assets: Set[AssetsDefinition] = set()
+    excluded_assets: Set[AssetsDefinition] = set()
+
+    # Do not match any assets with no keys
+    for asset in set(a for a in assets if a.has_keys or a.has_check_keys):
+        # intersection
+        selected_subset = selected_asset_keys & asset.keys
+
+        # if specific checks were selected, only include those
+        if selected_asset_check_keys is not None:
+            selected_check_subset = selected_asset_check_keys & asset.check_keys
+        # if no checks were selected, filter to checks that target selected assets
+        else:
+            selected_check_subset = {
+                key for key in asset.check_keys if key.asset_key in selected_asset_keys
+            }
+
+        # all assets in this def are selected
+        if selected_subset == asset.keys and selected_check_subset == asset.check_keys:
+            included_assets.add(asset)
+        # no assets in this def are selected
+        elif len(selected_subset) == 0 and len(selected_check_subset) == 0:
+            excluded_assets.add(asset)
+        elif asset.can_subset:
+            # subset of the asset that we want
+            subset_asset = asset.subset_for(selected_asset_keys, selected_check_subset)
+            included_assets.add(subset_asset)
+            # subset of the asset that we don't want
+            excluded_assets.add(
+                asset.subset_for(
+                    selected_asset_keys=asset.keys - subset_asset.keys,
+                    selected_asset_check_keys=(asset.check_keys - subset_asset.check_keys),
+                )
+            )
+        # If the AssetsDefinition is not subsettable, include the whole definition without
+        # subsetting, even though some keys are not present in our selection.
+        elif allow_extraneous_asset_keys:
+            included_assets.add(asset)
+        else:
+            raise DagsterInvalidSubsetError(
+                f"When building job, the AssetsDefinition '{asset.node_def.name}' "
+                f"contains asset keys {sorted(list(asset.keys))} and check keys "
+                f"{sorted(list(asset.check_keys))}, but "
+                f"attempted to select only assets {sorted(list(selected_subset))} and checks "
+                f"{sorted(list(selected_check_subset))}. "
+                "This AssetsDefinition does not support subsetting. Please select all "
+                "asset and check keys produced by this asset.\n\nIf using an AssetSelection, you may "
+                "use required_multi_asset_neighbors() to select any remaining assets, for "
+                "example:\nAssetSelection.assets('my_asset').required_multi_asset_neighbors()"
             )
 
-    return first_asset_with_partitions_def.partitions_def
+    return (
+        list(included_assets),
+        list(excluded_assets),
+    )
 
 
-def _key_for_asset(asset: Union[AssetsDefinition, SourceAsset]) -> AssetKey:
-    if isinstance(asset, AssetsDefinition):
-        return next(iter(asset.keys))
+def _infer_and_validate_common_partitions_def(
+    asset_graph: AssetGraph,
+    asset_keys: Iterable[AssetKey],
+    required_partitions_def: Optional[PartitionsDefinition] = None,
+) -> Optional[PartitionsDefinition]:
+    keys_by_partitions_def = defaultdict(set)
+    for key in asset_keys:
+        partitions_def = asset_graph.get(key).partitions_def
+        if partitions_def is not None:
+            if required_partitions_def is not None and partitions_def != required_partitions_def:
+                raise DagsterInvalidDefinitionError(
+                    f"Executable asset {key} has a different partitions definition than"
+                    f" the one specified for the job. Specifed partitions definition: {required_partitions_def}."
+                    f" Asset partitions definition: {partitions_def}."
+                )
+            keys_by_partitions_def[partitions_def].add(key)
+
+    if len(keys_by_partitions_def) > 1:
+        keys_by_partitions_def_str = "\n".join(
+            f"{partitions_def}: {asset_keys}"
+            for partitions_def, asset_keys in keys_by_partitions_def.items()
+        )
+        raise DagsterInvalidDefinitionError(
+            f"Selected assets must have the same partitions definitions, but the"
+            f" selected assets have different partitions definitions: \n{keys_by_partitions_def_str}"
+        )
+    elif len(keys_by_partitions_def) == 1:
+        return next(iter(keys_by_partitions_def.keys()))
     else:
-        return asset.key
+        return None
 
 
 def _get_blocking_asset_check_output_handles_by_asset_key(
-    assets_defs_by_node_handle, asset_checks_defs_by_node_handle
+    assets_defs_by_node_handle: Mapping[NodeHandle, AssetsDefinition],
 ) -> Mapping[AssetKey, AbstractSet[NodeOutputHandle]]:
     """For each asset key, returns the set of node output handles that correspond to asset check
     specs that should block the execution of downstream assets if they fail.
     """
     check_specs_by_node_output_handle: Mapping[NodeOutputHandle, AssetCheckSpec] = {}
 
     for node_handle, assets_def in assets_defs_by_node_handle.items():
         for output_name, check_spec in assets_def.check_specs_by_output_name.items():
             check_specs_by_node_output_handle[
                 NodeOutputHandle(node_handle, output_name=output_name)
             ] = check_spec
 
-    for node_handle, asset_checks_def in asset_checks_defs_by_node_handle.items():
-        for output_name, check_spec in asset_checks_def.specs_by_output_name.items():
-            check_specs_by_node_output_handle[
-                NodeOutputHandle(node_handle, output_name=output_name)
-            ] = check_spec
-
     blocking_asset_check_output_handles_by_asset_key: Dict[AssetKey, Set[NodeOutputHandle]] = (
         defaultdict(set)
     )
     for node_output_handle, check_spec in check_specs_by_node_output_handle.items():
         if check_spec.blocking:
             blocking_asset_check_output_handles_by_asset_key[check_spec.asset_key].add(
                 node_output_handle
             )
 
     return blocking_asset_check_output_handles_by_asset_key
 
 
 def build_node_deps(
-    assets_defs: Iterable[AssetsDefinition],
-    asset_checks_defs: Sequence[AssetChecksDefinition],
+    asset_graph: AssetGraph,
 ) -> Tuple[
     DependencyMapping[NodeInvocation],
     Mapping[NodeHandle, AssetsDefinition],
-    Mapping[NodeHandle, AssetChecksDefinition],
 ]:
     # sort so that nodes get a consistent name
-    assets_defs = sorted(assets_defs, key=lambda ad: (sorted((ak for ak in ad.keys))))
+    assets_defs = sorted(asset_graph.assets_defs, key=lambda ad: (sorted((ak for ak in ad.keys))))
 
     # if the same graph/op is used in multiple assets_definitions, their invocations must have
     # different names. we keep track of definitions that share a name and add a suffix to their
     # invocations to solve this issue
     collisions: Dict[str, int] = {}
     assets_defs_by_node_handle: Dict[NodeHandle, AssetsDefinition] = {}
     node_alias_and_output_by_asset_key: Dict[AssetKey, Tuple[str, str]] = {}
-    for assets_def in assets_defs:
+    for assets_def in (ad for ad in assets_defs if ad.is_executable):
         node_name = assets_def.node_def.name
         if collisions.get(node_name):
             collisions[node_name] += 1
             node_alias = f"{node_name}_{collisions[node_name]}"
         else:
             collisions[node_name] = 1
             node_alias = node_name
 
         # unique handle for each AssetsDefinition
         assets_defs_by_node_handle[NodeHandle(node_alias, parent=None)] = assets_def
         for output_name, key in assets_def.keys_by_output_name.items():
             node_alias_and_output_by_asset_key[key] = (node_alias, output_name)
 
-    asset_checks_defs_by_node_handle: Dict[NodeHandle, AssetChecksDefinition] = {}
-    for asset_checks_def in asset_checks_defs:
-        node_def_name = asset_checks_def.node_def.name
-        node_key = NodeInvocation(node_def_name)
-        asset_checks_defs_by_node_handle[NodeHandle(node_def_name, parent=None)] = asset_checks_def
-
     blocking_asset_check_output_handles_by_asset_key = (
         _get_blocking_asset_check_output_handles_by_asset_key(
-            assets_defs_by_node_handle, asset_checks_defs_by_node_handle
+            assets_defs_by_node_handle,
         )
     )
 
     deps: Dict[NodeInvocation, Dict[str, IDependencyDefinition]] = {}
     for node_handle, assets_def in assets_defs_by_node_handle.items():
         # the key that we'll use to reference the node inside this AssetsDefinition
         node_def_name = assets_def.node_def.name
         alias = node_handle.name if node_handle.name != node_def_name else None
         node_key = NodeInvocation(node_def_name, alias=alias)
         deps[node_key] = {}
 
+        # TODO: We should be able to remove this after a refactor of `AssetsDefinition` and just use
+        # a single method. At present using `keys_by_input_name` for asset checks only will exclude
+        # `additional_deps`, so we need to use `node_keys_by_input_name`. But using
+        # `node_keys_by_input_name` breaks cycle resolution on subsettable multi-assets.
+        inputs_map = (
+            assets_def.node_keys_by_input_name
+            if has_only_asset_checks(assets_def)
+            else assets_def.keys_by_input_name
+        )
+
         # connect each input of this AssetsDefinition to the proper upstream node
-        for input_name, upstream_asset_key in assets_def.keys_by_input_name.items():
+        for input_name, upstream_asset_key in inputs_map.items():
             # ignore self-deps
             if upstream_asset_key in assets_def.keys:
                 continue
 
-            blocking_asset_check_output_handles = (
-                blocking_asset_check_output_handles_by_asset_key.get(upstream_asset_key)
-            )
-            asset_check_deps = [
-                DependencyDefinition(
-                    node_output_handle.node_handle.name, node_output_handle.output_name
+            # if this assets def itself performs checks on an upstream key, exempt it from being
+            # blocked on other checks
+            if upstream_asset_key not in {ck.asset_key for ck in assets_def.check_keys}:
+                blocking_asset_check_output_handles = (
+                    blocking_asset_check_output_handles_by_asset_key.get(upstream_asset_key)
                 )
-                for node_output_handle in blocking_asset_check_output_handles or []
-            ]
+                asset_check_deps = [
+                    DependencyDefinition(
+                        node_output_handle.node_handle.name, node_output_handle.output_name
+                    )
+                    for node_output_handle in blocking_asset_check_output_handles or []
+                ]
+            else:
+                blocking_asset_check_output_handles = set()
+                asset_check_deps = []
 
             if upstream_asset_key in node_alias_and_output_by_asset_key:
                 upstream_node_alias, upstream_output_name = node_alias_and_output_by_asset_key[
                     upstream_asset_key
                 ]
 
                 asset_dep_def = DependencyDefinition(upstream_node_alias, upstream_output_name)
@@ -436,33 +546,15 @@
                     )
                 else:
                     deps[node_key][input_name] = asset_dep_def
             elif asset_check_deps:
                 deps[node_key][input_name] = BlockingAssetChecksDependencyDefinition(
                     asset_check_dependencies=asset_check_deps, other_dependency=None
                 )
-
-    # put asset checks downstream of the assets they're checking
-    asset_checks_defs_by_node_handle: Dict[NodeHandle, AssetChecksDefinition] = {}
-    for asset_checks_def in asset_checks_defs:
-        node_def_name = asset_checks_def.node_def.name
-        node_key = NodeInvocation(node_def_name)
-        deps[node_key] = {}
-        asset_checks_defs_by_node_handle[NodeHandle(node_def_name, parent=None)] = asset_checks_def
-
-        for input_name, asset_key in asset_checks_def.asset_keys_by_input_name.items():
-            if asset_key in node_alias_and_output_by_asset_key:
-                upstream_node_alias, upstream_output_name = node_alias_and_output_by_asset_key[
-                    asset_key
-                ]
-                deps[node_key][input_name] = DependencyDefinition(
-                    upstream_node_alias, upstream_output_name
-                )
-
-    return deps, assets_defs_by_node_handle, asset_checks_defs_by_node_handle
+    return deps, assets_defs_by_node_handle
 
 
 def _has_cycles(
     deps: DependencyMapping[NodeInvocation],
 ) -> bool:
     """Detect if there are cycles in a dependency dictionary."""
     try:
@@ -483,101 +575,78 @@
         list(toposort(node_deps))
         return False
     # only try to resolve cycles if we have a cycle
     except CircularDependencyError:
         return True
 
 
-def _attempt_resolve_cycles(
-    assets_defs: Iterable["AssetsDefinition"],
-    source_assets: Iterable["SourceAsset"],
-) -> Sequence["AssetsDefinition"]:
+def _attempt_resolve_node_cycles(asset_graph: AssetGraph) -> AssetGraph:
     """DFS starting at root nodes to color the asset dependency graph. Each time you leave your
     current AssetsDefinition, the color increments.
 
     At the end of this process, we'll have a coloring for the asset graph such that any asset which
     is downstream of another asset via a different AssetsDefinition will be guaranteed to have
     a different (greater) color.
 
     Once we have our coloring, if any AssetsDefinition contains assets with different colors,
     we split that AssetsDefinition into a subset for each individual color.
 
     This ensures that no asset that shares a node with another asset will be downstream of
     that asset via a different node (i.e. there will be no cycles).
     """
-    from dagster._core.selector.subset_selector import generate_asset_dep_graph
-
-    # get asset dependencies
-    asset_deps = generate_asset_dep_graph(assets_defs, source_assets)
-
-    # index AssetsDefinitions by their asset names
-    assets_defs_by_asset_key: Dict[AssetKey, AssetsDefinition] = {}
-    for assets_def in assets_defs:
-        for asset_key in assets_def.keys:
-            assets_defs_by_asset_key[asset_key] = assets_def
-
     # color for each asset
-    colors = {}
+    colors: Dict[AssetKey, int] = {}
 
     # recursively color an asset and all of its downstream assets
-    def _dfs(key, cur_color):
+    def _dfs(key: AssetKey, cur_color: int):
+        node = asset_graph.get(key)
         colors[key] = cur_color
-        if key in assets_defs_by_asset_key:
-            cur_node_asset_keys = assets_defs_by_asset_key[key].keys
-        else:
-            # in a SourceAsset, treat all downstream as if they're in the same node
-            cur_node_asset_keys = asset_deps["downstream"][key]
+        # in an external asset, treat all downstream as if they're in the same node
+        cur_node_asset_keys = node.assets_def.keys if node.is_materializable else node.child_keys
 
-        for downstream_key in asset_deps["downstream"][key]:
+        for child_key in node.child_keys:
             # if the downstream asset is in the current node,keep the same color
-            if downstream_key in cur_node_asset_keys:
-                new_color = cur_color
-            else:
-                new_color = cur_color + 1
+            new_color = cur_color if child_key in cur_node_asset_keys else cur_color + 1
 
             # if current color of the downstream asset is less than the new color, re-do dfs
-            if colors.get(downstream_key, -1) < new_color:
-                _dfs(downstream_key, new_color)
+            if colors.get(child_key, -1) < new_color:
+                _dfs(child_key, new_color)
 
-    # validate that there are no cycles in the overall asset graph
-    toposorted = list(toposort(asset_deps["upstream"]))
-
-    # dfs for each root node
-    for root_name in toposorted[0]:
-        _dfs(root_name, 0)
+    # dfs for each root node; will throw an error if there are key-level cycles
+    root_keys = asset_graph.toposorted_asset_keys_by_level[0]
+    for key in root_keys:
+        _dfs(key, 0)
 
     color_mapping_by_assets_defs: Dict[AssetsDefinition, Any] = defaultdict(
         lambda: defaultdict(set)
     )
     for key, color in colors.items():
-        # ignore source assets
-        if key not in assets_defs_by_asset_key:
-            continue
-        color_mapping_by_assets_defs[assets_defs_by_asset_key[key]][color].add(key)
+        node = asset_graph.get(key)
+        color_mapping_by_assets_defs[node.assets_def][color].add(key)
 
-    ret = []
+    subsetted_assets_defs: List[AssetsDefinition] = []
     for assets_def, color_mapping in color_mapping_by_assets_defs.items():
-        if len(color_mapping) == 1 or not assets_def.can_subset:
-            ret.append(assets_def)
+        if assets_def.is_external or len(color_mapping) == 1 or not assets_def.can_subset:
+            subsetted_assets_defs.append(assets_def)
         else:
             for asset_keys in color_mapping.values():
-                ret.append(assets_def.subset_for(asset_keys, selected_asset_check_keys=None))
+                subsetted_assets_defs.append(
+                    assets_def.subset_for(asset_keys, selected_asset_check_keys=None)
+                )
 
-    return ret
+    return AssetGraph.from_assets(subsetted_assets_defs)
 
 
 def _ensure_resources_dont_conflict(
-    assets: Iterable[AssetsDefinition],
-    source_assets: Sequence[SourceAsset],
+    asset_graph: AssetGraph,
     resource_defs: Mapping[str, ResourceDefinition],
 ) -> None:
     """Ensures that resources between assets, source assets, and provided resource dictionary do not conflict."""
     resource_defs_from_assets = {}
-    all_assets: Sequence[Union[AssetsDefinition, SourceAsset]] = [*assets, *source_assets]
-    for asset in all_assets:
+    for asset in asset_graph.assets_defs:
         for resource_key, resource_def in asset.resource_defs.items():
             if resource_key not in resource_defs_from_assets:
                 resource_defs_from_assets[resource_key] = resource_def
             if resource_defs_from_assets[resource_key] != resource_def:
                 raise DagsterInvalidDefinitionError(
                     f"Conflicting versions of resource with key '{resource_key}' "
                     "were provided to different assets. When constructing a "
@@ -595,48 +664,35 @@
                 "conflicts with resource provided to assets. When constructing a "
                 "job, all resource definitions provided must "
                 "match by reference equality for a given key."
             )
 
 
 def check_resources_satisfy_requirements(
-    assets: Iterable[AssetsDefinition],
-    source_assets: Sequence[SourceAsset],
-    asset_checks: Iterable[AssetChecksDefinition],
+    asset_graph: AssetGraph,
     resource_defs: Mapping[str, ResourceDefinition],
 ) -> None:
     """Ensures that between the provided resources on an asset and the resource_defs mapping, that all resource requirements are satisfied.
 
     Note that resources provided on assets cannot satisfy resource requirements provided on other assets.
     """
-    _ensure_resources_dont_conflict(assets, source_assets, resource_defs)
+    _ensure_resources_dont_conflict(asset_graph, resource_defs)
 
-    all_assets: Sequence[Union[AssetsDefinition, SourceAsset]] = [*assets, *source_assets]
-    for asset in all_assets:
+    for assets_def in asset_graph.assets_defs:
         ensure_requirements_satisfied(
-            merge_dicts(resource_defs, asset.resource_defs), list(asset.get_resource_requirements())
-        )
-    for asset_check in asset_checks:
-        ensure_requirements_satisfied(
-            merge_dicts(resource_defs, asset_check.resource_defs),
-            list(asset_check.get_resource_requirements()),
+            merge_dicts(resource_defs, assets_def.resource_defs),
+            list(assets_def.get_resource_requirements()),
         )
 
 
 def get_all_resource_defs(
-    assets: Iterable[AssetsDefinition],
-    asset_checks: Iterable[AssetChecksDefinition],
-    source_assets: Sequence[SourceAsset],
+    asset_graph: AssetGraph,
     resource_defs: Mapping[str, ResourceDefinition],
 ) -> Mapping[str, ResourceDefinition]:
     # Ensures that no resource keys conflict, and each asset has its resource requirements satisfied.
-    check_resources_satisfy_requirements(assets, source_assets, asset_checks, resource_defs)
+    check_resources_satisfy_requirements(asset_graph, resource_defs)
 
     all_resource_defs = dict(resource_defs)
-    all_assets: Sequence[Union[AssetsDefinition, SourceAsset]] = [*assets, *source_assets]
-    for asset in all_assets:
-        all_resource_defs = merge_dicts(all_resource_defs, asset.resource_defs)
-
-    for asset_check in asset_checks:
-        all_resource_defs = merge_dicts(all_resource_defs, asset_check.resource_defs)
+    for assets_def in asset_graph.assets_defs:
+        all_resource_defs = merge_dicts(all_resource_defs, assets_def.resource_defs)
 
     return all_resource_defs
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/auto_materialize_policy.py` & `dagster-1.7.0/dagster/_core/definitions/auto_materialize_policy.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from enum import Enum
 from typing import TYPE_CHECKING, AbstractSet, Dict, FrozenSet, NamedTuple, Optional, Sequence
 
 import dagster._check as check
-from dagster._annotations import experimental, public
+from dagster._annotations import deprecated, experimental, public
 from dagster._serdes.serdes import (
     NamedTupleSerializer,
     UnpackContext,
     UnpackedValue,
     whitelist_for_serdes,
 )
 
@@ -211,16 +211,22 @@
             max_materializations_per_minute=check.opt_int_param(
                 max_materializations_per_minute, "max_materializations_per_minute"
             ),
         )
 
     @public
     @staticmethod
+    @deprecated(
+        breaking_version="1.8",
+        additional_warn_text="Lazy auto-materialize is deprecated, in favor of explicit cron-based "
+        "scheduling rules. Additional alternatives to replicate more of the lazy auto-materialize "
+        "behavior will be provided before this is fully removed.",
+    )
     def lazy(max_materializations_per_minute: Optional[int] = 1) -> "AutoMaterializePolicy":
-        """Constructs a lazy AutoMaterializePolicy.
+        """(Deprecated) Constructs a lazy AutoMaterializePolicy.
 
         Args:
             max_materializations_per_minute (Optional[int]): The maximum number of
                 auto-materializations for this asset that may be initiated per minute. If this limit
                 is exceeded, the partitions which would have been materialized will be discarded,
                 and will require manual materialization in order to be updated. Defaults to 1.
         """
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/auto_materialize_rule.py` & `dagster-1.7.0/dagster/_core/definitions/auto_materialize_rule.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
     Sequence,
     Set,
 )
 
 import pytz
 
 import dagster._check as check
-from dagster._annotations import experimental, public
+from dagster._annotations import deprecated, experimental, public
 from dagster._core.definitions.asset_subset import AssetSubset, ValidAssetSubset
 from dagster._core.definitions.auto_materialize_rule_evaluation import (
     AutoMaterializeDecisionType,
     AutoMaterializeRuleSnapshot,
     ParentUpdatedRuleEvaluationData,
     WaitingOnAssetsRuleEvaluationData,
 )
@@ -30,27 +30,28 @@
 )
 from dagster._core.definitions.multi_dimensional_partitions import MultiPartitionsDefinition
 from dagster._core.definitions.time_window_partitions import (
     TimeWindow,
     TimeWindowPartitionsDefinition,
     get_time_partitions_def,
 )
-from dagster._core.storage.dagster_run import RunsFilter
+from dagster._core.errors import DagsterInvariantViolationError
+from dagster._core.storage.dagster_run import IN_PROGRESS_RUN_STATUSES, RunsFilter
 from dagster._core.storage.tags import AUTO_MATERIALIZE_TAG
 from dagster._serdes.serdes import (
     whitelist_for_serdes,
 )
 from dagster._utils.schedules import (
     cron_string_iterator,
     is_valid_cron_string,
     reverse_cron_string_iterator,
 )
 
 from .asset_condition.asset_condition_evaluation_context import AssetConditionEvaluationContext
-from .asset_graph import sort_key_for_asset_partition
+from .base_asset_graph import sort_key_for_asset_partition
 
 if TYPE_CHECKING:
     from dagster._core.definitions.asset_condition.asset_condition import (
         AssetCondition,
         AssetConditionResult,
     )
 
@@ -94,15 +95,15 @@
         to.
         """
         ...
 
     @public
     @staticmethod
     def materialize_on_required_for_freshness() -> "MaterializeOnRequiredForFreshnessRule":
-        """Materialize an asset partition if it is required to satisfy a freshness policy of this
+        """(Deprecated) Materialize an asset partition if it is required to satisfy a freshness policy of this
         asset or one of its downstream assets.
 
         Note: This rule has no effect on partitioned assets.
         """
         return MaterializeOnRequiredForFreshnessRule()
 
     @public
@@ -230,14 +231,18 @@
         Args:
             all_partitions (bool): If True, skips all partitions of the asset being backfilled,
                 regardless of whether the specific partition is targeted by a backfill.
                 If False, skips only partitions targeted by a backfill. Defaults to False.
         """
         return SkipOnBackfillInProgressRule(all_partitions)
 
+    @staticmethod
+    def skip_on_run_in_progress() -> "SkipOnRunInProgressRule":
+        return SkipOnRunInProgressRule()
+
     def to_snapshot(self) -> AutoMaterializeRuleSnapshot:
         """Returns a serializable snapshot of this rule for historical evaluations."""
         return AutoMaterializeRuleSnapshot(
             class_name=self.__class__.__name__,
             description=self.description,
             decision_type=self.decision_type,
         )
@@ -247,14 +252,20 @@
         return type(self) == type(other) and super().__eq__(other)
 
     def __hash__(self) -> int:
         # override the default NamedTuple __hash__ method to factor in types
         return hash(hash(type(self)) + super().__hash__())
 
 
+@deprecated(
+    breaking_version="1.8",
+    additional_warn_text="Lazy auto-materialize is deprecated, in favor of explicit cron-based "
+    "scheduling rules. Additional alternatives to replicate more of the lazy auto-materialize "
+    "behavior will be provided before this is fully removed.",
+)
 @whitelist_for_serdes
 class MaterializeOnRequiredForFreshnessRule(
     AutoMaterializeRule, NamedTuple("_MaterializeOnRequiredForFreshnessRule", [])
 ):
     @property
     def decision_type(self) -> AutoMaterializeDecisionType:
         return AutoMaterializeDecisionType.MATERIALIZE
@@ -290,15 +301,16 @@
     def description(self) -> str:
         return f"not materialized since last cron schedule tick of '{self.cron_schedule}' (timezone: {self.timezone})"
 
     def missed_cron_ticks(
         self, context: AssetConditionEvaluationContext
     ) -> Sequence[datetime.datetime]:
         """Returns the cron ticks which have been missed since the previous cursor was generated."""
-        if not context.previous_evaluation_timestamp:
+        # if it's the first time evaluating this rule, then just count the latest tick as missed
+        if not context.previous_evaluation or not context.previous_evaluation_timestamp:
             previous_dt = next(
                 reverse_cron_string_iterator(
                     end_timestamp=context.evaluation_time.timestamp(),
                     cron_string=self.cron_schedule,
                     execution_timezone=self.timezone,
                 )
             )
@@ -310,19 +322,17 @@
             execution_timezone=self.timezone,
         ):
             if dt > context.evaluation_time:
                 break
             missed_ticks.append(dt)
         return missed_ticks
 
-    def get_new_asset_partitions_to_request(
-        self, context: AssetConditionEvaluationContext
+    def get_new_candidate_asset_partitions(
+        self, context: AssetConditionEvaluationContext, missed_ticks: Sequence[datetime.datetime]
     ) -> AbstractSet[AssetKeyPartitionKey]:
-        missed_ticks = self.missed_cron_ticks(context)
-
         if not missed_ticks:
             return set()
 
         partitions_def = context.partitions_def
         if partitions_def is None:
             return {AssetKeyPartitionKey(context.asset_key)}
 
@@ -378,17 +388,28 @@
             }
 
     def evaluate_for_asset(
         self, context: AssetConditionEvaluationContext
     ) -> "AssetConditionResult":
         from .asset_condition.asset_condition import AssetConditionResult
 
-        new_asset_partitions_to_request = self.get_new_asset_partitions_to_request(context)
+        missed_ticks = self.missed_cron_ticks(context)
+        new_asset_partitions = self.get_new_candidate_asset_partitions(context, missed_ticks)
+
+        # if it's the first time evaluating this rule, must query for the actual subset that has
+        # been materialized since the previous cron tick, as materializations may have happened
+        # before the previous evaluation, which
+        # `context.materialized_requested_or_discarded_since_previous_tick_subset` would not capture
+        if context.previous_evaluation is None:
+            new_asset_partitions -= context.instance_queryer.get_asset_subset_updated_after_time(
+                asset_key=context.asset_key, after_time=missed_ticks[-1]
+            ).asset_partitions
+
         asset_subset_to_request = AssetSubset.from_asset_partitions_set(
-            context.asset_key, context.partitions_def, new_asset_partitions_to_request
+            context.asset_key, context.partitions_def, new_asset_partitions
         ) | (
             context.previous_true_subset.as_valid(context.partitions_def)
             - context.materialized_requested_or_discarded_since_previous_tick_subset
         )
 
         return AssetConditionResult.create(context, true_subset=asset_subset_to_request)
 
@@ -755,16 +776,16 @@
             missing_parent_asset_keys = set()
             for parent in context.get_parents_that_will_not_be_materialized_on_current_tick(
                 asset_partition=candidate
             ):
                 # ignore missing or unexecutable assets, which will never have a materialization or
                 # observation
                 if not (
-                    context.asset_graph.has_asset(parent.asset_key)
-                    and context.asset_graph.is_executable(parent.asset_key)
+                    context.asset_graph.has(parent.asset_key)
+                    and context.asset_graph.get(parent.asset_key).is_executable
                 ):
                     continue
                 if not context.instance_queryer.asset_partition_has_materialization_or_observation(
                     parent
                 ):
                     missing_parent_asset_keys.add(parent.asset_key)
             if missing_parent_asset_keys:
@@ -845,15 +866,15 @@
                 # All upstream partitions must be updated in order for the candidate to be updated
                 non_updated_parent_keys = {
                     parent.asset_key for parent in parent_partitions - updated_parent_partitions
                 }
             else:
                 # At least one upstream partition in each upstream asset must be updated in order
                 # for the candidate to be updated
-                parent_asset_keys = context.asset_graph.get_parents(context.asset_key)
+                parent_asset_keys = context.asset_graph.get(context.asset_key).parent_keys
                 updated_parent_keys = {ap.asset_key for ap in updated_parent_partitions}
                 non_updated_parent_keys = parent_asset_keys - updated_parent_keys
 
             # do not require past partitions of this asset to be updated
             non_updated_parent_keys -= {context.asset_key}
 
             if non_updated_parent_keys:
@@ -950,19 +971,19 @@
         self, context: AssetConditionEvaluationContext, passed_time_window: TimeWindow
     ) -> Mapping[AssetKey, ValidAssetSubset]:
         """Returns a mapping of parent asset keys to the AssetSubset of each parent that has been
         updated since the end of the previous cron tick. Does not compute this value for time-window
         partitioned parents, as their partitions encode the time windows they have processed.
         """
         updated_subsets_by_key = {}
-        for parent_asset_key in context.asset_graph.get_parents(context.asset_key):
+        for parent_asset_key in context.asset_graph.get(context.asset_key).parent_keys:
             # no need to incrementally calculate updated time-window partitions definitions, as
             # their partitions encode the time windows they have processed.
             if isinstance(
-                context.asset_graph.get_partitions_def(parent_asset_key),
+                context.asset_graph.get(parent_asset_key).partitions_def,
                 TimeWindowPartitionsDefinition,
             ):
                 continue
             updated_subsets_by_key[parent_asset_key] = self.get_parent_subset_updated_since_cron(
                 context, parent_asset_key, passed_time_window
             )
         return updated_subsets_by_key
@@ -974,15 +995,15 @@
         parent_asset_key: AssetKey,
         child_asset_partition: AssetKeyPartitionKey,
         updated_parent_subset: ValidAssetSubset,
     ) -> bool:
         """Returns if, for a given child asset partition, the given parent asset been updated with
         information from the required time window.
         """
-        parent_partitions_def = context.asset_graph.get_partitions_def(parent_asset_key)
+        parent_partitions_def = context.asset_graph.get(parent_asset_key).partitions_def
 
         if isinstance(parent_partitions_def, TimeWindowPartitionsDefinition):
             # for time window partitions definitions, we simply assert that all time partitions that
             # were newly created between the previous cron ticks have been materialized
             required_parent_partitions = parent_partitions_def.get_partition_keys_in_time_window(
                 time_window=passed_time_window
             )
@@ -1055,15 +1076,15 @@
                     self.parent_updated_since_cron(
                         context,
                         passed_time_window,
                         parent_asset_key,
                         candidate,
                         updated_subsets_by_key.get(parent_asset_key, context.empty_subset()),
                     )
-                    for parent_asset_key in context.asset_graph.get_parents(candidate.asset_key)
+                    for parent_asset_key in context.asset_graph.get(candidate.asset_key).parent_keys
                 )
             },
         )
         # if your parents were all updated since the previous cron tick on the previous evaluation,
         # that will still be true unless a new cron tick has happened since the previous evaluation
         if not has_new_passed_time_window:
             all_parents_updated_subset = (
@@ -1189,7 +1210,37 @@
 
         return AssetConditionResult.create(
             context,
             AssetSubset.from_asset_partitions_set(
                 context.asset_key, context.partitions_def, rate_limited_asset_partitions
             ),
         )
+
+
+@whitelist_for_serdes
+class SkipOnRunInProgressRule(AutoMaterializeRule, NamedTuple("_SkipOnRunInProgressRule", [])):
+    @property
+    def decision_type(self) -> AutoMaterializeDecisionType:
+        return AutoMaterializeDecisionType.SKIP
+
+    @property
+    def description(self) -> str:
+        return "in-progress run for asset"
+
+    def evaluate_for_asset(
+        self, context: AssetConditionEvaluationContext
+    ) -> "AssetConditionResult":
+        from .asset_condition.asset_condition import AssetConditionResult
+
+        if context.partitions_def is not None:
+            raise DagsterInvariantViolationError(
+                "SkipOnRunInProgressRule is currently only support for non-partitioned assets."
+            )
+        instance = context.instance_queryer.instance
+        planned_materialization_info = (
+            instance.event_log_storage.get_latest_planned_materialization_info(context.asset_key)
+        )
+        if planned_materialization_info:
+            dagster_run = instance.get_run_by_id(planned_materialization_info.run_id)
+            if dagster_run and dagster_run.status in IN_PROGRESS_RUN_STATUSES:
+                return AssetConditionResult.create(context, context.candidate_subset)
+        return AssetConditionResult.create(context, context.empty_subset())
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/auto_materialize_rule_evaluation.py` & `dagster-1.7.0/dagster/_core/definitions/auto_materialize_rule_evaluation.py`

 * *Files 1% similar despite different names*

```diff
@@ -25,14 +25,15 @@
     PackableValue,
     UnpackContext,
     UnpackedValue,
     WhitelistMap,
     deserialize_value,
     whitelist_for_serdes,
 )
+from dagster._utils.security import non_secure_md5_hash_str
 
 from .partition import PartitionsDefinition, SerializedPartitionsSubset
 
 if TYPE_CHECKING:
     from .asset_condition.asset_condition import (
         AssetConditionEvaluation,
         AssetConditionEvaluationWithRunIds,
@@ -211,15 +212,15 @@
 
     def _asset_condition_snapshot_from_rule_snapshot(
         self, rule_snapshot: AutoMaterializeRuleSnapshot
     ) -> "AssetConditionSnapshot":
         from .asset_condition.asset_condition import AssetConditionSnapshot, RuleCondition
 
         unique_id_parts = [rule_snapshot.class_name, rule_snapshot.description]
-        unique_id = hashlib.md5("".join(unique_id_parts).encode()).hexdigest()
+        unique_id = non_secure_md5_hash_str("".join(unique_id_parts).encode())
 
         return AssetConditionSnapshot(
             class_name=RuleCondition.__name__,
             description=rule_snapshot.description,
             unique_id=unique_id,
         )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/auto_materialize_sensor_definition.py` & `dagster-1.7.0/dagster/_core/definitions/auto_materialize_sensor_definition.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Any, Mapping, Optional, cast
 
 from dagster._annotations import experimental
 from dagster._core.definitions.asset_selection import CoercibleToAssetSelection
 
 from .asset_selection import AssetSelection
 from .sensor_definition import DefaultSensorStatus, SensorDefinition, SensorType
-from .utils import check_valid_name, validate_tags
+from .utils import check_valid_name, normalize_tags
 
 
 @experimental
 class AutoMaterializeSensorDefinition(SensorDefinition):
     """Targets a set of assets and repeatedly evaluates all the AutoMaterializePolicys on all of
     those assets to determine which to request runs for.
 
@@ -32,15 +32,15 @@
         *,
         asset_selection: CoercibleToAssetSelection,
         run_tags: Optional[Mapping[str, Any]] = None,
         default_status: DefaultSensorStatus = DefaultSensorStatus.STOPPED,
         minimum_interval_seconds: Optional[int] = None,
         description: Optional[str] = None,
     ):
-        self._run_tags = validate_tags(run_tags)
+        self._run_tags = normalize_tags(run_tags).tags
 
         def evaluation_fn(context):
             raise NotImplementedError(
                 "Automation policy sensors cannot be evaluated like regular user-space sensors."
             )
 
         super(AutoMaterializeSensorDefinition, self).__init__(
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/backfill_policy.py` & `dagster-1.7.0/dagster/_core/definitions/backfill_policy.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/cacheable_assets.py` & `dagster-1.7.0/dagster/_core/definitions/cacheable_assets.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/composition.py` & `dagster-1.7.0/dagster/_core/definitions/composition.py`

 * *Files 5% similar despite different names*

```diff
@@ -47,25 +47,25 @@
 from .inference import infer_output_props
 from .input import InputDefinition, InputMapping
 from .logger_definition import LoggerDefinition
 from .node_definition import NodeDefinition
 from .output import OutputDefinition, OutputMapping
 from .policy import RetryPolicy
 from .resource_definition import ResourceDefinition
-from .utils import check_valid_name, validate_tags
+from .utils import NormalizedTags, check_valid_name, normalize_tags
 from .version_strategy import VersionStrategy
 
 if TYPE_CHECKING:
     from dagster._core.execution.execute_in_process_result import ExecuteInProcessResult
     from dagster._core.instance import DagsterInstance
 
+    from .assets import AssetsDefinition
     from .executor_definition import ExecutorDefinition
     from .job_definition import JobDefinition
     from .partition import PartitionedConfig, PartitionsDefinition
-    from .source_asset import SourceAsset
 
 
 _composition_stack: List["InProgressCompositionContext"] = []
 
 
 class MappedInputPlaceholder:
     """Marker for holding places in fan-in lists where input mappings will feed."""
@@ -81,60 +81,41 @@
     def __init__(self, node_name: str, output_name: str, node_type: str):
         self.node_name = check.str_param(node_name, "node_name")
         self.output_name = check.str_param(output_name, "output_name")
         self.node_type = check.str_param(node_type, "node_type")
 
     def __iter__(self) -> NoReturn:
         raise DagsterInvariantViolationError(
-            'Attempted to iterate over an {cls}. This object represents the output "{out}" '
-            'from the op/graph "{node}". Consider defining multiple Outs if you seek to pass '
-            "different parts of this output to different op/graph.".format(
-                cls=self.__class__.__name__, out=self.output_name, node=self.node_name
-            )
+            f'Attempted to iterate over an {self.__class__.__name__}. This object represents the output "{self.output_name}" '
+            f'from the op/graph "{self.node_name}". Consider defining multiple Outs if you seek to pass '
+            "different parts of this output to different op/graph."
         )
 
     def __getitem__(self, idx: object) -> NoReturn:
         raise DagsterInvariantViolationError(
-            'Attempted to index in to an {cls}. This object represents the output "{out}" '
-            "from the {described_node}. Consider defining multiple Outs if you seek to pass "
-            "different parts of this output to different {node_type}s.".format(
-                cls=self.__class__.__name__,
-                out=self.output_name,
-                described_node=self.describe_node(),
-                node_type=self.node_type,
-            )
+            f'Attempted to index in to an {self.__class__.__name__}. This object represents the output "{self.output_name}" '
+            f"from the {self.describe_node()}. Consider defining multiple Outs if you seek to pass "
+            f"different parts of this output to different {self.node_type}s."
         )
 
     def describe_node(self) -> str:
         return f"{self.node_type} '{self.node_name}'"
 
     def alias(self, _) -> NoReturn:
         raise DagsterInvariantViolationError(
-            "In {source} {name}, attempted to call alias method for {cls}. This object "
-            'represents the output "{out}" from the already invoked {described_node}. Consider '
-            "checking the location of parentheses.".format(
-                source=current_context().source,
-                name=current_context().name,
-                cls=self.__class__.__name__,
-                out=self.output_name,
-                described_node=self.describe_node(),
-            )
+            f"In {current_context().source} {current_context().name}, attempted to call alias method for {self.__class__.__name__}. This object "
+            f'represents the output "{self.output_name}" from the already invoked {self.describe_node()}. Consider '
+            "checking the location of parentheses."
         )
 
     def with_hooks(self, _) -> NoReturn:
         raise DagsterInvariantViolationError(
-            "In {source} {name}, attempted to call hook method for {cls}. This object "
-            'represents the output "{out}" from the already invoked {described_node}. Consider '
-            "checking the location of parentheses.".format(
-                source=current_context().source,
-                name=current_context().name,
-                cls=self.__class__.__name__,
-                out=self.output_name,
-                described_node=self.describe_node(),
-            )
+            f"In {current_context().source} {current_context().name}, attempted to call hook method for {self.__class__.__name__}. This object "
+            f'represents the output "{self.output_name}" from the already invoked {self.describe_node()}. Consider '
+            "checking the location of parentheses."
         )
 
 
 class InputMappingNode(NamedTuple):
     input_def: InputDefinition
 
 
@@ -147,15 +128,15 @@
     output_name: str
 
 
 InputSource: TypeAlias = Union[
     InvokedNodeOutputHandle,
     InputMappingNode,
     DynamicFanIn,
-    "SourceAsset",
+    "AssetsDefinition",
     List[Union[InvokedNodeOutputHandle, InputMappingNode]],
 ]
 
 
 def _not_invoked_warning(
     node: "PendingNodeInvocation",
     context_source: str,
@@ -251,17 +232,15 @@
                 self._collisions[node_name] = 1
         else:
             node_name = given_alias
             self._pending_invocations.pop(node_name, None)
 
         if self._invocations.get(node_name):
             raise DagsterInvalidDefinitionError(
-                "{source} {name} invoked the same node ({node_name}) twice without aliasing.".format(
-                    source=self.source, name=self.name, node_name=node_name
-                )
+                f"{self.source} {self.name} invoked the same node ({node_name}) twice without aliasing."
             )
 
         self._invocations[node_name] = InvokedNode(
             node_name, node_def, input_bindings, tags, hook_defs, retry_policy
         )
         return node_name
 
@@ -285,30 +264,30 @@
     """The processed information from capturing node invocations during a composition function."""
 
     name: str
     node_defs: Sequence[NodeDefinition]
     dependencies: DependencyMapping[NodeInvocation]
     input_mappings: Sequence[InputMapping]
     output_mapping_dict: Mapping[str, OutputMapping]
-    node_input_source_assets: Mapping[str, Mapping[str, "SourceAsset"]]
+    node_input_assets: Mapping[str, Mapping[str, "AssetsDefinition"]]
 
     @staticmethod
     def create(
         name: str,
         source: str,
         invocations: Mapping[str, "InvokedNode"],
         output_mapping_dict: Mapping[str, OutputMapping],
         pending_invocations: Mapping[str, "PendingNodeInvocation"],
     ) -> "CompleteCompositionContext":
-        from .source_asset import SourceAsset
+        from .assets import AssetsDefinition
 
         dep_dict: Dict[NodeInvocation, Dict[str, IDependencyDefinition]] = {}
         node_def_dict: Dict[str, NodeDefinition] = {}
         input_mappings = []
-        node_input_source_assets: Dict[str, Dict[str, "SourceAsset"]] = defaultdict(dict)
+        node_input_assets: Dict[str, Dict[str, "AssetsDefinition"]] = defaultdict(dict)
 
         for node in pending_invocations.values():
             _not_invoked_warning(node, source, name)
 
         for invocation in invocations.values():
             def_name = invocation.node_def.name
             if def_name in node_def_dict and node_def_dict[def_name] is not invocation.node_def:
@@ -321,16 +300,16 @@
             for input_name, node in invocation.input_bindings.items():
                 if isinstance(node, InvokedNodeOutputHandle):
                     deps[input_name] = DependencyDefinition(node.node_name, node.output_name)
                 elif isinstance(node, InputMappingNode):
                     input_mappings.append(
                         node.input_def.mapping_to(invocation.node_name, input_name)
                     )
-                elif isinstance(node, SourceAsset):
-                    node_input_source_assets[invocation.node_name][input_name] = node
+                elif isinstance(node, AssetsDefinition):
+                    node_input_assets[invocation.node_name][input_name] = node
                 elif isinstance(node, list):
                     entries: List[Union[DependencyDefinition, Type[MappedInputPlaceholder]]] = []
                     for idx, fanned_in_node in enumerate(node):
                         if isinstance(fanned_in_node, InvokedNodeOutputHandle):
                             entries.append(
                                 DependencyDefinition(
                                     fanned_in_node.node_name, fanned_in_node.output_name
@@ -366,15 +345,15 @@
 
         return CompleteCompositionContext(
             name,
             list(node_def_dict.values()),
             dep_dict,
             input_mappings,
             output_mapping_dict,
-            node_input_source_assets=node_input_source_assets,
+            node_input_assets=node_input_assets,
         )
 
 
 T_NodeDefinition = TypeVar("T_NodeDefinition", bound=NodeDefinition)
 
 
 class PendingNodeInvocation(Generic[T_NodeDefinition]):
@@ -441,36 +420,24 @@
         assert_in_composition(node_name, self.node_def)
         input_bindings: Dict[str, InputSource] = {}
 
         # handle *args
         for idx, output_node in enumerate(args):
             if idx >= len(self.node_def.input_defs):
                 raise DagsterInvalidDefinitionError(
-                    "In {source} {name}, received too many inputs for "
-                    "invocation {node_name}. Only {def_num} defined, received {arg_num}".format(
-                        source=current_context().source,
-                        name=current_context().name,
-                        node_name=node_name,
-                        def_num=len(self.node_def.input_defs),
-                        arg_num=len(args),
-                    )
+                    f"In {current_context().source} {current_context().name}, received too many inputs for "
+                    f"invocation {node_name}. Only {len(self.node_def.input_defs)} defined, received {len(args)}"
                 )
 
             input_name = self.node_def.resolve_input_name_at_position(idx)
             if input_name is None:
                 raise DagsterInvalidDefinitionError(
-                    "In {source} {name}, could not resolve input based on position at "
-                    "index {idx} for invocation {node_name}. Use keyword args instead, "
-                    "available inputs are: {inputs}".format(
-                        idx=idx,
-                        source=current_context().source,
-                        name=current_context().name,
-                        node_name=node_name,
-                        inputs=list(map(lambda inp: inp.name, self.node_def.input_defs)),
-                    )
+                    f"In {current_context().source} {current_context().name}, could not resolve input based on position at "
+                    f"index {idx} for invocation {node_name}. Use keyword args instead, "
+                    f"available inputs are: {list(map(lambda inp: inp.name, self.node_def.input_defs))}"
                 )
 
             self._process_argument_node(
                 node_name,
                 output_node,
                 input_name,
                 input_bindings,
@@ -534,118 +501,89 @@
     def describe_node(self) -> str:
         node_name = self.given_alias if self.given_alias else self.node_def.name
         return f"{self.node_def.node_type_str} '{node_name}'"
 
     def _process_argument_node(
         self, node_name: str, output_node, input_name: str, input_bindings, arg_desc: str
     ) -> None:
+        from .assets import AssetsDefinition
+        from .external_asset import create_external_asset_from_source_asset
         from .source_asset import SourceAsset
 
         # already set - conflict between kwargs and args
         if input_bindings.get(input_name):
             raise DagsterInvalidInvocationError(
                 f"{self.node_def.node_type_str} {node_name} got multiple values for"
                 f" argument '{input_name}'"
             )
 
-        if isinstance(
-            output_node, (InvokedNodeOutputHandle, InputMappingNode, DynamicFanIn, SourceAsset)
+        if isinstance(output_node, SourceAsset):
+            input_bindings[input_name] = create_external_asset_from_source_asset(output_node)
+        elif isinstance(
+            output_node, (AssetsDefinition, InvokedNodeOutputHandle, InputMappingNode, DynamicFanIn)
         ):
             input_bindings[input_name] = output_node
 
         elif isinstance(output_node, list):
             input_bindings[input_name] = []
             for idx, fanned_in_node in enumerate(output_node):
                 if isinstance(fanned_in_node, (InvokedNodeOutputHandle, InputMappingNode)):
                     input_bindings[input_name].append(fanned_in_node)
                 else:
                     raise DagsterInvalidDefinitionError(
-                        "In {source} {name}, received a list containing an invalid type "
-                        'at index {idx} for input "{input_name}" {arg_desc} in '
-                        "{node_type} invocation {node_name}. Lists can only contain the "
+                        f"In {current_context().source} {current_context().name}, received a list containing an invalid type "
+                        f'at index {idx} for input "{input_name}" {arg_desc} in '
+                        f"{self.node_def.node_type_str} invocation {node_name}. Lists can only contain the "
                         "output from previous op invocations or input mappings, "
-                        "received {type}".format(
-                            source=current_context().source,
-                            name=current_context().name,
-                            arg_desc=arg_desc,
-                            input_name=input_name,
-                            node_type=self.node_def.node_type_str,
-                            node_name=node_name,
-                            idx=idx,
-                            type=type(output_node),
-                        )
+                        f"received {type(output_node)}"
                     )
 
         elif is_named_tuple_instance(output_node) and all(
             map(lambda item: isinstance(item, InvokedNodeOutputHandle), output_node)
         ):
             raise DagsterInvalidDefinitionError(
-                "In {source} {name}, received a tuple of multiple outputs for "
-                'input "{input_name}" {arg_desc} in {node_type} invocation {node_name}. '
-                "Must pass individual output, available from tuple: {options}".format(
-                    source=current_context().source,
-                    name=current_context().name,
-                    arg_desc=arg_desc,
-                    input_name=input_name,
-                    node_name=node_name,
-                    node_type=self.node_def.node_type_str,
-                    options=output_node._fields,
-                )
+                f"In {current_context().source} {current_context().name}, received a tuple of multiple outputs for "
+                f'input "{input_name}" {arg_desc} in {self.node_def.node_type_str} invocation {node_name}. '
+                f"Must pass individual output, available from tuple: {output_node._fields}"
             )
         elif isinstance(output_node, InvokedNodeDynamicOutputWrapper):
             raise DagsterInvalidDefinitionError(
                 f"In {current_context().source} {current_context().name}, received the dynamic"
                 f" output {output_node.output_name} from {output_node.describe_node()} directly."
                 " Dynamic output must be unpacked by invoking map or collect."
             )
 
         elif isinstance(output_node, (NodeDefinition, PendingNodeInvocation)):
             raise DagsterInvalidDefinitionError(
-                "In {source} {name}, received an un-invoked {described_node} "
+                f"In {current_context().source} {current_context().name}, received an un-invoked {output_node.describe_node()} "
                 " for input "
-                '"{input_name}" {arg_desc} in {node_type} invocation "{node_name}". '
-                "Did you forget parentheses?".format(
-                    source=current_context().source,
-                    described_node=output_node.describe_node(),
-                    name=current_context().name,
-                    arg_desc=arg_desc,
-                    input_name=input_name,
-                    node_name=node_name,
-                    node_type=output_node.describe_node(),
-                )
+                f'"{input_name}" {arg_desc} in {output_node.describe_node()} invocation "{node_name}". '
+                "Did you forget parentheses?"
             )
         else:
             raise DagsterInvalidDefinitionError(
-                "In {source} {name}, received invalid type {type} for input "
-                '"{input_name}" {arg_desc} in {node_type} invocation "{node_name}". '
+                f"In {current_context().source} {current_context().name}, received invalid type {type(output_node)} for input "
+                f'"{input_name}" {arg_desc} in {self.node_def.node_type_str} invocation "{node_name}". '
                 "Must pass the output from previous node invocations or inputs to the "
-                "composition function as inputs when invoking nodes during composition.".format(
-                    source=current_context().source,
-                    name=current_context().name,
-                    type=type(output_node),
-                    arg_desc=arg_desc,
-                    input_name=input_name,
-                    node_name=node_name,
-                    node_type=self.node_def.node_type_str,
-                )
+                "composition function as inputs when invoking nodes during composition."
             )
 
     @public
     def alias(self, name: str) -> "PendingNodeInvocation[T_NodeDefinition]":
         return PendingNodeInvocation(
             node_def=self.node_def,
             given_alias=name,
             tags=self.tags,
             hook_defs=self.hook_defs,
             retry_policy=self.retry_policy,
         )
 
     @public
     def tag(self, tags: Optional[Mapping[str, str]]) -> "PendingNodeInvocation[T_NodeDefinition]":
-        tags = validate_tags(tags)
+        tags = normalize_tags(tags).tags
         return PendingNodeInvocation(
             node_def=self.node_def,
             given_alias=self.given_alias,
             tags={**(self.tags or {}), **tags},
             hook_defs=self.hook_defs,
             retry_policy=self.retry_policy,
         )
@@ -678,42 +616,42 @@
     @public
     def to_job(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
         resource_defs: Optional[Mapping[str, ResourceDefinition]] = None,
         config: Optional[Union[ConfigMapping, Mapping[str, Any], "PartitionedConfig"]] = None,
-        tags: Optional[Mapping[str, Any]] = None,
+        tags: Union[NormalizedTags, Optional[Mapping[str, Any]]] = None,
         logger_defs: Optional[Mapping[str, LoggerDefinition]] = None,
         executor_def: Optional["ExecutorDefinition"] = None,
         hooks: Optional[AbstractSet[HookDefinition]] = None,
         op_retry_policy: Optional[RetryPolicy] = None,
         version_strategy: Optional[VersionStrategy] = None,
         partitions_def: Optional["PartitionsDefinition"] = None,
         input_values: Optional[Mapping[str, object]] = None,
     ) -> "JobDefinition":
         if not isinstance(self.node_def, GraphDefinition):
             raise DagsterInvalidInvocationError(
                 "Attemped to call `to_job` on a non-graph.  Only graphs "
                 "constructed using the `@graph` decorator support this method."
             )
 
-        tags = check.opt_mapping_param(tags, "tags", key_type=str)
+        tags = normalize_tags(tags)
         hooks = check.opt_set_param(hooks, "hooks", HookDefinition)
         input_values = check.opt_mapping_param(input_values, "input_values")
         op_retry_policy = check.opt_inst_param(op_retry_policy, "op_retry_policy", RetryPolicy)
         job_hooks: Set[HookDefinition] = set()
         job_hooks.update(check.opt_set_param(hooks, "hooks", HookDefinition))
         job_hooks.update(self.hook_defs)
         return self.node_def.to_job(
             name=name or self.given_alias,
             description=description,
             resource_defs=resource_defs,
             config=config,
-            tags={**(self.tags or {}), **tags},
+            tags=NormalizedTags(self.tags or {}).with_normalized_tags(tags),
             logger_defs=logger_defs,
             executor_def=executor_def,
             hooks=job_hooks,
             op_retry_policy=op_retry_policy,
             version_strategy=version_strategy,
             partitions_def=partitions_def,
             input_values=input_values,
@@ -822,60 +760,40 @@
         return DynamicFanIn(self.node_name, self.output_name)
 
     def unwrap_for_composite_mapping(self) -> InvokedNodeOutputHandle:
         return InvokedNodeOutputHandle(self.node_name, self.output_name, self.node_type)
 
     def __iter__(self) -> NoReturn:
         raise DagsterInvariantViolationError(
-            'Attempted to iterate over an {cls}. This object represents the dynamic output "{out}" '
-            'from the {described_node}. Use the "map" method on this object to create '
+            f'Attempted to iterate over an {self.__class__.__name__}. This object represents the dynamic output "{self.output_name}" '
+            f'from the {self.describe_node()}. Use the "map" method on this object to create '
             "downstream dependencies that will be cloned for each DynamicOut "
-            "that is resolved at runtime.".format(
-                cls=self.__class__.__name__,
-                out=self.output_name,
-                described_node=self.describe_node(),
-            )
+            "that is resolved at runtime."
         )
 
     def __getitem__(self, idx) -> NoReturn:
         raise DagsterInvariantViolationError(
-            'Attempted to index in to an {cls}. This object represents the dynamic out "{out}" '
-            'from the {described_node}. Use the "map" method on this object to create '
+            f'Attempted to index in to an {self.__class__.__name__}. This object represents the dynamic out "{self.output_name}" '
+            f'from the {self.describe_node()}. Use the "map" method on this object to create '
             "downstream dependencies that will be cloned for each DynamicOut "
-            "that is resolved at runtime.".format(
-                cls=self.__class__.__name__,
-                out=self.output_name,
-                described_node=self.describe_node(),
-            )
+            "that is resolved at runtime."
         )
 
     def alias(self, _) -> NoReturn:
         raise DagsterInvariantViolationError(
-            "In {source} {name}, attempted to call alias method for {cls}. This object represents"
-            ' the dynamic out "{out}" from the already invoked {described_node}. Consider checking'
-            " the location of parentheses.".format(
-                source=current_context().source,
-                name=current_context().name,
-                cls=self.__class__.__name__,
-                described_node=self.describe_node(),
-                out=self.output_name,
-            )
+            f"In {current_context().source} {current_context().name}, attempted to call alias method for {self.__class__.__name__}. This object represents"
+            f' the dynamic out "{self.output_name}" from the already invoked {self.describe_node()}. Consider checking'
+            " the location of parentheses."
         )
 
     def with_hooks(self, _) -> NoReturn:
         raise DagsterInvariantViolationError(
-            "In {source} {name}, attempted to call hook method for {cls}. This object represents"
-            ' the dynamic out "{out}" from the already invoked {described_node}. Consider checking'
-            " the location of parentheses.".format(
-                source=current_context().source,
-                name=current_context().name,
-                cls=self.__class__.__name__,
-                out=self.output_name,
-                described_node=self.describe_node(),
-            )
+            f"In {current_context().source} {current_context().name}, attempted to call hook method for {self.__class__.__name__}. This object represents"
+            f' the dynamic out "{self.output_name}" from the already invoked {self.describe_node()}. Consider checking'
+            " the location of parentheses."
         )
 
 
 def composite_mapping_from_output(
     output: Any,
     output_defs: Sequence[OutputDefinition],
     node_name: str,
@@ -972,15 +890,15 @@
 ) -> Tuple[
     Sequence[InputMapping],
     Sequence[OutputMapping],
     DependencyMapping[NodeInvocation],
     Sequence[NodeDefinition],
     Optional[ConfigMapping],
     Sequence[str],
-    Mapping[str, Mapping[str, "SourceAsset"]],
+    Mapping[str, Mapping[str, "AssetsDefinition"]],
 ]:
     """This a function used by both @job and @graph to implement their composition
     function which is our DSL for constructing a dependency graph.
 
     Args:
         decorator_name (str): Name of the calling decorator. e.g. "@graph" or "@job"
         graph_name (str): User-defined name of the definition being constructed
@@ -1081,15 +999,15 @@
     return (
         input_mappings,
         output_mappings,
         context.dependencies,
         context.node_defs,
         config_mapping,
         compute_fn.positional_inputs(),
-        context.node_input_source_assets,
+        context.node_input_assets,
     )
 
 
 def get_validated_config_mapping(
     name: str,
     config_schema: Any,
     config_fn: Optional[Callable[[Any], Any]],
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/config.py` & `dagster-1.7.0/dagster/_core/definitions/config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/configurable.py` & `dagster-1.7.0/dagster/_core/definitions/configurable.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/data_time.py` & `dagster-1.7.0/dagster/_core/definitions/data_time.py`

 * *Files 5% similar despite different names*

```diff
@@ -14,16 +14,16 @@
 
 import datetime
 from typing import AbstractSet, Dict, Mapping, Optional, Sequence, Tuple, cast
 
 import pendulum
 
 import dagster._check as check
-from dagster._core.definitions.asset_graph import AssetGraph
-from dagster._core.definitions.asset_selection import AssetSelection
+from dagster._core.definitions.asset_selection import KeysAssetSelection
+from dagster._core.definitions.base_asset_graph import BaseAssetGraph
 from dagster._core.definitions.data_version import (
     DATA_VERSION_TAG,
     DataVersion,
     get_input_event_pointer_tag,
 )
 from dagster._core.definitions.events import AssetKey, AssetKeyPartitionKey
 from dagster._core.definitions.freshness_policy import FreshnessMinutes
@@ -39,25 +39,25 @@
 from dagster._utils.caching_instance_queryer import CachingInstanceQueryer
 
 DATA_TIME_METADATA_KEY = "dagster/data_time"
 
 
 class CachingDataTimeResolver:
     _instance_queryer: CachingInstanceQueryer
-    _asset_graph: AssetGraph
+    _asset_graph: BaseAssetGraph
 
     def __init__(self, instance_queryer: CachingInstanceQueryer):
         self._instance_queryer = instance_queryer
 
     @property
     def instance_queryer(self) -> CachingInstanceQueryer:
         return self._instance_queryer
 
     @property
-    def asset_graph(self) -> AssetGraph:
+    def asset_graph(self) -> BaseAssetGraph:
         return self.instance_queryer.asset_graph
 
     ####################
     # PARTITIONED DATA TIME
     ####################
 
     def _calculate_data_time_partitioned(
@@ -159,30 +159,34 @@
         """
         partition_data_time = self._calculate_data_time_partitioned(
             asset_key=asset_key,
             cursor=cursor,
             partitions_def=partitions_def,
         )
 
-        root_keys = AssetSelection.keys(asset_key).upstream().sources().resolve(self.asset_graph)
+        root_keys = (
+            KeysAssetSelection(selected_keys=[asset_key])
+            .upstream()
+            .sources()
+            .resolve(self.asset_graph)
+        )
         return {key: partition_data_time for key in root_keys}
 
     ####################
     # UNPARTITIONED DATA TIME
     ####################
 
     def _upstream_records_by_key(
         self, asset_key: AssetKey, record_id: int, record_tags_dict: Mapping[str, str]
     ) -> Mapping[AssetKey, "EventLogRecord"]:
         upstream_records: Dict[AssetKey, EventLogRecord] = {}
 
-        for parent_key in self.asset_graph.get_parents(asset_key):
+        for parent_key in self.asset_graph.get(asset_key).parent_keys:
             if not (
-                self.asset_graph.has_asset(parent_key)
-                and self.asset_graph.is_executable(parent_key)
+                self.asset_graph.has(parent_key) and self.asset_graph.get(parent_key).is_executable
             ):
                 continue
 
             input_event_pointer_tag = get_input_event_pointer_tag(parent_key)
             if input_event_pointer_tag not in record_tags_dict:
                 # if the input event id was not recorded (materialized pre-1.1.0), just grab
                 # the most recent event for this parent which happened before the current record
@@ -308,22 +312,22 @@
         record_tags: Tuple[Tuple[str, str]],  # for hashability
         current_time: datetime.datetime,
     ) -> Mapping[AssetKey, Optional[datetime.datetime]]:
         if record_id is None:
             return {key: None for key in self.asset_graph.get_materializable_roots(asset_key)}
         record_timestamp = check.not_none(record_timestamp)
 
-        partitions_def = self.asset_graph.get_partitions_def(asset_key)
+        partitions_def = self.asset_graph.get(asset_key).partitions_def
         if isinstance(partitions_def, TimeWindowPartitionsDefinition):
             return self._calculate_data_time_by_key_time_partitioned(
                 asset_key=asset_key,
                 cursor=record_id,
                 partitions_def=partitions_def,
             )
-        elif self.asset_graph.is_observable(asset_key):
+        elif self.asset_graph.get(asset_key).is_observable:
             return self._calculate_data_time_by_key_observable_source(
                 asset_key=asset_key,
                 record_id=record_id,
                 record_tags=record_tags,
                 current_time=current_time,
             )
         else:
@@ -374,15 +378,15 @@
 
         # if you're here, then this asset is planned, but not materialized. in the worst case, this
         # asset's data time will be equal to the current time once it finishes materializing
         if not self.asset_graph.has_materializable_parents(asset_key):
             return current_time
 
         data_time = current_time
-        for parent_key in self.asset_graph.get_parents(asset_key):
+        for parent_key in self.asset_graph.get(asset_key).parent_keys:
             if parent_key not in self.asset_graph.materializable_asset_keys:
                 continue
             parent_data_time = self._get_in_progress_data_time_in_run(
                 run_id=run_id, asset_key=parent_key, current_time=current_time
             )
             if parent_data_time is None:
                 return None
@@ -529,22 +533,22 @@
             )
 
     def get_minutes_overdue(
         self,
         asset_key: AssetKey,
         evaluation_time: datetime.datetime,
     ) -> Optional[FreshnessMinutes]:
-        freshness_policy = self.asset_graph.get_freshness_policy(asset_key)
-        if freshness_policy is None:
+        asset = self.asset_graph.get(asset_key)
+        if asset.freshness_policy is None:
             raise DagsterInvariantViolationError(
                 "Cannot calculate minutes late for asset without a FreshnessPolicy"
             )
 
-        if self.asset_graph.is_observable(asset_key):
+        if asset.is_observable:
             current_data_time = self._get_source_data_time(asset_key, current_time=evaluation_time)
         else:
             current_data_time = self.get_current_data_time(asset_key, current_time=evaluation_time)
 
-        return freshness_policy.minutes_overdue(
+        return asset.freshness_policy.minutes_overdue(
             data_time=current_data_time,
             evaluation_time=evaluation_time,
         )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/data_version.py` & `dagster-1.7.0/dagster/_core/definitions/data_version.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,15 +16,15 @@
 from typing_extensions import Final
 
 from dagster import _check as check
 from dagster._annotations import deprecated, experimental
 from dagster._utils.cached_method import cached_method
 
 if TYPE_CHECKING:
-    from dagster._core.definitions.asset_graph import AssetGraph
+    from dagster._core.definitions.base_asset_graph import BaseAssetGraph
     from dagster._core.definitions.events import (
         AssetKey,
         AssetKeyPartitionKey,
         AssetMaterialization,
         AssetObservation,
     )
     from dagster._core.event_api import EventLogRecord
@@ -370,27 +370,27 @@
     """Used to resolve data version information. Avoids redundant database
     calls that would otherwise occur. Intended for use within the scope of a
     single "request" (e.g. GQL request, RunRequest resolution).
     """
 
     _instance: "DagsterInstance"
     _instance_queryer: Optional["CachingInstanceQueryer"]
-    _asset_graph: Optional["AssetGraph"]
-    _asset_graph_load_fn: Optional[Callable[[], "AssetGraph"]]
+    _asset_graph: Optional["BaseAssetGraph"]
+    _asset_graph_load_fn: Optional[Callable[[], "BaseAssetGraph"]]
 
     def __init__(
         self,
         instance: "DagsterInstance",
-        asset_graph: Union["AssetGraph", Callable[[], "AssetGraph"]],
+        asset_graph: Union["BaseAssetGraph", Callable[[], "BaseAssetGraph"]],
     ):
-        from dagster._core.definitions.asset_graph import AssetGraph
+        from dagster._core.definitions.base_asset_graph import BaseAssetGraph
 
         self._instance = instance
         self._instance_queryer = None
-        if isinstance(asset_graph, AssetGraph):
+        if isinstance(asset_graph, BaseAssetGraph):
             self._asset_graph = asset_graph
             self._asset_graph_load_fn = None
         else:
             self._asset_graph = None
             self._asset_graph_load_fn = asset_graph
 
     def get_status(self, key: "AssetKey", partition_key: Optional[str] = None) -> StaleStatus:
@@ -419,60 +419,63 @@
 
         return self._get_current_data_version(key=AssetKeyPartitionKey(key, partition_key))
 
     @cached_method
     def _get_status(self, key: "AssetKeyPartitionKey") -> StaleStatus:
         # The status loader does not support querying for the stale status of a
         # partitioned asset without specifying a partition, so we return here.
-        if self.asset_graph.is_partitioned(key.asset_key) and not key.partition_key:
+        asset = self.asset_graph.get(key.asset_key)
+        if asset.is_partitioned and not key.partition_key:
             return StaleStatus.FRESH
         else:
             current_version = self._get_current_data_version(key=key)
             if current_version == NULL_DATA_VERSION:
                 return StaleStatus.MISSING
-            elif self.asset_graph.is_external(key.asset_key):
+            elif asset.is_external:
                 return StaleStatus.FRESH
             else:
                 causes = self._get_stale_causes(key=key)
                 return StaleStatus.FRESH if len(causes) == 0 else StaleStatus.STALE
 
     @cached_method
     def _get_stale_causes(self, key: "AssetKeyPartitionKey") -> Sequence[StaleCause]:
         # Querying for the stale status of a partitioned asset without specifying a partition key
         # is strictly speaking undefined, but we return an empty list here (from which FRESH status
         # is inferred) for backcompat.
-        if self.asset_graph.is_partitioned(key.asset_key) and not key.partition_key:
+        asset = self.asset_graph.get(key.asset_key)
+        if asset.is_partitioned and not key.partition_key:
             return []
-        elif self.asset_graph.is_external(key.asset_key):
+        elif asset.is_external:
             return []
         else:
             current_version = self._get_current_data_version(key=key)
             if current_version == NULL_DATA_VERSION:
                 return []
             else:
                 return sorted(
                     self._get_stale_causes_materialized(key=key), key=lambda cause: cause.sort_key
                 )
 
     def _is_dep_updated(self, provenance: DataProvenance, dep_key: "AssetKeyPartitionKey") -> bool:
+        dep_asset = self.asset_graph.get(dep_key.asset_key)
         if dep_key.partition_key is None:
             current_data_version = self._get_current_data_version(key=dep_key)
             return provenance.input_data_versions[dep_key.asset_key] != current_data_version
         else:
             cursor = provenance.input_storage_ids[dep_key.asset_key]
             updated_record = self._instance.get_latest_data_version_record(
                 dep_key.asset_key,
-                self.asset_graph.is_external(dep_key.asset_key),
+                dep_asset.is_external,
                 dep_key.partition_key,
                 after_cursor=cursor,
             )
             if updated_record:
                 previous_record = self._instance.get_latest_data_version_record(
                     dep_key.asset_key,
-                    self.asset_graph.is_external(dep_key.asset_key),
+                    dep_asset.is_external,
                     dep_key.partition_key,
                     before_cursor=cursor + 1 if cursor else None,
                 )
                 previous_version = (
                     extract_data_version_from_entry(previous_record.event_log_entry)
                     if previous_record
                     else None
@@ -481,18 +484,18 @@
                 return previous_version != updated_version
             else:
                 return False
 
     def _get_stale_causes_materialized(self, key: "AssetKeyPartitionKey") -> Iterator[StaleCause]:
         from dagster._core.definitions.events import AssetKeyPartitionKey
 
-        code_version = self.asset_graph.get_code_version(key.asset_key)
+        code_version = self.asset_graph.get(key.asset_key).code_version
         provenance = self._get_current_data_provenance(key=key)
 
-        asset_deps = self.asset_graph.get_parents(key.asset_key)
+        asset_deps = self.asset_graph.get(key.asset_key).parent_keys
 
         # only used if no provenance available
         materialization = check.not_none(self._get_latest_data_version_record(key=key))
         materialization_time = materialization.timestamp
 
         if provenance:
             if code_version and code_version != provenance.code_version:
@@ -509,14 +512,15 @@
 
         # If a partition has greater than or equal to SKIP_PARTITION_DATA_VERSION_DEPENDENCY_THRESHOLD of
         # dependencies, it is not included in partition_deps. This is for performance reasons. This
         # constraint can be removed when we have thoroughly tested performance for large upstream
         # partition counts.
         partition_deps = self._get_partition_dependencies(key=key)
         for dep_key in sorted(partition_deps):
+            dep_asset = self.asset_graph.get(dep_key.asset_key)
             if self._get_status(key=dep_key) == StaleStatus.STALE:
                 yield StaleCause(
                     key,
                     StaleCauseCategory.DATA,
                     "stale dependency",
                     dep_key,
                     self._get_stale_causes(key=dep_key),
@@ -528,17 +532,18 @@
                         StaleCauseCategory.DEPENDENCIES,
                         f"has a new dependency on {dep_key.asset_key.to_user_string()}",
                         dep_key,
                     )
                 # Currently we exclude assets downstream of AllPartitionMappings from stale
                 # status logic due to potentially huge numbers of dependencies.
                 elif self._is_dep_updated(provenance, dep_key):
-                    report_data_version = self.asset_graph.get_code_version(
-                        dep_key.asset_key
-                    ) is not None or self._is_current_data_version_user_provided(key=dep_key)
+                    report_data_version = (
+                        dep_asset.code_version is not None
+                        or self._is_current_data_version_user_provided(key=dep_key)
+                    )
                     yield StaleCause(
                         key,
                         StaleCauseCategory.DATA,
                         (
                             "has a new dependency data version"
                             if report_data_version
                             else "has a new dependency materialization"
@@ -559,15 +564,15 @@
                             )
                         ],
                     )
             # If no provenance and dep is a materializable asset, then use materialization
             # timestamps instead of versions this should be removable eventually since
             # provenance is on all newer materializations. If dep is a source, then we'll never
             # provide a stale reason here.
-            elif not self.asset_graph.is_external(dep_key.asset_key):
+            elif not dep_asset.is_external:
                 dep_materialization = self._get_latest_data_version_record(key=dep_key)
                 if dep_materialization is None:
                     # The input must be new if it has no materialization
                     yield StaleCause(key, StaleCauseCategory.DATA, "has a new input", dep_key)
                 elif dep_materialization.timestamp > materialization_time:
                     yield StaleCause(
                         key,
@@ -598,15 +603,15 @@
                         next_candidates.extend(cause.children)
                     visited.add(cause.dedupe_key)
 
             candidates = next_candidates
         return root_causes
 
     @property
-    def asset_graph(self) -> "AssetGraph":
+    def asset_graph(self) -> "BaseAssetGraph":
         if self._asset_graph is None:
             self._asset_graph = check.not_none(self._asset_graph_load_fn)()
         return self._asset_graph
 
     # This is lazily constructed because it depends on the asset graph, which needs to be lazily
     # constructed for GQL performance reasons.
     @property
@@ -618,25 +623,25 @@
         return self._instance_queryer
 
     @cached_method
     def _get_current_data_version(self, *, key: "AssetKeyPartitionKey") -> DataVersion:
         # Currently we can only use asset records, which are fetched in one shot, for non-source
         # assets. This is because the most recent AssetObservation is not stored on the AssetRecord.
         record = self._get_latest_data_version_record(key=key)
-        if self.asset_graph.is_external(key.asset_key) and record is None:
+        if self.asset_graph.get(key.asset_key).is_external and record is None:
             return DEFAULT_DATA_VERSION
         elif record is None:
             return NULL_DATA_VERSION
         else:
             data_version = extract_data_version_from_entry(record.event_log_entry)
             return data_version or DEFAULT_DATA_VERSION
 
     @cached_method
     def _is_current_data_version_user_provided(self, *, key: "AssetKeyPartitionKey") -> bool:
-        if self.asset_graph.is_external(key.asset_key):
+        if self.asset_graph.get(key.asset_key).is_external:
             return True
         else:
             provenance = self._get_current_data_provenance(key=key)
             return provenance is not None and provenance.is_user_provided
 
     @cached_method
     def _get_current_data_provenance(
@@ -650,18 +655,19 @@
 
     # Volatility means that an asset is assumed to be constantly changing. We assume that observable
     # source assets are non-volatile, since the primary purpose of the observation function is to
     # determine if a source asset has changed. We assume that regular assets are volatile if they
     # are at the root of the graph (have no dependencies) or are downstream of a volatile asset.
     @cached_method
     def _is_volatile(self, *, key: "AssetKey") -> bool:
-        if self.asset_graph.is_external(key):
-            return self.asset_graph.is_observable(key)
+        asset = self.asset_graph.get(key)
+        if asset.is_external:
+            return asset.is_observable
         else:
-            deps = self.asset_graph.get_parents(key)
+            deps = asset.get(key).parent_keys
             return len(deps) == 0 or any(self._is_volatile(key=dep_key) for dep_key in deps)
 
     @cached_method
     def _get_latest_data_version_event(
         self, *, key: "AssetKeyPartitionKey"
     ) -> Optional[Union["AssetMaterialization", "AssetObservation"]]:
         record = self._get_latest_data_version_record(key=key)
@@ -674,18 +680,18 @@
     @cached_method
     def _get_latest_data_version_record(
         self, key: "AssetKeyPartitionKey"
     ) -> Optional["EventLogRecord"]:
         # If an asset record is cached, all of its ancestors have already been cached.
         if (
             key.partition_key is None
-            and not self.asset_graph.is_external(key.asset_key)
+            and not self.asset_graph.get(key.asset_key).is_external
             and not self.instance_queryer.has_cached_asset_record(key.asset_key)
         ):
-            ancestors = self.asset_graph.get_ancestors(key.asset_key, include_self=True)
+            ancestors = self.asset_graph.get_ancestor_asset_keys(key.asset_key, include_self=True)
             self.instance_queryer.prefetch_asset_records(ancestors)
         return self.instance_queryer.get_latest_materialization_or_observation_record(
             asset_partition=key
         )
 
     # If a partition has greater than or equal to SKIP_PARTITION_DATA_VERSION_DEPENDENCY_THRESHOLD
     # of dependencies, it is not included in partition_deps. This is for performance reasons. This
@@ -703,19 +709,19 @@
     def _get_partition_dependencies(
         self, *, key: "AssetKeyPartitionKey"
     ) -> Sequence["AssetKeyPartitionKey"]:
         from dagster._core.definitions.events import (
             AssetKeyPartitionKey,
         )
 
-        asset_deps = self.asset_graph.get_parents(key.asset_key)
+        asset_deps = self.asset_graph.get(key.asset_key).parent_keys
 
         deps = []
         for dep_asset_key in asset_deps:
-            if not self.asset_graph.is_partitioned(dep_asset_key):
+            if not self.asset_graph.get(dep_asset_key).is_partitioned:
                 deps.append(AssetKeyPartitionKey(dep_asset_key, None))
             elif key.asset_key == dep_asset_key and self._exceeds_self_partition_limit(
                 key.asset_key
             ):
                 continue
             else:
                 upstream_partition_keys = list(
@@ -734,10 +740,10 @@
                             for partition_key in upstream_partition_keys
                         ]
                     )
         return deps
 
     def _exceeds_self_partition_limit(self, asset_key: "AssetKey") -> bool:
         return (
-            check.not_none(self.asset_graph.get_partitions_def(asset_key)).get_num_partitions()
+            check.not_none(self.asset_graph.get(asset_key).partitions_def).get_num_partitions()
             >= SKIP_PARTITION_DATA_VERSION_SELF_DEPENDENCY_THRESHOLD
         )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/__init__.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/asset_check_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/asset_check_decorator.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,30 +1,40 @@
-from typing import AbstractSet, Any, Callable, Iterable, Mapping, Optional, Set, Tuple, Union
+from typing import (
+    AbstractSet,
+    Any,
+    Callable,
+    Iterable,
+    Mapping,
+    Optional,
+    Sequence,
+    Set,
+    Tuple,
+    Union,
+)
 
 from typing_extensions import TypeAlias
 
 from dagster import _check as check
-from dagster._annotations import experimental
 from dagster._config import UserConfigSchema
 from dagster._core.definitions.asset_check_result import AssetCheckResult
 from dagster._core.definitions.asset_check_spec import AssetCheckSpec
-from dagster._core.definitions.asset_checks import (
-    AssetChecksDefinition,
-    AssetChecksDefinitionInputOutputProps,
-)
+from dagster._core.definitions.asset_checks import AssetChecksDefinition
 from dagster._core.definitions.asset_dep import CoercibleToAssetDep
 from dagster._core.definitions.asset_in import AssetIn
 from dagster._core.definitions.assets import AssetsDefinition
 from dagster._core.definitions.events import AssetKey, CoercibleToAssetKey
 from dagster._core.definitions.output import Out
 from dagster._core.definitions.policy import RetryPolicy
 from dagster._core.definitions.resource_annotation import get_resource_args
 from dagster._core.definitions.source_asset import SourceAsset
 from dagster._core.errors import DagsterInvalidDefinitionError
 from dagster._core.execution.build_resources import wrap_resources_for_execution
+from dagster._utils.warnings import (
+    disable_dagster_warnings,
+)
 
 from ..input import In
 from .asset_decorator import (
     build_asset_ins,
     get_function_params_without_context_or_config_or_resources,
     make_asset_deps,
 )
@@ -85,29 +95,29 @@
     return build_asset_ins(
         fn=fn,
         asset_ins=all_ins,
         deps=all_deps,
     )
 
 
-@experimental
 def asset_check(
     *,
     asset: Union[CoercibleToAssetKey, AssetsDefinition, SourceAsset],
     name: Optional[str] = None,
     description: Optional[str] = None,
     blocking: bool = False,
     additional_ins: Optional[Mapping[str, AssetIn]] = None,
     additional_deps: Optional[Iterable[CoercibleToAssetDep]] = None,
     required_resource_keys: Optional[Set[str]] = None,
     resource_defs: Optional[Mapping[str, object]] = None,
     config_schema: Optional[UserConfigSchema] = None,
     compute_kind: Optional[str] = None,
     op_tags: Optional[Mapping[str, Any]] = None,
     retry_policy: Optional[RetryPolicy] = None,
+    metadata: Optional[Mapping[str, Any]] = None,
 ) -> Callable[[AssetCheckFunction], AssetChecksDefinition]:
     """Create a definition for how to execute an asset check.
 
     Args:
         asset (Union[AssetKey, Sequence[str], str, AssetsDefinition, SourceAsset]): The
             asset that the check applies to.
         name (Optional[str]): The name of the check. If not specified, the name of the decorated
@@ -134,14 +144,15 @@
         op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that executes the check.
             Frameworks may expect and require certain metadata to be attached to a op. Values that
             are not strings will be json encoded and must meet the criteria that
             `json.loads(json.dumps(value)) == value`.
         compute_kind (Optional[str]): A string to represent the kind of computation that executes
             the check, e.g. "dbt" or "spark".
         retry_policy (Optional[RetryPolicy]): The retry policy for the op that executes the check.
+        metadata (Optional[Mapping[str, Any]]): A dictionary of static metadata for the check.
 
 
     Produces an :py:class:`AssetChecksDefinition` object.
 
 
     Example:
         .. code-block:: python
@@ -196,14 +207,15 @@
 
         spec = AssetCheckSpec(
             name=resolved_name,
             description=description,
             asset=asset_key,
             additional_deps=additional_ins_and_deps,
             blocking=blocking,
+            metadata=metadata,
         )
 
         arg_resource_keys = {arg.name for arg in get_resource_args(fn)}
 
         check.param_invariant(
             len(required_resource_keys or []) == 0 or len(arg_resource_keys) == 0,
             "Cannot specify resource requirements in both @asset_check decorator and as arguments"
@@ -228,23 +240,132 @@
                 **({"kind": compute_kind} if compute_kind else {}),
                 **(op_tags or {}),
             },
             config_schema=config_schema,
             retry_policy=retry_policy,
         )(fn)
 
-        checks_def = AssetChecksDefinition(
+        return AssetChecksDefinition.create(
+            keys_by_input_name={
+                input_tuple[0]: asset_key
+                for asset_key, input_tuple in input_tuples_by_asset_key.items()
+            },
             node_def=op_def,
             resource_defs=wrap_resources_for_execution(resource_defs),
-            specs=[spec],
-            input_output_props=AssetChecksDefinitionInputOutputProps(
-                asset_keys_by_input_name={
-                    input_tuple[0]: asset_key
-                    for asset_key, input_tuple in input_tuples_by_asset_key.items()
-                },
-                asset_check_keys_by_output_name={op_def.output_defs[0].name: spec.key},
-            ),
+            check_specs_by_output_name={op_def.output_defs[0].name: spec},
+            can_subset=False,
+        )
+
+    return inner
+
+
+MultiAssetCheckFunctionReturn: TypeAlias = Iterable[AssetCheckResult]
+MultiAssetCheckFunction: TypeAlias = Callable[..., MultiAssetCheckFunctionReturn]
+
+
+def multi_asset_check(
+    *,
+    name: Optional[str] = None,
+    specs: Sequence[AssetCheckSpec],
+    description: Optional[str] = None,
+    can_subset: bool = False,
+    compute_kind: Optional[str] = None,
+    op_tags: Optional[Mapping[str, Any]] = None,
+    resource_defs: Optional[Mapping[str, object]] = None,
+    required_resource_keys: Optional[Set[str]] = None,
+    retry_policy: Optional[RetryPolicy] = None,
+    config_schema: Optional[UserConfigSchema] = None,
+) -> Callable[[Callable[..., Any]], AssetChecksDefinition]:
+    """Defines a set of asset checks that can be executed together with the same op.
+
+    Args:
+        specs (Sequence[AssetCheckSpec]): Specs for the asset checks.
+        name (Optional[str]): The name of the op. If not specified, the name of the decorated
+            function will be used.
+        description (Optional[str]): Description of the op.
+        required_resource_keys (Optional[Set[str]]): A set of keys for resources that are required
+            by the function that execute the checks. These can alternatively be specified by
+            including resource-typed parameters in the function signature.
+        config_schema (Optional[ConfigSchema): The configuration schema for the asset checks' underlying
+            op. If set, Dagster will check that config provided for the op matches this schema and fail
+            if it does not. If not set, Dagster will accept any config provided for the op.
+        op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that executes the checks.
+            Frameworks may expect and require certain metadata to be attached to a op. Values that
+            are not strings will be json encoded and must meet the criteria that
+            `json.loads(json.dumps(value)) == value`.
+        compute_kind (Optional[str]): A string to represent the kind of computation that executes
+            the checks, e.g. "dbt" or "spark".
+        retry_policy (Optional[RetryPolicy]): The retry policy for the op that executes the checks.
+        can_subset (bool): Whether the op can emit results for a subset of the asset checks
+            keys, based on the context.selected_asset_check_keys argument. Defaults to False.
+
+
+    Examples:
+        .. code-block:: python
+
+            @multi_asset_check(
+                specs=[
+                    AssetCheckSpec("enough_rows", asset="asset1"),
+                    AssetCheckSpec("no_dupes", asset="asset1"),
+                    AssetCheckSpec("enough_rows", asset="asset2"),
+                ],
+            )
+            def checks():
+                yield AssetCheckResult(passed=True, asset_key="asset1", check_name="enough_rows")
+                yield AssetCheckResult(passed=False, asset_key="asset1", check_name="no_dupes")
+                yield AssetCheckResult(passed=True, asset_key="asset2", check_name="enough_rows")
+
+    """
+    required_resource_keys = check.opt_set_param(
+        required_resource_keys, "required_resource_keys", of_type=str
+    )
+    resource_defs = wrap_resources_for_execution(
+        check.opt_mapping_param(resource_defs, "resource_defs", key_type=str)
+    )
+    config_schema = check.opt_mapping_param(
+        config_schema,  # type: ignore
+        "config_schema",
+        additional_message="Only dicts are supported for asset config_schema.",
+    )
+
+    def inner(fn: MultiAssetCheckFunction) -> AssetChecksDefinition:
+        op_name = name or fn.__name__
+        arg_resource_keys = {arg.name for arg in get_resource_args(fn)}
+        op_required_resource_keys = required_resource_keys - arg_resource_keys
+
+        outs = {
+            spec.get_python_identifier(): Out(None, is_required=not can_subset) for spec in specs
+        }
+        input_tuples_by_asset_key = build_asset_ins(
+            fn=fn,
+            asset_ins={},
+            deps={spec.asset_key for spec in specs}
+            | {dep.asset_key for spec in specs for dep in spec.additional_deps or []},
         )
 
-        return checks_def
+        with disable_dagster_warnings():
+            op_def = _Op(
+                name=op_name,
+                description=description,
+                ins=dict(input_tuples_by_asset_key.values()),
+                out=outs,
+                required_resource_keys=op_required_resource_keys,
+                tags={
+                    **({"kind": compute_kind} if compute_kind else {}),
+                    **(op_tags or {}),
+                },
+                config_schema=config_schema,
+                retry_policy=retry_policy,
+            )(fn)
+
+        return AssetChecksDefinition.create(
+            node_def=op_def,
+            resource_defs=wrap_resources_for_execution(resource_defs),
+            keys_by_input_name={
+                input_tuple[0]: asset_key
+                for asset_key, input_tuple in input_tuples_by_asset_key.items()
+            },
+            check_specs_by_output_name={spec.get_python_identifier(): spec for spec in specs},
+            can_subset=can_subset,
+        )
 
     return inner
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/asset_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/asset_decorator.py`

 * *Files 1% similar despite different names*

```diff
@@ -47,15 +47,20 @@
 from ..decorators.op_decorator import _Op
 from ..events import AssetKey, CoercibleToAssetKey, CoercibleToAssetKeyPrefix
 from ..input import GraphIn, In
 from ..output import GraphOut, Out
 from ..partition import PartitionsDefinition
 from ..policy import RetryPolicy
 from ..resource_definition import ResourceDefinition
-from ..utils import DEFAULT_IO_MANAGER_KEY, DEFAULT_OUTPUT, NoValueSentinel
+from ..utils import (
+    DEFAULT_IO_MANAGER_KEY,
+    DEFAULT_OUTPUT,
+    NoValueSentinel,
+    validate_definition_tags,
+)
 
 
 @overload
 def asset(
     compute_fn: Callable[..., Any],
 ) -> AssetsDefinition: ...
 
@@ -64,14 +69,15 @@
 def asset(
     *,
     name: Optional[str] = ...,
     key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
     ins: Optional[Mapping[str, AssetIn]] = ...,
     deps: Optional[Iterable[CoercibleToAssetDep]] = ...,
     metadata: Optional[Mapping[str, Any]] = ...,
+    tags: Optional[Mapping[str, str]] = ...,
     description: Optional[str] = ...,
     config_schema: Optional[UserConfigSchema] = None,
     required_resource_keys: Optional[AbstractSet[str]] = ...,
     resource_defs: Optional[Mapping[str, object]] = ...,
     io_manager_def: Optional[object] = ...,
     io_manager_key: Optional[str] = ...,
     compute_kind: Optional[str] = ...,
@@ -93,25 +99,27 @@
 
 
 @experimental_param(param="resource_defs")
 @experimental_param(param="io_manager_def")
 @experimental_param(param="auto_materialize_policy")
 @experimental_param(param="backfill_policy")
 @experimental_param(param="owners")
+@experimental_param(param="tags")
 @deprecated_param(
     param="non_argument_deps", breaking_version="2.0.0", additional_warn_text="use `deps` instead."
 )
 def asset(
     compute_fn: Optional[Callable[..., Any]] = None,
     *,
     name: Optional[str] = None,
     key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
     ins: Optional[Mapping[str, AssetIn]] = None,
     deps: Optional[Iterable[CoercibleToAssetDep]] = None,
     metadata: Optional[ArbitraryMetadataMapping] = None,
+    tags: Optional[Mapping[str, str]] = None,
     description: Optional[str] = None,
     config_schema: Optional[UserConfigSchema] = None,
     required_resource_keys: Optional[AbstractSet[str]] = None,
     resource_defs: Optional[Mapping[str, object]] = None,
     io_manager_def: Optional[object] = None,
     io_manager_key: Optional[str] = None,
     compute_kind: Optional[str] = None,
@@ -158,14 +166,16 @@
             The assets that are upstream dependencies, but do not correspond to a parameter of the
             decorated function. If the AssetsDefinition for a multi_asset is provided, dependencies on
             all assets created by the multi_asset will be created.
         config_schema (Optional[ConfigSchema): The configuration schema for the asset's underlying
             op. If set, Dagster will check that config provided for the op matches this schema and fail
             if it does not. If not set, Dagster will accept any config provided for the op.
         metadata (Optional[Dict[str, Any]]): A dict of metadata entries for the asset.
+        tags (Optional[Mapping[str, str]]): Tags for filtering and organizing. These tags are not
+            attached to runs of the asset.
         required_resource_keys (Optional[Set[str]]): Set of resource handles required by the op.
         io_manager_key (Optional[str]): The resource key of the IOManager used
             for storing the output of the op as an asset, and for loading it in downstream ops
             (default: "io_manager"). Only one of io_manager_key and io_manager_def can be provided.
         io_manager_def (Optional[object]): (Experimental) The IOManager used for
             storing the output of the op as an asset,  and for loading it in
             downstream ops. Only one of io_manager_def and io_manager_key can be provided.
@@ -184,16 +194,16 @@
         resource_defs (Optional[Mapping[str, object]]):
             (Experimental) A mapping of resource keys to resources. These resources
             will be initialized during execution, and can be accessed from the
             context within the body of the function.
         output_required (bool): Whether the decorated function will always materialize an asset.
             Defaults to True. If False, the function can return None, which will not be materialized to
             storage and will halt execution of downstream assets.
-        freshness_policy (FreshnessPolicy): A constraint telling Dagster how often this asset is intended to be updated
-            with respect to its root data.
+        freshness_policy (FreshnessPolicy): (Deprecated) A constraint telling Dagster how often this
+            asset is intended to be updated with respect to its root data.
         auto_materialize_policy (AutoMaterializePolicy): (Experimental) Configure Dagster to automatically materialize
             this asset according to its FreshnessPolicy and when upstream dependencies change.
         backfill_policy (BackfillPolicy): (Experimental) Configure Dagster to backfill this asset according to its
             BackfillPolicy.
         retry_policy (Optional[RetryPolicy]): The retry policy for the op that computes the asset.
         code_version (Optional[str]): (Experimental) Version of the code that generates this asset. In
             general, versions should be set only for code that deterministically produces the same
@@ -222,14 +232,15 @@
 
         return _Asset(
             name=cast(Optional[str], name),  # (mypy bug that it can't infer name is Optional[str])
             key_prefix=key_prefix,
             ins=ins,
             deps=upstream_asset_deps,
             metadata=metadata,
+            tags=validate_definition_tags(tags),
             description=description,
             config_schema=config_schema,
             required_resource_keys=required_resource_keys,
             resource_defs=resource_defs,
             io_manager_key=io_manager_key,
             io_manager_def=io_manager_def,
             compute_kind=check.opt_str_param(compute_kind, "compute_kind"),
@@ -295,14 +306,15 @@
     def __init__(
         self,
         name: Optional[str] = None,
         key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
         ins: Optional[Mapping[str, AssetIn]] = None,
         deps: Optional[Iterable[AssetDep]] = None,
         metadata: Optional[ArbitraryMetadataMapping] = None,
+        tags: Optional[Mapping[str, str]] = None,
         description: Optional[str] = None,
         config_schema: Optional[UserConfigSchema] = None,
         required_resource_keys: Optional[Set[str]] = None,
         resource_defs: Optional[Mapping[str, object]] = None,
         io_manager_key: Optional[str] = None,
         io_manager_def: Optional[object] = None,
         compute_kind: Optional[str] = None,
@@ -321,14 +333,15 @@
         owners: Optional[Sequence[str]] = None,
     ):
         self.name = name
         self.key_prefix = key_prefix
         self.ins = ins or {}
         self.deps = deps or []
         self.metadata = metadata
+        self.tags = tags
         self.description = description
         self.required_resource_keys = check.opt_set_param(
             required_resource_keys, "required_resource_keys"
         )
         self.io_manager_key = io_manager_key
         self.io_manager_def = io_manager_def
         self.config_schema = config_schema
@@ -481,14 +494,15 @@
                 else None
             ),
             backfill_policy=self.backfill_policy,
             asset_deps=None,  # no asset deps in single-asset decorator
             selected_asset_keys=None,  # no subselection in decorator
             can_subset=False,
             metadata_by_key={out_asset_key: self.metadata} if self.metadata else None,
+            tags_by_key={out_asset_key: self.tags} if self.tags else None,
             # see comment in @multi_asset's call to dagster_internal_init for the gory details
             # this is best understood as an _override_ which @asset does not support
             descriptions_by_key=None,
             check_specs_by_output_name=check_specs_by_output_name,
             selected_asset_check_keys=None,  # no subselection in decorator
             is_subset=False,
             owners_by_key={out_asset_key: self.owners} if self.owners else None,
@@ -559,15 +573,15 @@
             compose the assets.
         backfill_policy (Optional[BackfillPolicy]): The backfill policy for the op that computes the asset.
         op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that computes the asset.
             Frameworks may expect and require certain metadata to be attached to a op. Values that
             are not strings will be json encoded and must meet the criteria that
             `json.loads(json.dumps(value)) == value`.
         can_subset (bool): If this asset's computation can emit a subset of the asset
-            keys based on the context.selected_assets argument. Defaults to False.
+            keys based on the context.selected_asset_keys argument. Defaults to False.
         resource_defs (Optional[Mapping[str, object]]):
             (Experimental) A mapping of resource keys to resources. These resources
             will be initialized during execution, and can be accessed from the
             context within the body of the function.
         group_name (Optional[str]): A string name used to organize multiple assets into groups. This
             group name will be applied to all assets produced by this multi_asset.
         retry_policy (Optional[RetryPolicy]): The retry policy for the op that computes the asset.
@@ -642,16 +656,15 @@
         op_name = name or fn.__name__
 
         if asset_out_map and specs:
             raise DagsterInvalidDefinitionError("Must specify only outs or specs but not both.")
         elif specs:
             output_tuples_by_asset_key = {}
             for asset_spec in specs:
-                # output names are asset keys joined with _
-                output_name = "_".join(asset_spec.key.path)
+                output_name = asset_spec.key.to_python_identifier()
                 output_tuples_by_asset_key[asset_spec.key] = (
                     output_name,
                     Out(
                         Nothing,
                         is_required=not (can_subset or asset_spec.skippable),
                         description=asset_spec.description,
                         code_version=asset_spec.code_version,
@@ -858,14 +871,19 @@
             if props.auto_materialize_policy is not None
         }
         metadata_by_key = {
             asset_key: props.metadata
             for asset_key, props in props_by_asset_key.items()
             if props.metadata is not None
         }
+        tags_by_key = {
+            asset_key: props.tags
+            for asset_key, props in props_by_asset_key.items()
+            if props.tags is not None
+        }
         owners_by_key = {
             asset_key: props.owners
             for asset_key, props in props_by_asset_key.items()
             if props.owners is not None
         }
 
         return AssetsDefinition.dagster_internal_init(
@@ -889,14 +907,15 @@
             # to create a memoized cached dictionary of asset keys for perf or something we do
             # that in the `__init__` or on demand.
             #
             # This is actually an override. We do not override descriptions
             # in OutputDefinitions in @multi_asset
             descriptions_by_key=None,
             metadata_by_key=metadata_by_key,
+            tags_by_key=tags_by_key,
             check_specs_by_output_name=check_specs_by_output_name,
             selected_asset_check_keys=None,  # no subselection in decorator
             is_subset=False,
             owners_by_key=owners_by_key,
         )
 
     return inner
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/config_mapping_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/config_mapping_decorator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/graph_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/graph_decorator.py`

 * *Files 5% similar despite different names*

```diff
@@ -71,15 +71,15 @@
         (
             input_mappings,
             output_mappings,
             dependencies,
             node_defs,
             config_mapping,
             positional_inputs,
-            node_input_source_assets,
+            input_assets,
         ) = do_composition(
             decorator_name="@graph",
             graph_name=self.name,
             fn=fn,
             provided_input_defs=input_defs,
             provided_output_defs=output_defs,
             ignore_output_from_composition_fn=False,
@@ -92,15 +92,15 @@
             node_defs=node_defs,
             description=self.description or format_docstring_for_description(fn),
             input_mappings=input_mappings,
             output_mappings=output_mappings,
             config=config_mapping,
             positional_inputs=positional_inputs,
             tags=self.tags,
-            node_input_source_assets=node_input_source_assets,
+            input_assets=input_assets,
         )
         update_wrapper(graph_def, fn)
         return graph_def
 
 
 @overload
 def graph(compose_fn: Callable[..., Any]) -> GraphDefinition: ...
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/hook_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/hook_decorator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/job_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/job_decorator.py`

 * *Files 0% similar despite different names*

```diff
@@ -9,14 +9,15 @@
 from ..graph_definition import GraphDefinition
 from ..hook_definition import HookDefinition
 from ..job_definition import JobDefinition
 from ..logger_definition import LoggerDefinition
 from ..metadata import RawMetadataValue
 from ..policy import RetryPolicy
 from ..resource_definition import ResourceDefinition
+from ..utils import normalize_tags
 from ..version_strategy import VersionStrategy
 
 if TYPE_CHECKING:
     from ..executor_definition import ExecutorDefinition
     from ..partition import PartitionedConfig, PartitionsDefinition
     from ..run_config import RunConfig
 
@@ -40,15 +41,15 @@
         partitions_def: Optional["PartitionsDefinition"] = None,
         input_values: Optional[Mapping[str, object]] = None,
     ):
         from dagster._core.definitions.run_config import convert_config_input
 
         self.name = name
         self.description = description
-        self.tags = tags
+        self.tags = normalize_tags(tags, warning_stacklevel=5)
         self.metadata = metadata
         self.resource_defs = resource_defs
         self.config = convert_config_input(config)
         self.logger_defs = logger_defs
         self.executor_def = executor_def
         self.hooks = hooks
         self.op_retry_policy = op_retry_policy
@@ -67,15 +68,15 @@
         (
             input_mappings,
             output_mappings,
             dependencies,
             node_defs,
             config_mapping,
             positional_inputs,
-            node_input_source_assets,
+            input_assets,
         ) = do_composition(
             decorator_name="@job",
             graph_name=self.name,
             fn=fn,
             provided_input_defs=[],
             provided_output_defs=[],
             ignore_output_from_composition_fn=False,
@@ -88,15 +89,15 @@
             node_defs=node_defs,
             description=self.description or format_docstring_for_description(fn),
             input_mappings=input_mappings,
             output_mappings=output_mappings,
             config=config_mapping,
             positional_inputs=positional_inputs,
             tags=self.tags,
-            node_input_source_assets=node_input_source_assets,
+            input_assets=input_assets,
         )
 
         job_def = graph_def.to_job(
             description=self.description or format_docstring_for_description(fn),
             resource_defs=self.resource_defs,
             config=self.config,
             tags=self.tags,
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/op_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/op_decorator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/repository_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/repository_decorator.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,14 @@
 from dagster._core.definitions.metadata import (
     RawMetadataValue,
     normalize_metadata,
 )
 from dagster._core.definitions.resource_definition import ResourceDefinition
 from dagster._core.errors import DagsterInvalidDefinitionError
 
-from ..asset_checks import AssetChecksDefinition
 from ..executor_definition import ExecutorDefinition
 from ..graph_definition import GraphDefinition
 from ..job_definition import JobDefinition
 from ..logger_definition import LoggerDefinition
 from ..partitioned_schedule import UnresolvedPartitionedAssetScheduleDefinition
 from ..repository_definition import (
     VALID_REPOSITORY_DATA_DICT_KEYS,
@@ -132,15 +131,14 @@
                         ScheduleDefinition,
                         UnresolvedPartitionedAssetScheduleDefinition,
                         SensorDefinition,
                         GraphDefinition,
                         AssetsDefinition,
                         SourceAsset,
                         UnresolvedAssetJobDefinition,
-                        AssetChecksDefinition,
                     ),
                 ):
                     bad_defns.append((i, type(definition)))
                 else:
                     repository_defns.append(definition)
 
             if bad_defns:
@@ -183,17 +181,17 @@
                     )
                 )
             repository_data = CachingRepositoryData.from_dict(repository_definitions)
         elif isinstance(repository_definitions, RepositoryData):
             repository_data = repository_definitions
         else:
             raise DagsterInvalidDefinitionError(
-                "Bad return value of type {type_} from repository construction function: must "
+                f"Bad return value of type {type(repository_definitions)} from repository construction function: must "
                 "return list, dict, or RepositoryData. See the @repository decorator docstring for "
-                "details and examples".format(type_=type(repository_definitions)),
+                "details and examples",
             )
 
         if isinstance(repository_definitions, list) and repository_data is None:
             return PendingRepositoryDefinition(
                 self.name,
                 repository_definitions=list(_flatten(repository_definitions)),
                 description=self.description,
@@ -203,15 +201,15 @@
                 _top_level_resources=self.top_level_resources,
             )
         else:
             repository_def = RepositoryDefinition(
                 name=self.name,
                 description=self.description,
                 metadata=self.metadata,
-                repository_data=repository_data,
+                repository_data=check.not_none(repository_data),
             )
 
             update_wrapper(repository_def, fn)
             return repository_def
 
 
 @overload
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/schedule_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/schedule_decorator.py`

 * *Files 2% similar despite different names*

```diff
@@ -31,15 +31,15 @@
     RunRequestIterator,
     ScheduleDefinition,
     ScheduleEvaluationContext,
     has_at_least_one_parameter,
     validate_and_get_schedule_resource_dict,
 )
 from ..target import ExecutableDefinition
-from ..utils import validate_tags
+from ..utils import normalize_tags
 
 
 def schedule(
     cron_schedule: Union[str, Sequence[str]],
     *,
     job_name: Optional[str] = None,
     name: Optional[str] = None,
@@ -109,15 +109,15 @@
         # perform upfront validation of schedule tags
         if tags_fn and tags:
             raise DagsterInvalidDefinitionError(
                 "Attempted to provide both tags_fn and tags as arguments"
                 " to ScheduleDefinition. Must provide only one of the two."
             )
         elif tags:
-            validated_tags = validate_tags(tags, allow_reserved_tags=False)
+            validated_tags = normalize_tags(tags, allow_reserved_tags=False, warning_stacklevel=3)
 
         context_param_name = get_context_param_name(fn)
         resource_arg_names: Set[str] = {arg.name for arg in get_resource_args(fn)}
 
         def _wrapped_fn(context: ScheduleEvaluationContext) -> RunRequestIterator:
             if should_execute:
                 with user_code_error_boundary(
@@ -145,15 +145,15 @@
 
                 if isinstance(result, dict):
                     # this is the run-config based decorated function, wrap the evaluated run config
                     # and tags in a RunRequest
                     evaluated_run_config = copy.deepcopy(result)
                     evaluated_tags = (
                         validated_tags
-                        or (tags_fn and validate_tags(tags_fn(context), allow_reserved_tags=False))
+                        or (tags_fn and normalize_tags(tags_fn(context), allow_reserved_tags=False))
                         or None
                     )
                     yield RunRequest(
                         run_key=None,
                         run_config=evaluated_run_config,
                         tags=evaluated_tags,
                     )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/sensor_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/sensor_decorator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/decorators/source_asset_decorator.py` & `dagster-1.7.0/dagster/_core/definitions/decorators/source_asset_decorator.py`

 * *Files 3% similar despite different names*

```diff
@@ -19,18 +19,16 @@
 from dagster._core.definitions.freshness_policy import FreshnessPolicy
 from dagster._core.definitions.metadata import (
     RawMetadataMapping,
 )
 from dagster._core.definitions.partition import PartitionsDefinition
 from dagster._core.definitions.resource_annotation import get_resource_args
 from dagster._core.definitions.resource_definition import ResourceDefinition
-from dagster._core.definitions.source_asset import (
-    SourceAsset,
-    SourceAssetObserveFunction,
-)
+from dagster._core.definitions.source_asset import SourceAsset, SourceAssetObserveFunction
+from dagster._core.definitions.utils import validate_definition_tags
 
 
 @overload
 def observable_source_asset(observe_fn: SourceAssetObserveFunction) -> SourceAsset: ...
 
 
 @overload
@@ -46,14 +44,15 @@
     group_name: Optional[str] = None,
     required_resource_keys: Optional[AbstractSet[str]] = None,
     resource_defs: Optional[Mapping[str, ResourceDefinition]] = None,
     partitions_def: Optional[PartitionsDefinition] = None,
     auto_observe_interval_minutes: Optional[float] = None,
     freshness_policy: Optional[FreshnessPolicy] = None,
     op_tags: Optional[Mapping[str, Any]] = None,
+    tags: Optional[Mapping[str, str]] = None,
 ) -> "_ObservableSourceAsset": ...
 
 
 @experimental
 def observable_source_asset(
     observe_fn: Optional[SourceAssetObserveFunction] = None,
     *,
@@ -67,14 +66,15 @@
     group_name: Optional[str] = None,
     required_resource_keys: Optional[AbstractSet[str]] = None,
     resource_defs: Optional[Mapping[str, ResourceDefinition]] = None,
     partitions_def: Optional[PartitionsDefinition] = None,
     auto_observe_interval_minutes: Optional[float] = None,
     freshness_policy: Optional[FreshnessPolicy] = None,
     op_tags: Optional[Mapping[str, Any]] = None,
+    tags: Optional[Mapping[str, str]] = None,
 ) -> Union[SourceAsset, "_ObservableSourceAsset"]:
     """Create a `SourceAsset` with an associated observation function.
 
     The observation function of a source asset is wrapped inside of an op and can be executed as
     part of a job. Each execution generates an `AssetObservation` event associated with the source
     asset. The source asset observation function should return a :py:class:`~dagster.DataVersion`,
     a `~dagster.DataVersionsByPartition`, or an :py:class:`~dagster.ObserveResult`.
@@ -105,14 +105,16 @@
             of the observation function for this asset will be launched at this interval.
         freshness_policy (FreshnessPolicy): A constraint telling Dagster how often this asset is intended to be updated
             with respect to its root data.
         op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that computes the asset.
             Frameworks may expect and require certain metadata to be attached to a op. Values that
             are not strings will be json encoded and must meet the criteria that
             `json.loads(json.dumps(value)) == value`.
+        tags (Optional[Mapping[str, str]]): Tags for filtering and organizing. These tags are not
+            attached to runs of the asset.
         observe_fn (Optional[SourceAssetObserveFunction]) Observation function for the source asset.
     """
     if observe_fn is not None:
         return _ObservableSourceAsset()(observe_fn)
 
     return _ObservableSourceAsset(
         key,
@@ -125,14 +127,15 @@
         group_name,
         required_resource_keys,
         resource_defs,
         partitions_def,
         auto_observe_interval_minutes,
         freshness_policy,
         op_tags,
+        tags=validate_definition_tags(tags),
     )
 
 
 class _ObservableSourceAsset:
     def __init__(
         self,
         key: Optional[CoercibleToAssetKey] = None,
@@ -145,14 +148,15 @@
         group_name: Optional[str] = None,
         required_resource_keys: Optional[AbstractSet[str]] = None,
         resource_defs: Optional[Mapping[str, ResourceDefinition]] = None,
         partitions_def: Optional[PartitionsDefinition] = None,
         auto_observe_interval_minutes: Optional[float] = None,
         freshness_policy: Optional[FreshnessPolicy] = None,
         op_tags: Optional[Mapping[str, Any]] = None,
+        tags: Optional[Mapping[str, str]] = None,
     ):
         self.key = key
         self.name = name
         if isinstance(key_prefix, str):
             key_prefix = [key_prefix]
         elif key_prefix is None:
             key_prefix = []
@@ -164,14 +168,15 @@
         self.group_name = group_name
         self.required_resource_keys = required_resource_keys
         self.resource_defs = resource_defs
         self.partitions_def = partitions_def
         self.auto_observe_interval_minutes = auto_observe_interval_minutes
         self.freshness_policy = freshness_policy
         self.op_tags = op_tags
+        self.tags = tags
 
     def __call__(self, observe_fn: SourceAssetObserveFunction) -> SourceAsset:
         source_asset_key, source_asset_name = resolve_asset_key_and_name_for_decorator(
             key=self.key,
             key_prefix=self.key_prefix,
             name=self.name,
             fn=observe_fn,
@@ -197,14 +202,15 @@
             _required_resource_keys=resolved_resource_keys,
             resource_defs=self.resource_defs,
             observe_fn=observe_fn,
             op_tags=self.op_tags,
             partitions_def=self.partitions_def,
             auto_observe_interval_minutes=self.auto_observe_interval_minutes,
             freshness_policy=self.freshness_policy,
+            tags=self.tags,
         )
 
 
 @experimental
 def multi_observable_source_asset(
     *,
     specs: Sequence[AssetSpec],
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/definition_config_schema.py` & `dagster-1.7.0/dagster/_core/definitions/definition_config_schema.py`

 * *Files 0% similar despite different names*

```diff
@@ -87,17 +87,17 @@
         return self._config_field
 
 
 def _get_user_code_error_str_lambda(
     configured_definition: "ConfigurableDefinition",
 ) -> Callable[[], str]:
     return lambda: (
-        "The config mapping function on a `configured` {} has thrown an unexpected "
+        f"The config mapping function on a `configured` {configured_definition.__class__.__name__} has thrown an unexpected "
         "error during its execution."
-    ).format(configured_definition.__class__.__name__)
+    )
 
 
 class ConfiguredDefinitionConfigSchema(IDefinitionConfigSchema):
     parent_def: "ConfigurableDefinition"
     _current_field: Optional[Field]
     _config_fn: Callable[..., object]
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/definitions_class.py` & `dagster-1.7.0/dagster/_core/definitions/definitions_class.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,17 +14,17 @@
 
 import dagster._check as check
 from dagster._annotations import deprecated, experimental, public
 from dagster._config.pythonic_config import (
     attach_resource_id_to_key_mapping,
 )
 from dagster._core.definitions.asset_checks import AssetChecksDefinition
+from dagster._core.definitions.asset_graph import AssetGraph
 from dagster._core.definitions.events import AssetKey, CoercibleToAssetKey
 from dagster._core.definitions.executor_definition import ExecutorDefinition
-from dagster._core.definitions.internal_asset_graph import InternalAssetGraph
 from dagster._core.definitions.logger_definition import LoggerDefinition
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.execution.build_resources import wrap_resources_for_execution
 from dagster._core.execution.with_resources import with_resources
 from dagster._core.executor.base import Executor
 from dagster._core.instance import DagsterInstance
 from dagster._utils.cached_method import cached_method
@@ -566,10 +566,10 @@
     ) -> Union[RepositoryDefinition, PendingRepositoryDefinition]:
         """This method is used internally to access the inner repository during the loading process
         at CLI entry points. We explicitly do not want to resolve the pending repo because the entire
         point is to defer that resolution until later.
         """
         return self._created_pending_or_normal_repo
 
-    def get_asset_graph(self) -> InternalAssetGraph:
+    def get_asset_graph(self) -> AssetGraph:
         """Get the AssetGraph for this set of definitions."""
         return self.get_repository_def().asset_graph
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/dependency.py` & `dagster-1.7.0/dagster/_core/definitions/dependency.py`

 * *Files 1% similar despite different names*

```diff
@@ -31,15 +31,15 @@
     whitelist_for_serdes,
 )
 from dagster._utils import hash_collection
 
 from .hook_definition import HookDefinition
 from .input import FanInInputPointer, InputDefinition, InputMapping, InputPointer
 from .output import OutputDefinition
-from .utils import DEFAULT_OUTPUT, struct_to_string, validate_tags
+from .utils import DEFAULT_OUTPUT, normalize_tags, struct_to_string
 
 if TYPE_CHECKING:
     from dagster._core.definitions.op_definition import OpDefinition
 
     from .asset_layer import AssetLayer
     from .composition import MappedInputPlaceholder
     from .graph_definition import GraphDefinition
@@ -140,15 +140,15 @@
         self.name = check.str_param(name, "name")
         self.definition = check.inst_param(definition, "definition", NodeDefinition)
         self.graph_definition = check.inst_param(
             graph_definition,
             "graph_definition",
             GraphDefinition,
         )
-        self._additional_tags = validate_tags(tags)
+        self._additional_tags = normalize_tags(tags).tags
         self._hook_defs = check.opt_set_param(hook_defs, "hook_defs", of_type=HookDefinition)
         self._retry_policy = check.opt_inst_param(retry_policy, "retry_policy", RetryPolicy)
 
         self._inputs = {
             name: NodeInput(self, input_def)
             for name, input_def in self.definition.input_dict.items()
         }
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/events.py` & `dagster-1.7.0/dagster/_core/definitions/events.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-import re
 from enum import Enum
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Any,
     Callable,
     Generic,
@@ -13,16 +12,21 @@
     Sequence,
     TypeVar,
     Union,
     cast,
 )
 
 import dagster._check as check
-import dagster._seven as seven
 from dagster._annotations import PublicAttr, deprecated, experimental_param, public
+from dagster._core.definitions.asset_key import (
+    AssetKey as AssetKey,
+    CoercibleToAssetKey as CoercibleToAssetKey,
+    CoercibleToAssetKeyPrefix as CoercibleToAssetKeyPrefix,
+    parse_asset_key_string,
+)
 from dagster._core.definitions.data_version import DATA_VERSION_TAG, DataVersion
 from dagster._core.storage.tags import MULTIDIMENSIONAL_PARTITION_PREFIX, SYSTEM_TAG_PREFIX
 from dagster._serdes import whitelist_for_serdes
 from dagster._serdes.serdes import NamedTupleSerializer
 
 from .metadata import (
     MetadataFieldSerializer,
@@ -30,210 +34,26 @@
     MetadataValue,
     RawMetadataValue,
     normalize_metadata,
 )
 from .utils import DEFAULT_OUTPUT, check_valid_name
 
 if TYPE_CHECKING:
-    from dagster._core.definitions.assets import AssetsDefinition
-    from dagster._core.definitions.source_asset import SourceAsset
     from dagster._core.execution.context.output import OutputContext
 
 
-ASSET_KEY_SPLIT_REGEX = re.compile("[^a-zA-Z0-9_]")
-ASSET_KEY_DELIMITER = "/"
-
-
-def parse_asset_key_string(s: str) -> Sequence[str]:
-    return list(filter(lambda x: x, re.split(ASSET_KEY_SPLIT_REGEX, s)))
-
-
-@whitelist_for_serdes
-class AssetKey(NamedTuple("_AssetKey", [("path", PublicAttr[Sequence[str]])])):
-    """Object representing the structure of an asset key.  Takes in a sanitized string, list of
-    strings, or tuple of strings.
-
-    Example usage:
-
-    .. code-block:: python
-
-        from dagster import op
-
-        @op
-        def emit_metadata(context, df):
-            yield AssetMaterialization(
-                asset_key=AssetKey('flat_asset_key'),
-                metadata={"text_metadata": "Text-based metadata for this event"},
-            )
-
-        @op
-        def structured_asset_key(context, df):
-            yield AssetMaterialization(
-                asset_key=AssetKey(['parent', 'child', 'grandchild']),
-                metadata={"text_metadata": "Text-based metadata for this event"},
-            )
-
-        @op
-        def structured_asset_key_2(context, df):
-            yield AssetMaterialization(
-                asset_key=AssetKey(('parent', 'child', 'grandchild')),
-                metadata={"text_metadata": "Text-based metadata for this event"},
-            )
-
-    Args:
-        path (Sequence[str]): String, list of strings, or tuple of strings.  A list of strings
-            represent the hierarchical structure of the asset_key.
-    """
-
-    def __new__(cls, path: Sequence[str]):
-        if isinstance(path, str):
-            path = [path]
-        else:
-            path = list(check.sequence_param(path, "path", of_type=str))
-
-        return super(AssetKey, cls).__new__(cls, path=path)
-
-    def __str__(self):
-        return f"AssetKey({self.path})"
-
-    def __repr__(self):
-        return f"AssetKey({self.path})"
-
-    def __hash__(self):
-        return hash(tuple(self.path))
-
-    def __eq__(self, other):
-        if not isinstance(other, AssetKey):
-            return False
-        if len(self.path) != len(other.path):
-            return False
-        for i in range(0, len(self.path)):
-            if self.path[i] != other.path[i]:
-                return False
-        return True
-
-    def to_string(self) -> str:
-        """E.g. '["first_component", "second_component"]'."""
-        return seven.json.dumps(self.path)
-
-    def to_user_string(self) -> str:
-        """E.g. "first_component/second_component"."""
-        return ASSET_KEY_DELIMITER.join(self.path)
-
-    def to_python_identifier(self, suffix: Optional[str] = None) -> str:
-        """Build a valid Python identifier based on the asset key that can be used for
-        operation names or I/O manager keys.
-        """
-        path = list(self.path)
-
-        if suffix is not None:
-            path.append(suffix)
-
-        return "__".join(path).replace("-", "_")
-
-    @staticmethod
-    def from_user_string(asset_key_string: str) -> "AssetKey":
-        return AssetKey(asset_key_string.split(ASSET_KEY_DELIMITER))
-
-    @staticmethod
-    def from_db_string(asset_key_string: Optional[str]) -> Optional["AssetKey"]:
-        if not asset_key_string:
-            return None
-        if asset_key_string[0] == "[":
-            # is a json string
-            try:
-                path = seven.json.loads(asset_key_string)
-            except seven.JSONDecodeError:
-                path = parse_asset_key_string(asset_key_string)
-        else:
-            path = parse_asset_key_string(asset_key_string)
-        return AssetKey(path)
-
-    @staticmethod
-    def get_db_prefix(path: Sequence[str]):
-        check.sequence_param(path, "path", of_type=str)
-        return seven.json.dumps(path)[:-2]  # strip trailing '"]' from json string
-
-    @staticmethod
-    def from_graphql_input(graphql_input_asset_key: Mapping[str, Sequence[str]]) -> "AssetKey":
-        return AssetKey(graphql_input_asset_key["path"])
-
-    def to_graphql_input(self) -> Mapping[str, Sequence[str]]:
-        return {"path": self.path}
-
-    @staticmethod
-    def from_coercible(arg: "CoercibleToAssetKey") -> "AssetKey":
-        if isinstance(arg, AssetKey):
-            return check.inst_param(arg, "arg", AssetKey)
-        elif isinstance(arg, str):
-            return AssetKey([arg])
-        elif isinstance(arg, list):
-            check.list_param(arg, "arg", of_type=str)
-            return AssetKey(arg)
-        elif isinstance(arg, tuple):
-            check.tuple_param(arg, "arg", of_type=str)
-            return AssetKey(arg)
-        else:
-            check.failed(f"Unexpected type for AssetKey: {type(arg)}")
-
-    @staticmethod
-    def from_coercible_or_definition(
-        arg: Union["CoercibleToAssetKey", "AssetsDefinition", "SourceAsset"],
-    ) -> "AssetKey":
-        from dagster._core.definitions.assets import AssetsDefinition
-        from dagster._core.definitions.source_asset import SourceAsset
-
-        if isinstance(arg, AssetsDefinition):
-            return arg.key
-        elif isinstance(arg, SourceAsset):
-            return arg.key
-        else:
-            return AssetKey.from_coercible(arg)
-
-    def has_prefix(self, prefix: Sequence[str]) -> bool:
-        return len(self.path) >= len(prefix) and self.path[: len(prefix)] == prefix
-
-    def with_prefix(self, prefix: "CoercibleToAssetKeyPrefix") -> "AssetKey":
-        prefix = key_prefix_from_coercible(prefix)
-        return AssetKey(list(prefix) + list(self.path))
-
-
 class AssetKeyPartitionKey(NamedTuple):
     """An AssetKey with an (optional) partition key. Refers either to a non-partitioned asset or a
     partition of a partitioned asset.
     """
 
     asset_key: AssetKey
     partition_key: Optional[str] = None
 
 
-CoercibleToAssetKey = Union[AssetKey, str, Sequence[str]]
-CoercibleToAssetKeyPrefix = Union[str, Sequence[str]]
-
-
-def check_opt_coercible_to_asset_key_prefix_param(
-    prefix: Optional[CoercibleToAssetKeyPrefix], param_name: str
-) -> Optional[Sequence[str]]:
-    try:
-        return key_prefix_from_coercible(prefix) if prefix is not None else None
-    except check.CheckError:
-        raise check.ParameterCheckError(
-            f'Param "{param_name}" is not a string or a sequence of strings'
-        )
-
-
-def key_prefix_from_coercible(key_prefix: CoercibleToAssetKeyPrefix) -> Sequence[str]:
-    if isinstance(key_prefix, str):
-        return [key_prefix]
-    elif isinstance(key_prefix, list):
-        return key_prefix
-    else:
-        check.failed(f"Unexpected type for key_prefix: {type(key_prefix)}")
-
-
 DynamicAssetKey = Callable[["OutputContext"], Optional[AssetKey]]
 
 
 @whitelist_for_serdes
 class AssetLineageInfo(
     NamedTuple("_AssetLineageInfo", [("asset_key", AssetKey), ("partitions", AbstractSet[str])])
 ):
@@ -593,16 +413,16 @@
             asset_key=cast(Union[str, AssetKey, List[str]], asset_key),
             description=description,
             metadata={"path": MetadataValue.path(path)},
         )
 
 
 @deprecated(
-    breaking_version="1.7",
-    additional_warn_text="Please use AssetCheckResult and @asset_check instead.",
+    breaking_version="2.0",
+    additional_warn_text="If using assets, use AssetCheckResult and @asset_check instead.",
 )
 @whitelist_for_serdes(
     storage_field_names={"metadata": "metadata_entries"},
     field_serializers={"metadata": MetadataFieldSerializer},
 )
 class ExpectationResult(
     NamedTuple(
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/executor_definition.py` & `dagster-1.7.0/dagster/_core/definitions/executor_definition.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/external_asset.py` & `dagster-1.7.0/dagster/_core/definitions/external_asset.py`

 * *Files 4% similar despite different names*

```diff
@@ -162,14 +162,15 @@
             # `resource_defs` (it is added during `SourceAsset` initialization).
             resource_defs=source_asset.resource_defs,
             # We need to access the raw attribute because the property will return a computed value that
             # includes requirements for the io manager. Those requirements will be inferred again when
             # we create an AssetsDefinition.
             required_resource_keys=source_asset._required_resource_keys,  # noqa: SLF001
             freshness_policy=source_asset.freshness_policy,
+            tags=source_asset.tags,
         )
         def _shim_assets_def(context: AssetExecutionContext):
             if not source_asset.observe_fn:
                 raise NotImplementedError(f"Asset {source_asset.key} is not executable")
 
             op_function = wrap_source_asset_observe_fn_in_op_compute_fn(source_asset)
             return_value = op_function.decorated_fn(context)
@@ -177,7 +178,18 @@
                 isinstance(return_value, Output)
                 and SYSTEM_METADATA_KEY_SOURCE_ASSET_OBSERVATION in return_value.metadata,
                 "The wrapped decorated_fn should return an Output with a special metadata key.",
             )
             return return_value
 
     return _shim_assets_def
+
+
+# Create unexecutable assets defs for each asset key in the provided assets def. This is used to
+# make a materializable assets def available only for loading in a job.
+def create_unexecutable_external_assets_from_assets_def(
+    assets_def: AssetsDefinition,
+) -> Sequence[AssetsDefinition]:
+    if not assets_def.is_executable:
+        return [assets_def]
+    else:
+        return [create_external_asset_from_source_asset(sa) for sa in assets_def.to_source_assets()]
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/freshness_based_auto_materialize.py` & `dagster-1.7.0/dagster/_core/definitions/freshness_based_auto_materialize.py`

 * *Files 3% similar despite different names*

```diff
@@ -114,32 +114,32 @@
 
 def get_expected_data_time_for_asset_key(
     context: "AssetConditionEvaluationContext", will_materialize: bool
 ) -> Optional[datetime.datetime]:
     """Returns the data time that you would expect this asset to have if you were to execute it
     on this tick.
     """
-    from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
+    from dagster._core.definitions.remote_asset_graph import RemoteAssetGraph
 
     asset_key = context.asset_key
     asset_graph = context.asset_graph
     current_time = context.evaluation_time
 
     # don't bother calculating if no downstream assets have freshness policies
     if not asset_graph.get_downstream_freshness_policies(asset_key=asset_key):
         return None
     # if asset will not be materialized, just return the current time
     elif not will_materialize:
         return context.data_time_resolver.get_current_data_time(asset_key, current_time)
     elif asset_graph.has_materializable_parents(asset_key):
         expected_data_time = None
-        for parent_key in asset_graph.get_parents(asset_key):
+        for parent_key in asset_graph.get(asset_key).parent_keys:
             # if the parent will be materialized on this tick, and it's not in the same repo, then
             # we must wait for this asset to be materialized
-            if isinstance(asset_graph, ExternalAssetGraph) and context.will_update_asset_partition(
+            if isinstance(asset_graph, RemoteAssetGraph) and context.will_update_asset_partition(
                 AssetKeyPartitionKey(parent_key)
             ):
                 parent_repo = asset_graph.get_repository_handle(parent_key)
                 if parent_repo != asset_graph.get_repository_handle(asset_key):
                     return context.data_time_resolver.get_current_data_time(asset_key, current_time)
             # find the minimum non-None data time of your parents
             parent_expected_data_time = context.expected_data_time_mapping.get(
@@ -164,17 +164,18 @@
     Attempts to minimize the total number of asset executions.
     """
     from .asset_condition.asset_condition import AssetSubsetWithMetadata
 
     asset_key = context.asset_key
     current_time = context.evaluation_time
 
-    if not context.asset_graph.get_downstream_freshness_policies(
-        asset_key=asset_key
-    ) or context.asset_graph.is_partitioned(asset_key):
+    if (
+        not context.asset_graph.get_downstream_freshness_policies(asset_key=asset_key)
+        or context.asset_graph.get(asset_key).is_partitioned
+    ):
         return context.empty_subset(), []
 
     # figure out the current contents of this asset
     current_data_time = context.data_time_resolver.get_current_data_time(asset_key, current_time)
 
     # figure out the data time you would expect if you were to execute this asset on this tick
     expected_data_time = get_expected_data_time_for_asset_key(
@@ -204,15 +205,15 @@
 
     # figure out a time period that you can execute this asset within to solve a maximum
     # number of constraints
     (
         execution_period,
         evaluation_data,
     ) = get_execution_period_and_evaluation_data_for_policies(
-        local_policy=context.asset_graph.get_freshness_policy(asset_key),
+        local_policy=context.asset_graph.get(asset_key).freshness_policy,
         policies=context.asset_graph.get_downstream_freshness_policies(asset_key=asset_key),
         effective_data_time=effective_data_time,
         current_time=current_time,
     )
 
     if (
         execution_period is not None
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/freshness_policy.py` & `dagster-1.7.0/dagster/_core/definitions/freshness_policy.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import datetime
 from typing import AbstractSet, NamedTuple, Optional
 
 import dagster._check as check
-from dagster._annotations import experimental
+from dagster._annotations import deprecated
 from dagster._core.errors import DagsterInvalidDefinitionError
 from dagster._serdes import whitelist_for_serdes
 from dagster._seven.compat.pendulum import pendulum_create_timezone
 from dagster._utils.schedules import (
     is_valid_cron_schedule,
     reverse_cron_string_iterator,
 )
@@ -21,15 +21,20 @@
 
 
 class FreshnessMinutes(NamedTuple):
     overdue_minutes: float
     lag_minutes: float
 
 
-@experimental
+@deprecated(
+    breaking_version="1.8",
+    additional_warn_text="For monitoring freshness, use freshness checks instead. If using lazy "
+    "auto-materialize, using FreshnessPolicys is still required, and an alternative system will "
+    "be provided before this class is fully removed.",
+)
 @whitelist_for_serdes
 class FreshnessPolicy(
     NamedTuple(
         "_FreshnessPolicy",
         [
             ("maximum_lag_minutes", float),
             ("cron_schedule", Optional[str]),
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/freshness_policy_sensor_definition.py` & `dagster-1.7.0/dagster/_core/definitions/freshness_policy_sensor_definition.py`

 * *Files 1% similar despite different names*

```diff
@@ -254,15 +254,15 @@
             # get the previous status from the cursor
             previous_minutes_late_by_key = FreshnessPolicySensorCursor.from_json(
                 context.cursor
             ).minutes_late_by_key
 
             minutes_late_by_key: Dict[AssetKey, Optional[float]] = {}
             for asset_key in monitored_keys:
-                freshness_policy = asset_graph.get_freshness_policy(asset_key)
+                freshness_policy = asset_graph.get(asset_key).freshness_policy
                 if freshness_policy is None:
                     continue
 
                 # get the current minutes_overdue value for this asset
                 result = data_time_resolver.get_minutes_overdue(
                     evaluation_time=evaluation_time,
                     asset_key=asset_key,
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/graph_definition.py` & `dagster-1.7.0/dagster/_core/definitions/graph_definition.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,25 +17,26 @@
     cast,
 )
 
 from toposort import CircularDependencyError, toposort_flatten
 from typing_extensions import Self
 
 import dagster._check as check
-from dagster._annotations import public
+from dagster._annotations import deprecated_param, public
 from dagster._core.definitions.config import ConfigMapping
 from dagster._core.definitions.definition_config_schema import IDefinitionConfigSchema
 from dagster._core.definitions.policy import RetryPolicy
 from dagster._core.errors import DagsterInvalidDefinitionError, DagsterInvariantViolationError
 from dagster._core.selector.subset_selector import AssetSelectionData
 from dagster._core.types.dagster_type import (
     DagsterType,
     DagsterTypeKind,
     construct_dagster_type_dictionary,
 )
+from dagster._utils.warnings import normalize_renamed_param
 
 from .dependency import (
     DependencyMapping,
     DependencyStructure,
     GraphNode,
     Node,
     NodeHandle,
@@ -47,21 +48,23 @@
 from .input import FanInInputPointer, InputDefinition, InputMapping, InputPointer
 from .logger_definition import LoggerDefinition
 from .metadata import RawMetadataValue
 from .node_container import create_execution_structure, normalize_dependency_dict
 from .node_definition import NodeDefinition
 from .output import OutputDefinition, OutputMapping
 from .resource_requirement import ResourceRequirement
+from .utils import NormalizedTags
 from .version_strategy import VersionStrategy
 
 if TYPE_CHECKING:
     from dagster._core.execution.execute_in_process_result import ExecuteInProcessResult
     from dagster._core.instance import DagsterInstance
 
     from .asset_layer import AssetLayer
+    from .assets import AssetsDefinition
     from .composition import PendingNodeInvocation
     from .executor_definition import ExecutorDefinition
     from .job_definition import JobDefinition
     from .op_definition import OpDefinition
     from .partition import PartitionedConfig, PartitionsDefinition
     from .run_config import RunConfig
     from .source_asset import SourceAsset
@@ -76,18 +79,18 @@
 
     _node_defs = check.opt_sequence_param(node_defs, "node_defs")
     for node_def in _node_defs:
         if isinstance(node_def, NodeDefinition):
             continue
         elif callable(node_def):
             raise DagsterInvalidDefinitionError(
-                """You have passed a lambda or function {func} into {name} that is
+                f"""You have passed a lambda or function {node_def.__name__} into {graph_name} that is
                 not a node. You have likely forgetten to annotate this function with
                 the @op or @graph decorators.'
-                """.format(name=graph_name, func=node_def.__name__)
+                """
             )
         else:
             raise DagsterInvalidDefinitionError(f"Invalid item in node list: {node_def!r}")
 
     return node_defs
 
 
@@ -115,14 +118,19 @@
 
     for s in nodes:
         visit(s.name)
 
     return (forward_edges, backward_edges)
 
 
+@deprecated_param(
+    param="node_input_source_assets",
+    breaking_version="2.0",
+    additional_warn_text="Use `input_assets` instead.",
+)
 class GraphDefinition(NodeDefinition):
     """Defines a Dagster op graph.
 
     An op graph is made up of
 
     - Nodes, which can either be an op (the functional unit of computation), or another graph.
     - Dependencies, which determine how the values produced by nodes as outputs flow from
@@ -178,36 +186,42 @@
     _dependency_structure: DependencyStructure
     _node_dict: Mapping[str, Node]
     _input_mappings: Sequence[InputMapping]
     _output_mappings: Sequence[OutputMapping]
     _config_mapping: Optional[ConfigMapping]
     _nodes_in_topological_order: Sequence[Node]
 
-    # (node name within the graph -> (input name -> SourceAsset to load that input from))
+    # (node name within the graph -> (input name -> AssetsDefinition to load that input from))
     # Does NOT include keys for:
     # - Inputs to the graph itself
     # - Inputs to nodes within sub-graphs of the graph
-    _node_input_source_assets: Mapping[str, Mapping[str, "SourceAsset"]]
+    _input_assets: Mapping[str, Mapping[str, "AssetsDefinition"]]
 
     def __init__(
         self,
         name: str,
         *,
         description: Optional[str] = None,
         node_defs: Optional[Sequence[NodeDefinition]] = None,
         dependencies: Optional[
             Union[DependencyMapping[str], DependencyMapping[NodeInvocation]]
         ] = None,
         input_mappings: Optional[Sequence[InputMapping]] = None,
         output_mappings: Optional[Sequence[OutputMapping]] = None,
         config: Optional[ConfigMapping] = None,
-        tags: Optional[Mapping[str, str]] = None,
+        tags: Union[NormalizedTags, Optional[Mapping[str, str]]] = None,
         node_input_source_assets: Optional[Mapping[str, Mapping[str, "SourceAsset"]]] = None,
+        input_assets: Optional[
+            Mapping[str, Mapping[str, Union["AssetsDefinition", "SourceAsset"]]]
+        ] = None,
         **kwargs: Any,
     ):
+        from .external_asset import create_external_asset_from_source_asset
+        from .source_asset import SourceAsset
+
         self._node_defs = _check_node_defs_arg(name, node_defs)
 
         # `dependencies` will be converted to `dependency_structure` and `node_dict`, which may
         # alternatively be passed directly (useful when copying)
         self._dependencies = normalize_dependency_dict(dependencies)
         self._dependency_structure, self._node_dict = create_execution_structure(
             self._node_defs, self._dependencies, graph_definition=self
@@ -242,17 +256,39 @@
             **kwargs,
         )
 
         # must happen after base class construction as properties are assumed to be there
         # eager computation to detect cycles
         self._nodes_in_topological_order = self._get_nodes_in_topological_order()
         self._dagster_type_dict = construct_dagster_type_dictionary([self])
-        self._node_input_source_assets = check.opt_mapping_param(
-            node_input_source_assets, "node_input_source_assets", key_type=str, value_type=dict
+
+        # Backcompat: the previous  API `node_input_source_assets` with a Dict[str, Dict[str,
+        # SourceAsset]]. The new API is `input_assets` and accepts external assets as well as
+        # SourceAsset.
+        self._input_assets = {}
+        input_assets = check.opt_mapping_param(
+            normalize_renamed_param(
+                new_val=input_assets,
+                new_arg="input_assets",
+                old_val=node_input_source_assets,
+                old_arg="node_input_source_assets",
+            ),
+            "input_assets",
+            key_type=str,
+            value_type=dict,
         )
+        for node_name, inputs in input_assets.items():
+            self._input_assets[node_name] = {
+                input_name: (
+                    create_external_asset_from_source_asset(asset)
+                    if isinstance(asset, SourceAsset)
+                    else asset
+                )
+                for input_name, asset in inputs.items()
+            }
 
     def _get_nodes_in_topological_order(self) -> Sequence[Node]:
         _forward_edges, backward_edges = create_adjacency_lists(
             self.nodes, self.dependency_structure
         )
 
         try:
@@ -308,16 +344,16 @@
         return self._node_defs
 
     @property
     def nodes_in_topological_order(self) -> Sequence[Node]:
         return self._nodes_in_topological_order
 
     @property
-    def node_input_source_assets(self) -> Mapping[str, Mapping[str, "SourceAsset"]]:
-        return self._node_input_source_assets
+    def input_assets(self) -> Mapping[str, Mapping[str, "AssetsDefinition"]]:
+        return self._input_assets
 
     def has_node_named(self, name: str) -> bool:
         check.str_param(name, "name")
         return name in self._node_dict
 
     def node_named(self, name: str) -> Node:
         check.str_param(name, "name")
@@ -508,26 +544,26 @@
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
         input_mappings: Optional[Sequence[InputMapping]] = None,
         output_mappings: Optional[Sequence[OutputMapping]] = None,
         config: Optional[ConfigMapping] = None,
         tags: Optional[Mapping[str, str]] = None,
-        node_input_source_assets: Optional[Mapping[str, Mapping[str, "SourceAsset"]]] = None,
+        input_assets: Optional[Mapping[str, Mapping[str, "AssetsDefinition"]]] = None,
     ) -> Self:
         return self.__class__(
             node_defs=self.node_defs,
             dependencies=self.dependencies,
             name=name or self.name,
             description=description or self.description,
             input_mappings=input_mappings or self._input_mappings,
             output_mappings=output_mappings or self._output_mappings,
             config=config or self.config_mapping,
             tags=tags or self.tags,
-            node_input_source_assets=node_input_source_assets or self.node_input_source_assets,
+            input_assets=input_assets or self._input_assets,
         )
 
     def copy_for_configured(
         self,
         name: str,
         description: Optional[str],
         config_schema: Any,
@@ -557,15 +593,15 @@
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
         resource_defs: Optional[Mapping[str, object]] = None,
         config: Optional[
             Union["RunConfig", ConfigMapping, Mapping[str, object], "PartitionedConfig"]
         ] = None,
-        tags: Optional[Mapping[str, str]] = None,
+        tags: Union[NormalizedTags, Optional[Mapping[str, str]]] = None,
         metadata: Optional[Mapping[str, RawMetadataValue]] = None,
         logger_defs: Optional[Mapping[str, LoggerDefinition]] = None,
         executor_def: Optional["ExecutorDefinition"] = None,
         hooks: Optional[AbstractSet[HookDefinition]] = None,
         op_retry_policy: Optional[RetryPolicy] = None,
         version_strategy: Optional[VersionStrategy] = None,
         op_selection: Optional[Sequence[str]] = None,
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/hook_definition.py` & `dagster-1.7.0/dagster/_core/definitions/hook_definition.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/hook_invocation.py` & `dagster-1.7.0/dagster/_core/definitions/hook_invocation.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/inference.py` & `dagster-1.7.0/dagster/_core/definitions/inference.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/input.py` & `dagster-1.7.0/dagster/_core/definitions/input.py`

 * *Files 1% similar despite different names*

```diff
@@ -110,15 +110,15 @@
         asset_partitions: Optional[Union[Set[str], Callable[["InputContext"], Set[str]]]] = None,
         input_manager_key: Optional[str] = None,
         # when adding new params, make sure to update combine_with_inferred and with_dagster_type below
     ):
         self._name = check_valid_name(name, allow_list=["config"])
 
         self._type_not_set = dagster_type is None
-        self._dagster_type = check.inst(resolve_dagster_type(dagster_type), DagsterType)
+        self._dagster_type = resolve_dagster_type(dagster_type)
 
         self._description = check.opt_str_param(description, "description")
 
         self._default_value = _check_default_value(self._name, self._dagster_type, default_value)
 
         self._input_manager_key = check.opt_str_param(input_manager_key, "input_manager_key")
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/instigation_logger.py` & `dagster-1.7.0/dagster/_core/definitions/instigation_logger.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/job_base.py` & `dagster-1.7.0/dagster/_core/definitions/job_base.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/job_definition.py` & `dagster-1.7.0/dagster/_core/definitions/job_definition.py`

 * *Files 3% similar despite different names*

```diff
@@ -21,14 +21,15 @@
 
 import dagster._check as check
 from dagster._annotations import deprecated, experimental_param, public
 from dagster._config import Field, Shape, StringSource
 from dagster._config.config_type import ConfigType
 from dagster._config.validate import validate_config
 from dagster._core.definitions.asset_check_spec import AssetCheckKey
+from dagster._core.definitions.asset_selection import AssetSelection
 from dagster._core.definitions.dependency import (
     Node,
     NodeHandle,
     NodeInputHandle,
     NodeInvocation,
 )
 from dagster._core.definitions.events import AssetKey
@@ -60,39 +61,40 @@
 )
 from dagster._core.storage.tags import MEMOIZED_RUN_TAG
 from dagster._core.types.dagster_type import DagsterType
 from dagster._core.utils import str_format_set
 from dagster._utils import IHasInternalInit
 from dagster._utils.merger import merge_dicts
 
-from .asset_layer import AssetLayer, build_asset_selection_job
+from .asset_layer import AssetLayer
 from .config import ConfigMapping
 from .dependency import (
     DependencyMapping,
     DependencyStructure,
     OpNode,
 )
 from .executor_definition import ExecutorDefinition, multi_or_in_process_executor
 from .graph_definition import GraphDefinition, SubselectedGraphDefinition
 from .hook_definition import HookDefinition
 from .logger_definition import LoggerDefinition
 from .metadata import MetadataValue, RawMetadataValue, normalize_metadata
 from .partition import PartitionedConfig, PartitionsDefinition
 from .resource_definition import ResourceDefinition
 from .run_request import RunRequest
-from .utils import DEFAULT_IO_MANAGER_KEY, validate_tags
+from .utils import DEFAULT_IO_MANAGER_KEY, NormalizedTags, normalize_tags
 from .version_strategy import VersionStrategy
 
 if TYPE_CHECKING:
     from dagster._config.snap import ConfigSchemaSnapshot
+    from dagster._core.definitions.assets import AssetsDefinition
     from dagster._core.definitions.run_config import RunConfig
     from dagster._core.execution.execute_in_process_result import ExecuteInProcessResult
     from dagster._core.execution.resources_init import InitResourceContext
-    from dagster._core.host_representation.job_index import JobIndex
     from dagster._core.instance import DagsterInstance, DynamicPartitionsStore
+    from dagster._core.remote_representation.job_index import JobIndex
     from dagster._core.snap import JobSnapshot
 
     from .run_config_schema import RunConfigSchema
 
 DEFAULT_EXECUTOR_DEF = multi_or_in_process_executor
 
 
@@ -125,15 +127,15 @@
         logger_defs: Optional[Mapping[str, LoggerDefinition]] = None,
         name: Optional[str] = None,
         config: Optional[
             Union[ConfigMapping, Mapping[str, object], PartitionedConfig, "RunConfig"]
         ] = None,
         description: Optional[str] = None,
         partitions_def: Optional[PartitionsDefinition] = None,
-        tags: Optional[Mapping[str, Any]] = None,
+        tags: Union[NormalizedTags, Optional[Mapping[str, Any]]] = None,
         metadata: Optional[Mapping[str, RawMetadataValue]] = None,
         hook_defs: Optional[AbstractSet[HookDefinition]] = None,
         op_retry_policy: Optional[RetryPolicy] = None,
         version_strategy: Optional[VersionStrategy] = None,
         _subset_selection_data: Optional[Union[OpSelectionData, AssetSelectionData]] = None,
         asset_layer: Optional[AssetLayer] = None,
         input_values: Optional[Mapping[str, object]] = None,
@@ -168,15 +170,15 @@
 
         partitions_def = check.opt_inst_param(
             partitions_def, "partitions_def", PartitionsDefinition
         )
         # tags and description can exist on graph as well, but since
         # same graph may be in multiple jobs, keep separate layer
         self._description = check.opt_str_param(description, "description")
-        self._tags = validate_tags(tags)
+        self._tags = normalize_tags(tags).tags
         self._metadata = normalize_metadata(
             check.opt_mapping_param(metadata, "metadata", key_type=str)
         )
         self._hook_defs = check.opt_set_param(hook_defs, "hook_defs")
         self._op_retry_policy = check.opt_inst_param(
             op_retry_policy, "op_retry_policy", RetryPolicy
         )
@@ -260,15 +262,15 @@
         logger_defs: Optional[Mapping[str, LoggerDefinition]],
         name: Optional[str],
         config: Optional[
             Union[ConfigMapping, Mapping[str, object], PartitionedConfig, "RunConfig"]
         ],
         description: Optional[str],
         partitions_def: Optional[PartitionsDefinition],
-        tags: Optional[Mapping[str, Any]],
+        tags: Union[NormalizedTags, Optional[Mapping[str, Any]]],
         metadata: Optional[Mapping[str, RawMetadataValue]],
         hook_defs: Optional[AbstractSet[HookDefinition]],
         op_retry_policy: Optional[RetryPolicy],
         version_strategy: Optional[VersionStrategy],
         _subset_selection_data: Optional[Union[OpSelectionData, AssetSelectionData]],
         asset_layer: Optional[AssetLayer],
         input_values: Optional[Mapping[str, object]],
@@ -752,88 +754,51 @@
             "op_selection cannot be provided with asset_selection or asset_check_selection to"
             " execute_in_process",
         )
         if op_selection:
             return self._get_job_def_for_op_selection(op_selection)
         if asset_selection or asset_check_selection:
             return self._get_job_def_for_asset_selection(
-                asset_selection=asset_selection, asset_check_selection=asset_check_selection
+                AssetSelectionData(
+                    asset_selection=asset_selection,
+                    asset_check_selection=asset_check_selection,
+                    parent_job_def=self,
+                )
             )
         else:
             return self
 
     def _get_job_def_for_asset_selection(
-        self,
-        asset_selection: Optional[AbstractSet[AssetKey]] = None,
-        asset_check_selection: Optional[AbstractSet[AssetCheckKey]] = None,
+        self, selection_data: AssetSelectionData
     ) -> "JobDefinition":
-        asset_selection = check.opt_set_param(asset_selection, "asset_selection", AssetKey)
-        check.opt_set_param(asset_check_selection, "asset_check_selection", AssetCheckKey)
+        from dagster._core.definitions.asset_job import (
+            build_asset_job,
+            get_asset_graph_for_job,
+        )
 
-        nonexistent_assets = [
-            asset
-            for asset in asset_selection
-            if asset not in self.asset_layer.asset_keys
-            and asset not in self.asset_layer.source_assets_by_key
-        ]
-        nonexistent_asset_strings = [
-            asset_str
-            for asset_str in (asset.to_string() for asset in nonexistent_assets)
-            if asset_str
-        ]
-        if nonexistent_assets:
-            raise DagsterInvalidSubsetError(
-                "Assets provided in asset_selection argument "
-                f"{', '.join(nonexistent_asset_strings)} do not exist in parent asset group or job."
+        # If a non-null check selection is provided, use that. Otherwise the selection will resolve
+        # to all checks matching a selected asset by default.
+        selection = AssetSelection.assets(*selection_data.asset_selection)
+        if selection_data.asset_check_selection is not None:
+            selection = selection.without_checks() | AssetSelection.checks(
+                *selection_data.asset_check_selection
             )
 
-        # Test that selected asset checks exist
-        all_check_keys = self.asset_layer.node_output_handles_by_asset_check_key.keys()
+        job_asset_graph = get_asset_graph_for_job(self.asset_layer.asset_graph, selection)
 
-        nonexistent_asset_checks = [
-            asset_check
-            for asset_check in asset_check_selection or set()
-            if asset_check not in all_check_keys
-        ]
-        nonexistent_asset_check_strings = [
-            str(asset_check) for asset_check in nonexistent_asset_checks
-        ]
-        if nonexistent_asset_checks:
-            raise DagsterInvalidSubsetError(
-                "Asset checks provided in asset_check_selection argument"
-                f" {', '.join(nonexistent_asset_check_strings)} do not exist in parent asset group"
-                " or job."
-            )
-
-        asset_selection_data = AssetSelectionData(
-            asset_selection=asset_selection,
-            asset_check_selection=asset_check_selection,
-            parent_job_def=self,
-        )
-
-        check.invariant(
-            self.asset_layer.assets_defs_by_key is not None,
-            "Asset layer must have _asset_defs argument defined",
-        )
-
-        new_job = build_asset_selection_job(
+        return build_asset_job(
             name=self.name,
-            assets=set(self.asset_layer.assets_defs_by_key.values()),
-            source_assets=self.asset_layer.source_assets_by_key.values(),
+            asset_graph=job_asset_graph,
             executor_def=self.executor_def,
             resource_defs=self.resource_defs,
             description=self.description,
             tags=self.tags,
-            asset_selection=asset_selection,
-            asset_check_selection=asset_check_selection,
-            asset_selection_data=asset_selection_data,
             config=self.config_mapping or self.partitioned_config,
-            asset_checks=self.asset_layer.asset_checks_defs,
+            _asset_selection_data=selection_data,
         )
-        return new_job
 
     def _get_job_def_for_op_selection(self, op_selection: Iterable[str]) -> "JobDefinition":
         try:
             sub_graph = get_graph_subset(self.graph, op_selection)
 
             # if explicit config was passed the config_mapping that resolves the defaults implicitly is
             # very unlikely to work. The job will still present the default config in the Dagster UI.
@@ -950,15 +915,15 @@
     def get_config_schema_snapshot(self) -> "ConfigSchemaSnapshot":
         return self.get_job_snapshot().config_schema_snapshot
 
     def get_job_snapshot(self) -> "JobSnapshot":
         return self.get_job_index().job_snapshot
 
     def get_job_index(self) -> "JobIndex":
-        from dagster._core.host_representation import JobIndex
+        from dagster._core.remote_representation import JobIndex
         from dagster._core.snap import JobSnapshot
 
         return JobIndex(JobSnapshot.from_job_def(self), self.get_parent_job_snapshot())
 
     def get_job_snapshot_id(self) -> str:
         return self.get_job_index().job_snapshot_id
 
@@ -1212,79 +1177,73 @@
         logger_defs=logger_defs,
         asset_layer=asset_layer,
         _was_explicitly_provided_resources=was_explicitly_provided_resources,
     ).run_config_schema.run_config_schema_type
 
 
 def _infer_asset_layer_from_source_asset_deps(job_graph_def: GraphDefinition) -> AssetLayer:
-    """For non-asset jobs that have some inputs that are fed from SourceAssets, constructs an
-    AssetLayer that includes those SourceAssets.
+    """For non-asset jobs that have some inputs that are fed from assets, constructs an
+    AssetLayer that includes these assets as loadables.
     """
+    from dagster._core.definitions.asset_graph import (
+        AssetGraph,
+    )
+
     asset_keys_by_node_input_handle: Dict[NodeInputHandle, AssetKey] = {}
-    source_assets_list = []
-    source_asset_keys_set = set()
-    io_manager_keys_by_asset_key: Mapping[AssetKey, str] = {}
+    all_input_assets: List[AssetsDefinition] = []
+    input_asset_keys: Set[AssetKey] = set()
 
     # each entry is a graph definition and its handle relative to the job root
     stack: List[Tuple[GraphDefinition, Optional[NodeHandle]]] = [(job_graph_def, None)]
 
     while stack:
         graph_def, parent_node_handle = stack.pop()
 
-        for node_name, input_source_assets in graph_def.node_input_source_assets.items():
+        for node_name, input_assets in graph_def.input_assets.items():
             node_handle = NodeHandle(node_name, parent_node_handle)
-            for input_name, source_asset in input_source_assets.items():
-                if source_asset.key not in source_asset_keys_set:
-                    source_asset_keys_set.add(source_asset.key)
-                    source_assets_list.append(source_asset)
+            for input_name, assets_def in input_assets.items():
+                if assets_def.key not in input_asset_keys:
+                    input_asset_keys.add(assets_def.key)
+                    all_input_assets.append(assets_def)
 
                 input_handle = NodeInputHandle(node_handle, input_name)
-                asset_keys_by_node_input_handle[input_handle] = source_asset.key
+                asset_keys_by_node_input_handle[input_handle] = assets_def.key
                 for resolved_input_handle in graph_def.node_dict[
                     node_name
                 ].definition.resolve_input_to_destinations(input_handle):
-                    asset_keys_by_node_input_handle[resolved_input_handle] = source_asset.key
-
-                if source_asset.io_manager_key:
-                    io_manager_keys_by_asset_key[source_asset.key] = source_asset.io_manager_key
+                    asset_keys_by_node_input_handle[resolved_input_handle] = assets_def.key
 
         for node_name, node in graph_def.node_dict.items():
             if isinstance(node.definition, GraphDefinition):
                 stack.append((node.definition, NodeHandle(node_name, parent_node_handle)))
 
     return AssetLayer(
+        asset_graph=AssetGraph.from_assets(all_input_assets),
         assets_defs_by_node_handle={},
         asset_keys_by_node_input_handle=asset_keys_by_node_input_handle,
         asset_info_by_node_output_handle={},
         asset_deps={},
         dependency_node_handles_by_asset_key={},
-        assets_defs_by_key={},
-        source_assets_by_key={
-            source_asset.key: source_asset for source_asset in source_assets_list
-        },
-        io_manager_keys_by_asset_key=io_manager_keys_by_asset_key,
         dep_asset_keys_by_node_output_handle={},
         partition_mappings_by_asset_dep={},
-        asset_checks_defs_by_node_handle={},
         node_output_handles_by_asset_check_key={},
         check_names_by_asset_key_by_node_handle={},
         check_key_by_node_output_handle={},
+        assets_defs_by_check_key={},
     )
 
 
 def _build_all_node_defs(node_defs: Sequence[NodeDefinition]) -> Mapping[str, NodeDefinition]:
     all_defs: Dict[str, NodeDefinition] = {}
     for current_level_node_def in node_defs:
         for node_def in current_level_node_def.iterate_node_defs():
             if node_def.name in all_defs:
                 if all_defs[node_def.name] != node_def:
                     raise DagsterInvalidDefinitionError(
-                        'Detected conflicting node definitions with the same name "{name}"'.format(
-                            name=node_def.name
-                        )
+                        f'Detected conflicting node definitions with the same name "{node_def.name}"'
                     )
             else:
                 all_defs[node_def.name] = node_def
 
     return all_defs
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/load_asset_checks_from_modules.py` & `dagster-1.7.0/dagster/_core/definitions/load_asset_checks_from_modules.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,42 +1,46 @@
 import inspect
 from importlib import import_module
 from types import ModuleType
-from typing import Iterable, Optional, Sequence
+from typing import Iterable, Optional, Sequence, cast
 
 import dagster._check as check
+from dagster._core.definitions.assets import AssetsDefinition
 
-from .asset_checks import AssetChecksDefinition
-from .events import (
+from .asset_checks import AssetChecksDefinition, has_only_asset_checks
+from .asset_key import (
     CoercibleToAssetKeyPrefix,
     check_opt_coercible_to_asset_key_prefix_param,
 )
-from .load_assets_from_modules import find_modules_in_package, find_objects_in_module_of_types
+from .load_assets_from_modules import (
+    find_modules_in_package,
+    find_objects_in_module_of_types,
+    prefix_assets,
+)
 
 
 def _checks_from_modules(modules: Iterable[ModuleType]) -> Sequence[AssetChecksDefinition]:
     checks = []
     for module in modules:
-        for c in find_objects_in_module_of_types(module, AssetChecksDefinition):
-            checks.append(c)
+        for c in find_objects_in_module_of_types(module, AssetsDefinition):
+            if has_only_asset_checks(c):
+                checks.append(cast(AssetChecksDefinition, c))
     return checks
 
 
 def _checks_with_attributes(
     checks_defs: Sequence[AssetChecksDefinition],
     asset_key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
 ) -> Sequence[AssetChecksDefinition]:
     modified_checks = []
-    for c in checks_defs:
-        modified_checks.append(
-            c.with_attributes(
-                asset_key_prefix=asset_key_prefix,
-            )
-        )
-    return modified_checks
+    if asset_key_prefix:
+        modified_checks, _ = prefix_assets(checks_defs, asset_key_prefix, [], None)
+        return cast(Sequence[AssetChecksDefinition], modified_checks)
+    else:
+        return checks_defs
 
 
 def load_asset_checks_from_modules(
     modules: Iterable[ModuleType],
     asset_key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
 ) -> Sequence[AssetChecksDefinition]:
     """Constructs a list of asset checks from the given modules. This is most often used in
@@ -51,15 +55,14 @@
     Returns:
         Sequence[AssetChecksDefinition]:
             A list containing asset checks defined in the given modules.
     """
     asset_key_prefix = check_opt_coercible_to_asset_key_prefix_param(
         asset_key_prefix, "asset_key_prefix"
     )
-
     return _checks_with_attributes(_checks_from_modules(modules), asset_key_prefix=asset_key_prefix)
 
 
 def load_asset_checks_from_current_module(
     asset_key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
 ) -> Sequence[AssetChecksDefinition]:
     """Constructs a list of asset checks from the module where this function is called. This is most
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/load_assets_from_modules.py` & `dagster-1.7.0/dagster/_core/definitions/load_assets_from_modules.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 import inspect
-import os
 import pkgutil
 from importlib import import_module
 from types import ModuleType
 from typing import (
     Dict,
     Iterable,
     Iterator,
@@ -18,21 +17,21 @@
 
 import dagster._check as check
 from dagster._core.definitions.auto_materialize_policy import AutoMaterializePolicy
 from dagster._core.definitions.backfill_policy import BackfillPolicy
 from dagster._core.definitions.freshness_policy import FreshnessPolicy
 from dagster._core.errors import DagsterInvalidDefinitionError
 
-from .assets import AssetsDefinition
-from .cacheable_assets import CacheableAssetsDefinition
-from .events import (
+from .asset_key import (
     AssetKey,
     CoercibleToAssetKeyPrefix,
     check_opt_coercible_to_asset_key_prefix_param,
 )
+from .assets import AssetsDefinition
+from .cacheable_assets import CacheableAssetsDefinition
 from .source_asset import SourceAsset
 
 
 def find_objects_in_module_of_types(module: ModuleType, types) -> Iterator:
     """Yields objects of the given type(s)."""
     for attr in dir(module):
         value = getattr(module, attr)
@@ -336,18 +335,19 @@
         backfill_policy=backfill_policy,
         source_key_prefix=source_key_prefix,
     )
 
 
 def find_modules_in_package(package_module: ModuleType) -> Iterable[ModuleType]:
     yield package_module
-    package_path = package_module.__file__
-    if package_path:
-        for _, modname, is_pkg in pkgutil.walk_packages([os.path.dirname(package_path)]):
-            submodule = import_module(f"{package_module.__name__}.{modname}")
+    if package_module.__file__:
+        for _, modname, is_pkg in pkgutil.walk_packages(
+            package_module.__path__, prefix=package_module.__name__ + "."
+        ):
+            submodule = import_module(modname)
             if is_pkg:
                 yield from find_modules_in_package(submodule)
             else:
                 yield submodule
     else:
         raise ValueError(
             f"Tried to find modules in package {package_module}, but its __file__ is None"
@@ -392,28 +392,31 @@
             result = prefixed_asset_key_replacements([asset1, asset2], "my_prefix")
             assert result.assets[0].asset_key == AssetKey(["my_prefix", "asset1"])
             assert result.assets[1].asset_key == AssetKey(["my_prefix", "asset2"])
             assert result.assets[1].dependency_keys == {AssetKey(["my_prefix", "asset1"])}
 
     """
     asset_keys = {asset_key for assets_def in assets_defs for asset_key in assets_def.keys}
+    check_target_keys = {
+        key.asset_key for assets_def in assets_defs for key in assets_def.check_keys
+    }
     source_asset_keys = {source_asset.key for source_asset in source_assets}
 
     if isinstance(key_prefix, str):
         key_prefix = [key_prefix]
     key_prefix = check.is_list(key_prefix, of_type=str)
 
     result_assets: List[AssetsDefinition] = []
     for assets_def in assets_defs:
         output_asset_key_replacements = {
             asset_key: AssetKey([*key_prefix, *asset_key.path]) for asset_key in assets_def.keys
         }
         input_asset_key_replacements = {}
-        for dep_asset_key in assets_def.dependency_keys:
-            if dep_asset_key in asset_keys:
+        for dep_asset_key in assets_def.keys_by_input_name.values():
+            if dep_asset_key in asset_keys or dep_asset_key in check_target_keys:
                 input_asset_key_replacements[dep_asset_key] = AssetKey(
                     [*key_prefix, *dep_asset_key.path]
                 )
             elif source_key_prefix and dep_asset_key in source_asset_keys:
                 input_asset_key_replacements[dep_asset_key] = AssetKey(
                     [*source_key_prefix, *dep_asset_key.path]
                 )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/logger_definition.py` & `dagster-1.7.0/dagster/_core/definitions/logger_definition.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/logger_invocation.py` & `dagster-1.7.0/dagster/_core/definitions/logger_invocation.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/materialize.py` & `dagster-1.7.0/dagster/_core/definitions/materialize.py`

 * *Files 0% similar despite different names*

```diff
@@ -96,14 +96,18 @@
             all_executable_keys = all_executable_keys.union(set(asset.keys))
 
     defs = Definitions(
         jobs=[define_asset_job(name=EPHEMERAL_JOB_NAME, selection=selection)],
         assets=assets,
         resources=resources,
     )
+
+    # validate input asset graph and resources
+    defs.get_all_job_defs()
+
     return check.not_none(
         defs.get_job_def(EPHEMERAL_JOB_NAME),
         "This should always return a job",
     ).execute_in_process(
         run_config=run_config,
         instance=instance,
         partition_key=partition_key,
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/metadata/__init__.py` & `dagster-1.7.0/dagster/_core/definitions/metadata/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,29 +1,33 @@
 import os
 from abc import ABC, abstractmethod
+from datetime import datetime
 from typing import (
-    TYPE_CHECKING,
+    AbstractSet,
     Any,
     Callable,
     Dict,
     Generic,
     List,
     Mapping,
     NamedTuple,
     Optional,
     Sequence,
+    Type,
     Union,
     cast,
 )
 
+from pydantic import BaseModel
 from typing_extensions import Self, TypeAlias, TypeVar
 
 import dagster._check as check
 import dagster._seven as seven
 from dagster._annotations import PublicAttr, deprecated, deprecated_param, experimental, public
+from dagster._core.definitions.asset_key import AssetKey
 from dagster._core.errors import DagsterInvalidMetadata
 from dagster._serdes import whitelist_for_serdes
 from dagster._serdes.serdes import (
     FieldSerializer,
     PackableValue,
     UnpackContext,
     WhitelistMap,
@@ -33,34 +37,34 @@
     deprecation_warning,
     normalize_renamed_param,
 )
 
 from .table import (  # re-exported
     TableColumn as TableColumn,
     TableColumnConstraints as TableColumnConstraints,
+    TableColumnDep as TableColumnDep,
+    TableColumnLineage as TableColumnLineage,
     TableConstraints as TableConstraints,
     TableRecord as TableRecord,
     TableSchema as TableSchema,
 )
 
-if TYPE_CHECKING:
-    from dagster._core.definitions.events import AssetKey
-
 ArbitraryMetadataMapping: TypeAlias = Mapping[str, Any]
 
 RawMetadataValue = Union[
     "MetadataValue",
     TableSchema,
-    "AssetKey",
+    AssetKey,
     os.PathLike,
     Dict[Any, Any],
     float,
     int,
     List[Any],
     str,
+    datetime,
     None,
 ]
 
 MetadataMapping: TypeAlias = Mapping[str, "MetadataValue"]
 RawMetadataMapping: TypeAlias = Mapping[str, RawMetadataValue]
 
 T_Packable = TypeVar("T_Packable", bound=PackableValue, default=PackableValue, covariant=True)
@@ -100,17 +104,19 @@
                     f'Could not resolve the metadata value for "{k}" to a known type. {e}'
                 ) from None
         normalized_metadata[k] = normalized_value
 
     return normalized_metadata
 
 
-def normalize_metadata_value(raw_value: RawMetadataValue) -> "MetadataValue[Any]":
-    from dagster._core.definitions.events import AssetKey
+def has_corresponding_metadata_value_class(obj: Any) -> bool:
+    return isinstance(obj, (str, float, bool, int, list, dict, os.PathLike, AssetKey, TableSchema))
+
 
+def normalize_metadata_value(raw_value: RawMetadataValue) -> "MetadataValue[Any]":
     if isinstance(raw_value, MetadataValue):
         return raw_value
     elif isinstance(raw_value, str):
         return MetadataValue.text(raw_value)
     elif isinstance(raw_value, float):
         return MetadataValue.float(raw_value)
     elif isinstance(raw_value, bool):
@@ -121,14 +127,16 @@
         return MetadataValue.json(raw_value)
     elif isinstance(raw_value, os.PathLike):
         return MetadataValue.path(raw_value)
     elif isinstance(raw_value, AssetKey):
         return MetadataValue.asset(raw_value)
     elif isinstance(raw_value, TableSchema):
         return MetadataValue.table_schema(raw_value)
+    elif isinstance(raw_value, TableColumnLineage):
+        return MetadataValue.column_lineage(raw_value)
     elif raw_value is None:
         return MetadataValue.null()
 
     raise DagsterInvalidMetadata(
         f"Its type was {type(raw_value)}. Consider wrapping the value with the appropriate "
         "MetadataValue type."
     )
@@ -404,14 +412,38 @@
         Args:
             value (bool): The bool value for a metadata entry.
         """
         return BoolMetadataValue(value)
 
     @public
     @staticmethod
+    def timestamp(value: Union["float", datetime]) -> "TimestampMetadataValue":
+        """Static constructor for a metadata value wrapping a UNIX timestamp as a
+        :py:class:`TimestampMetadataValue`. Can be used as the value type for the `metadata`
+        parameter for supported events.
+
+        Args:
+            value (Union[float, datetime]): The unix timestamp value for a metadata entry. If a
+                datetime is provided, the timestamp will be extracted. datetimes without timezones
+                are not accepted, because their timestamps can be ambiguous.
+        """
+        if isinstance(value, float):
+            return TimestampMetadataValue(value)
+        elif isinstance(value, datetime):
+            if value.tzinfo is None:
+                check.failed(
+                    "Datetime values provided to MetadataValue.timestamp must have timezones, "
+                    f"but {value.isoformat()} does not"
+                )
+            return TimestampMetadataValue(value.timestamp())
+        else:
+            check.failed(f"Expected either a float or a datetime, but received a {type(value)}")
+
+    @public
+    @staticmethod
     def dagster_run(run_id: str) -> "DagsterRunMetadataValue":
         """Static constructor for a metadata value wrapping a reference to a Dagster run.
 
         Args:
             run_id (str): The ID of the run.
         """
         return DagsterRunMetadataValue(run_id)
@@ -543,14 +575,28 @@
         Args:
             schema (TableSchema): The table schema for a metadata entry.
         """
         return TableSchemaMetadataValue(schema)
 
     @public
     @staticmethod
+    def column_lineage(
+        lineage: TableColumnLineage,
+    ) -> "TableColumnLineageMetadataValue":
+        """Static constructor for a metadata value wrapping a column lineage as
+        :py:class:`TableColumnLineageMetadataValue`. Can be used as the value type
+        for the `metadata` parameter for supported events.
+
+        Args:
+            lineage (TableColumnLineage): The column lineage for a metadata entry.
+        """
+        return TableColumnLineageMetadataValue(lineage)
+
+    @public
+    @staticmethod
     def null() -> "NullMetadataValue":
         """Static constructor for a metadata value representing null. Can be used as the value type
         for the `metadata` parameter for supported events.
         """
         return NullMetadataValue()
 
 
@@ -808,14 +854,32 @@
         value (Optional[bool]): The bool value.
     """
 
     def __new__(cls, value: Optional[bool]):
         return super(BoolMetadataValue, cls).__new__(cls, check.opt_bool_param(value, "value"))
 
 
+@whitelist_for_serdes
+class TimestampMetadataValue(
+    NamedTuple(
+        "_DateTimeMetadataValue",
+        [("value", PublicAttr[float])],
+    ),
+    MetadataValue[float],
+):
+    """Container class for metadata value that's a unix timestamp.
+
+    Args:
+        value (float): Seconds since the unix epoch.
+    """
+
+    def __new__(cls, value: float):
+        return super(TimestampMetadataValue, cls).__new__(cls, check.float_param(value, "value"))
+
+
 @whitelist_for_serdes(storage_name="DagsterPipelineRunMetadataEntryData")
 class DagsterRunMetadataValue(
     NamedTuple(
         "_DagsterRunMetadataValue",
         [
             ("run_id", PublicAttr[str]),
         ],
@@ -1000,14 +1064,40 @@
     @public
     @property
     def value(self) -> TableSchema:
         """TableSchema: The wrapped :py:class:`TableSchema`."""
         return self.schema
 
 
+@whitelist_for_serdes
+class TableColumnLineageMetadataValue(
+    NamedTuple(
+        "_TableColumnLineageMetadataValue", [("column_lineage", PublicAttr[TableColumnLineage])]
+    ),
+    MetadataValue[TableColumnLineage],
+):
+    """Representation of the lineage of column inputs to column outputs of arbitrary tabular data.
+
+    Args:
+        column_lineage (TableColumnLineage): The lineage of column inputs to column outputs
+            for the table.
+    """
+
+    def __new__(cls, column_lineage: TableColumnLineage):
+        return super(TableColumnLineageMetadataValue, cls).__new__(
+            cls, check.inst_param(column_lineage, "column_lineage", TableColumnLineage)
+        )
+
+    @public
+    @property
+    def value(self) -> TableColumnLineage:
+        """TableSpec: The wrapped :py:class:`TableSpec`."""
+        return self.column_lineage
+
+
 @whitelist_for_serdes(storage_name="NullMetadataEntryData")
 class NullMetadataValue(NamedTuple("_NullMetadataValue", []), MetadataValue[None]):
     """Representation of null."""
 
     @public
     @property
     def value(self) -> None:
@@ -1125,7 +1215,100 @@
             check.inst_param(value, "value", MetadataValue),
         )
 
     @property
     def value(self):
         """Alias of `entry_data`."""
         return self.entry_data
+
+
+T_NamespacedMetadataEntries = TypeVar(
+    "T_NamespacedMetadataEntries", bound="NamespacedMetadataEntries"
+)
+
+
+class NamespacedMetadataEntries(ABC, BaseModel, frozen=True):
+    """Extend this class to define a set of metadata fields in the same namespace.
+
+    Supports splatting to a dictionary that can be placed inside a metadata argument along with
+    other dictionary-structured metadata.
+
+    .. code-block:: python
+
+        my_metadata: NamespacedMetadataEntries = ...
+        return MaterializeResult(metadata={**my_metadata, ...})
+    """
+
+    @classmethod
+    @abstractmethod
+    def namespace(cls) -> str:
+        raise NotImplementedError()
+
+    @classmethod
+    def _namespaced_key(cls, key: str) -> str:
+        return f"{cls.namespace()}/{key}"
+
+    @staticmethod
+    def _strip_namespace_from_key(key: str) -> str:
+        return key.split("/", 1)[1]
+
+    def keys(self) -> AbstractSet[str]:
+        return {
+            self._namespaced_key(key)
+            for key in self.__fields__.keys()
+            # getattr returns the pydantic property on the subclass
+            if getattr(self, key) is not None
+        }
+
+    def __getitem__(self, key: str) -> Any:
+        # getattr returns the pydantic property on the subclass
+        return getattr(self, self._strip_namespace_from_key(key))
+
+    @classmethod
+    def extract(
+        cls: Type[T_NamespacedMetadataEntries], metadata: Mapping[str, Any]
+    ) -> T_NamespacedMetadataEntries:
+        """Extracts entries from the provided metadata dictionary into an instance of this class.
+
+        Ignores any entries in the metadata dictionary whose keys don't correspond to fields on this
+        class.
+
+        In general, the following should always pass:
+
+        .. code-block:: python
+
+            class MyMetadataEntries(NamedspacedMetadataEntries):
+                ...
+
+            metadata_entries: MyMetadataEntries  = ...
+            assert MyMetadataEntries.extract(dict(metadata_entries)) == metadata_entries
+
+        Args:
+            metadata (Mapping[str, Any]): A dictionary of metadata entries.
+        """
+        kwargs = {}
+        for namespaced_key, value in metadata.items():
+            splits = namespaced_key.split("/")
+            if len(splits) == 2:
+                namespace, key = splits
+                if namespace == cls.namespace() and key in cls.__fields__:
+                    kwargs[key] = value.value if isinstance(value, MetadataValue) else value
+
+        return cls(**kwargs)
+
+
+class TableMetadataEntries(NamespacedMetadataEntries, frozen=True):
+    """Metadata entries that apply to definitions, observations, or materializations of assets that
+    are tables.
+
+    Args:
+        column_schema (Optional[TableSchema]): The schema of the columns in the table.
+        column_lineage (Optional[TableColumnLineage]): The lineage of column inputs to column
+            outputs for the table.
+    """
+
+    column_schema: Optional[TableSchema] = None
+    column_lineage: Optional[TableColumnLineage] = None
+
+    @classmethod
+    def namespace(cls) -> str:
+        return "dagster"
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/metadata/table.py` & `dagster-1.7.0/dagster/_core/definitions/metadata/table.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 from typing import Mapping, NamedTuple, Optional, Sequence, Union, cast
 
 import dagster._check as check
 from dagster._annotations import PublicAttr, experimental, public
+from dagster._core.definitions.asset_key import AssetKey
 from dagster._serdes.serdes import (
     whitelist_for_serdes,
 )
 
 # ########################
 # ##### TABLE RECORD
 # ########################
@@ -255,7 +256,67 @@
             nullable=check.bool_param(nullable, "nullable"),
             unique=check.bool_param(unique, "unique"),
             other=check.opt_sequence_param(other, "other"),
         )
 
 
 _DEFAULT_TABLE_COLUMN_CONSTRAINTS = TableColumnConstraints()
+
+
+# ###########################
+# ##### TABLE COLUMN LINEAGE
+# ###########################
+
+
+@whitelist_for_serdes
+class TableColumnDep(
+    NamedTuple(
+        "_TableColumnDep",
+        [
+            ("asset_key", PublicAttr[AssetKey]),
+            ("column_name", PublicAttr[str]),
+        ],
+    )
+):
+    """Object representing an identifier for a column in an asset."""
+
+    def __new__(
+        cls,
+        asset_key: AssetKey,
+        column_name: str,
+    ):
+        return super(TableColumnDep, cls).__new__(
+            cls,
+            asset_key=check.inst_param(asset_key, "asset_key", AssetKey),
+            column_name=check.str_param(column_name, "column_name"),
+        )
+
+
+@experimental
+@whitelist_for_serdes
+class TableColumnLineage(
+    NamedTuple(
+        "_TableSpec",
+        [
+            ("deps_by_column", PublicAttr[Mapping[str, Sequence[TableColumnDep]]]),
+        ],
+    )
+):
+    """Represents the lineage of column outputs to column inputs for a tabular asset."""
+
+    def __new__(cls, deps_by_column: Mapping[str, Sequence[TableColumnDep]]):
+        deps_by_column = check.mapping_param(
+            deps_by_column, "deps_by_column", key_type=str, value_type=list
+        )
+
+        sorted_deps_by_column = {}
+        for column, deps in deps_by_column.items():
+            sorted_deps_by_column[column] = sorted(
+                deps, key=lambda dep: (dep.asset_key, dep.column_name)
+            )
+
+            check.invariant(
+                len(deps) == len(set((dep.asset_key, dep.column_name) for dep in deps)),
+                f"The deps for column `{column}` must be unique by asset key and column name.",
+            )
+
+        return super(TableColumnLineage, cls).__new__(cls, deps_by_column=sorted_deps_by_column)
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/multi_asset_sensor_definition.py` & `dagster-1.7.0/dagster/_core/definitions/multi_asset_sensor_definition.py`

 * *Files 1% similar despite different names*

```diff
@@ -245,23 +245,26 @@
 
         self._repository_def = normalize_to_repository(
             check.opt_inst_param(definitions, "definitions", Definitions),
             check.opt_inst_param(repository_def, "repository_def", RepositoryDefinition),
         )
         self._monitored_asset_keys: Sequence[AssetKey]
         if isinstance(monitored_assets, AssetSelection):
-            repo_assets = self._repository_def.assets_defs_by_key.values()
+            repo_assets = self._repository_def.asset_graph.assets_defs
             self._monitored_asset_keys = list(monitored_assets.resolve(repo_assets))
         else:
             self._monitored_asset_keys = monitored_assets
 
         self._assets_by_key: Dict[AssetKey, Optional[AssetsDefinition]] = {}
         self._partitions_def_by_asset_key: Dict[AssetKey, Optional[PartitionsDefinition]] = {}
+        asset_graph = self._repository_def.asset_graph
         for asset_key in self._monitored_asset_keys:
-            assets_def = self._repository_def.assets_defs_by_key.get(asset_key)
+            assets_def = (
+                asset_graph.get(asset_key).assets_def if asset_graph.has(asset_key) else None
+            )
             self._assets_by_key[asset_key] = assets_def
 
             self._partitions_def_by_asset_key[asset_key] = (
                 assets_def.partitions_def if assets_def else None
             )
 
         # Cursor object with utility methods for updating and retrieving cursor information.
@@ -666,27 +669,26 @@
 
         return all([partition in materialized_partitions for partition in partitions])
 
     def _get_asset(self, asset_key: AssetKey, fn_name: str) -> AssetsDefinition:
         from dagster._core.definitions.repository_definition import RepositoryDefinition
 
         repo_def = cast(RepositoryDefinition, self._repository_def)
-        repository_assets = repo_def.assets_defs_by_key
         if asset_key in self._assets_by_key:
             asset_def = self._assets_by_key[asset_key]
             if asset_def is None:
                 raise DagsterInvalidInvocationError(
                     f"Asset key {asset_key} does not have an AssetDefinition in this repository"
                     f" (likely because it is a SourceAsset). fn context.{fn_name} can only be"
                     " called for assets with AssetDefinitions in the repository."
                 )
             else:
                 return asset_def
-        elif asset_key in repository_assets:
-            return repository_assets[asset_key]
+        elif repo_def.asset_graph.has(asset_key):
+            return repo_def.asset_graph.get(asset_key).assets_def
         else:
             raise DagsterInvalidInvocationError(
                 f"Asset key {asset_key} not monitored in sensor and does not exist in target jobs"
             )
 
     @public
     def get_downstream_partition_keys(
@@ -1028,17 +1030,15 @@
                 " instance."
             )
 
         asset_keys: Sequence[AssetKey]
         if isinstance(monitored_assets, AssetSelection):
             asset_keys = cast(
                 List[AssetKey],
-                list(
-                    monitored_assets.resolve(list(set(repository_def.assets_defs_by_key.values())))
-                ),
+                list(monitored_assets.resolve(list(set(repository_def.asset_graph.assets_defs)))),
             )
         else:
             asset_keys = monitored_assets
 
         cursor = get_cursor_from_latest_materializations(asset_keys, instance)
 
     return MultiAssetSensorEvaluationContext(
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/multi_dimensional_partitions.py` & `dagster-1.7.0/dagster/_core/definitions/multi_dimensional_partitions.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,14 +16,15 @@
     cast,
 )
 
 import pendulum
 
 import dagster._check as check
 from dagster._annotations import public
+from dagster._core.definitions.partition_key_range import PartitionKeyRange
 from dagster._core.errors import (
     DagsterInvalidDefinitionError,
     DagsterInvalidInvocationError,
     DagsterUnknownPartitionError,
 )
 from dagster._core.instance import DynamicPartitionsStore
 from dagster._core.storage.tags import (
@@ -215,14 +216,40 @@
             key=lambda x: x.name,
         )
 
     @property
     def partitions_subset_class(self) -> Type["PartitionsSubset"]:
         return DefaultPartitionsSubset
 
+    def get_partition_keys_in_range(
+        self,
+        partition_key_range: PartitionKeyRange,
+        dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
+    ) -> Sequence[str]:
+        start: MultiPartitionKey = self.get_partition_key_from_str(partition_key_range.start)
+        end: MultiPartitionKey = self.get_partition_key_from_str(partition_key_range.end)
+
+        partition_key_sequences = [
+            partition_dim.partitions_def.get_partition_keys_in_range(
+                PartitionKeyRange(
+                    start.keys_by_dimension[partition_dim.name],
+                    end.keys_by_dimension[partition_dim.name],
+                ),
+                dynamic_partitions_store=dynamic_partitions_store,
+            )
+            for partition_dim in self._partitions_defs
+        ]
+
+        return [
+            MultiPartitionKey(
+                {self._partitions_defs[i].name: key for i, key in enumerate(partition_key_tuple)}
+            )
+            for partition_key_tuple in itertools.product(*partition_key_sequences)
+        ]
+
     def get_serializable_unique_identifier(
         self, dynamic_partitions_store: Optional[DynamicPartitionsStore] = None
     ) -> str:
         return hashlib.sha1(
             str(
                 {
                     dim_def.name: dim_def.partitions_def.get_serializable_unique_identifier(
@@ -391,19 +418,15 @@
     def _get_primary_and_secondary_dimension(
         self,
     ) -> Tuple[PartitionDimensionDefinition, PartitionDimensionDefinition]:
         # Multipartitions subsets are serialized by primary dimension. If changing
         # the selection of primary/secondary dimension, will need to also update the
         # serialization of MultiPartitionsSubsets
 
-        time_dimensions = [
-            dim
-            for dim in self.partitions_defs
-            if isinstance(dim.partitions_def, TimeWindowPartitionsDefinition)
-        ]
+        time_dimensions = self._get_time_window_dims()
         if len(time_dimensions) == 1:
             primary_dimension, secondary_dimension = (
                 time_dimensions[0],
                 next(iter([dim for dim in self.partitions_defs if dim != time_dimensions[0]])),
             )
         else:
             primary_dimension, secondary_dimension = (
@@ -425,23 +448,38 @@
         partition_key = cast(MultiPartitionKey, self.get_partition_key_from_str(partition_key))
         tags = {**super().get_tags_for_partition_key(partition_key)}
         tags.update(get_tags_from_multi_partition_key(partition_key))
         return tags
 
     @property
     def time_window_dimension(self) -> PartitionDimensionDefinition:
-        time_window_dims = [
+        time_window_dims = self._get_time_window_dims()
+        check.invariant(
+            len(time_window_dims) == 1, "Expected exactly one time window partitioned dimension"
+        )
+        return next(iter(time_window_dims))
+
+    def _get_time_window_dims(self) -> List[PartitionDimensionDefinition]:
+        return [
             dim
             for dim in self.partitions_defs
             if isinstance(dim.partitions_def, TimeWindowPartitionsDefinition)
         ]
-        check.invariant(
-            len(time_window_dims) == 1, "Expected exactly one time window partitioned dimension"
+
+    @property
+    def has_time_window_dimension(self) -> bool:
+        return bool(self._get_time_window_dims())
+
+    @property
+    def time_window_partitions_def(self) -> TimeWindowPartitionsDefinition:
+        check.invariant(self.has_time_window_dimension, "Must have time window dimension")
+        return cast(
+            TimeWindowPartitionsDefinition,
+            check.inst(self.primary_dimension.partitions_def, TimeWindowPartitionsDefinition),
         )
-        return next(iter(time_window_dims))
 
     def time_window_for_partition_key(self, partition_key: str) -> TimeWindow:
         if not isinstance(partition_key, MultiPartitionKey):
             partition_key = self.get_partition_key_from_str(partition_key)
 
         time_window_dimension = self.time_window_dimension
         return cast(
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/node_container.py` & `dagster-1.7.0/dagster/_core/definitions/node_container.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/node_definition.py` & `dagster-1.7.0/dagster/_core/definitions/node_definition.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,23 +4,24 @@
     AbstractSet,
     Iterable,
     Iterator,
     Mapping,
     Optional,
     Sequence,
     Tuple,
+    Union,
 )
 
 import dagster._check as check
 from dagster._core.definitions.configurable import NamedConfigurableDefinition
 from dagster._core.definitions.policy import RetryPolicy
 from dagster._core.errors import DagsterInvariantViolationError
 
 from .hook_definition import HookDefinition
-from .utils import check_valid_name, validate_tags
+from .utils import NormalizedTags, check_valid_name, normalize_tags
 
 if TYPE_CHECKING:
     from dagster._core.types.dagster_type import DagsterType
 
     from .asset_layer import AssetLayer
     from .composition import PendingNodeInvocation
     from .dependency import NodeHandle, NodeInputHandle
@@ -43,20 +44,20 @@
 
     def __init__(
         self,
         name: str,
         input_defs: Sequence["InputDefinition"],
         output_defs: Sequence["OutputDefinition"],
         description: Optional[str] = None,
-        tags: Optional[Mapping[str, str]] = None,
+        tags: Union[NormalizedTags, Optional[Mapping[str, str]]] = None,
         positional_inputs: Optional[Sequence[str]] = None,
     ):
         self._name = check_valid_name(name)
         self._description = check.opt_str_param(description, "description")
-        self._tags = validate_tags(tags)
+        self._tags = normalize_tags(tags).tags
         self._input_defs = input_defs
         self._input_dict = {input_def.name: input_def for input_def in input_defs}
         check.invariant(len(self._input_defs) == len(self._input_dict), "Duplicate input def names")
         self._output_defs = output_defs
         self._output_dict = {output_def.name: output_def for output_def in output_defs}
         check.invariant(
             len(self._output_defs) == len(self._output_dict), "Duplicate output def names"
@@ -199,15 +200,15 @@
         retry_policy: Optional[RetryPolicy] = None,
     ) -> "PendingNodeInvocation":
         from .composition import PendingNodeInvocation
 
         return PendingNodeInvocation(
             node_def=self,
             given_alias=given_alias,
-            tags=validate_tags(tags) if tags else None,
+            tags=normalize_tags(tags).tags if tags else None,
             hook_defs=hook_defs,
             retry_policy=retry_policy,
         )
 
     def __call__(self, *args: object, **kwargs: object) -> object:
         return self.get_pending_invocation()(*args, **kwargs)
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/observe.py` & `dagster-1.7.0/dagster/_core/definitions/observe.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/op_definition.py` & `dagster-1.7.0/dagster/_core/definitions/op_definition.py`

 * *Files 5% similar despite different names*

```diff
@@ -26,14 +26,15 @@
 from dagster._core.definitions.policy import RetryPolicy
 from dagster._core.definitions.resource_requirement import (
     InputManagerRequirement,
     OpDefinitionResourceRequirement,
     OutputManagerRequirement,
     ResourceRequirement,
 )
+from dagster._core.definitions.utils import DEFAULT_IO_MANAGER_KEY
 from dagster._core.errors import (
     DagsterInvalidDefinitionError,
     DagsterInvalidInvocationError,
     DagsterInvariantViolationError,
 )
 from dagster._core.types.dagster_type import DagsterType, DagsterTypeKind
 from dagster._utils import IHasInternalInit
@@ -423,15 +424,19 @@
                     node_description=node_description,
                     input_name=input_def.name,
                     root_input=False,
                 )
             elif asset_layer and handle:
                 input_asset_key = asset_layer.asset_key_for_input(handle, input_def.name)
                 if input_asset_key:
-                    io_manager_key = asset_layer.io_manager_key_for_asset(input_asset_key)
+                    io_manager_key = (
+                        asset_layer.get(input_asset_key).io_manager_key
+                        if asset_layer.has(input_asset_key)
+                        else DEFAULT_IO_MANAGER_KEY
+                    )
                     yield InputManagerRequirement(
                         key=io_manager_key,
                         node_description=node_description,
                         input_name=input_def.name,
                         root_input=False,
                     )
 
@@ -553,25 +558,30 @@
 
 
 def _validate_context_type_hint(fn):
     from inspect import _empty as EmptyAnnotation
 
     from dagster._core.decorator_utils import get_function_params
     from dagster._core.definitions.decorators.op_decorator import is_context_provided
-    from dagster._core.execution.context.compute import AssetExecutionContext, OpExecutionContext
+    from dagster._core.execution.context.compute import (
+        AssetCheckExecutionContext,
+        AssetExecutionContext,
+        OpExecutionContext,
+    )
 
     params = get_function_params(fn)
     if is_context_provided(params):
-        if (
-            params[0].annotation is not AssetExecutionContext
-            and params[0].annotation is not OpExecutionContext
-            and params[0].annotation is not EmptyAnnotation
-        ):
+        if params[0].annotation not in [
+            AssetExecutionContext,
+            OpExecutionContext,
+            EmptyAnnotation,
+            AssetCheckExecutionContext,
+        ]:
             raise DagsterInvalidDefinitionError(
                 f"Cannot annotate `context` parameter with type {params[0].annotation}. `context`"
-                " must be annotated with AssetExecutionContext, OpExecutionContext, or left blank."
+                " must be annotated with AssetExecutionContext, AssetCheckExecutionContext, OpExecutionContext, or left blank."
             )
 
 
 def _is_result_object_type(ttype):
     # Is this type special result object type
     return ttype in (MaterializeResult, ObserveResult, AssetCheckResult)
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/op_invocation.py` & `dagster-1.7.0/dagster/_core/definitions/op_invocation.py`

 * *Files 0% similar despite different names*

```diff
@@ -218,29 +218,29 @@
     )
 
     try:
         # if the compute function fails, we want to ensure we unbind the context. This
         # try-except handles "vanilla" asset and op invocation (generators and async handled in
         # _type_check_output_wrapper)
 
-        input_dict = _resolve_inputs(op_def, input_args, input_kwargs, bound_context)  # type: ignore (pyright bug)
+        input_dict = _resolve_inputs(op_def, input_args, input_kwargs, bound_context)  # type: ignore # (pyright bug)
 
         result = invoke_compute_fn(
             fn=compute_fn.decorated_fn,
-            context=bound_context,  # type: ignore (pyright bug)
+            context=bound_context,  # type: ignore # (pyright bug)
             kwargs=input_dict,
             context_arg_provided=compute_fn.has_context_arg(),
             config_arg_cls=(
                 compute_fn.get_config_arg().annotation if compute_fn.has_config_arg() else None
             ),
             resource_args=resource_arg_mapping,
         )
-        return _type_check_output_wrapper(op_def, result, bound_context)  # type: ignore (pyright bug)
+        return _type_check_output_wrapper(op_def, result, bound_context)  # type: ignore # (pyright bug)
     except Exception:
-        bound_context.unbind()  # type: ignore (pyright bug)
+        bound_context.unbind()  # type: ignore # (pyright bug)
         raise
 
 
 def _resolve_inputs(
     op_def: "OpDefinition", args, kwargs, context: "BaseDirectExecutionContext"
 ) -> Mapping[str, Any]:
     from dagster._core.execution.plan.execute_step import do_type_check
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/op_selection.py` & `dagster-1.7.0/dagster/_core/definitions/op_selection.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/output.py` & `dagster-1.7.0/dagster/_core/definitions/output.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/partition.py` & `dagster-1.7.0/dagster/_core/definitions/partition.py`

 * *Files 2% similar despite different names*

```diff
@@ -44,15 +44,15 @@
 from ..errors import (
     DagsterInvalidDefinitionError,
     DagsterInvalidDeserializationVersionError,
     DagsterInvalidInvocationError,
     DagsterUnknownPartitionError,
 )
 from .config import ConfigMapping
-from .utils import validate_tags
+from .utils import normalize_tags
 
 DEFAULT_DATE_FORMAT = "%Y-%m-%d"
 
 T_cov = TypeVar("T_cov", default=Any, covariant=True)
 T_str = TypeVar("T_str", bound=str, default=str, covariant=True)
 T_PartitionsDefinition = TypeVar(
     "T_PartitionsDefinition",
@@ -105,19 +105,23 @@
     MONTHLY = "MONTHLY"
 
     @property
     def ordinal(self):
         return {"HOURLY": 1, "DAILY": 2, "WEEKLY": 3, "MONTHLY": 4}[self.value]
 
     def __gt__(self, other: "ScheduleType") -> bool:
-        check.inst(other, ScheduleType, "Cannot compare ScheduleType with non-ScheduleType")
+        check.inst_param(
+            other, "other", ScheduleType, "Cannot compare ScheduleType with non-ScheduleType"
+        )
         return self.ordinal > other.ordinal
 
     def __lt__(self, other: "ScheduleType") -> bool:
-        check.inst(other, ScheduleType, "Cannot compare ScheduleType with non-ScheduleType")
+        check.inst_param(
+            other, "other", ScheduleType, "Cannot compare ScheduleType with non-ScheduleType"
+        )
         return self.ordinal < other.ordinal
 
 
 class PartitionsDefinition(ABC, Generic[T_str]):
     """Defines a set of partitions, which can be attached to a software-defined asset or job.
 
     Abstract class with implementations for different kinds of partitions.
@@ -521,15 +525,17 @@
                 dynamic_partitions_store, "dynamic_partitions_store", DynamicPartitionsStore
             )
 
             if dynamic_partitions_store is None:
                 check.failed(
                     "The instance is not available to load partitions. You may be seeing this error"
                     " when using dynamic partitions with a version of dagster-webserver or"
-                    " dagster-cloud that is older than 1.1.18."
+                    " dagster-cloud that is older than 1.1.18. The other possibility is that an"
+                    " internal framework error where a dynamic partitions store was not properly"
+                    " threaded down a call stack."
                 )
 
             return dynamic_partitions_store.get_dynamic_partitions(
                 partitions_def_name=self._validated_name()
             )
 
     def has_partition_key(
@@ -541,15 +547,17 @@
         if self.partition_fn:
             return partition_key in self.get_partition_keys(current_time)
         else:
             if dynamic_partitions_store is None:
                 check.failed(
                     "The instance is not available to load partitions. You may be seeing this error"
                     " when using dynamic partitions with a version of dagster-webserver or"
-                    " dagster-cloud that is older than 1.1.18."
+                    " dagster-cloud that is older than 1.1.18. The other possibility is that an"
+                    " internal framework error where a dynamic partitions store was not properly"
+                    " threaded down a call stack."
                 )
 
             return dynamic_partitions_store.has_dynamic_partition(
                 partitions_def_name=self._validated_name(), partition_key=partition_key
             )
 
     def build_add_request(self, partition_keys: Sequence[str]) -> AddDynamicPartitionsRequest:
@@ -707,26 +715,26 @@
 
     # Assumes partition key already validated
     def get_tags_for_partition_key(
         self,
         partition_key: str,
         job_name: Optional[str] = None,
     ) -> Mapping[str, str]:
-        from dagster._core.host_representation.external_data import (
+        from dagster._core.remote_representation.external_data import (
             external_partition_set_name_for_job_name,
         )
 
         # _tags_for_partition_fn is deprecated, we can remove this branching logic in 2.0
         if self._tags_for_partition_fn:
             user_tags = self._tags_for_partition_fn(Partition(partition_key))
         elif self._tags_for_partition_key_fn:
             user_tags = self._tags_for_partition_key_fn(partition_key)
         else:
             user_tags = {}
-        user_tags = validate_tags(user_tags, allow_reserved_tags=False)
+        user_tags = normalize_tags(user_tags, allow_reserved_tags=False).tags
 
         system_tags = {
             **self.partitions_def.get_tags_for_partition_key(partition_key),
             # `PartitionSetDefinition` has been deleted but we still need to attach this special tag in
             # order for reexecution against partitions to work properly.
             **(
                 {PARTITION_SET_TAG: external_partition_set_name_for_job_name(job_name)}
@@ -965,29 +973,38 @@
     ) -> "PartitionsSubset[T_str]":
         return self.with_partition_keys(
             partitions_def.get_partition_keys_in_range(
                 partition_key_range, dynamic_partitions_store=dynamic_partitions_store
             )
         )
 
-    def __or__(self, other: "PartitionsSubset") -> "PartitionsSubset[T_str]":
+    def __or__(self, other: "PartitionsSubset") -> "PartitionsSubset":
         if self is other:
             return self
+        # Anything | AllPartitionsSubset = AllPartitionsSubset
+        if isinstance(other, AllPartitionsSubset):
+            return other
         return self.with_partition_keys(other.get_partition_keys())
 
-    def __sub__(self, other: "PartitionsSubset") -> "PartitionsSubset[T_str]":
+    def __sub__(self, other: "PartitionsSubset") -> "PartitionsSubset":
         if self is other:
             return self.empty_subset()
+        # Anything - AllPartitionsSubset = Empty
+        if isinstance(other, AllPartitionsSubset):
+            return self.empty_subset()
         return self.empty_subset().with_partition_keys(
             set(self.get_partition_keys()).difference(set(other.get_partition_keys()))
         )
 
-    def __and__(self, other: "PartitionsSubset") -> "PartitionsSubset[T_str]":
+    def __and__(self, other: "PartitionsSubset") -> "PartitionsSubset":
         if self is other:
             return self
+        # Anything & AllPartitionsSubset = Anything
+        if isinstance(other, AllPartitionsSubset):
+            return self
         return self.empty_subset().with_partition_keys(
             set(self.get_partition_keys()) & set(other.get_partition_keys())
         )
 
     @abstractmethod
     def serialize(self) -> str: ...
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/partition_key_range.py` & `dagster-1.7.0/dagster/_core/definitions/partition_key_range.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/partition_mapping.py` & `dagster-1.7.0/dagster/_core/definitions/partition_mapping.py`

 * *Files 2% similar despite different names*

```diff
@@ -884,49 +884,51 @@
 
         self._inverse_mapping = defaultdict(set)
         for upstream_key, downstream_keys in self._mapping.items():
             for downstream_key in downstream_keys:
                 self._inverse_mapping[downstream_key].add(upstream_key)
 
     @cached_method
-    def _check_upstream(self, *, upstream_partitions_def: PartitionsDefinition):
+    def _check_upstream(self, *, upstream_partitions_def: StaticPartitionsDefinition):
         """Validate that the mapping from upstream to downstream is only defined on upstream keys."""
-        check.inst(
+        check.inst_param(
             upstream_partitions_def,
+            "upstream_partitions_def",
             StaticPartitionsDefinition,
             "StaticPartitionMapping can only be defined between two StaticPartitionsDefinitions",
         )
         upstream_keys = upstream_partitions_def.get_partition_keys()
         extra_keys = set(self._mapping.keys()).difference(upstream_keys)
         if extra_keys:
             raise ValueError(
                 f"mapping source partitions not in the upstream partitions definition: {extra_keys}"
             )
 
     @cached_method
-    def _check_downstream(self, *, downstream_partitions_def: PartitionsDefinition):
+    def _check_downstream(self, *, downstream_partitions_def: StaticPartitionsDefinition):
         """Validate that the mapping from upstream to downstream only maps to downstream keys."""
-        check.inst(
+        check.inst_param(
             downstream_partitions_def,
+            "downstream_partitions_def",
             StaticPartitionsDefinition,
             "StaticPartitionMapping can only be defined between two StaticPartitionsDefinitions",
         )
         downstream_keys = downstream_partitions_def.get_partition_keys()
         extra_keys = set(self._inverse_mapping.keys()).difference(downstream_keys)
         if extra_keys:
             raise ValueError(
                 "mapping target partitions not in the downstream partitions definition:"
                 f" {extra_keys}"
             )
 
     def get_downstream_partitions_for_partitions(
         self,
         upstream_partitions_subset: PartitionsSubset,
-        upstream_partitions_def: PartitionsDefinition,
-        downstream_partitions_def: PartitionsDefinition,
+        upstream_partitions_def: StaticPartitionsDefinition,
+        downstream_partitions_def: StaticPartitionsDefinition,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
     ) -> PartitionsSubset:
         self._check_downstream(downstream_partitions_def=downstream_partitions_def)
 
         downstream_subset = downstream_partitions_def.empty_subset()
         downstream_keys = set()
@@ -934,15 +936,15 @@
             downstream_keys.update(self._mapping[key])
         return downstream_subset.with_partition_keys(downstream_keys)
 
     def get_upstream_mapped_partitions_result_for_partitions(
         self,
         downstream_partitions_subset: Optional[PartitionsSubset],
         downstream_partitions_def: Optional[PartitionsDefinition],
-        upstream_partitions_def: PartitionsDefinition,
+        upstream_partitions_def: StaticPartitionsDefinition,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
     ) -> UpstreamPartitionsResult:
         self._check_upstream(upstream_partitions_def=upstream_partitions_def)
 
         upstream_subset = upstream_partitions_def.empty_subset()
         if downstream_partitions_subset is None:
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/partitioned_schedule.py` & `dagster-1.7.0/dagster/_core/definitions/partitioned_schedule.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/policy.py` & `dagster-1.7.0/dagster/_core/definitions/policy.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/reconstruct.py` & `dagster-1.7.0/dagster/_core/definitions/reconstruct.py`

 * *Files 0% similar despite different names*

```diff
@@ -666,16 +666,16 @@
 
     target = def_from_pointer(pointer)
 
     if isinstance(target, JobDefinition):
         return target
 
     raise DagsterInvariantViolationError(
-        "CodePointer ({str}) must resolve to a JobDefinition (or JobDefinition for legacy"
-        " code). Received a {type}".format(str=pointer.describe(), type=type(target))
+        f"CodePointer ({pointer.describe()}) must resolve to a JobDefinition (or JobDefinition for legacy"
+        f" code). Received a {type(target)}"
     )
 
 
 @overload
 def repository_def_from_target_def(
     target: Union["RepositoryDefinition", "JobDefinition", "GraphDefinition"],
     repository_load_data: Optional["RepositoryLoadData"] = None,
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/repository_definition/__init__.py` & `dagster-1.7.0/dagster/_core/definitions/repository_definition/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/repository_definition/caching_index.py` & `dagster-1.7.0/dagster/_core/definitions/repository_definition/caching_index.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/repository_definition/repository_data.py` & `dagster-1.7.0/dagster/_core/definitions/repository_definition/repository_data.py`

 * *Files 6% similar despite different names*

```diff
@@ -11,14 +11,15 @@
     Sequence,
     TypeVar,
     Union,
 )
 
 import dagster._check as check
 from dagster._annotations import public
+from dagster._core.definitions.asset_check_spec import AssetCheckKey
 from dagster._core.definitions.events import AssetKey
 from dagster._core.definitions.executor_definition import ExecutorDefinition
 from dagster._core.definitions.graph_definition import SubselectedGraphDefinition
 from dagster._core.definitions.job_definition import JobDefinition
 from dagster._core.definitions.logger_definition import LoggerDefinition
 from dagster._core.definitions.resource_definition import ResourceDefinition
 from dagster._core.definitions.schedule_definition import ScheduleDefinition
@@ -27,14 +28,15 @@
 from dagster._core.errors import DagsterInvalidDefinitionError, DagsterInvariantViolationError
 
 from .caching_index import CacheingDefinitionIndex
 from .valid_definitions import RepositoryListDefinition
 
 if TYPE_CHECKING:
     from dagster._core.definitions import AssetsDefinition
+    from dagster._core.definitions.asset_checks import AssetChecksDefinition
     from dagster._core.definitions.partitioned_schedule import (
         UnresolvedPartitionedAssetScheduleDefinition,
     )
 
 T = TypeVar("T")
 Resolvable = Callable[[], T]
 
@@ -190,14 +192,19 @@
         return {}
 
     @public
     def get_assets_defs_by_key(self) -> Mapping[AssetKey, "AssetsDefinition"]:
         """Mapping[AssetKey, AssetsDefinition]: Get the asset definitions for the repository."""
         return {}
 
+    @public
+    def get_asset_checks_defs_by_key(self) -> Mapping[AssetKey, "AssetChecksDefinition"]:
+        """Mapping[AssetKey, AssetChecksDefinition]: Get the asset checks definitions for the repository."""
+        return {}
+
     def load_all_definitions(self):
         # force load of all lazy constructed code artifacts
         self.get_all_jobs()
         self.get_all_schedules()
         self.get_all_sensors()
         self.get_source_assets_by_key()
 
@@ -211,14 +218,15 @@
     def __init__(
         self,
         jobs: Mapping[str, Union[JobDefinition, Resolvable[JobDefinition]]],
         schedules: Mapping[str, Union[ScheduleDefinition, Resolvable[ScheduleDefinition]]],
         sensors: Mapping[str, Union[SensorDefinition, Resolvable[SensorDefinition]]],
         source_assets_by_key: Mapping[AssetKey, SourceAsset],
         assets_defs_by_key: Mapping[AssetKey, "AssetsDefinition"],
+        asset_checks_defs_by_key: Mapping[AssetCheckKey, "AssetChecksDefinition"],
         top_level_resources: Mapping[str, ResourceDefinition],
         utilized_env_vars: Mapping[str, AbstractSet[str]],
         resource_key_mapping: Mapping[int, str],
         unresolved_partitioned_asset_schedules: Mapping[
             str, "UnresolvedPartitionedAssetScheduleDefinition"
         ],
     ):
@@ -239,14 +247,16 @@
             schedules (Mapping[str, Union[ScheduleDefinition, Callable[[], ScheduleDefinition]]]):
                 The schedules belonging to the repository.
             sensors (Mapping[str, Union[SensorDefinition, Callable[[], SensorDefinition]]]):
                 The sensors belonging to a repository.
             source_assets_by_key (Mapping[AssetKey, SourceAsset]): The source assets belonging to a repository.
             assets_defs_by_key (Mapping[AssetKey, AssetsDefinition]): The assets definitions
                 belonging to a repository.
+            asset_checks_defs_by_key (Mapping[AssetKey, AssetChecksDefinition]): The asset checks definitions
+                belonging to a repository.
             top_level_resources (Mapping[str, ResourceDefinition]): A dict of top-level
                 resource keys to defintions, for resources which should be displayed in the UI.
         """
         from dagster._core.definitions import AssetsDefinition
 
         check.mapping_param(jobs, "jobs", key_type=str, value_type=(JobDefinition, FunctionType))
         check.mapping_param(
@@ -258,14 +268,20 @@
         check.mapping_param(
             source_assets_by_key, "source_assets_by_key", key_type=AssetKey, value_type=SourceAsset
         )
         check.mapping_param(
             assets_defs_by_key, "assets_defs_by_key", key_type=AssetKey, value_type=AssetsDefinition
         )
         check.mapping_param(
+            asset_checks_defs_by_key,
+            "assets_checks_defs_by_key",
+            key_type=AssetCheckKey,
+            value_type=AssetsDefinition,
+        )
+        check.mapping_param(
             top_level_resources, "top_level_resources", key_type=str, value_type=ResourceDefinition
         )
         check.mapping_param(
             utilized_env_vars,
             "utilized_resources",
             key_type=str,
         )
@@ -299,14 +315,15 @@
             self._validate_schedule,
         )
         # load all schedules to force validation
         self._schedules.get_all_definitions()
 
         self._source_assets_by_key = source_assets_by_key
         self._assets_defs_by_key = assets_defs_by_key
+        self._assets_checks_defs_by_key = asset_checks_defs_by_key
         self._top_level_resources = top_level_resources
         self._utilized_env_vars = utilized_env_vars
         self._resource_key_mapping = resource_key_mapping
 
         self._sensors = CacheingDefinitionIndex(
             SensorDefinition,
             "SensorDefinition",
@@ -487,14 +504,17 @@
 
     def get_source_assets_by_key(self) -> Mapping[AssetKey, SourceAsset]:
         return self._source_assets_by_key
 
     def get_assets_defs_by_key(self) -> Mapping[AssetKey, "AssetsDefinition"]:
         return self._assets_defs_by_key
 
+    def get_asset_checks_defs_by_key(self) -> Mapping[AssetCheckKey, "AssetChecksDefinition"]:
+        return self._assets_checks_defs_by_key
+
     def _check_node_defs(self, job_defs: Sequence[JobDefinition]) -> None:
         node_defs = {}
         node_to_job = {}
         for job_def in job_defs:
             for node_def in [*job_def.all_node_defs, job_def.graph]:
                 # skip checks for subselected graphs because they don't have their own names
                 if isinstance(node_def, SubselectedGraphDefinition):
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/repository_definition/repository_data_builder.py` & `dagster-1.7.0/dagster/_core/definitions/repository_definition/repository_data_builder.py`

 * *Files 9% similar despite different names*

```diff
@@ -20,49 +20,41 @@
 from dagster._config.pythonic_config import (
     ConfigurableIOManagerFactoryResourceDefinition,
     ConfigurableResourceFactoryResourceDefinition,
     ResourceWithKeyMapping,
 )
 from dagster._core.definitions.asset_checks import AssetChecksDefinition
 from dagster._core.definitions.asset_graph import AssetGraph
-from dagster._core.definitions.asset_spec import (
-    SYSTEM_METADATA_KEY_AUTO_CREATED_STUB_ASSET,
-    AssetSpec,
-)
-from dagster._core.definitions.assets_job import (
+from dagster._core.definitions.asset_job import (
     get_base_asset_jobs,
     is_base_asset_job_name,
 )
 from dagster._core.definitions.auto_materialize_sensor_definition import (
     AutoMaterializeSensorDefinition,
 )
+from dagster._core.definitions.base_asset_graph import BaseAssetGraph
 from dagster._core.definitions.executor_definition import ExecutorDefinition
-from dagster._core.definitions.external_asset import (
-    create_external_asset_from_source_asset,
-    external_asset_from_spec,
-)
 from dagster._core.definitions.graph_definition import GraphDefinition
-from dagster._core.definitions.internal_asset_graph import InternalAssetGraph
 from dagster._core.definitions.job_definition import JobDefinition
 from dagster._core.definitions.logger_definition import LoggerDefinition
 from dagster._core.definitions.partitioned_schedule import (
     UnresolvedPartitionedAssetScheduleDefinition,
 )
-from dagster._core.definitions.resolved_asset_deps import ResolvedAssetDependencies
 from dagster._core.definitions.resource_definition import ResourceDefinition
 from dagster._core.definitions.schedule_definition import ScheduleDefinition
 from dagster._core.definitions.sensor_definition import SensorDefinition
 from dagster._core.definitions.source_asset import SourceAsset
 from dagster._core.definitions.unresolved_asset_job_definition import UnresolvedAssetJobDefinition
 from dagster._core.errors import DagsterInvalidDefinitionError
 
 from .repository_data import CachingRepositoryData
 from .valid_definitions import VALID_REPOSITORY_DATA_DICT_KEYS, RepositoryListDefinition
 
 if TYPE_CHECKING:
+    from dagster._core.definitions.asset_check_spec import AssetCheckKey
     from dagster._core.definitions.events import AssetKey
 
 
 def _find_env_vars(config_entry: Any) -> Set[str]:
     """Given a part of a config dictionary, return a set of environment variables that are used in
     that part of the config.
     """
@@ -112,15 +104,15 @@
             )
 
     return env_vars
 
 
 def _resolve_unresolved_job_def_lambda(
     unresolved_job_def: UnresolvedAssetJobDefinition,
-    asset_graph: InternalAssetGraph,
+    asset_graph: AssetGraph,
     default_executor_def: Optional[ExecutorDefinition],
     top_level_resources: Optional[Mapping[str, ResourceDefinition]],
     default_logger_defs: Optional[Mapping[str, LoggerDefinition]],
 ) -> Callable[[], JobDefinition]:
     def resolve_unresolved_job_def() -> JobDefinition:
         job_def = unresolved_job_def.resolve(
             asset_graph=asset_graph,
@@ -167,14 +159,15 @@
     schedules: Dict[str, ScheduleDefinition] = {}
     unresolved_partitioned_asset_schedules: Dict[
         str, UnresolvedPartitionedAssetScheduleDefinition
     ] = {}
     sensors: Dict[str, SensorDefinition] = {}
     assets_defs: List[AssetsDefinition] = []
     asset_keys: Set[AssetKey] = set()
+    asset_check_keys: Set["AssetCheckKey"] = set()
     source_assets: List[SourceAsset] = []
     asset_checks_defs: List[AssetChecksDefinition] = []
     for definition in repository_definitions:
         if isinstance(definition, JobDefinition):
             if (
                 definition.name in jobs and jobs[definition.name] != definition
             ) or definition.name in unresolved_jobs:
@@ -222,71 +215,51 @@
         elif isinstance(definition, UnresolvedAssetJobDefinition):
             if definition.name in jobs or definition.name in unresolved_jobs:
                 raise DagsterInvalidDefinitionError(
                     f"Duplicate definition found for unresolved job '{definition.name}'"
                 )
             # we can only resolve these once we have all assets
             unresolved_jobs[definition.name] = definition
+        elif isinstance(definition, AssetChecksDefinition):
+            for key in definition.check_keys:
+                if key in asset_check_keys:
+                    raise DagsterInvalidDefinitionError(f"Duplicate asset check key: {key}")
+            asset_check_keys.update(definition.check_keys)
+            asset_checks_defs.append(definition)
         elif isinstance(definition, AssetsDefinition):
             for key in definition.keys:
                 if key in asset_keys:
                     raise DagsterInvalidDefinitionError(f"Duplicate asset key: {key}")
+            for key in definition.check_keys:
+                if key in asset_check_keys:
+                    raise DagsterInvalidDefinitionError(f"Duplicate asset check key: {key}")
 
             asset_keys.update(definition.keys)
+            asset_check_keys.update(definition.check_keys)
             assets_defs.append(definition)
         elif isinstance(definition, SourceAsset):
             source_assets.append(definition)
-            assets_defs.append(create_external_asset_from_source_asset(definition))
             asset_keys.add(definition.key)
-        elif isinstance(definition, AssetChecksDefinition):
-            asset_checks_defs.append(definition)
         else:
             check.failed(f"Unexpected repository entry {definition}")
 
-    # Resolve all asset dependencies. An asset dependency is resolved when it's key is an AssetKey
-    # not subject to any further manipulation.
-    resolved_deps = ResolvedAssetDependencies(assets_defs, [])
-    assets_defs = [
-        ad.with_attributes(
-            input_asset_key_replacements={
-                raw_key: resolved_deps.get_resolved_asset_key_for_input(ad, input_name)
-                for input_name, raw_key in ad.keys_by_input_name.items()
-            }
-        )
-        for ad in assets_defs
-    ]
-
-    # Create unexecutable external assets definitions for any referenced keys for which no
-    # definition was provided.
-    all_referenced_asset_keys = {
-        *(key for asset_def in assets_defs for key in asset_def.dependency_keys),
-        *(checks_def.asset_key for checks_def in asset_checks_defs),
+    asset_graph = AssetGraph.from_assets([*assets_defs, *asset_checks_defs, *source_assets])
+    source_assets_by_key = {source_asset.key: source_asset for source_asset in source_assets}
+    assets_defs_by_key = {key: asset for asset in assets_defs for key in asset.keys}
+    asset_checks_defs_by_key = {
+        key: checks_def for checks_def in asset_checks_defs for key in checks_def.check_keys
     }
-    for key in all_referenced_asset_keys.difference(asset_keys):
-        assets_defs.append(
-            external_asset_from_spec(
-                AssetSpec(key=key, metadata={SYSTEM_METADATA_KEY_AUTO_CREATED_STUB_ASSET: True})
-            )
-        )
-        asset_keys.add(key)
-
-    if assets_defs or source_assets or asset_checks_defs:
-        for job_def in get_base_asset_jobs(
-            assets=assets_defs,
+    if assets_defs or asset_checks_defs or source_assets:
+        for job_name, job_def in get_base_asset_jobs(
+            asset_graph=asset_graph,
             executor_def=default_executor_def,
             resource_defs=top_level_resources,
-            asset_checks=asset_checks_defs,
-        ):
-            jobs[job_def.name] = job_def
-
-        source_assets_by_key = {source_asset.key: source_asset for source_asset in source_assets}
-        assets_defs_by_key = {key: asset for asset in assets_defs for key in asset.keys}
-    else:
-        source_assets_by_key = {}
-        assets_defs_by_key = {}
+            logger_defs=default_logger_defs,
+        ).items():
+            jobs[job_name] = job_def
 
     for name, sensor_def in sensors.items():
         if sensor_def.has_loadable_targets():
             targets = sensor_def.load_targets()
             for target in targets:
                 _process_and_validate_target(
                     sensor_def, coerced_graphs, unresolved_jobs, jobs, target
@@ -295,15 +268,14 @@
     for name, schedule_def in schedules.items():
         if schedule_def.has_loadable_target():
             target = schedule_def.load_target()
             _process_and_validate_target(
                 schedule_def, coerced_graphs, unresolved_jobs, jobs, target
             )
 
-    asset_graph = InternalAssetGraph.from_assets(assets_defs, asset_checks=asset_checks_defs)
     _validate_auto_materialize_sensors(sensors.values(), asset_graph)
 
     if unresolved_partitioned_asset_schedules:
         for (
             name,
             unresolved_partitioned_asset_schedule,
         ) in unresolved_partitioned_asset_schedules.items():
@@ -350,14 +322,15 @@
 
     return CachingRepositoryData(
         jobs=jobs,
         schedules=schedules,
         sensors=sensors,
         source_assets_by_key=source_assets_by_key,
         assets_defs_by_key=assets_defs_by_key,
+        asset_checks_defs_by_key=asset_checks_defs_by_key,
         top_level_resources=top_level_resources or {},
         utilized_env_vars=utilized_env_vars,
         resource_key_mapping=resource_key_mapping or {},
         unresolved_partitioned_asset_schedules=unresolved_partitioned_asset_schedules,
     )
 
 
@@ -394,15 +367,15 @@
 
     for key, raw_job_def in repository_definitions["jobs"].items():
         if isinstance(raw_job_def, GraphDefinition):
             repository_definitions["jobs"][key] = raw_job_def.coerce_to_job()
         elif isinstance(raw_job_def, UnresolvedAssetJobDefinition):
             repository_definitions["jobs"][key] = raw_job_def.resolve(
                 # TODO: https://github.com/dagster-io/dagster/issues/8263
-                asset_graph=InternalAssetGraph.from_assets([]),
+                asset_graph=AssetGraph.from_assets([]),
                 default_executor_def=None,
             )
         elif not isinstance(raw_job_def, JobDefinition) and not isfunction(raw_job_def):
             raise DagsterInvalidDefinitionError(
                 f"Object mapped to {key} is not an instance of JobDefinition or GraphDefinition."
             )
 
@@ -412,14 +385,15 @@
         if isinstance(job_def, JobDefinition):
             job_def.validate_resource_requirements_satisfied()
 
     return CachingRepositoryData(
         **repository_definitions,
         source_assets_by_key={},
         assets_defs_by_key={},
+        asset_checks_defs_by_key={},
         top_level_resources={},
         utilized_env_vars={},
         resource_key_mapping={},
         unresolved_partitioned_asset_schedules={},
     )
 
 
@@ -482,15 +456,15 @@
             raise DagsterInvalidDefinitionError(
                 _get_error_msg_for_target_conflict(targeter, "job", target.name, dupe_target_type)
             )
         jobs[target.name] = target
 
 
 def _validate_auto_materialize_sensors(
-    sensors: Iterable[SensorDefinition], asset_graph: AssetGraph
+    sensors: Iterable[SensorDefinition], asset_graph: BaseAssetGraph
 ) -> None:
     """Raises an error if two or more automation policy sensors target the same asset."""
     sensor_names_by_asset_key: Dict[AssetKey, str] = {}
     for sensor in sensors:
         if isinstance(sensor, AutoMaterializeSensorDefinition):
             asset_keys = sensor.asset_selection.resolve(asset_graph)
             for asset_key in asset_keys:
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/repository_definition/repository_definition.py` & `dagster-1.7.0/dagster/_core/definitions/repository_definition/repository_definition.py`

 * *Files 3% similar despite different names*

```diff
@@ -12,41 +12,43 @@
     Type,
     Union,
 )
 
 import dagster._check as check
 from dagster._annotations import public
 from dagster._core.definitions.asset_check_spec import AssetCheckKey
-from dagster._core.definitions.assets_job import (
+from dagster._core.definitions.asset_graph import AssetGraph
+from dagster._core.definitions.asset_job import (
     ASSET_BASE_JOB_PREFIX,
 )
 from dagster._core.definitions.cacheable_assets import AssetsDefinitionCacheableData
 from dagster._core.definitions.events import AssetKey, CoercibleToAssetKey
 from dagster._core.definitions.executor_definition import ExecutorDefinition
-from dagster._core.definitions.internal_asset_graph import InternalAssetGraph
 from dagster._core.definitions.job_definition import JobDefinition
 from dagster._core.definitions.logger_definition import LoggerDefinition
 from dagster._core.definitions.metadata import MetadataMapping
 from dagster._core.definitions.resource_definition import ResourceDefinition
 from dagster._core.definitions.schedule_definition import ScheduleDefinition
 from dagster._core.definitions.sensor_definition import SensorDefinition
 from dagster._core.definitions.source_asset import SourceAsset
 from dagster._core.definitions.utils import check_valid_name
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.instance import DagsterInstance
 from dagster._serdes import whitelist_for_serdes
 from dagster._utils import hash_collection
+from dagster._utils.cached_method import cached_method
 
 from .repository_data import CachingRepositoryData, RepositoryData
 from .valid_definitions import (
     RepositoryListDefinition as RepositoryListDefinition,
 )
 
 if TYPE_CHECKING:
     from dagster._core.definitions import AssetsDefinition
+    from dagster._core.definitions.asset_checks import AssetChecksDefinition
     from dagster._core.definitions.cacheable_assets import CacheableAssetsDefinition
     from dagster._core.storage.asset_value_loader import AssetValueLoader
 
 
 @whitelist_for_serdes
 class RepositoryLoadData(
     NamedTuple(
@@ -91,26 +93,24 @@
         repository_data (RepositoryData): Contains the definitions making up the repository.
         description (Optional[str]): A string description of the repository.
         metadata (Optional[MetadataMapping]): A map of arbitrary metadata for the repository.
     """
 
     def __init__(
         self,
-        name,
+        name: str,
         *,
-        repository_data,
-        description=None,
-        metadata=None,
-        repository_load_data=None,
+        repository_data: RepositoryData,
+        description: Optional[str] = None,
+        metadata: Optional[Mapping[str, Any]] = None,
+        repository_load_data: Optional[RepositoryLoadData] = None,
     ):
         self._name = check_valid_name(name)
         self._description = check.opt_str_param(description, "description")
-        self._repository_data: RepositoryData = check.inst_param(
-            repository_data, "repository_data", RepositoryData
-        )
+        self._repository_data = check.inst_param(repository_data, "repository_data", RepositoryData)
         self._metadata = check.opt_mapping_param(metadata, "metadata", key_type=str)
         self._repository_load_data = check.opt_inst_param(
             repository_load_data, "repository_load_data", RepositoryLoadData
         )
 
     @property
     def repository_load_data(self) -> Optional[RepositoryLoadData]:
@@ -130,15 +130,15 @@
 
     @public
     @property
     def metadata(self) -> Optional[MetadataMapping]:
         """Optional[MetadataMapping]: Arbitrary metadata for the repository."""
         return self._metadata
 
-    def load_all_definitions(self):
+    def load_all_definitions(self) -> None:
         # force load of all lazy constructed code artifacts
         self._repository_data.load_all_definitions()
 
     @public
     @property
     def job_names(self) -> Sequence[str]:
         """List[str]: Names of all jobs in the repository."""
@@ -236,25 +236,41 @@
         return self._repository_data.get_sensor(name)
 
     @public
     def has_sensor_def(self, name: str) -> bool:
         """bool: Check if a sensor with a given name is present in the repository."""
         return self._repository_data.has_sensor(name)
 
+    @public
     @property
     def source_assets_by_key(self) -> Mapping[AssetKey, SourceAsset]:
+        """Mapping[AssetKey, SourceAsset]: The source assets defined in the repository."""
         return self._repository_data.get_source_assets_by_key()
 
+    # NOTE: `assets_defs_by_key` should generally not be used internally. It returns the
+    # `AssetsDefinition` supplied at repository construction time. Internally, assets defs should be
+    # obtained from the `AssetGraph` via `asset_graph.assets_defs`. This returns a normalized set of
+    # assets defs, where:
+    #
+    # - `SourceAsset` instances are replaced with external `AssetsDefinition`
+    # - Relative asset key dependencies are resolved
+    # - External `AssetsDefinition` have been generated for referenced asset keys without a
+    #   corresponding user-provided definition
+
+    @public
     @property
     def assets_defs_by_key(self) -> Mapping[AssetKey, "AssetsDefinition"]:
+        """Mapping[AssetKey, AssetsDefinition]: The assets definitions defined in the repository."""
         return self._repository_data.get_assets_defs_by_key()
 
+    @public
     @property
-    def external_assets_defs_by_key(self) -> Mapping[AssetKey, "AssetsDefinition"]:
-        return {k: v for k, v in self.assets_defs_by_key.items() if v.is_external}
+    def asset_checks_defs_by_key(self) -> Mapping[AssetKey, "AssetChecksDefinition"]:
+        """Mapping[AssetCheckKey, AssetChecksDefinition]: The assets checks defined in the repository."""
+        return self._repository_data.get_asset_checks_defs_by_key()
 
     def has_implicit_global_asset_job_def(self) -> bool:
         """Returns true is there is a single implicit asset job for all asset keys in a repository."""
         return self.has_job(ASSET_BASE_JOB_PREFIX)
 
     def get_implicit_global_asset_job_def(self) -> JobDefinition:
         """A useful conveninence method for repositories where there are a set of assets with
@@ -279,28 +295,26 @@
         self, asset_keys: Iterable[AssetKey]
     ) -> Optional[JobDefinition]:
         """Returns the asset base job that contains all the given assets, or None if there is no such
         job.
         """
         if self.has_job(ASSET_BASE_JOB_PREFIX):
             base_job = self.get_job(ASSET_BASE_JOB_PREFIX)
+            asset_layer = base_job.asset_layer
             if all(
-                key in base_job.asset_layer.assets_defs_by_key
-                or base_job.asset_layer.is_observable_for_asset(key)
-                for key in asset_keys
+                asset_layer.has(key) and asset_layer.get(key).is_executable for key in asset_keys
             ):
                 return base_job
         else:
             i = 0
             while self.has_job(f"{ASSET_BASE_JOB_PREFIX}_{i}"):
                 base_job = self.get_job(f"{ASSET_BASE_JOB_PREFIX}_{i}")
-
+                asset_layer = base_job.asset_layer
                 if all(
-                    key in base_job.asset_layer.assets_defs_by_key
-                    or base_job.asset_layer.is_observable_for_asset(key)
+                    asset_layer.has(key) and asset_layer.get(key).is_executable
                     for key in asset_keys
                 ):
                     return base_job
 
                 i += 1
 
         return None
@@ -349,15 +363,19 @@
                 to the :py:class:`IOManager`.
 
         Returns:
             The contents of an asset as a Python object.
         """
         from dagster._core.storage.asset_value_loader import AssetValueLoader
 
-        with AssetValueLoader(self.assets_defs_by_key, instance=instance) as loader:
+        # The normalized assets defs must be obtained from the asset graph, not the repository data
+        normalized_assets_defs_by_key = {
+            k: ad for ad in self.asset_graph.assets_defs for k in ad.keys
+        }
+        with AssetValueLoader(normalized_assets_defs_by_key, instance=instance) as loader:
             return loader.load_asset_value(
                 asset_key,
                 python_type=python_type,
                 partition_key=partition_key,
                 metadata=metadata,
                 resource_config=resource_config,
             )
@@ -378,19 +396,30 @@
             with my_repo.get_asset_value_loader() as loader:
                 asset1 = loader.load_asset_value("asset1")
                 asset2 = loader.load_asset_value("asset2")
 
         """
         from dagster._core.storage.asset_value_loader import AssetValueLoader
 
-        return AssetValueLoader(self.assets_defs_by_key, instance=instance)
+        # The normalized assets defs must be obtained from the asset graph, not the repository data
+        normalized_assets_defs_by_key = {
+            k: ad for ad in self.asset_graph.assets_defs for k in ad.keys
+        }
+        return AssetValueLoader(normalized_assets_defs_by_key, instance=instance)
 
     @property
-    def asset_graph(self) -> InternalAssetGraph:
-        return InternalAssetGraph.from_assets(list(dict.fromkeys(self.assets_defs_by_key.values())))
+    @cached_method
+    def asset_graph(self) -> AssetGraph:
+        return AssetGraph.from_assets(
+            [
+                *list(set(self.assets_defs_by_key.values())),
+                *self.source_assets_by_key.values(),
+                *list(set(self.asset_checks_defs_by_key.values())),
+            ],
+        )
 
     # If definition comes from the @repository decorator, then the __call__ method will be
     # overwritten. Therefore, we want to maintain the call-ability of repository definitions.
     def __call__(self, *args, **kwargs):
         return self
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/repository_definition/valid_definitions.py` & `dagster-1.7.0/dagster/_core/definitions/repository_definition/valid_definitions.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/resolved_asset_deps.py` & `dagster-1.7.0/dagster/_core/definitions/resolved_asset_deps.py`

 * *Files 6% similar despite different names*

```diff
@@ -50,36 +50,53 @@
     error message that can help users debug their asset dependencies.
     """
     similar_names: List[AssetKey] = []
 
     target_asset_key_split = ("/".join(target_asset_key.path)).split("/")
 
     for asset_key in asset_keys:
+        *target_asset_key_prefix, target_asset_key_name = target_asset_key.path
+        *asset_key_prefix, asset_key_name = asset_key.path
+
         try:
             from rapidfuzz import fuzz
 
-            # Whether the asset key or upstream key has the same prefix and a similar
-            # name
-            # e.g. [snowflake, elementl, key] and [snowflake, elementl, ey]
-            is_same_prefix_similar_name = (
-                asset_key.path[:-1] == target_asset_key.path[:-1]
-                and fuzz.ratio(asset_key.path[-1], target_asset_key.path[-1]) > 80
+            is_similar_name = bool(
+                fuzz.ratio(asset_key_name, target_asset_key_name, score_cutoff=80)
             )
-
-            # Whether the asset key or upstream key has a similar prefix and the same
-            # name
-            # e.g. [snowflake, elementl, key] and [nowflake, elementl, key]
-            is_similar_prefix_same_name = (
-                asset_key.path[-1] == target_asset_key.path[-1]
-                and fuzz.ratio(" ".join(asset_key.path[:-1]), " ".join(target_asset_key.path[:-1]))
-                > 80
+            is_similar_prefix = bool(
+                fuzz.ratio(
+                    " ".join(asset_key_prefix),
+                    " ".join(target_asset_key_prefix),
+                    score_cutoff=80,
+                )
             )
         except ImportError:
-            is_same_prefix_similar_name = False
-            is_similar_prefix_same_name = False
+            from difflib import get_close_matches
+
+            is_similar_name = bool(
+                get_close_matches(asset_key_name, [target_asset_key_name], cutoff=0.8)
+            )
+            is_similar_prefix = bool(
+                get_close_matches(
+                    " ".join(asset_key_prefix), [" ".join(target_asset_key_prefix)], cutoff=0.8
+                )
+            )
+
+        # Whether the asset key or upstream key has the same prefix and a similar
+        # name
+        # e.g. [snowflake, elementl, key] and [snowflake, elementl, ey]
+        is_same_prefix_similar_name = (
+            asset_key_prefix == target_asset_key_prefix and is_similar_name
+        )
+
+        # Whether the asset key or upstream key has a similar prefix and the same
+        # name
+        # e.g. [snowflake, elementl, key] and [nowflake, elementl, key]
+        is_similar_prefix_same_name = asset_key_name == target_asset_key_name and is_similar_prefix
 
         # Whether the asset key or upstream key has one more prefix component than
         # the other, and the same name
         # e.g. [snowflake, elementl, key] and [snowflake, elementl, prod, key]
         is_off_by_one_prefix_component_same_name = (
             asset_key.path[-1] == target_asset_key.path[-1]
             and len(set(asset_key.path).symmetric_difference(set(target_asset_key.path))) == 1
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/resource_annotation.py` & `dagster-1.7.0/dagster/_core/definitions/resource_annotation.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/resource_definition.py` & `dagster-1.7.0/dagster/_core/definitions/resource_definition.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/resource_invocation.py` & `dagster-1.7.0/dagster/_core/definitions/resource_invocation.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/resource_requirement.py` & `dagster-1.7.0/dagster/_core/definitions/resource_requirement.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/result.py` & `dagster-1.7.0/dagster/_core/definitions/result.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/run_config.py` & `dagster-1.7.0/dagster/_core/definitions/run_config.py`

 * *Files 2% similar despite different names*

```diff
@@ -45,15 +45,15 @@
 from .dependency import DependencyStructure, GraphNode, Node, NodeHandle, NodeInput, OpNode
 from .graph_definition import GraphDefinition
 from .logger_definition import LoggerDefinition
 from .op_definition import NodeDefinition, OpDefinition
 from .resource_definition import ResourceDefinition
 
 if TYPE_CHECKING:
-    from .source_asset import SourceAsset
+    from .assets import AssetsDefinition
 
 
 def define_resource_dictionary_cls(
     resource_defs: Mapping[str, ResourceDefinition],
     required_resources: AbstractSet[str],
 ) -> Shape:
     fields = {}
@@ -167,15 +167,15 @@
         "inputs": get_inputs_field(
             node=top_level_node,
             handle=NodeHandle(top_level_node.name, parent=None),
             dependency_structure=creation_data.dependency_structure,
             resource_defs=creation_data.resource_defs,
             node_ignored=False,
             direct_inputs=creation_data.direct_inputs,
-            input_source_assets={},
+            input_assets={},
             asset_layer=creation_data.asset_layer,
         ),
     }
 
     if creation_data.graph_def.has_config_mapping:
         config_schema = cast(IDefinitionConfigSchema, creation_data.graph_def.config_schema)
         nodes_field = Field(
@@ -186,15 +186,15 @@
         nodes_field = Field(
             define_node_shape(
                 nodes=creation_data.nodes,
                 ignored_nodes=creation_data.ignored_nodes,
                 dependency_structure=creation_data.dependency_structure,
                 resource_defs=creation_data.resource_defs,
                 asset_layer=creation_data.asset_layer,
-                node_input_source_assets=creation_data.graph_def.node_input_source_assets,
+                input_assets=creation_data.graph_def.input_assets,
             ),
             description="Configure runtime parameters for ops or assets.",
         )
 
     fields["ops"] = nodes_field
 
     return Shape(
@@ -211,35 +211,34 @@
 def get_inputs_field(
     node: Node,
     handle: NodeHandle,
     dependency_structure: DependencyStructure,
     resource_defs: Mapping[str, ResourceDefinition],
     node_ignored: bool,
     asset_layer: AssetLayer,
-    input_source_assets: Mapping[str, "SourceAsset"],
+    input_assets: Mapping[str, "AssetsDefinition"],
     direct_inputs: Optional[Mapping[str, Any]] = None,
 ) -> Optional[Field]:
     direct_inputs = check.opt_mapping_param(direct_inputs, "direct_inputs")
     inputs_field_fields = {}
     for name, inp in node.definition.input_dict.items():
         inp_handle = NodeInput(node, inp)
         has_upstream = input_has_upstream(dependency_structure, inp_handle, node, name)
         if inp.input_manager_key:
             input_field = get_input_manager_input_field(node, inp, resource_defs)
         elif (
-            # if you have asset definitions, input will be loaded from the source asset
-            asset_layer.has_assets_defs
-            or asset_layer.has_asset_check_defs
+            # if you have assets defs, input will be loaded from the source asset
+            asset_layer.assets_defs
             and asset_layer.asset_key_for_input(handle, name)
             and not has_upstream
         ):
             input_field = None
         elif name in direct_inputs and not has_upstream:
             input_field = None
-        elif name in input_source_assets and not has_upstream:
+        elif name in input_assets and not has_upstream:
             input_field = None
         elif inp.dagster_type.loader and not has_upstream:
             input_field = get_type_loader_input_field(node, name, inp)
         else:
             input_field = None
 
         if input_field:
@@ -369,26 +368,26 @@
     node: Node,
     handle: NodeHandle,
     dependency_structure: DependencyStructure,
     config_schema: Optional[IDefinitionConfigSchema],
     resource_defs: Mapping[str, ResourceDefinition],
     ignored: bool,
     asset_layer: AssetLayer,
-    input_source_assets: Mapping[str, "SourceAsset"],
+    input_assets: Mapping[str, "AssetsDefinition"],
 ) -> Optional[Field]:
     return node_config_field(
         {
             "inputs": get_inputs_field(
                 node,
                 handle,
                 dependency_structure,
                 resource_defs,
                 ignored,
                 asset_layer,
-                input_source_assets,
+                input_assets,
             ),
             "outputs": get_outputs_field(node, resource_defs),
             "config": config_schema.as_field() if config_schema else None,
         },
         ignored=ignored,
     )
 
@@ -396,15 +395,15 @@
 def define_node_field(
     node: Node,
     handle: NodeHandle,
     dependency_structure: DependencyStructure,
     resource_defs: Mapping[str, ResourceDefinition],
     ignored: bool,
     asset_layer: AssetLayer,
-    input_source_assets: Mapping[str, "SourceAsset"],
+    input_assets: Mapping[str, "AssetsDefinition"],
 ) -> Optional[Field]:
     # All nodes regardless of compositing status get the same inputs and outputs
     # config. The only thing the varies is on extra element of configuration
     # 1) Vanilla op definition: a 'config' key with the config_schema as the value
     # 2) Graph with field mapping: a 'config' key with the config_schema of
     #    the config mapping (via GraphDefinition#config_schema)
     # 3) Graph without field mapping: an 'ops' key with recursively defined
@@ -419,15 +418,15 @@
             node,
             handle,
             dependency_structure,
             node.definition.config_schema,
             resource_defs,
             ignored,
             asset_layer,
-            input_source_assets,
+            input_assets,
         )
 
     graph_def = node.definition
 
     if graph_def.has_config_mapping:
         # has_config_mapping covers cases 2 & 4 from above (only config mapped graphs can
         # be `configured`)...
@@ -436,53 +435,53 @@
             handle,
             dependency_structure,
             # ...and in both cases, the correct schema for 'config' key is exposed by this property:
             graph_def.config_schema,
             resource_defs,
             ignored,
             asset_layer,
-            input_source_assets,
+            input_assets,
         )
         # This case omits an 'ops' key, thus if a graph is `configured` or has a field
         # mapping, the user cannot stub any config, inputs, or outputs for inner (child) nodes.
     else:
         fields = {
             "inputs": get_inputs_field(
                 node,
                 handle,
                 dependency_structure,
                 resource_defs,
                 ignored,
                 asset_layer,
-                input_source_assets,
+                input_assets,
             ),
             "outputs": get_outputs_field(node, resource_defs),
             "ops": Field(
                 define_node_shape(
                     nodes=graph_def.nodes,
                     ignored_nodes=None,
                     dependency_structure=graph_def.dependency_structure,
                     parent_handle=handle,
                     resource_defs=resource_defs,
                     asset_layer=asset_layer,
-                    node_input_source_assets=graph_def.node_input_source_assets,
+                    input_assets=graph_def.input_assets,
                 )
             ),
         }
 
         return node_config_field(fields, ignored=ignored)
 
 
 def define_node_shape(
     nodes: Sequence[Node],
     ignored_nodes: Optional[Sequence[Node]],
     dependency_structure: DependencyStructure,
     resource_defs: Mapping[str, ResourceDefinition],
     asset_layer: AssetLayer,
-    node_input_source_assets: Mapping[str, Mapping[str, "SourceAsset"]],
+    input_assets: Mapping[str, Mapping[str, "AssetsDefinition"]],
     parent_handle: Optional[NodeHandle] = None,
 ) -> Shape:
     """Examples of what this method is used to generate the schema for:
     1.
         inputs: ...
         ops:
       >    op1: ...
@@ -506,29 +505,29 @@
         node_field = define_node_field(
             node,
             NodeHandle(node.name, parent_handle),
             dependency_structure,
             resource_defs,
             ignored=False,
             asset_layer=asset_layer,
-            input_source_assets=node_input_source_assets.get(node.name, {}),
+            input_assets=input_assets.get(node.name, {}),
         )
 
         if node_field:
             fields[node.name] = node_field
 
     for node in ignored_nodes:
         node_field = define_node_field(
             node,
             NodeHandle(node.name, parent_handle),
             dependency_structure,
             resource_defs,
             ignored=True,
             asset_layer=asset_layer,
-            input_source_assets=node_input_source_assets.get(node.name, {}),
+            input_assets=input_assets.get(node.name, {}),
         )
         if node_field:
             fields[node.name] = node_field
 
     return Shape(fields)
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/run_config_schema.py` & `dagster-1.7.0/dagster/_core/definitions/run_config_schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/run_request.py` & `dagster-1.7.0/dagster/_core/definitions/run_request.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,17 +12,18 @@
     Union,
     cast,
 )
 
 import dagster._check as check
 from dagster._annotations import PublicAttr, experimental_param
 from dagster._core.definitions.asset_check_evaluation import AssetCheckEvaluation
+from dagster._core.definitions.asset_check_spec import AssetCheckKey
 from dagster._core.definitions.events import AssetKey, AssetMaterialization, AssetObservation
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
-from dagster._core.definitions.utils import validate_tags
+from dagster._core.definitions.utils import NormalizedTags, normalize_tags
 from dagster._core.instance import DynamicPartitionsStore
 from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._core.storage.tags import (
     ASSET_PARTITION_RANGE_END_TAG,
     ASSET_PARTITION_RANGE_START_TAG,
     PARTITION_NAME_TAG,
 )
@@ -118,14 +119,15 @@
             ("run_key", PublicAttr[Optional[str]]),
             ("run_config", PublicAttr[Mapping[str, Any]]),
             ("tags", PublicAttr[Mapping[str, str]]),
             ("job_name", PublicAttr[Optional[str]]),
             ("asset_selection", PublicAttr[Optional[Sequence[AssetKey]]]),
             ("stale_assets_only", PublicAttr[bool]),
             ("partition_key", PublicAttr[Optional[str]]),
+            ("asset_check_keys", PublicAttr[Optional[Sequence[AssetCheckKey]]]),
         ],
     )
 ):
     """Represents all the information required to launch a single run.  Must be returned by a
     SensorDefinition or ScheduleDefinition's evaluation function for a run to be launched.
 
     Attributes:
@@ -142,45 +144,56 @@
             Required for sensors that target multiple jobs.
         asset_selection (Optional[Sequence[AssetKey]]): A subselection of assets that should be
             launched with this run. If the sensor or schedule targets a job, then by default a
             RunRequest returned from it will launch all of the assets in the job. If the sensor
             targets an asset selection, then by default a RunRequest returned from it will launch
             all the assets in the selection. This argument is used to specify that only a subset of
             these assets should be launched, instead of all of them.
+        asset_check_keys (Optional[Sequence[AssetCheckKey]]): (Experimental) A subselection of asset checks that
+            should be launched with this run. This is currently only supported on sensors. If the
+            sensor targets a job, then by default a RunRequest returned from it will launch all of
+            the asset checks in the job. If the sensor targets an asset selection, then by default a
+            RunRequest returned from it will launch all the asset checks in the selection. This
+            argument is used to specify that only a subset of these asset checks should be launched,
+            instead of all of them.
         stale_assets_only (bool): Set to true to further narrow the asset
             selection to stale assets. If passed without an asset selection, all stale assets in the
             job will be materialized. If the job does not materialize assets, this flag is ignored.
         partition_key (Optional[str]): The partition key for this run request.
     """
 
     def __new__(
         cls,
         run_key: Optional[str] = None,
         run_config: Optional[Union["RunConfig", Mapping[str, Any]]] = None,
-        tags: Optional[Mapping[str, Any]] = None,
+        tags: Union[NormalizedTags, Optional[Mapping[str, Any]]] = None,
         job_name: Optional[str] = None,
         asset_selection: Optional[Sequence[AssetKey]] = None,
         stale_assets_only: bool = False,
         partition_key: Optional[str] = None,
+        asset_check_keys: Optional[Sequence[AssetCheckKey]] = None,
     ):
         from dagster._core.definitions.run_config import convert_config_input
 
         return super(RunRequest, cls).__new__(
             cls,
             run_key=check.opt_str_param(run_key, "run_key"),
             run_config=check.opt_mapping_param(
                 convert_config_input(run_config), "run_config", key_type=str
             ),
-            tags=validate_tags(check.opt_mapping_param(tags, "tags", key_type=str)),
+            tags=normalize_tags(tags).tags,
             job_name=check.opt_str_param(job_name, "job_name"),
             asset_selection=check.opt_nullable_sequence_param(
                 asset_selection, "asset_selection", of_type=AssetKey
             ),
             stale_assets_only=check.bool_param(stale_assets_only, "stale_assets_only"),
             partition_key=check.opt_str_param(partition_key, "partition_key"),
+            asset_check_keys=check.opt_nullable_sequence_param(
+                asset_check_keys, "asset_check_keys", of_type=AssetCheckKey
+            ),
         )
 
     def with_replaced_attrs(self, **kwargs: Any) -> "RunRequest":
         fields = self._asdict()
         for k in fields.keys():
             if k in kwargs:
                 fields[k] = kwargs[k]
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/run_status_sensor_definition.py` & `dagster-1.7.0/dagster/_core/definitions/run_status_sensor_definition.py`

 * *Files 2% similar despite different names*

```diff
@@ -765,37 +765,47 @@
                 dagster_run = run_records[0].dagster_run
                 job_match = False
 
                 # if monitor_all_repositories is provided, then we want to run the sensor for all jobs in all repositories
                 if monitor_all_code_locations:
                     job_match = True
 
+                code_location_name = (
+                    context.code_location_origin.location_name
+                    if context.code_location_origin
+                    else None
+                )
+
                 # check if the run is in the current repository and (if provided) one of jobs specified in monitored_jobs
                 if (
                     not job_match
                     and
                     # the job has a repository (not manually executed)
                     dagster_run.external_job_origin
                     and
+                    # the job belongs to the current code location
+                    dagster_run.external_job_origin.repository_origin.code_location_origin.location_name
+                    == code_location_name
+                    and
                     # the job belongs to the current repository
-                    dagster_run.external_job_origin.external_repository_origin.repository_name
+                    dagster_run.external_job_origin.repository_origin.repository_name
                     == context.repository_name
                 ):
                     if monitored_jobs:
                         if dagster_run.job_name in map(lambda x: x.name, current_repo_jobs):
                             job_match = True
                     else:
                         job_match = True
 
                 if not job_match:
                     # check if the run is one of the jobs specified by JobSelector or RepositorySelector (ie in another repo)
                     # make a JobSelector for the run in question
                     external_repository_origin = check.not_none(
                         dagster_run.external_job_origin
-                    ).external_repository_origin
+                    ).repository_origin
                     run_job_selector = JobSelector(
                         location_name=external_repository_origin.code_location_origin.location_name,
                         repository_name=external_repository_origin.repository_name,
                         job_name=dagster_run.job_name,
                     )
                     if run_job_selector in other_repo_jobs:
                         job_match = True
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/schedule_definition.py` & `dagster-1.7.0/dagster/_core/definitions/schedule_definition.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 import copy
 import logging
+import warnings
 from contextlib import ExitStack
 from datetime import datetime
 from enum import Enum
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
@@ -27,15 +28,15 @@
 from dagster._core.definitions.instigation_logger import InstigationLogger
 from dagster._core.definitions.resource_annotation import get_resource_args
 from dagster._core.definitions.scoped_resources_builder import Resources, ScopedResourcesBuilder
 from dagster._serdes import whitelist_for_serdes
 from dagster._seven.compat.pendulum import pendulum_create_timezone
 from dagster._utils import IHasInternalInit, ensure_gen
 from dagster._utils.merger import merge_dicts
-from dagster._utils.schedules import is_valid_cron_schedule
+from dagster._utils.schedules import has_out_of_range_cron_interval, is_valid_cron_schedule
 
 from ..decorator_utils import has_at_least_one_parameter
 from ..errors import (
     DagsterInvalidDefinitionError,
     DagsterInvalidInvocationError,
     DagsterInvariantViolationError,
     ScheduleExecutionError,
@@ -45,15 +46,15 @@
 from ..instance.ref import InstanceRef
 from ..storage.dagster_run import DagsterRun
 from .graph_definition import GraphDefinition
 from .job_definition import JobDefinition
 from .run_request import RunRequest, SkipReason
 from .target import DirectTarget, ExecutableDefinition, RepoRelativeTarget
 from .unresolved_asset_job_definition import UnresolvedAssetJobDefinition
-from .utils import check_valid_name, validate_tags
+from .utils import NormalizedTags, check_valid_name, normalize_tags
 
 if TYPE_CHECKING:
     from dagster import ResourceDefinition
     from dagster._core.definitions.repository_definition import RepositoryDefinition
 T = TypeVar("T")
 
 RunConfig: TypeAlias = Mapping[str, Any]
@@ -554,15 +555,15 @@
         self,
         name: Optional[str] = None,
         *,
         cron_schedule: Optional[Union[str, Sequence[str]]] = None,
         job_name: Optional[str] = None,
         run_config: Optional[Any] = None,
         run_config_fn: Optional[ScheduleRunConfigFunction] = None,
-        tags: Optional[Mapping[str, str]] = None,
+        tags: Union[NormalizedTags, Optional[Mapping[str, str]]] = None,
         tags_fn: Optional[ScheduleTagsFunction] = None,
         should_execute: Optional[ScheduleShouldExecuteFunction] = None,
         environment_vars: Optional[Mapping[str, str]] = None,
         execution_timezone: Optional[str] = None,
         execution_fn: Optional[ScheduleExecutionFunction] = None,
         description: Optional[str] = None,
         job: Optional[ExecutableDefinition] = None,
@@ -574,14 +575,22 @@
             check.sequence_param(self._cron_schedule, "cron_schedule", of_type=str)  # type: ignore
 
         if not is_valid_cron_schedule(self._cron_schedule):  # type: ignore
             raise DagsterInvalidDefinitionError(
                 f"Found invalid cron schedule '{self._cron_schedule}' for schedule '{name}''. "
                 "Dagster recognizes standard cron expressions consisting of 5 fields."
             )
+        if has_out_of_range_cron_interval(self._cron_schedule):  # type: ignore
+            warnings.warn(
+                "Found a cron schedule with an interval greater than the expected range for"
+                f" schedule '{name}'. Dagster currently normalizes this to an interval that may"
+                " fire more often than expected. You may want to break this cron schedule up into"
+                " a sequence of cron schedules. See"
+                " https://github.com/dagster-io/dagster/issues/15294 for more information."
+            )
 
         if job is not None:
             self._target: Union[DirectTarget, RepoRelativeTarget] = DirectTarget(job)
         else:
             self._target = RepoRelativeTarget(
                 job_name=check.str_param(job_name, "job_name"),
                 op_selection=None,
@@ -592,15 +601,15 @@
         elif job_name:
             self._name = job_name + "_schedule"
         elif job:
             self._name = job.name + "_schedule"
 
         self._description = check.opt_str_param(description, "description")
 
-        self._environment_vars = check.opt_mapping_param(
+        self._environment_vars = check.opt_nullable_mapping_param(
             environment_vars, "environment_vars", key_type=str, value_type=str
         )
 
         self._execution_timezone = check.opt_str_param(execution_timezone, "execution_timezone")
 
         if execution_fn and (run_config_fn or tags_fn or should_execute or tags or run_config):
             raise DagsterInvalidDefinitionError(
@@ -632,15 +641,15 @@
 
             if tags_fn and tags:
                 raise DagsterInvalidDefinitionError(
                     "Attempted to provide both tags_fn and tags as arguments"
                     " to ScheduleDefinition. Must provide only one of the two."
                 )
             elif tags:
-                tags = validate_tags(tags, allow_reserved_tags=False)
+                tags = normalize_tags(tags, allow_reserved_tags=False).tags
                 tags_fn = lambda _context: tags
             else:
                 tags_fn = check.opt_callable_param(
                     tags_fn, "tags_fn", default=lambda _context: cast(Mapping[str, str], {})
                 )
             self._tags_fn = tags_fn
             self._tags = tags
@@ -675,15 +684,15 @@
                         else _run_config_fn()  # type: ignore  # (strict type guard)
                     )
 
                 with user_code_error_boundary(
                     ScheduleExecutionError,
                     lambda: f"Error occurred during the execution of tags_fn for schedule {name}",
                 ):
-                    evaluated_tags = validate_tags(tags_fn(context), allow_reserved_tags=False)
+                    evaluated_tags = normalize_tags(tags_fn(context), allow_reserved_tags=False)
 
                 yield RunRequest(
                     run_key=None,
                     run_config=evaluated_run_config,
                     tags=evaluated_tags,
                 )
 
@@ -807,15 +816,15 @@
 
     @public
     @deprecated(
         breaking_version="2.0",
         additional_warn_text="Setting this property no longer has any effect.",
     )
     @property
-    def environment_vars(self) -> Mapping[str, str]:
+    def environment_vars(self) -> Optional[Mapping[str, str]]:
         """Mapping[str, str]: Environment variables to export to the cron schedule."""
         return self._environment_vars
 
     @public
     @property
     def required_resource_keys(self) -> Set[str]:
         """Set[str]: The set of keys for resources that must be provided to this schedule."""
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/scoped_resources_builder.py` & `dagster-1.7.0/dagster/_core/definitions/scoped_resources_builder.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/selector.py` & `dagster-1.7.0/dagster/_core/definitions/selector.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/sensor_definition.py` & `dagster-1.7.0/dagster/_core/definitions/sensor_definition.py`

 * *Files 2% similar despite different names*

```diff
@@ -59,15 +59,15 @@
 from dagster._utils import IHasInternalInit, normalize_to_repository
 from dagster._utils.merger import merge_dicts
 from dagster._utils.warnings import normalize_renamed_param
 
 from ..decorator_utils import (
     get_function_params,
 )
-from .asset_selection import AssetSelection
+from .asset_selection import AssetSelection, KeysAssetSelection
 from .graph_definition import GraphDefinition
 from .run_request import (
     AddDynamicPartitionsRequest,
     DagsterRunReaction,
     DeleteDynamicPartitionsRequest,
     RunRequest,
     SensorResult,
@@ -77,14 +77,15 @@
 from .unresolved_asset_job_definition import UnresolvedAssetJobDefinition
 from .utils import check_valid_name
 
 if TYPE_CHECKING:
     from dagster import ResourceDefinition
     from dagster._core.definitions.definitions_class import Definitions
     from dagster._core.definitions.repository_definition import RepositoryDefinition
+    from dagster._core.remote_representation.origin import CodeLocationOrigin
 
 
 @whitelist_for_serdes
 class DefaultSensorStatus(Enum):
     RUNNING = "RUNNING"
     STOPPED = "STOPPED"
 
@@ -131,14 +132,15 @@
             directly (primarily useful in testing contexts).
         definitions (Optional[Definitions]): `Definitions` object that the sensor is defined in.
             If needed by the sensor, top-level resource definitions will be pulled from these
             definitions. You can provide either this or `repository_def`.
         resources (Optional[Dict[str, Any]]): A dict of resource keys to resource
             definitions to be made available during sensor execution.
         last_sensor_start_time (float): The last time that the sensor was started (UTC).
+        code_location_origin (Optional[CodeLocationOrigin]): The code location that the sensor is in.
 
     Example:
         .. code-block:: python
 
             from dagster import sensor, SensorEvaluationContext
 
             @sensor
@@ -157,19 +159,21 @@
         repository_name: Optional[str] = None,
         repository_def: Optional["RepositoryDefinition"] = None,
         instance: Optional[DagsterInstance] = None,
         sensor_name: Optional[str] = None,
         resources: Optional[Mapping[str, "ResourceDefinition"]] = None,
         definitions: Optional["Definitions"] = None,
         last_sensor_start_time: Optional[float] = None,
+        code_location_origin: Optional["CodeLocationOrigin"] = None,
         # deprecated param
         last_completion_time: Optional[float] = None,
     ):
         from dagster._core.definitions.definitions_class import Definitions
         from dagster._core.definitions.repository_definition import RepositoryDefinition
+        from dagster._core.remote_representation.origin import CodeLocationOrigin
 
         self._exit_stack = ExitStack()
         self._instance_ref = check.opt_inst_param(instance_ref, "instance_ref", InstanceRef)
         self._last_tick_completion_time = normalize_renamed_param(
             last_tick_completion_time,
             "last_tick_completion_time",
             last_completion_time,
@@ -182,14 +186,17 @@
         self._cursor = check.opt_str_param(cursor, "cursor")
         self._repository_name = check.opt_str_param(repository_name, "repository_name")
         self._repository_def = normalize_to_repository(
             check.opt_inst_param(definitions, "definitions", Definitions),
             check.opt_inst_param(repository_def, "repository_def", RepositoryDefinition),
             error_on_none=False,
         )
+        self._code_location_origin = check.opt_inst_param(
+            code_location_origin, "code_location_origin", CodeLocationOrigin
+        )
         self._instance = check.opt_inst_param(instance, "instance", DagsterInstance)
         self._sensor_name = sensor_name
 
         # Wait to set resources unless they're accessed
         self._resource_defs = resources
         self._resources = None
         self._cm_scope_entered = False
@@ -248,14 +255,15 @@
             instance=self._instance,
             sensor_name=self._sensor_name,
             resources={
                 **(self._resource_defs or {}),
                 **wrap_resources_for_execution(resources_dict),
             },
             last_sensor_start_time=self._last_sensor_start_time,
+            code_location_origin=self.code_location_origin,
         )
 
     @public
     @property
     def resources(self) -> Resources:
         """Resources: A mapping from resource key to instantiated resources for this sensor."""
         from dagster._core.definitions.scoped_resources_builder import (
@@ -399,14 +407,19 @@
     @public
     @property
     def repository_def(self) -> Optional["RepositoryDefinition"]:
         """Optional[RepositoryDefinition]: The RepositoryDefinition that this sensor resides in."""
         return self._repository_def
 
     @property
+    def code_location_origin(self) -> Optional["CodeLocationOrigin"]:
+        """Optional[CodeLocationOrigin]: The CodeLocation that this sensor resides in."""
+        return self._code_location_origin
+
+    @property
     def log(self) -> logging.Logger:
         if self._logger:
             return self._logger
 
         if not self._instance_ref:
             self._logger = self._exit_stack.enter_context(
                 InstigationLogger(
@@ -789,16 +802,15 @@
         ] = []
         updated_cursor = context.cursor
         asset_events = []
 
         if not result or result == [None]:
             skip_message = "Sensor function returned an empty result"
         elif len(result) == 1:
-            item = result[0]
-            check.inst(item, (SkipReason, RunRequest, DagsterRunReaction, SensorResult))
+            item = check.inst(result[0], (SkipReason, RunRequest, DagsterRunReaction, SensorResult))
 
             if isinstance(item, SensorResult):
                 run_requests = list(item.run_requests) if item.run_requests else []
                 skip_message = (
                     item.skip_reason.skip_message
                     if item.skip_reason
                     else (None if run_requests else "Sensor function returned an empty result")
@@ -1272,15 +1284,15 @@
     asset_graph = context.repository_def.asset_graph  # type: ignore  # (possible none)
     result = []
     for run_request in run_requests:
         if run_request.asset_selection:
             asset_keys = run_request.asset_selection
 
             unexpected_asset_keys = (
-                AssetSelection.keys(*asset_keys) - outer_asset_selection
+                KeysAssetSelection(selected_keys=asset_keys) - outer_asset_selection
             ).resolve(asset_graph)
             if unexpected_asset_keys:
                 raise DagsterInvalidSubsetError(
                     "RunRequest includes asset keys that are not part of sensor's asset_selection:"
                     f" {unexpected_asset_keys}"
                 )
         else:
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/source_asset.py` & `dagster-1.7.0/dagster/_core/definitions/source_asset.py`

 * *Files 1% similar despite different names*

```diff
@@ -47,14 +47,16 @@
 )
 from dagster._core.errors import (
     DagsterInvalidDefinitionError,
     DagsterInvalidInvocationError,
     DagsterInvalidObservationError,
 )
 
+from .utils import validate_definition_tags
+
 if TYPE_CHECKING:
     from dagster._core.definitions.decorators.op_decorator import (
         DecoratedOpFunction,
     )
 from dagster._core.storage.io_manager import IOManagerDefinition
 from dagster._utils.merger import merge_dicts
 from dagster._utils.warnings import disable_dagster_warnings
@@ -150,14 +152,15 @@
 
     return DecoratedOpFunction(fn)
 
 
 @experimental_param(param="resource_defs")
 @experimental_param(param="io_manager_def")
 @experimental_param(param="freshness_policy")
+@experimental_param(param="tags")
 class SourceAsset(ResourceAddable):
     """A SourceAsset represents an asset that will be loaded by (but not updated by) Dagster.
 
     Attributes:
         key (Union[AssetKey, Sequence[str], str]): The key of the asset.
         metadata (Mapping[str, MetadataValue]): Metadata associated with the asset.
         io_manager_key (Optional[str]): The key for the IOManager that will be used to load the contents of
@@ -174,14 +177,16 @@
             are not strings will be json encoded and must meet the criteria that
             `json.loads(json.dumps(value)) == value`.
         auto_observe_interval_minutes (Optional[float]): While the asset daemon is turned on, a run
             of the observation function for this asset will be launched at this interval. `observe_fn`
             must be provided.
         freshness_policy (FreshnessPolicy): A constraint telling Dagster how often this asset is intended to be updated
             with respect to its root data.
+        tags (Optional[Mapping[str, str]]): Tags for filtering and organizing. These tags are not
+            attached to runs of the asset.
     """
 
     key: PublicAttr[AssetKey]
     metadata: PublicAttr[MetadataMapping]
     raw_metadata: PublicAttr[ArbitraryMetadataMapping]
     io_manager_key: PublicAttr[Optional[str]]
     _io_manager_def: PublicAttr[Optional[IOManagerDefinition]]
@@ -190,14 +195,15 @@
     group_name: PublicAttr[str]
     resource_defs: PublicAttr[Dict[str, ResourceDefinition]]
     observe_fn: PublicAttr[Optional[SourceAssetObserveFunction]]
     op_tags: Optional[Mapping[str, Any]]
     _node_def: Optional[OpDefinition]  # computed lazily
     auto_observe_interval_minutes: Optional[float]
     freshness_policy: Optional[FreshnessPolicy]
+    tags: Optional[Mapping[str, str]]
 
     def __init__(
         self,
         key: CoercibleToAssetKey,
         metadata: Optional[ArbitraryMetadataMapping] = None,
         io_manager_key: Optional[str] = None,
         io_manager_def: Optional[object] = None,
@@ -206,14 +212,15 @@
         group_name: Optional[str] = None,
         resource_defs: Optional[Mapping[str, object]] = None,
         observe_fn: Optional[SourceAssetObserveFunction] = None,
         op_tags: Optional[Mapping[str, Any]] = None,
         *,
         auto_observe_interval_minutes: Optional[float] = None,
         freshness_policy: Optional[FreshnessPolicy] = None,
+        tags: Optional[Mapping[str, str]] = None,
         # This is currently private because it is necessary for source asset observation functions,
         # but we have not yet decided on a final API for associated one or more ops with a source
         # asset. If we were to make this public, then we would have a canonical public
         # `required_resource_keys` used for observation that might end up conflicting with a set of
         # required resource keys for a different operation.
         _required_resource_keys: Optional[AbstractSet[str]] = None,
         # Add additional fields to with_resources and with_group below
@@ -222,14 +229,15 @@
             wrap_resources_for_execution,
         )
 
         self.key = AssetKey.from_coercible(key)
         metadata = check.opt_mapping_param(metadata, "metadata", key_type=str)
         self.raw_metadata = metadata
         self.metadata = normalize_metadata(metadata, allow_invalid=True)
+        self.tags = validate_definition_tags(tags) or {}
 
         resource_defs_dict = dict(check.opt_mapping_param(resource_defs, "resource_defs"))
         if io_manager_def:
             if not io_manager_key:
                 io_manager_key = self.key.to_python_identifier("io_manager")
 
             if (
@@ -376,14 +384,15 @@
                 partitions_def=self.partitions_def,
                 metadata=self.raw_metadata,
                 resource_defs=relevant_resource_defs,
                 group_name=self.group_name,
                 observe_fn=self.observe_fn,
                 auto_observe_interval_minutes=self.auto_observe_interval_minutes,
                 freshness_policy=self.freshness_policy,
+                tags=self.tags,
                 _required_resource_keys=self._required_resource_keys,
             )
 
     def with_attributes(
         self, group_name: Optional[str] = None, key: Optional[AssetKey] = None
     ) -> "SourceAsset":
         if group_name is not None and self.group_name != DEFAULT_GROUP_NAME:
@@ -396,18 +405,19 @@
             return SourceAsset(
                 key=key or self.key,
                 metadata=self.raw_metadata,
                 io_manager_key=self.io_manager_key,
                 io_manager_def=self.io_manager_def,
                 description=self.description,
                 partitions_def=self.partitions_def,
-                group_name=group_name,
+                group_name=group_name or self.group_name,
                 resource_defs=self.resource_defs,
                 observe_fn=self.observe_fn,
                 auto_observe_interval_minutes=self.auto_observe_interval_minutes,
+                tags=self.tags,
                 _required_resource_keys=self._required_resource_keys,
             )
 
     def get_resource_requirements(self) -> Iterator[ResourceRequirement]:
         if self.node_def is not None:
             yield from self.node_def.get_resource_requirements()
         yield SourceAssetIOManagerRequirement(
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/step_launcher.py` & `dagster-1.7.0/dagster/_core/definitions/step_launcher.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/target.py` & `dagster-1.7.0/dagster/_core/definitions/target.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/time_window_partition_mapping.py` & `dagster-1.7.0/dagster/_core/definitions/time_window_partition_mapping.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/definitions/time_window_partitions.py` & `dagster-1.7.0/dagster/_core/definitions/time_window_partitions.py`

 * *Files 0% similar despite different names*

```diff
@@ -230,14 +230,22 @@
         start (datetime): A pendulum datetime that marks the start of the window.
         end (datetime): A pendulum datetime that marks the end of the window.
     """
 
     start: PublicAttr[datetime]
     end: PublicAttr[datetime]
 
+    @property
+    def is_empty(self) -> bool:
+        return self.start == self.end
+
+    @staticmethod
+    def empty() -> "TimeWindow":
+        return TimeWindow(start=datetime.max, end=datetime.max)
+
 
 @whitelist_for_serdes(
     field_serializers={"start": DatetimeFieldSerializer, "end": DatetimeFieldSerializer},
     is_pickleable=False,
 )
 class TimeWindowPartitionsDefinition(
     PartitionsDefinition,
@@ -2037,15 +2045,15 @@
             included_partition_keys=self._included_partition_keys,
         )
 
     def __repr__(self) -> str:
         return f"PartitionKeysTimeWindowPartitionsSubset({self.get_partition_key_ranges(self.partitions_def)})"
 
     def to_serializable_subset(self) -> "TimeWindowPartitionsSubset":
-        from dagster._core.host_representation.external_data import (
+        from dagster._core.remote_representation.external_data import (
             external_time_window_partitions_definition_from_def,
         )
 
         # in cases where we're dealing with (e.g.) HourlyPartitionsDefinition, we need to convert
         # this partitions definition into a raw TimeWindowPartitionsDefinition to make it
         # serializable. to do this, we just convert it to its external representation and back.
         partitions_def = self.partitions_def
@@ -2199,15 +2207,15 @@
             included_time_windows=self.included_time_windows,
         )
 
     def __repr__(self) -> str:
         return f"TimeWindowPartitionsSubset({self.get_partition_key_ranges(self.partitions_def)})"
 
     def to_serializable_subset(self) -> "TimeWindowPartitionsSubset":
-        from dagster._core.host_representation.external_data import (
+        from dagster._core.remote_representation.external_data import (
             external_time_window_partitions_definition_from_def,
         )
 
         # in cases where we're dealing with (e.g.) HourlyPartitionsDefinition, we need to convert
         # this partitions definition into a raw TimeWindowPartitionsDefinition to make it
         # serializable. to do this, we just convert it to its external representation and back.
         # note that we rarely serialize subsets on the user code side of a serialization boundary,
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/unresolved_asset_job_definition.py` & `dagster-1.7.0/dagster/_core/definitions/unresolved_asset_job_definition.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,35 +1,34 @@
-from collections import defaultdict
 from datetime import datetime
 from typing import TYPE_CHECKING, AbstractSet, Any, Mapping, NamedTuple, Optional, Sequence, Union
 
 import dagster._check as check
 from dagster._annotations import deprecated
 from dagster._core.definitions import AssetKey
+from dagster._core.definitions.asset_job import build_asset_job, get_asset_graph_for_job
 from dagster._core.definitions.run_request import RunRequest
 from dagster._core.errors import DagsterInvalidDefinitionError
 from dagster._core.instance import DynamicPartitionsStore
 
-from .asset_layer import build_asset_selection_job
 from .config import ConfigMapping
 from .metadata import RawMetadataValue
 from .policy import RetryPolicy
 
 if TYPE_CHECKING:
     from dagster._core.definitions import (
         AssetSelection,
         ExecutorDefinition,
         HookDefinition,
         JobDefinition,
         PartitionedConfig,
         PartitionsDefinition,
         ResourceDefinition,
     )
+    from dagster._core.definitions.asset_graph import AssetGraph
     from dagster._core.definitions.asset_selection import CoercibleToAssetSelection
-    from dagster._core.definitions.internal_asset_graph import InternalAssetGraph
     from dagster._core.definitions.run_config import RunConfig
 
 
 class UnresolvedAssetJobDefinition(
     NamedTuple(
         "_UnresolvedAssetJobDefinition",
         [
@@ -172,79 +171,34 @@
             tags=run_request_tags,
             asset_selection=asset_selection,
             partition_key=partition_key,
         )
 
     def resolve(
         self,
-        asset_graph: "InternalAssetGraph",
+        asset_graph: "AssetGraph",
         default_executor_def: Optional["ExecutorDefinition"] = None,
         resource_defs: Optional[Mapping[str, "ResourceDefinition"]] = None,
     ) -> "JobDefinition":
         """Resolve this UnresolvedAssetJobDefinition into a JobDefinition."""
-        assets = asset_graph.assets_defs
-        selected_asset_keys = self.selection.resolve(asset_graph)
-
-        if (
-            len(selected_asset_keys & asset_graph.materializable_asset_keys) > 0
-            and len(selected_asset_keys & asset_graph.external_asset_keys) > 0
-        ):
-            raise DagsterInvalidDefinitionError(
-                f"Asset selection for job '{self.name}' specified both regular assets and external "
-                "assets. This is not currently supported. Selections must be all regular "
-                "assets or all source assets.",
-            )
-
-        selected_asset_checks = self.selection.resolve_checks(asset_graph)
-
-        asset_keys_by_partitions_def = defaultdict(set)
-        for asset_key in selected_asset_keys:
-            partitions_def = asset_graph.get_partitions_def(asset_key)
-            if partitions_def is not None:
-                asset_keys_by_partitions_def[partitions_def].add(asset_key)
-
-        if len(asset_keys_by_partitions_def) > 1:
-            keys_by_partitions_def_str = "\n".join(
-                f"{partitions_def}: {asset_keys}"
-                for partitions_def, asset_keys in asset_keys_by_partitions_def.items()
-            )
+        try:
+            job_asset_graph = get_asset_graph_for_job(asset_graph, self.selection)
+        except DagsterInvalidDefinitionError as e:
             raise DagsterInvalidDefinitionError(
-                f"Multiple partitioned assets exist in assets job '{self.name}'. Selected assets"
-                " must have the same partitions definitions, but the selected assets have"
-                f" different partitions definitions: \n{keys_by_partitions_def_str}"
-            )
-
-        inferred_partitions_def = (
-            next(iter(asset_keys_by_partitions_def.keys()))
-            if asset_keys_by_partitions_def
-            else None
-        )
-        if (
-            inferred_partitions_def
-            and self.partitions_def != inferred_partitions_def
-            and self.partitions_def is not None
-        ):
-            raise DagsterInvalidDefinitionError(
-                f"Job '{self.name}' received a partitions_def of {self.partitions_def}, but the"
-                f" selected assets {next(iter(asset_keys_by_partitions_def.values()))} have a"
-                f" non-matching partitions_def of {inferred_partitions_def}"
-            )
+                f'Error resolving selection for asset job "{self.name}": {e}'
+            ) from e
 
-        return build_asset_selection_job(
-            name=self.name,
-            assets=assets,
-            asset_checks=asset_graph.asset_checks_defs,
+        return build_asset_job(
+            self.name,
+            asset_graph=job_asset_graph,
             config=self.config,
-            source_assets=[],
             description=self.description,
             tags=self.tags,
             metadata=self.metadata,
-            asset_selection=selected_asset_keys,
-            asset_check_selection=selected_asset_checks,
-            partitions_def=self.partitions_def if self.partitions_def else inferred_partitions_def,
+            partitions_def=self.partitions_def,
             executor_def=self.executor_def or default_executor_def,
             hooks=self.hooks,
             op_retry_policy=self.op_retry_policy,
             resource_defs=resource_defs,
         )
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/utils.py` & `dagster-1.7.0/dagster/_core/definitions/utils.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 import keyword
 import os
 import re
+import warnings
 from glob import glob
-from typing import Any, Dict, List, Mapping, Optional, Sequence, Tuple, cast
+from typing import Any, Dict, List, Mapping, NamedTuple, Optional, Sequence, Tuple, Union, cast
 
 import yaml
 
 import dagster._check as check
 import dagster._seven as seven
 from dagster._core.errors import DagsterInvalidDefinitionError, DagsterInvariantViolationError
 from dagster._core.storage.tags import check_reserved_tags
@@ -87,18 +88,37 @@
 
 def struct_to_string(name: str, **kwargs: object) -> str:
     # Sort the kwargs to ensure consistent representations across Python versions
     props_str = ", ".join([_kv_str(key, value) for key, value in sorted(kwargs.items())])
     return f"{name}({props_str})"
 
 
-def validate_tags(
-    tags: Optional[Mapping[str, Any]], allow_reserved_tags: bool = True
-) -> Mapping[str, str]:
+class NormalizedTags(NamedTuple):
+    tags: Mapping[str, str]
+
+    def with_normalized_tags(self, normalized_tags: "NormalizedTags") -> "NormalizedTags":
+        return NormalizedTags({**self.tags, **normalized_tags.tags})
+
+
+def normalize_tags(
+    tags: Union[NormalizedTags, Optional[Mapping[str, Any]]],
+    allow_reserved_tags: bool = True,
+    warn_on_deprecated_tags: bool = True,
+    warning_stacklevel: int = 4,
+) -> NormalizedTags:
+    """Normalizes JSON-object tags into string tags and warns on deprecated tags.
+
+    New tags properties should _not_ use this function, because it doesn't hard error on tags that
+    are no longer supported.
+    """
+    if isinstance(tags, NormalizedTags):
+        return tags
+
     valid_tags: Dict[str, str] = {}
+    invalid_tag_keys = []
     for key, value in check.opt_mapping_param(tags, "tags", key_type=str).items():
         if not isinstance(value, str):
             valid = False
             err_reason = f'Could not JSON encode value "{value}"'
             str_val = None
             try:
                 str_val = seven.json.dumps(value)
@@ -114,18 +134,78 @@
                     "or meet the constraint that json.loads(json.dumps(value)) == value."
                 )
 
             valid_tags[key] = str_val  # type: ignore  # (possible none)
         else:
             valid_tags[key] = value
 
+        if not is_valid_definition_tag_key(key):
+            invalid_tag_keys.append(key)
+
+    if invalid_tag_keys:
+        invalid_tag_keys_sample = invalid_tag_keys[: min(5, len(invalid_tag_keys))]
+        if warn_on_deprecated_tags:
+            warnings.warn(
+                f"Non-compliant tag keys like {invalid_tag_keys_sample} are deprecated. {VALID_DEFINITION_TAG_KEY_EXPLANATION}",
+                category=DeprecationWarning,
+                stacklevel=warning_stacklevel,
+            )
+
     if not allow_reserved_tags:
         check_reserved_tags(valid_tags)
 
-    return valid_tags
+    return NormalizedTags(valid_tags)
+
+
+# Inspired by allowed Kubernetes labels:
+# https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set
+VALID_DEFINITION_TAG_KEY_REGEX_STR = r"^([A-Za-z0-9_.-]{1,63}/)?[A-Za-z0-9_.-]{1,63}$"
+VALID_DEFINITION_TAG_KEY_REGEX = re.compile(VALID_DEFINITION_TAG_KEY_REGEX_STR)
+VALID_DEFINITION_TAG_KEY_EXPLANATION = (
+    "Allowed characters: alpha-numeric, '_', '-', '.'. "
+    "Tag keys can also contain a namespace section, separated by a '/'. Each section "
+    "must have <= 63 characters."
+)
+
+VALID_DEFINITION_TAG_VALUE_REGEX_STR = r"^[A-Za-z0-9_.-]{0,63}$"
+VALID_DEFINITION_TAG_VALUE_REGEX = re.compile(VALID_DEFINITION_TAG_VALUE_REGEX_STR)
+
+
+def is_valid_definition_tag_key(key: str) -> bool:
+    return bool(VALID_DEFINITION_TAG_KEY_REGEX.match(key))
+
+
+def is_valid_definition_tag_value(key: str) -> bool:
+    return bool(VALID_DEFINITION_TAG_VALUE_REGEX.match(key))
+
+
+def validate_definition_tags(tags: Optional[Mapping[str, str]]) -> Optional[Mapping[str, str]]:
+    """More restrictive than validate_tags."""
+    if tags is None:
+        return tags
+
+    for key, value in tags.items():
+        if not isinstance(key, str):
+            raise DagsterInvalidDefinitionError("Tag keys must be strings")
+
+        if not isinstance(value, str):
+            raise DagsterInvalidDefinitionError("Tag values must be strings")
+
+        if not is_valid_definition_tag_key(key):
+            raise DagsterInvalidDefinitionError(
+                f"Invalid tag key: {key}. {VALID_DEFINITION_TAG_KEY_EXPLANATION}"
+            )
+
+        if not is_valid_definition_tag_value(value):
+            raise DagsterInvalidDefinitionError(
+                f"Invalid tag value: {value}. Allowed characters: alpha-numeric, '_', '-', '.'. "
+                "Must have <= 63 characters."
+            )
+
+    return tags
 
 
 def validate_group_name(group_name: Optional[str]) -> str:
     """Ensures a string name is valid and returns a default if no name provided."""
     if group_name:
         check_valid_chars(group_name)
         return group_name
```

### Comparing `dagster-1.6.9/dagster/_core/definitions/version_strategy.py` & `dagster-1.7.0/dagster/_core/definitions/version_strategy.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/errors.py` & `dagster-1.7.0/dagster/_core/errors.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/event_api.py` & `dagster-1.7.0/dagster/_core/event_api.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/events/__init__.py` & `dagster-1.7.0/dagster/_core/events/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """Structured representations of system events."""
 
 import logging
 import os
 import sys
+import uuid
 from enum import Enum
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Any,
     Dict,
     Mapping,
@@ -239,14 +240,20 @@
     DagsterEventType.RUN_STARTING: DagsterRunStatus.STARTING,
     DagsterEventType.RUN_CANCELING: DagsterRunStatus.CANCELING,
     DagsterEventType.RUN_CANCELED: DagsterRunStatus.CANCELED,
 }
 
 PIPELINE_RUN_STATUS_TO_EVENT_TYPE = {v: k for k, v in EVENT_TYPE_TO_PIPELINE_RUN_STATUS.items()}
 
+# These are the only events currently supported in `EventLogStorage.store_event_batch`
+BATCH_WRITABLE_EVENTS = {
+    DagsterEventType.ASSET_MATERIALIZATION,
+    DagsterEventType.ASSET_OBSERVATION,
+}
+
 ASSET_EVENTS = {
     DagsterEventType.ASSET_MATERIALIZATION,
     DagsterEventType.ASSET_OBSERVATION,
     DagsterEventType.ASSET_MATERIALIZATION_PLANNED,
 }
 
 ASSET_CHECK_EVENTS = {
@@ -323,22 +330,31 @@
         check.inst_param(event_specific_data, "event_specific_data", AssetCheckEvaluationPlanned)
     elif event_type == DagsterEventType.ASSET_CHECK_EVALUATION:
         check.inst_param(event_specific_data, "event_specific_data", AssetCheckEvaluation)
 
     return event_specific_data
 
 
-def log_step_event(step_context: IStepContext, event: "DagsterEvent") -> None:
+def generate_event_batch_id():
+    return str(uuid.uuid4())
+
+
+def log_step_event(
+    step_context: IStepContext,
+    event: "DagsterEvent",
+    batch_metadata: Optional["DagsterEventBatchMetadata"],
+) -> None:
     event_type = DagsterEventType(event.event_type_value)
     log_level = logging.ERROR if event_type in FAILURE_EVENTS else logging.DEBUG
 
     step_context.log.log_dagster_event(
         level=log_level,
         msg=event.message or f"{event_type} for step {step_context.step.key}",
         dagster_event=event,
+        batch_metadata=batch_metadata,
     )
 
 
 def log_job_event(job_context: IPlanContext, event: "DagsterEvent") -> None:
     event_type = DagsterEventType(event.event_type_value)
     log_level = logging.ERROR if event_type in FAILURE_EVENTS else logging.DEBUG
 
@@ -389,14 +405,19 @@
             step_key=step_key,
             event_specific_data=EngineEventData(
                 error=serializable_error_info_from_exc_info(sys.exc_info())
             ),
         )
 
 
+class DagsterEventBatchMetadata(NamedTuple):
+    id: str
+    is_end: bool
+
+
 @whitelist_for_serdes(
     serializer=DagsterEventSerializer,
     storage_field_names={
         "node_handle": "solid_handle",
         "job_name": "pipeline_name",
     },
 )
@@ -435,28 +456,29 @@
 
     @staticmethod
     def from_step(
         event_type: "DagsterEventType",
         step_context: IStepContext,
         event_specific_data: Optional["EventSpecificData"] = None,
         message: Optional[str] = None,
+        batch_metadata: Optional["DagsterEventBatchMetadata"] = None,
     ) -> "DagsterEvent":
         event = DagsterEvent(
             event_type_value=check.inst_param(event_type, "event_type", DagsterEventType).value,
             job_name=step_context.job_name,
             step_handle=step_context.step.handle,
             node_handle=step_context.step.node_handle,
             step_kind_value=step_context.step.kind.value,
             logging_tags=step_context.event_tags,
             event_specific_data=_validate_event_specific_data(event_type, event_specific_data),
             message=check.opt_str_param(message, "message"),
             pid=os.getpid(),
         )
 
-        log_step_event(step_context, event)
+        log_step_event(step_context, event, batch_metadata)
 
         return event
 
     @staticmethod
     def from_job(
         event_type: DagsterEventType,
         job_context: IPlanContext,
@@ -947,67 +969,67 @@
         )
 
     @staticmethod
     def step_restarted_event(step_context: IStepContext, previous_attempts: int) -> "DagsterEvent":
         return DagsterEvent.from_step(
             event_type=DagsterEventType.STEP_RESTARTED,
             step_context=step_context,
-            message='Started re-execution (attempt # {n}) of step "{step_key}".'.format(
-                step_key=step_context.step.key, n=previous_attempts + 1
-            ),
+            message=f'Started re-execution (attempt # {previous_attempts + 1}) of step "{step_context.step.key}".',
         )
 
     @staticmethod
     def step_success_event(
         step_context: IStepContext, success: "StepSuccessData"
     ) -> "DagsterEvent":
         return DagsterEvent.from_step(
             event_type=DagsterEventType.STEP_SUCCESS,
             step_context=step_context,
             event_specific_data=success,
-            message='Finished execution of step "{step_key}" in {duration}.'.format(
-                step_key=step_context.step.key,
-                duration=format_duration(success.duration_ms),
-            ),
+            message=f'Finished execution of step "{step_context.step.key}" in {format_duration(success.duration_ms)}.',
         )
 
     @staticmethod
     def step_skipped_event(step_context: IStepContext) -> "DagsterEvent":
         return DagsterEvent.from_step(
             event_type=DagsterEventType.STEP_SKIPPED,
             step_context=step_context,
             message=f'Skipped execution of step "{step_context.step.key}".',
         )
 
     @staticmethod
     def asset_materialization(
         step_context: IStepContext,
         materialization: AssetMaterialization,
+        batch_metadata: Optional[DagsterEventBatchMetadata] = None,
     ) -> "DagsterEvent":
         return DagsterEvent.from_step(
             event_type=DagsterEventType.ASSET_MATERIALIZATION,
             step_context=step_context,
             event_specific_data=StepMaterializationData(materialization),
             message=(
                 materialization.description
                 if materialization.description
                 else "Materialized value{label_clause}.".format(
                     label_clause=f" {materialization.label}" if materialization.label else ""
                 )
             ),
+            batch_metadata=batch_metadata,
         )
 
     @staticmethod
     def asset_observation(
-        step_context: IStepContext, observation: AssetObservation
+        step_context: IStepContext,
+        observation: AssetObservation,
+        batch_metadata: Optional[DagsterEventBatchMetadata] = None,
     ) -> "DagsterEvent":
         return DagsterEvent.from_step(
             event_type=DagsterEventType.ASSET_OBSERVATION,
             step_context=step_context,
             event_specific_data=AssetObservationData(observation),
+            batch_metadata=batch_metadata,
         )
 
     @staticmethod
     def asset_check_evaluation(
         step_context: IStepContext, asset_check_evaluation: AssetCheckEvaluation
     ) -> "DagsterEvent":
         return DagsterEvent.from_step(
@@ -1292,21 +1314,15 @@
                 f"Retrieved intermediate object for input {value_name} in "
                 f"{object_store_name}object store{serialization_strategy_modifier}."
             )
         elif (
             ObjectStoreOperationType(object_store_operation_result.op)
             == ObjectStoreOperationType.CP_OBJECT
         ):
-            message = (
-                "Copied intermediate object for input {value_name} from {key} to {dest_key}"
-            ).format(
-                value_name=value_name,
-                key=object_store_operation_result.key,
-                dest_key=object_store_operation_result.dest_key,
-            )
+            message = f"Copied intermediate object for input {value_name} from {object_store_operation_result.key} to {object_store_operation_result.dest_key}"
         else:
             message = ""
 
         return DagsterEvent.from_step(
             DagsterEventType.OBJECT_STORE_OPERATION,
             step_context,
             event_specific_data=ObjectStoreOperationResultData(
```

### Comparing `dagster-1.6.9/dagster/_core/events/log.py` & `dagster-1.7.0/dagster/_core/events/log.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/events/utils.py` & `dagster-1.7.0/dagster/_core/events/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/api.py` & `dagster-1.7.0/dagster/_core/execution/api.py`

 * *Files 1% similar despite different names*

```diff
@@ -124,18 +124,16 @@
                 return gen_fail_restarted_run_worker()
 
     else:
         check.invariant(
             dagster_run.status == DagsterRunStatus.STARTED
             or dagster_run.status == DagsterRunStatus.STARTING,
             desc=(
-                "Run of {} ({}) in state {}, expected STARTED or STARTING because it's "
-                "resuming from a run worker failure".format(
-                    dagster_run.job_name, dagster_run.run_id, dagster_run.status
-                )
+                f"Run of {dagster_run.job_name} ({dagster_run.run_id}) in state {dagster_run.status}, expected STARTED or STARTING because it's "
+                "resuming from a run worker failure"
             ),
         )
 
     if (
         dagster_run.resolved_op_selection
         or dagster_run.asset_selection
         or dagster_run.asset_check_selection
@@ -216,17 +214,15 @@
             dagster_run,
         )
         raise DagsterInvariantViolationError(message)
 
     check.invariant(
         dagster_run.status == DagsterRunStatus.NOT_STARTED
         or dagster_run.status == DagsterRunStatus.STARTING,
-        desc="Run {} ({}) in state {}, expected NOT_STARTED or STARTING".format(
-            dagster_run.job_name, dagster_run.run_id, dagster_run.status
-        ),
+        desc=f"Run {dagster_run.job_name} ({dagster_run.run_id}) in state {dagster_run.status}, expected NOT_STARTED or STARTING",
     )
     if (
         dagster_run.resolved_op_selection
         or dagster_run.asset_selection
         or dagster_run.asset_check_selection
     ):
         # when `execute_run` is directly called, the sub job hasn't been created
```

### Comparing `dagster-1.6.9/dagster/_core/execution/asset_backfill.py` & `dagster-1.7.0/dagster/_core/execution/asset_backfill.py`

 * *Files 1% similar despite different names*

```diff
@@ -23,22 +23,22 @@
 import pendulum
 
 import dagster._check as check
 from dagster._core.definitions.asset_daemon_context import (
     build_run_requests,
     build_run_requests_with_backfill_policies,
 )
-from dagster._core.definitions.asset_graph import AssetGraph
 from dagster._core.definitions.asset_graph_subset import AssetGraphSubset
-from dagster._core.definitions.asset_selection import AssetSelection
+from dagster._core.definitions.asset_selection import KeysAssetSelection
+from dagster._core.definitions.base_asset_graph import BaseAssetGraph
 from dagster._core.definitions.events import AssetKey, AssetKeyPartitionKey
-from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
 from dagster._core.definitions.partition import PartitionsDefinition, PartitionsSubset
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
 from dagster._core.definitions.partition_mapping import IdentityPartitionMapping
+from dagster._core.definitions.remote_asset_graph import RemoteAssetGraph
 from dagster._core.definitions.run_request import RunRequest
 from dagster._core.definitions.selector import PartitionsByAssetSelector
 from dagster._core.definitions.time_window_partition_mapping import TimeWindowPartitionMapping
 from dagster._core.definitions.time_window_partitions import (
     DatetimeFieldSerializer,
     TimeWindowPartitionsSubset,
 )
@@ -207,15 +207,15 @@
             return self_and_downstream
 
         assets_with_no_parents_in_target_subset = {
             asset_key
             for asset_key in self.target_subset.asset_keys
             if all(
                 parent not in self.target_subset.asset_keys
-                for parent in instance_queryer.asset_graph.get_parents(asset_key)
+                for parent in instance_queryer.asset_graph.get(asset_key).parent_keys
                 - {asset_key}  # Do not include an asset as its own parent
             )
         }
 
         # The partitions that do not have any parents in the target subset
         root_subset = self.target_subset.filter_asset_keys(assets_with_no_parents_in_target_subset)
 
@@ -233,15 +233,15 @@
         ):
             # Find the asset graph subset is not yet targeted by the backfill
             unreachable_targets = self.target_subset - root_and_downstream_partitions
 
             # Find the root assets of the unreachable targets. Any targeted partition in these
             # assets becomes part of the root subset
             unreachable_target_root_subset = unreachable_targets.filter_asset_keys(
-                AssetSelection.keys(*unreachable_targets.asset_keys)
+                KeysAssetSelection(selected_keys=list(unreachable_targets.asset_keys))
                 .sources()
                 .resolve(instance_queryer.asset_graph)
             )
             root_subset = root_subset | unreachable_target_root_subset
 
             # Track the previous value of root_and_downstream_partitions.
             # If the values are the same, we know no new partitions have been targeted.
@@ -264,23 +264,25 @@
         return list(root_subset.iterate_asset_partitions())
 
     def get_target_partitions_subset(self, asset_key: AssetKey) -> PartitionsSubset:
         # Return the targeted partitions for the root partitioned asset keys
         return self.target_subset.get_partitions_subset(asset_key)
 
     def get_target_root_partitions_subset(
-        self, asset_graph: AssetGraph
+        self, asset_graph: BaseAssetGraph
     ) -> Optional[PartitionsSubset]:
         """Returns the most upstream partitions subset that was targeted by the backfill."""
         target_partitioned_asset_keys = {
             asset_key for asset_key in self.target_subset.partitions_subsets_by_asset_key
         }
 
         root_partitioned_asset_keys = (
-            AssetSelection.keys(*target_partitioned_asset_keys).sources().resolve(asset_graph)
+            KeysAssetSelection(selected_keys=list(target_partitioned_asset_keys))
+            .sources()
+            .resolve(asset_graph)
         )
 
         # Return the targeted partitions for the root partitioned asset keys
         if root_partitioned_asset_keys:
             return self.target_subset.get_partitions_subset(next(iter(root_partitioned_asset_keys)))
 
         return None
@@ -297,35 +299,35 @@
             return 0
         elif len(asset_partition_nums) == 1:
             return next(iter(asset_partition_nums))
         else:
             return None
 
     def get_targeted_asset_keys_topological_order(
-        self, asset_graph: AssetGraph
+        self, asset_graph: BaseAssetGraph
     ) -> Sequence[AssetKey]:
         """Returns a topological ordering of asset keys targeted by the backfill
         that exist in the asset graph.
 
         Orders keys in the same topological level alphabetically.
         """
         return [k for k in asset_graph.toposorted_asset_keys if k in self.target_subset.asset_keys]
 
     def get_backfill_status_per_asset_key(
-        self, asset_graph: AssetGraph
+        self, asset_graph: BaseAssetGraph
     ) -> Sequence[Union[PartitionedAssetBackfillStatus, UnpartitionedAssetBackfillStatus]]:
         """Returns a list containing each targeted asset key's backfill status.
         This list orders assets topologically and only contains statuses for assets that are
         currently existent in the asset graph.
         """
 
         def _get_status_for_asset_key(
             asset_key: AssetKey,
         ) -> Union[PartitionedAssetBackfillStatus, UnpartitionedAssetBackfillStatus]:
-            if asset_graph.get_partitions_def(asset_key) is not None:
+            if asset_graph.get(asset_key).is_partitioned:
                 materialized_subset = self.materialized_subset.get_partitions_subset(
                     asset_key, asset_graph
                 )
                 failed_subset = self.failed_and_downstream_subset.get_partitions_subset(
                     asset_key, asset_graph
                 )
                 requested_subset = self.requested_subset.get_partitions_subset(
@@ -403,23 +405,23 @@
             materialized_subset=AssetGraphSubset(),
             failed_and_downstream_subset=AssetGraphSubset(),
             latest_storage_id=None,
             backfill_start_time=backfill_start_time,
         )
 
     @classmethod
-    def is_valid_serialization(cls, serialized: str, asset_graph: AssetGraph) -> bool:
+    def is_valid_serialization(cls, serialized: str, asset_graph: BaseAssetGraph) -> bool:
         storage_dict = json.loads(serialized)
         return AssetGraphSubset.can_deserialize(
             storage_dict["serialized_target_subset"], asset_graph
         )
 
     @classmethod
     def from_serialized(
-        cls, serialized: str, asset_graph: AssetGraph, backfill_start_timestamp: float
+        cls, serialized: str, asset_graph: BaseAssetGraph, backfill_start_timestamp: float
     ) -> "AssetBackfillData":
         storage_dict = json.loads(serialized)
 
         return cls(
             target_subset=AssetGraphSubset.from_storage_dict(
                 storage_dict["serialized_target_subset"], asset_graph
             ),
@@ -436,15 +438,15 @@
             latest_storage_id=storage_dict["latest_storage_id"],
             backfill_start_time=utc_datetime_from_timestamp(backfill_start_timestamp),
         )
 
     @classmethod
     def from_partitions_by_assets(
         cls,
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         dynamic_partitions_store: DynamicPartitionsStore,
         backfill_start_time: datetime,
         partitions_by_assets: Sequence[PartitionsByAssetSelector],
     ) -> "AssetBackfillData":
         """Create an AssetBackfillData object from a list of PartitionsByAssetSelector objects.
         Accepts a list of asset partitions selections, used to determine the target partitions to backfill.
         For targeted assets, if partitioned and no partitions selections are provided, targets all partitions.
@@ -452,15 +454,15 @@
         check.sequence_param(partitions_by_assets, "partitions_by_asset", PartitionsByAssetSelector)
 
         non_partitioned_asset_keys = set()
         partitions_subsets_by_asset_key = dict()
         for partitions_by_asset_selector in partitions_by_assets:
             asset_key = partitions_by_asset_selector.asset_key
             partitions = partitions_by_asset_selector.partitions
-            partition_def = asset_graph.get_partitions_def(asset_key)
+            partition_def = asset_graph.get(asset_key).partitions_def
             if partitions and partition_def:
                 if partitions.partition_range:
                     # a range of partitions is selected
                     partition_keys_in_range = partition_def.get_partition_keys_in_range(
                         partition_key_range=PartitionKeyRange(
                             start=partitions.partition_range.start,
                             end=partitions.partition_range.end,
@@ -488,15 +490,15 @@
             non_partitioned_asset_keys=non_partitioned_asset_keys,
         )
         return cls.empty(target_subset, backfill_start_time, dynamic_partitions_store)
 
     @classmethod
     def from_asset_partitions(
         cls,
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         partition_names: Optional[Sequence[str]],
         asset_selection: Sequence[AssetKey],
         dynamic_partitions_store: DynamicPartitionsStore,
         backfill_start_time: datetime,
         all_partitions: bool,
     ) -> "AssetBackfillData":
         check.invariant(
@@ -508,22 +510,24 @@
             target_subset = AssetGraphSubset.from_asset_keys(
                 asset_selection, asset_graph, dynamic_partitions_store, backfill_start_time
             )
         elif partition_names is not None:
             partitioned_asset_keys = {
                 asset_key
                 for asset_key in asset_selection
-                if asset_graph.get_partitions_def(asset_key) is not None
+                if asset_graph.get(asset_key).is_partitioned
             }
 
             root_partitioned_asset_keys = (
-                AssetSelection.keys(*partitioned_asset_keys).sources().resolve(asset_graph)
+                KeysAssetSelection(selected_keys=list(partitioned_asset_keys))
+                .sources()
+                .resolve(asset_graph)
             )
             root_partitions_defs = {
-                asset_graph.get_partitions_def(asset_key)
+                asset_graph.get(asset_key).partitions_def
                 for asset_key in root_partitioned_asset_keys
             }
             if len(root_partitions_defs) > 1:
                 raise DagsterBackfillFailedError(
                     "All the assets at the root of the backfill must have the same"
                     " PartitionsDefinition"
                 )
@@ -550,15 +554,15 @@
                 )
         else:
             check.failed("Either partition_names must not be None or all_partitions must be True")
 
         return cls.empty(target_subset, backfill_start_time, dynamic_partitions_store)
 
     def serialize(
-        self, dynamic_partitions_store: DynamicPartitionsStore, asset_graph: AssetGraph
+        self, dynamic_partitions_store: DynamicPartitionsStore, asset_graph: BaseAssetGraph
     ) -> str:
         storage_dict = {
             "requested_runs_for_target_roots": self.requested_runs_for_target_roots,
             "serialized_target_subset": self.target_subset.to_storage_dict(
                 dynamic_partitions_store=dynamic_partitions_store, asset_graph=asset_graph
             ),
             "latest_storage_id": self.latest_storage_id,
@@ -572,15 +576,15 @@
                 dynamic_partitions_store=dynamic_partitions_store, asset_graph=asset_graph
             ),
         }
         return json.dumps(storage_dict)
 
 
 def create_asset_backfill_data_from_asset_partitions(
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     asset_selection: Sequence[AssetKey],
     partition_names: Sequence[str],
     dynamic_partitions_store: DynamicPartitionsStore,
 ) -> AssetBackfillData:
     backfill_timestamp = pendulum.now("UTC").timestamp()
     return AssetBackfillData.from_asset_partitions(
         asset_graph=asset_graph,
@@ -613,29 +617,29 @@
 class AssetBackfillIterationResult(NamedTuple):
     run_requests: Sequence[RunRequest]
     backfill_data: AssetBackfillData
 
 
 def _get_requested_asset_partitions_from_run_requests(
     run_requests: Sequence[RunRequest],
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     instance_queryer: CachingInstanceQueryer,
 ) -> AbstractSet[AssetKeyPartitionKey]:
     requested_partitions = set()
     for run_request in run_requests:
         # Run request targets a range of partitions
         range_start = run_request.tags.get(ASSET_PARTITION_RANGE_START_TAG)
         range_end = run_request.tags.get(ASSET_PARTITION_RANGE_END_TAG)
         if range_start and range_end:
             # When a run request targets a range of partitions, each asset is expected to
             # have the same partitions def
             selected_assets = cast(Sequence[AssetKey], run_request.asset_selection)
             check.invariant(len(selected_assets) > 0)
             partitions_defs = set(
-                asset_graph.get_partitions_def(asset_key) for asset_key in selected_assets
+                asset_graph.get(asset_key).partitions_def for asset_key in selected_assets
             )
             check.invariant(
                 len(partitions_defs) == 1,
                 "Expected all assets selected in partition range run request to have the same"
                 " partitions def",
             )
 
@@ -659,15 +663,15 @@
 
 def _submit_runs_and_update_backfill_in_chunks(
     instance: DagsterInstance,
     workspace_process_context: IWorkspaceProcessContext,
     backfill_id: str,
     asset_backfill_iteration_result: AssetBackfillIterationResult,
     previous_asset_backfill_data: AssetBackfillData,
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     instance_queryer: CachingInstanceQueryer,
     logger: logging.Logger,
 ) -> Iterable[Optional[AssetBackfillData]]:
     from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
 
     run_requests = asset_backfill_iteration_result.run_requests
     submitted_partitions = previous_asset_backfill_data.requested_subset
@@ -759,27 +763,27 @@
             )
 
     yield backfill_data_with_submitted_runs
 
 
 def _check_target_partitions_subset_is_valid(
     asset_key: AssetKey,
-    asset_graph: AssetGraph,
+    asset_graph: BaseAssetGraph,
     target_partitions_subset: Optional[PartitionsSubset],
     instance_queryer: CachingInstanceQueryer,
 ) -> None:
     """Checks for any partitions definition changes since backfill launch that should mark
     the backfill as failed.
     """
     if asset_key not in asset_graph.all_asset_keys:
         raise DagsterDefinitionChangedDeserializationError(
             f"Asset {asset_key} existed at storage-time, but no longer does"
         )
 
-    partitions_def = asset_graph.get_partitions_def(asset_key)
+    partitions_def = asset_graph.get(asset_key).partitions_def
 
     if target_partitions_subset:  # Asset was partitioned at storage time
         if partitions_def is None:
             raise DagsterDefinitionChangedDeserializationError(
                 f"Asset {asset_key} had a PartitionsDefinition at storage-time, but no longer"
                 " does"
             )
@@ -819,15 +823,15 @@
                 f"Asset {asset_key} was not partitioned at storage-time, but is now"
             )
 
 
 def _check_validity_and_deserialize_asset_backfill_data(
     workspace_context: BaseWorkspaceRequestContext,
     backfill: "PartitionBackfill",
-    asset_graph: AssetGraph,
+    asset_graph: BaseAssetGraph,
     instance_queryer: CachingInstanceQueryer,
     logger: logging.Logger,
 ) -> Optional[AssetBackfillData]:
     """Attempts to deserialize asset backfill data. If the asset backfill data is valid,
     returns the deserialized data, else returns None.
     """
     unloadable_locations = _get_unloadable_location_names(workspace_context, logger)
@@ -879,16 +883,15 @@
     expensive operations.
     """
     from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
 
     logger.info(f"Evaluating asset backfill {backfill.backfill_id}")
 
     workspace_context = workspace_process_context.create_request_context()
-
-    asset_graph = ExternalAssetGraph.from_workspace(workspace_context)
+    asset_graph = workspace_context.asset_graph
 
     if not backfill.is_asset_backfill:
         check.failed("Backfill must be an asset backfill")
 
     backfill_start_time = pendulum.from_timestamp(backfill.backfill_timestamp, "UTC")
     instance_queryer = CachingInstanceQueryer(
         instance=instance, asset_graph=asset_graph, evaluation_time=backfill_start_time
@@ -1049,15 +1052,15 @@
         check.failed(f"Unexpected backfill status: {backfill.status}")
 
 
 def get_canceling_asset_backfill_iteration_data(
     backfill_id: str,
     asset_backfill_data: AssetBackfillData,
     instance_queryer: CachingInstanceQueryer,
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     backfill_start_time: datetime,
 ) -> Iterable[Optional[AssetBackfillData]]:
     """For asset backfills in the "canceling" state, fetch the asset backfill data with the updated
     materialized and failed subsets.
     """
     updated_materialized_subset = None
     for updated_materialized_subset in get_asset_backfill_iteration_materialized_partitions(
@@ -1087,15 +1090,15 @@
 
     yield updated_backfill_data
 
 
 def get_asset_backfill_iteration_materialized_partitions(
     backfill_id: str,
     asset_backfill_data: AssetBackfillData,
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     instance_queryer: CachingInstanceQueryer,
 ) -> Iterable[Optional[AssetGraphSubset]]:
     """Returns the partitions that have been materialized by the backfill.
 
     This function is a generator so we can return control to the daemon and let it heartbeat
     during expensive operations.
     """
@@ -1131,15 +1134,15 @@
 
     yield updated_materialized_subset
 
 
 def _get_failed_and_downstream_asset_partitions(
     backfill_id: str,
     asset_backfill_data: AssetBackfillData,
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     instance_queryer: CachingInstanceQueryer,
     backfill_start_time: datetime,
 ) -> AssetGraphSubset:
     failed_and_downstream_subset = AssetGraphSubset.from_asset_partition_set(
         asset_graph.bfs_filter_asset_partitions(
             instance_queryer,
             lambda asset_partitions, _: any(
@@ -1167,15 +1170,15 @@
     )
     return max(next_latest_storage_id - cursor_offset, 0)
 
 
 def execute_asset_backfill_iteration_inner(
     backfill_id: str,
     asset_backfill_data: AssetBackfillData,
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     instance_queryer: CachingInstanceQueryer,
     run_tags: Mapping[str, str],
     backfill_start_time: datetime,
 ) -> Iterable[Optional[AssetBackfillIterationResult]]:
     """Core logic of a backfill iteration. Has no side effects.
 
     Computes which runs should be requested, if any, as well as updated bookkeeping about the status
@@ -1251,15 +1254,15 @@
         ),
         initial_asset_partitions=initial_candidates,
         evaluation_time=backfill_start_time,
     )
 
     # check if all assets have backfill policies if any of them do, otherwise, raise error
     asset_backfill_policies = [
-        asset_graph.get_backfill_policy(asset_key)
+        asset_graph.get(asset_key).backfill_policy
         for asset_key in {
             asset_partition.asset_key for asset_partition in asset_partitions_to_request
         }
     ]
     all_assets_have_backfill_policies = all(
         backfill_policy is not None for backfill_policy in asset_backfill_policies
     )
@@ -1306,85 +1309,82 @@
     yield AssetBackfillIterationResult(run_requests, updated_asset_backfill_data)
 
 
 def can_run_with_parent(
     parent: AssetKeyPartitionKey,
     candidate: AssetKeyPartitionKey,
     candidates_unit: Iterable[AssetKeyPartitionKey],
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     target_subset: AssetGraphSubset,
     asset_partitions_to_request_map: Mapping[AssetKey, AbstractSet[Optional[str]]],
 ) -> bool:
     """Returns if a given candidate can be materialized in the same run as a given parent on
     this tick.
     """
     parent_target_subset = target_subset.get_asset_subset(parent.asset_key, asset_graph)
-    parent_backfill_policy = asset_graph.get_backfill_policy(parent.asset_key)
     candidate_target_subset = target_subset.get_asset_subset(candidate.asset_key, asset_graph)
-    candidate_backfill_policy = asset_graph.get_backfill_policy(candidate.asset_key)
     partition_mapping = asset_graph.get_partition_mapping(
-        candidate.asset_key, in_asset_key=parent.asset_key
+        candidate.asset_key, parent_asset_key=parent.asset_key
     )
 
+    parent_node = asset_graph.get(parent.asset_key)
+    candidate_node = asset_graph.get(candidate.asset_key)
     # checks if there is a simple partition mapping between the parent and the child
     has_identity_partition_mapping = (
         # both unpartitioned
-        (
-            not asset_graph.is_partitioned(candidate.asset_key)
-            and not asset_graph.is_partitioned(parent.asset_key)
-        )
+        not candidate_node.is_partitioned
+        and not parent_node.is_partitioned
         # normal identity partition mapping
         or isinstance(partition_mapping, IdentityPartitionMapping)
         # for assets with the same time partitions definition, a non-offset partition
         # mapping functions as an identity partition mapping
         or (
             isinstance(partition_mapping, TimeWindowPartitionMapping)
             and partition_mapping.start_offset == 0
             and partition_mapping.end_offset == 0
         )
     )
     return (
-        parent_backfill_policy == candidate_backfill_policy
-        and asset_graph.get_repository_handle(candidate.asset_key)
-        is asset_graph.get_repository_handle(parent.asset_key)
-        and asset_graph.have_same_partitioning(parent.asset_key, candidate.asset_key)
+        parent_node.backfill_policy == candidate_node.backfill_policy
+        and parent_node.priority_repository_handle is candidate_node.priority_repository_handle
+        and parent_node.partitions_def == candidate_node.partitions_def
         and (
             parent.partition_key in asset_partitions_to_request_map[parent.asset_key]
             or parent in candidates_unit
         )
         and (
             # if there is a simple mapping between the parent and the child, then
             # with the parent
             has_identity_partition_mapping
             # if there is not a simple mapping, we can only materialize this asset with its
             # parent if...
             or (
                 # there is a backfill policy for the parent
-                parent_backfill_policy is not None
+                parent_node.backfill_policy is not None
                 # the same subset of parents is targeted as the child
                 and parent_target_subset.value == candidate_target_subset.value
                 and (
                     # there is no limit on the size of a single run or...
-                    parent_backfill_policy.max_partitions_per_run is None
+                    parent_node.backfill_policy.max_partitions_per_run is None
                     # a single run can materialize all requested parent partitions
-                    or parent_backfill_policy.max_partitions_per_run
+                    or parent_node.backfill_policy.max_partitions_per_run
                     > len(asset_partitions_to_request_map[parent.asset_key])
                 )
                 # all targeted parents are being requested this tick
                 and len(asset_partitions_to_request_map[parent.asset_key])
                 == parent_target_subset.size
             )
             # if all the above are true, then a single run can be launched this tick which
             # will materialize all requested partitions
         )
     )
 
 
 def should_backfill_atomic_asset_partitions_unit(
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     candidates_unit: Iterable[AssetKeyPartitionKey],
     asset_partitions_to_request: AbstractSet[AssetKeyPartitionKey],
     target_subset: AssetGraphSubset,
     requested_subset: AssetGraphSubset,
     materialized_subset: AssetGraphSubset,
     failed_and_downstream_subset: AssetGraphSubset,
     dynamic_partitions_store: DynamicPartitionsStore,
@@ -1434,15 +1434,15 @@
             ):
                 return False
 
     return True
 
 
 def _get_failed_asset_partitions(
-    instance_queryer: CachingInstanceQueryer, backfill_id: str, asset_graph: ExternalAssetGraph
+    instance_queryer: CachingInstanceQueryer, backfill_id: str, asset_graph: RemoteAssetGraph
 ) -> Sequence[AssetKeyPartitionKey]:
     """Returns asset partitions that materializations were requested for as part of the backfill, but
     will not be materialized.
 
     Includes canceled asset partitions. Implementation assumes that successful runs won't have any
     failed partitions.
     """
```

### Comparing `dagster-1.6.9/dagster/_core/execution/backfill.py` & `dagster-1.7.0/dagster/_core/execution/backfill.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,20 @@
 from enum import Enum
 from typing import Mapping, NamedTuple, Optional, Sequence, Union
 
 import pendulum
 
 from dagster import _check as check
 from dagster._core.definitions import AssetKey
-from dagster._core.definitions.asset_graph import AssetGraph
-from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
+from dagster._core.definitions.base_asset_graph import BaseAssetGraph
 from dagster._core.definitions.partition import PartitionsSubset
 from dagster._core.errors import DagsterDefinitionChangedDeserializationError
 from dagster._core.execution.bulk_actions import BulkActionType
-from dagster._core.host_representation.origin import ExternalPartitionSetOrigin
 from dagster._core.instance import DynamicPartitionsStore
+from dagster._core.remote_representation.origin import RemotePartitionSetOrigin
 from dagster._core.storage.tags import USER_TAG
 from dagster._core.workspace.workspace import IWorkspace
 from dagster._serdes import whitelist_for_serdes
 from dagster._utils.error import SerializableErrorInfo
 
 from ..definitions.selector import PartitionsByAssetSelector
 from .asset_backfill import (
@@ -47,15 +46,15 @@
             ("status", BulkActionStatus),
             ("from_failure", bool),
             ("tags", Mapping[str, str]),
             ("backfill_timestamp", float),
             ("error", Optional[SerializableErrorInfo]),
             ("asset_selection", Optional[Sequence[AssetKey]]),
             # fields that are only used by job backfills
-            ("partition_set_origin", Optional[ExternalPartitionSetOrigin]),
+            ("partition_set_origin", Optional[RemotePartitionSetOrigin]),
             ("partition_names", Optional[Sequence[str]]),
             ("last_submitted_partition_name", Optional[str]),
             ("reexecution_steps", Optional[Sequence[str]]),
             # only used by asset backfills
             ("serialized_asset_backfill_data", Optional[str]),
             ("asset_backfill_data", Optional[AssetBackfillData]),
         ],
@@ -66,15 +65,15 @@
         backfill_id: str,
         status: BulkActionStatus,
         from_failure: bool,
         tags: Optional[Mapping[str, str]],
         backfill_timestamp: float,
         error: Optional[SerializableErrorInfo] = None,
         asset_selection: Optional[Sequence[AssetKey]] = None,
-        partition_set_origin: Optional[ExternalPartitionSetOrigin] = None,
+        partition_set_origin: Optional[RemotePartitionSetOrigin] = None,
         partition_names: Optional[Sequence[str]] = None,
         last_submitted_partition_name: Optional[str] = None,
         reexecution_steps: Optional[Sequence[str]] = None,
         serialized_asset_backfill_data: Optional[str] = None,
         asset_backfill_data: Optional[AssetBackfillData] = None,
     ):
         check.invariant(
@@ -94,15 +93,15 @@
             check.inst_param(status, "status", BulkActionStatus),
             check.bool_param(from_failure, "from_failure"),
             check.opt_mapping_param(tags, "tags", key_type=str, value_type=str),
             check.float_param(backfill_timestamp, "backfill_timestamp"),
             check.opt_inst_param(error, "error", SerializableErrorInfo),
             check.opt_nullable_sequence_param(asset_selection, "asset_selection", of_type=AssetKey),
             check.opt_inst_param(
-                partition_set_origin, "partition_set_origin", ExternalPartitionSetOrigin
+                partition_set_origin, "partition_set_origin", RemotePartitionSetOrigin
             ),
             check.opt_nullable_sequence_param(partition_names, "partition_names", of_type=str),
             check.opt_str_param(last_submitted_partition_name, "last_submitted_partition_name"),
             check.opt_nullable_sequence_param(reexecution_steps, "reexecution_steps", of_type=str),
             check.opt_str_param(serialized_asset_backfill_data, "serialized_asset_backfill_data"),
             check.opt_inst_param(asset_backfill_data, "asset_backfill_data", AssetBackfillData),
         )
@@ -113,15 +112,15 @@
 
     @property
     def is_asset_backfill(self) -> bool:
         return (
             self.serialized_asset_backfill_data is not None or self.asset_backfill_data is not None
         )
 
-    def get_asset_backfill_data(self, asset_graph: AssetGraph) -> AssetBackfillData:
+    def get_asset_backfill_data(self, asset_graph: BaseAssetGraph) -> AssetBackfillData:
         if self.serialized_asset_backfill_data:
             asset_backfill_data = AssetBackfillData.from_serialized(
                 self.serialized_asset_backfill_data, asset_graph, self.backfill_timestamp
             )
         elif self.asset_backfill_data:
             asset_backfill_data = self.asset_backfill_data
         else:
@@ -150,15 +149,15 @@
         return None
 
     def is_valid_serialization(self, workspace: IWorkspace) -> bool:
         if self.is_asset_backfill:
             if self.serialized_asset_backfill_data:
                 return AssetBackfillData.is_valid_serialization(
                     self.serialized_asset_backfill_data,
-                    ExternalAssetGraph.from_workspace(workspace),
+                    workspace.asset_graph,
                 )
             else:
                 return True
         else:
             return True
 
     def get_backfill_status_per_asset_key(
@@ -167,15 +166,15 @@
         """Returns a sequence of backfill statuses for each targeted asset key in the asset graph,
         in topological order.
         """
         if not self.is_valid_serialization(workspace):
             return []
 
         if self.is_asset_backfill:
-            asset_graph = ExternalAssetGraph.from_workspace(workspace)
+            asset_graph = workspace.asset_graph
             try:
                 asset_backfill_data = self.get_asset_backfill_data(asset_graph)
             except DagsterDefinitionChangedDeserializationError:
                 return []
 
             return asset_backfill_data.get_backfill_status_per_asset_key(asset_graph)
         else:
@@ -184,15 +183,15 @@
     def get_target_partitions_subset(
         self, workspace: IWorkspace, asset_key: AssetKey
     ) -> Optional[PartitionsSubset]:
         if not self.is_valid_serialization(workspace):
             return None
 
         if self.is_asset_backfill:
-            asset_graph = ExternalAssetGraph.from_workspace(workspace)
+            asset_graph = workspace.asset_graph
             try:
                 asset_backfill_data = self.get_asset_backfill_data(asset_graph)
             except DagsterDefinitionChangedDeserializationError:
                 return None
 
             return asset_backfill_data.get_target_partitions_subset(asset_key)
         else:
@@ -201,30 +200,30 @@
     def get_target_root_partitions_subset(
         self, workspace: IWorkspace
     ) -> Optional[PartitionsSubset]:
         if not self.is_valid_serialization(workspace):
             return None
 
         if self.is_asset_backfill:
-            asset_graph = ExternalAssetGraph.from_workspace(workspace)
+            asset_graph = workspace.asset_graph
             try:
                 asset_backfill_data = self.get_asset_backfill_data(asset_graph)
             except DagsterDefinitionChangedDeserializationError:
                 return None
 
             return asset_backfill_data.get_target_root_partitions_subset(asset_graph)
         else:
             return None
 
     def get_num_partitions(self, workspace: IWorkspace) -> Optional[int]:
         if not self.is_valid_serialization(workspace):
             return 0
 
         if self.is_asset_backfill:
-            asset_graph = ExternalAssetGraph.from_workspace(workspace)
+            asset_graph = workspace.asset_graph
             try:
                 asset_backfill_data = self.get_asset_backfill_data(asset_graph)
             except DagsterDefinitionChangedDeserializationError:
                 return 0
 
             return asset_backfill_data.get_num_partitions()
         else:
@@ -234,15 +233,15 @@
             return len(self.partition_names)
 
     def get_partition_names(self, workspace: IWorkspace) -> Optional[Sequence[str]]:
         if not self.is_valid_serialization(workspace):
             return []
 
         if self.is_asset_backfill:
-            asset_graph = ExternalAssetGraph.from_workspace(workspace)
+            asset_graph = workspace.asset_graph
             try:
                 asset_backfill_data = self.get_asset_backfill_data(asset_graph)
             except DagsterDefinitionChangedDeserializationError:
                 return None
 
             return asset_backfill_data.get_partition_names()
         else:
@@ -329,15 +328,15 @@
             asset_backfill_data=self.asset_backfill_data,
         )
 
     def with_asset_backfill_data(
         self,
         asset_backfill_data: AssetBackfillData,
         dynamic_partitions_store: DynamicPartitionsStore,
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
     ) -> "PartitionBackfill":
         is_backcompat = self.serialized_asset_backfill_data is not None
         return PartitionBackfill(
             status=self.status,
             backfill_id=self.backfill_id,
             partition_set_origin=self.partition_set_origin,
             partition_names=self.partition_names,
@@ -356,15 +355,15 @@
             asset_backfill_data=asset_backfill_data if not is_backcompat else None,
         )
 
     @classmethod
     def from_asset_partitions(
         cls,
         backfill_id: str,
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         partition_names: Optional[Sequence[str]],
         asset_selection: Sequence[AssetKey],
         backfill_timestamp: float,
         tags: Mapping[str, str],
         dynamic_partitions_store: DynamicPartitionsStore,
         all_partitions: bool,
     ) -> "PartitionBackfill":
@@ -395,15 +394,15 @@
             asset_backfill_data=asset_backfill_data,
         )
 
     @classmethod
     def from_partitions_by_assets(
         cls,
         backfill_id: str,
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         backfill_timestamp: float,
         tags: Mapping[str, str],
         dynamic_partitions_store: DynamicPartitionsStore,
         partitions_by_assets: Sequence[PartitionsByAssetSelector],
     ):
         asset_backfill_data = AssetBackfillData.from_partitions_by_assets(
             asset_graph=asset_graph,
```

### Comparing `dagster-1.6.9/dagster/_core/execution/build_resources.py` & `dagster-1.7.0/dagster/_core/execution/build_resources.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/compute_logs.py` & `dagster-1.7.0/dagster/_core/execution/compute_logs.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/context/compute.py` & `dagster-1.7.0/dagster/_core/execution/context/compute.py`

 * *Files 4% similar despite different names*

```diff
@@ -21,15 +21,14 @@
 import dagster._check as check
 from dagster._annotations import (
     deprecated,
     experimental,
     public,
 )
 from dagster._core.definitions.asset_check_spec import AssetCheckKey, AssetCheckSpec
-from dagster._core.definitions.asset_checks import AssetChecksDefinition
 from dagster._core.definitions.assets import AssetsDefinition
 from dagster._core.definitions.data_version import (
     DataProvenance,
     DataVersion,
     extract_data_provenance_from_entry,
 )
 from dagster._core.definitions.decorators.op_decorator import DecoratedOpFunction
@@ -160,25 +159,30 @@
             "step_execution_context",
             StepExecutionContext,
         )
         self._pdb: Optional[ForkedPdb] = None
         self._events: List[DagsterEvent] = []
         self._output_metadata: Dict[str, Any] = {}
 
+    @property
+    def op_execution_context(self) -> "OpExecutionContext":
+        return self
+
     @public
     @property
     def op_config(self) -> Any:
         """Any: The parsed config specific to this op."""
         return self._step_execution_context.op_config
 
     @property
     def dagster_run(self) -> DagsterRun:
-        """PipelineRun: The current pipeline run."""
+        """DagsterRun: The current run."""
         return self._step_execution_context.dagster_run
 
+    @public
     @property
     def run(self) -> DagsterRun:
         """DagsterRun: The current run."""
         return self.dagster_run
 
     @public
     @property
@@ -586,61 +590,27 @@
     @property
     def selected_asset_keys(self) -> AbstractSet[AssetKey]:
         """Get the set of AssetKeys this execution is expected to materialize."""
         if not self.has_assets_def:
             return set()
         return self.assets_def.keys
 
-    @public
-    @property
-    def has_asset_checks_def(self) -> bool:
-        """Return a boolean indicating the presence of a backing AssetChecksDefinition
-        for the current execution.
-
-        Returns:
-            bool: True if there is a backing AssetChecksDefinition for the current execution, otherwise False.
-        """
-        return self.job_def.asset_layer.asset_checks_def_for_node(self.node_handle) is not None
-
-    @public
-    @property
-    def asset_checks_def(self) -> AssetChecksDefinition:
-        """The backing AssetChecksDefinition for what is currently executing, errors if not
-        available.
-
-        Returns:
-            AssetChecksDefinition.
-        """
-        asset_checks_def = self.job_def.asset_layer.asset_checks_def_for_node(self.node_handle)
-        if asset_checks_def is None:
-            raise DagsterInvalidPropertyError(
-                f"Op '{self.op.name}' does not have an asset checks definition."
-            )
-
-        return asset_checks_def
-
     @property
     def is_subset(self):
         """Whether the current AssetsDefinition is subsetted. Note that this can be True inside a
         a graph asset for an op that's not subsetted, if the graph asset is subsetted elsewhere.
         """
         if not self.has_assets_def:
             return False
         return self.assets_def.is_subset
 
     @public
     @property
     def selected_asset_check_keys(self) -> AbstractSet[AssetCheckKey]:
-        if self.has_assets_def:
-            return self.assets_def.check_keys
-
-        if self.has_asset_checks_def:
-            check.failed("Subset selection is not yet supported within an AssetChecksDefinition")
-
-        return set()
+        return self.assets_def.check_keys if self.has_assets_def else set()
 
     @public
     @property
     def selected_output_names(self) -> AbstractSet[str]:
         """Get the output names that correspond to the current selection of assets this execution is expected to materialize."""
         # map selected asset keys to the output names they correspond to
         selected_asset_keys = self.selected_asset_keys
@@ -1030,17 +1000,15 @@
 
                 # materializing the 2023-08-21 partition of this asset will log:
                 #   DailyPartitionsDefinition("2023-08-20")
                 #   DailyPartitionsDefinition("2023-08-20")
 
         """
         asset_key = self.asset_key_for_output(output_name)
-        result = self._step_execution_context.job_def.asset_layer.partitions_def_for_asset(
-            asset_key
-        )
+        result = self._step_execution_context.job_def.asset_layer.get(asset_key).partitions_def
         if result is None:
             raise DagsterInvariantViolationError(
                 f"Attempting to access partitions def for asset {asset_key}, but it is not"
                 " partitioned"
             )
 
         return result
@@ -1070,17 +1038,15 @@
                     context.log.info(context.asset_partitions_def_for_input("upstream_asset"))
 
                 # materializing the 2023-08-21 partition of this asset will log:
                 #   DailyPartitionsDefinition("2023-08-20")
 
         """
         asset_key = self.asset_key_for_input(input_name)
-        result = self._step_execution_context.job_def.asset_layer.partitions_def_for_asset(
-            asset_key
-        )
+        result = self._step_execution_context.job_def.asset_layer.get(asset_key).partitions_def
         if result is None:
             raise DagsterInvariantViolationError(
                 f"Attempting to access partitions def for asset {asset_key}, but it is not"
                 " partitioned"
             )
 
         return result
@@ -1315,22 +1281,14 @@
 
         Args:
             asset_key (AssetKey): Key of the asset for which to set the data version.
             data_version (DataVersion): The data version to set.
         """
         self._step_execution_context.set_data_version(asset_key, data_version)
 
-    @property
-    def asset_check_spec(self) -> AssetCheckSpec:
-        asset_checks_def = check.not_none(
-            self.job_def.asset_layer.asset_checks_def_for_node(self.node_handle),
-            "This context does not correspond to an AssetChecksDefinition",
-        )
-        return asset_checks_def.spec
-
     # In this mode no conversion is done on returned values and missing but expected outputs are not
     # allowed.
     @property
     def requires_typed_event_stream(self) -> bool:
         return self._step_execution_context.requires_typed_event_stream
 
     @property
@@ -1338,15 +1296,15 @@
         return self._step_execution_context.typed_event_stream_error_message
 
     def set_requires_typed_event_stream(self, *, error_message: Optional[str] = None) -> None:
         self._step_execution_context.set_requires_typed_event_stream(error_message=error_message)
 
     @staticmethod
     def get() -> "OpExecutionContext":
-        ctx = _current_asset_execution_context.get()
+        ctx = _current_execution_context.get()
         if ctx is None:
             raise DagsterInvariantViolationError("No current OpExecutionContext in scope.")
         return ctx.op_execution_context
 
 
 ###############################
 ######## AssetExecutionContext
@@ -1383,15 +1341,15 @@
     "op",
     "get_mapping_key",
     "selected_output_names",
 ]
 
 
 def _get_deprecation_kwargs(attr: str) -> Mapping[str, Any]:
-    deprecation_kwargs = {"breaking_version": "1.8.0"}
+    deprecation_kwargs = {"breaking_version": "a future release"}
     deprecation_kwargs["subject"] = f"AssetExecutionContext.{attr}"
 
     if attr in ALTERNATE_METHODS:
         deprecation_kwargs["additional_warn_text"] = (
             f"You have called the deprecated method {attr} on AssetExecutionContext. Use"
             f" context.{ALTERNATE_METHODS[attr]} instead."
         )
@@ -1414,17 +1372,22 @@
         self._op_execution_context = check.inst_param(
             op_execution_context, "op_execution_context", OpExecutionContext
         )
         self._step_execution_context = self._op_execution_context._step_execution_context  # noqa: SLF001
 
     @staticmethod
     def get() -> "AssetExecutionContext":
-        ctx = _current_asset_execution_context.get()
+        ctx = _current_execution_context.get()
         if ctx is None:
             raise DagsterInvariantViolationError("No current AssetExecutionContext in scope.")
+        if isinstance(ctx, AssetCheckExecutionContext):
+            raise DagsterInvariantViolationError(
+                "Can't use AssetExecutionContext.get() in the context of an "
+                "AssetCheckExecutionContext. Use AssetCheckExecutionContext.get() instead."
+            )
         return ctx
 
     @property
     def op_execution_context(self) -> OpExecutionContext:
         return self._op_execution_context
 
     ####### Top-level properties/methods on AssetExecutionContext
@@ -1777,34 +1740,17 @@
         )
 
     #### asset check related
 
     @public
     @property
     @_copy_docs_from_op_execution_context
-    def has_asset_checks_def(self) -> bool:
-        return self.op_execution_context.has_asset_checks_def
-
-    @public
-    @property
-    @_copy_docs_from_op_execution_context
-    def asset_checks_def(self) -> AssetChecksDefinition:
-        return self.op_execution_context.asset_checks_def
-
-    @public
-    @property
-    @_copy_docs_from_op_execution_context
     def selected_asset_check_keys(self) -> AbstractSet[AssetCheckKey]:
         return self.op_execution_context.selected_asset_check_keys
 
-    @property
-    @_copy_docs_from_op_execution_context
-    def asset_check_spec(self) -> AssetCheckSpec:
-        return self.op_execution_context.asset_check_spec
-
     #### data lineage related
 
     @public
     @experimental
     @_copy_docs_from_op_execution_context
     def get_asset_provenance(self, asset_key: AssetKey) -> Optional[DataProvenance]:
         return self.op_execution_context.get_asset_provenance(asset_key=asset_key)
@@ -1841,88 +1787,241 @@
         return self.op_execution_context.typed_event_stream_error_message
 
     @_copy_docs_from_op_execution_context
     def set_requires_typed_event_stream(self, *, error_message: Optional[str] = None) -> None:
         self.op_execution_context.set_requires_typed_event_stream(error_message=error_message)
 
 
+class AssetCheckExecutionContext:
+    def __init__(self, op_execution_context: OpExecutionContext) -> None:
+        self._op_execution_context = check.inst_param(
+            op_execution_context, "op_execution_context", OpExecutionContext
+        )
+        self._step_execution_context = self._op_execution_context._step_execution_context  # noqa: SLF001
+
+    @staticmethod
+    def get() -> "AssetCheckExecutionContext":
+        ctx = _current_execution_context.get()
+        if ctx is None:
+            raise DagsterInvariantViolationError("No current AssetExecutionContext in scope.")
+        if not isinstance(ctx, AssetCheckExecutionContext):
+            raise DagsterInvariantViolationError(
+                "Can't use AssetCheckExecutionContext.get() in the context of an "
+                "AssetCheckExecutionContext or OpExecutionContext. Use AssetCheckExecutionContext.get() instead."
+            )
+        return ctx
+
+    @property
+    def op_execution_context(self) -> OpExecutionContext:
+        return self._op_execution_context
+
+    @public
+    @property
+    def log(self) -> DagsterLogManager:
+        """The log manager available in the execution context. Logs will be viewable in the Dagster UI.
+        Returns: DagsterLogManager.
+        """
+        return self.op_execution_context.log
+
+    @public
+    @property
+    def pdb(self) -> ForkedPdb:
+        """Gives access to pdb debugging from within the asset. Materializing the asset via the
+        Dagster UI or CLI will enter the pdb debugging context in the process used to launch the UI or
+        run the CLI.
+
+        Returns: dagster.utils.forked_pdb.ForkedPdb
+        """
+        return self.op_execution_context.pdb
+
+    @property
+    def run(self) -> DagsterRun:
+        """The DagsterRun object corresponding to the execution. Information like run_id,
+        run configuration, and the assets selected for materialization can be found on the DagsterRun.
+        """
+        return self.op_execution_context.run
+
+    @public
+    @property
+    def job_def(self) -> JobDefinition:
+        """The definition for the currently executing job. Information like the job name, and job tags
+        can be found on the JobDefinition.
+        Returns: JobDefinition.
+        """
+        return self.op_execution_context.job_def
+
+    #### check related
+    @public
+    @property
+    @_copy_docs_from_op_execution_context
+    def selected_asset_check_keys(self) -> AbstractSet[AssetCheckKey]:
+        return self.op_execution_context.selected_asset_check_keys
+
+    @public
+    @property
+    def check_specs(self) -> Sequence[AssetCheckSpec]:
+        """The asset check specs for the currently executing asset check."""
+        return list(self.op_execution_context.assets_def.check_specs)
+
+    #### op related
+
+    @property
+    @_copy_docs_from_op_execution_context
+    def retry_number(self):
+        return self.op_execution_context.retry_number
+
+    @_copy_docs_from_op_execution_context
+    def describe_op(self) -> str:
+        return self.op_execution_context.describe_op()
+
+    @public
+    @property
+    @_copy_docs_from_op_execution_context
+    def op_def(self) -> OpDefinition:
+        return self.op_execution_context.op_def
+
+    #### execution related
+
+    @public
+    @property
+    @_copy_docs_from_op_execution_context
+    def instance(self) -> DagsterInstance:
+        return self.op_execution_context.instance
+
+    @property
+    @_copy_docs_from_op_execution_context
+    def step_launcher(self) -> Optional[StepLauncher]:
+        return self.op_execution_context.step_launcher
+
+    @_copy_docs_from_op_execution_context
+    def get_step_execution_context(self) -> StepExecutionContext:
+        return self.op_execution_context.get_step_execution_context()
+
+    # misc
+
+    @public
+    @property
+    @_copy_docs_from_op_execution_context
+    def resources(self) -> Any:
+        return self.op_execution_context.resources
+
+    @property
+    @_copy_docs_from_op_execution_context
+    def is_subset(self):
+        return self.op_execution_context.is_subset
+
+
+ExecutionContextTypes = Union[OpExecutionContext, AssetExecutionContext, AssetCheckExecutionContext]
+
+
 @contextmanager
 def enter_execution_context(
     step_context: StepExecutionContext,
-) -> Iterator[Union[OpExecutionContext, AssetExecutionContext]]:
+) -> Iterator[ExecutionContextTypes]:
     """Get the correct context based on the type of step (op or asset) and the user provided context
     type annotation. Follows these rules.
 
-    step type     annotation                result
-    asset         AssetExecutionContext     AssetExecutionContext
-    asset         OpExecutionContext        OpExecutionContext
-    asset         None                      AssetExecutionContext
-    op            AssetExecutionContext     Error - we cannot init an AssetExecutionContext w/o an AssetsDefinition
-    op            OpExecutionContext        OpExecutionContext
-    op            None                      OpExecutionContext
-    asset_check   AssetExecutionContext     AssetExecutionContext
-    asset_check   OpExecutionContext        OpExecutionContext
-    asset_check   None                      AssetExecutionContext
+    step type     annotation                   result
+    asset         AssetExecutionContext        AssetExecutionContext
+    asset         AssetCheckExecutionContext   Error - not an asset check
+    asset         OpExecutionContext           OpExecutionContext
+    asset         None                         AssetExecutionContext
+    op            AssetExecutionContext        Error - we cannot init an AssetExecutionContextext w/o an AssetsDefinition
+    op            AssetCheckExecutionContext   Error - not an asset check
+    op            OpExecutionContext           OpExecutionContext
+    op            None                         OpExecutionContext
+    asset_check   AssetCheckExecutionContext   AssetCheckExecutionContext
+    asset_check   AssetExecutionContext        Error - not an asset
+    asset_check   OpExecutionContext           OpExecutionContext
+    asset_check   None                         AssetCheckExecutionContext
 
     For ops in graph-backed assets
-    step type     annotation                result
-    op            AssetExecutionContext     AssetExecutionContext
-    op            OpExecutionContext        OpExecutionContext
-    op            None                      OpExecutionContext
+    step type     annotation                   result
+    op            AssetExecutionContext        AssetExecutionContext
+    op            AssetCheckExecutionContext   Error - not an asset check
+    op            OpExecutionContext           OpExecutionContext
+    op            None                         OpExecutionContext
+
     """
     is_sda_step = step_context.is_sda_step
     is_op_in_graph_asset = step_context.is_in_graph_asset
-    is_asset_check = step_context.is_asset_check_step
+    asset_check_only_step = (
+        step_context.is_asset_check_step and not is_sda_step and not is_op_in_graph_asset
+    )
     context_annotation = EmptyAnnotation
     compute_fn = step_context.op_def._compute_fn  # noqa: SLF001
     compute_fn = (
         compute_fn
         if isinstance(compute_fn, DecoratedOpFunction)
         else DecoratedOpFunction(compute_fn)
     )
     if compute_fn.has_context_arg():
         context_param = compute_fn.get_context_arg()
         context_annotation = context_param.annotation
 
-    # It would be nice to do this check at definition time, rather than at run time, but we don't
-    # know if the op is part of an op job or a graph-backed asset until we have the step execution context
-    if (
-        context_annotation is AssetExecutionContext
-        and not is_sda_step
-        and not is_asset_check
-        and not is_op_in_graph_asset
-    ):
-        # AssetExecutionContext requires an AssetsDefinition during init, so an op in an op job
-        # cannot be annotated with AssetExecutionContext
-        raise DagsterInvalidDefinitionError(
-            "Cannot annotate @op `context` parameter with type AssetExecutionContext unless the"
-            " op is part of a graph-backed asset. `context` must be annotated with"
-            " OpExecutionContext, or left blank."
+    if context_annotation is AssetCheckExecutionContext and not asset_check_only_step:
+        if is_sda_step:
+            raise DagsterInvalidDefinitionError(
+                "Cannot annotate @asset `context` parameter with type AssetCheckExecutionContext. "
+                "`context` must be annotated with AssetExecutionContext, OpExecutionContext, or left blank."
+            )
+        else:
+            raise DagsterInvalidDefinitionError(
+                "Cannot annotate @op `context` parameter with type AssetCheckExecutionContext. "
+                "`context` must be annotated with OpExecutionContext, AssetExecutionContext (if part of "
+                "a graph-backed-asset) or left blank."
+            )
+
+    if context_annotation is AssetExecutionContext:
+        if asset_check_only_step:
+            raise DagsterInvalidDefinitionError(
+                "Cannot annotate @asset_check `context` parameter with type AssetExecutionContext. "
+                "`context` must be annotated with AssetCheckExecutionContext, OpExecutionContext, or left blank."
+            )
+
+        # It would be nice to do this check at definition time, rather than at run time, but we don't
+        # know if the op is part of an op job or a graph-backed asset until we have the step execution context
+        if not is_sda_step and not is_op_in_graph_asset:
+            # AssetExecutionContext requires an AssetsDefinition during init, so an op in an op job
+            # cannot be annotated with AssetExecutionContext
+            raise DagsterInvalidDefinitionError(
+                "Cannot annotate @op `context` parameter with type AssetExecutionContext unless the"
+                " op is part of a graph-backed asset. `context` must be annotated with"
+                " OpExecutionContext, or left blank."
+            )
+
+    # default to AssetCheckExecutionContext in @asset_checks
+    if asset_check_only_step and context_annotation is not OpExecutionContext:
+        asset_ctx = AssetCheckExecutionContext(
+            op_execution_context=OpExecutionContext(step_context)
         )
+    else:
+        asset_ctx = AssetExecutionContext(op_execution_context=OpExecutionContext(step_context))
 
-    # Structured assuming upcoming changes to make AssetExecutionContext contain an OpExecutionContext
-    asset_ctx = AssetExecutionContext(op_execution_context=OpExecutionContext(step_context))
-    asset_token = _current_asset_execution_context.set(asset_ctx)
+    asset_token = _current_execution_context.set(asset_ctx)
 
     try:
         if context_annotation is EmptyAnnotation:
             # if no type hint has been given, default to:
             # * AssetExecutionContext for sda steps not in graph-backed assets, and asset_checks
             # * OpExecutionContext for non sda steps
             # * OpExecutionContext for ops in graph-backed assets
-            if is_asset_check:
+            if asset_check_only_step:
                 yield asset_ctx
             elif is_op_in_graph_asset or not is_sda_step:
                 yield asset_ctx.op_execution_context
             else:
                 yield asset_ctx
-        elif context_annotation is AssetExecutionContext:
+        elif (
+            context_annotation is AssetExecutionContext
+            or context_annotation is AssetCheckExecutionContext
+        ):
             yield asset_ctx
         else:
             yield asset_ctx.op_execution_context
     finally:
-        _current_asset_execution_context.reset(asset_token)
+        _current_execution_context.reset(asset_token)
 
 
-_current_asset_execution_context: ContextVar[Optional[AssetExecutionContext]] = ContextVar(
-    "_current_asset_execution_context", default=None
-)
+_current_execution_context: ContextVar[
+    Optional[Union[AssetExecutionContext, AssetCheckExecutionContext]]
+] = ContextVar("_current_execution_context", default=None)
```

### Comparing `dagster-1.6.9/dagster/_core/execution/context/hook.py` & `dagster-1.7.0/dagster/_core/execution/context/hook.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-import warnings
 from typing import TYPE_CHECKING, AbstractSet, Any, Dict, Mapping, Optional, Set, Union
 
 import dagster._check as check
 from dagster._annotations import public
 
 from ...definitions.composition import PendingNodeInvocation
 from ...definitions.decorators.graph_decorator import graph
@@ -85,22 +84,14 @@
         return self._step_execution_context.instance
 
     @property
     def op(self) -> Node:
         """The op instance associated with the hook."""
         return self._step_execution_context.op
 
-    @property
-    def step(self) -> ExecutionStep:
-        warnings.warn(
-            "The step property of HookContext has been deprecated, and will be removed "
-            "in a future release."
-        )
-        return self._step_execution_context.step
-
     @public
     @property
     def step_key(self) -> str:
         """The key for the step where this hook is being triggered."""
         return self._step_execution_context.step.key
 
     @public
@@ -111,58 +102,46 @@
 
     @public
     @property
     def resources(self) -> "Resources":
         """Resources available in the hook context."""
         return self._resources
 
-    @property
-    def solid_config(self) -> Any:
-        solid_config = self._step_execution_context.resolved_run_config.ops.get(
-            str(self._step_execution_context.step.node_handle)
-        )
-        return solid_config.config if solid_config else None
-
     @public
     @property
     def op_config(self) -> Any:
         """The parsed config specific to this op."""
-        return self.solid_config
+        op_config = self._step_execution_context.resolved_run_config.ops.get(
+            str(self._step_execution_context.step.node_handle)
+        )
+        return op_config.config if op_config else None
 
     # Because of the fact that we directly use the log manager of the step, if a user calls
     # hook_context.log.with_tags, then they will end up mutating the step's logging tags as well.
     # This is not problematic because the hook only runs after the step has been completed.
     @public
     @property
     def log(self) -> DagsterLogManager:
         """Centralized log dispatch from user code."""
         return self._step_execution_context.log
 
-    @property
-    def solid_exception(self) -> Optional[BaseException]:
-        """The thrown exception in a failed solid.
-
-        Returns:
-            Optional[BaseException]: the exception object, None if the solid execution succeeds.
-        """
-        return self.op_exception
-
     @public
     @property
     def op_exception(self) -> Optional[BaseException]:
         """The thrown exception in a failed op."""
         exc = self._step_execution_context.step_exception
 
         if isinstance(exc, RetryRequestedFromPolicy):
             return exc.__cause__
 
         return exc
 
+    @public
     @property
-    def solid_output_values(self) -> Mapping[str, Union[Any, Mapping[str, Any]]]:
+    def op_output_values(self) -> Mapping[str, Union[Any, Mapping[str, Any]]]:
         """The computed output values.
 
         Returns a dictionary where keys are output names and the values are:
             * the output values in the normal case
             * a dictionary from mapping key to corresponding value in the mapped case
         """
         results: Dict[str, Union[Any, Dict[str, Any]]] = {}
@@ -183,17 +162,42 @@
             else:
                 results[step_output_handle.output_name] = value
 
         return results
 
     @public
     @property
-    def op_output_values(self):
-        """Computed output values in an op."""
-        return self.solid_output_values
+    def op_output_metadata(self) -> Mapping[str, Union[Any, Mapping[str, Any]]]:
+        """The applied output metadata.
+
+        Returns a dictionary where keys are output names and the values are:
+            * the applied output metadata in the normal case
+            * a dictionary from mapping key to corresponding metadata in the mapped case
+        """
+        results: Dict[str, Union[Any, Dict[str, Any]]] = {}
+        captured = self._step_execution_context.step_output_metadata_capture
+
+        if captured is None:
+            check.failed("Outputs were unexpectedly not captured for hook")
+
+        # make the returned values more user-friendly
+        for step_output_handle, metadata in captured.items():
+            if step_output_handle.mapping_key:
+                if results.get(step_output_handle.output_name) is None:
+                    results[step_output_handle.output_name] = {
+                        step_output_handle.mapping_key: metadata
+                    }
+                else:
+                    results[step_output_handle.output_name][step_output_handle.mapping_key] = (
+                        metadata
+                    )
+            else:
+                results[step_output_handle.output_name] = metadata
+
+        return results
 
 
 class UnboundHookContext(HookContext):
     def __init__(
         self,
         resources: Mapping[str, Any],
         op: Optional[Union[OpDefinition, PendingNodeInvocation]],
@@ -281,34 +285,44 @@
                 "At least one provided resource is a generator, but attempting to access "
                 "resources outside of context manager scope. You can use the following syntax to "
                 "open a context manager: `with build_hook_context(...) as context:`"
             )
         return self._resources
 
     @property
-    def solid_config(self) -> Any:
-        raise DagsterInvalidPropertyError(_property_msg("solid_config", "property"))
+    def op_config(self) -> Any:
+        raise DagsterInvalidPropertyError(_property_msg("op_config", "property"))
 
     @property
     def log(self) -> DagsterLogManager:
         return self._log
 
     @property
     def op_exception(self) -> Optional[BaseException]:
         return self._op_exception
 
     @property
-    def solid_output_values(self) -> Mapping[str, Union[Any, Mapping[str, Any]]]:
+    def op_output_values(self) -> Mapping[str, Union[Any, Mapping[str, Any]]]:
         """The computed output values.
 
         Returns a dictionary where keys are output names and the values are:
             * the output values in the normal case
             * a dictionary from mapping key to corresponding value in the mapped case
         """
-        raise DagsterInvalidPropertyError(_property_msg("solid_output_values", "method"))
+        raise DagsterInvalidPropertyError(_property_msg("op_output_values", "method"))
+
+    @property
+    def op_output_metadata(self) -> Mapping[str, Union[Any, Mapping[str, Any]]]:
+        """The applied output metadata.
+
+        Returns a dictionary where keys are output names and the values are:
+            * the applied output metadata in the normal case
+            * a dictionary from mapping key to corresponding metadata in the mapped case
+        """
+        raise DagsterInvalidPropertyError(_property_msg("op_output_metadata", "method"))
 
     @property
     def instance(self) -> "DagsterInstance":
         if not self._instance:
             raise DagsterInvariantViolationError(
                 "Tried to access the HookContext instance, but no instance was provided to"
                 " `build_hook_context`."
@@ -373,34 +387,44 @@
         return self._hook_def.required_resource_keys
 
     @property
     def resources(self) -> "Resources":
         return self._resources
 
     @property
-    def solid_config(self) -> Any:
-        raise DagsterInvalidPropertyError(_property_msg("solid_config", "property"))
+    def op_config(self) -> Any:
+        raise DagsterInvalidPropertyError(_property_msg("op_config", "property"))
 
     @property
     def log(self) -> DagsterLogManager:
         return self._log_manager
 
     @property
     def op_exception(self):
         return self._op_exception
 
     @property
-    def solid_output_values(self) -> Mapping[str, Union[Any, Mapping[str, Any]]]:
+    def op_output_values(self) -> Mapping[str, Union[Any, Mapping[str, Any]]]:
         """The computed output values.
 
         Returns a dictionary where keys are output names and the values are:
             * the output values in the normal case
             * a dictionary from mapping key to corresponding value in the mapped case
         """
-        raise DagsterInvalidPropertyError(_property_msg("solid_output_values", "method"))
+        raise DagsterInvalidPropertyError(_property_msg("op_output_values", "method"))
+
+    @property
+    def op_output_metadata(self) -> Mapping[str, Union[Any, Mapping[str, Any]]]:
+        """The applied output metadata.
+
+        Returns a dictionary where keys are output names and the values are:
+            * the applied output metadata in the normal case
+            * a dictionary from mapping key to corresponding metadata in the mapped case
+        """
+        raise DagsterInvalidPropertyError(_property_msg("op_output_metadata", "method"))
 
     @property
     def instance(self) -> "DagsterInstance":
         if not self._instance:
             raise DagsterInvariantViolationError(
                 "Tried to access the HookContext instance, but no instance was provided to"
                 " `build_hook_context`."
```

### Comparing `dagster-1.6.9/dagster/_core/execution/context/init.py` & `dagster-1.7.0/dagster/_core/execution/context/init.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/context/input.py` & `dagster-1.7.0/dagster/_core/execution/context/input.py`

 * *Files 7% similar despite different names*

```diff
@@ -8,40 +8,46 @@
     Mapping,
     Optional,
     Sequence,
     Union,
 )
 
 import dagster._check as check
-from dagster._annotations import public
+from dagster._annotations import deprecated, deprecated_param, public
 from dagster._core.definitions.events import AssetKey, AssetObservation, CoercibleToAssetKey
 from dagster._core.definitions.metadata import (
     ArbitraryMetadataMapping,
     MetadataValue,
 )
 from dagster._core.definitions.partition import PartitionsSubset
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
 from dagster._core.definitions.time_window_partitions import (
     TimeWindow,
 )
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.instance import DagsterInstance, DynamicPartitionsStore
+from dagster._utils.warnings import normalize_renamed_param
 
 if TYPE_CHECKING:
     from dagster._core.definitions import PartitionsDefinition
     from dagster._core.definitions.op_definition import OpDefinition
     from dagster._core.definitions.resource_definition import Resources
     from dagster._core.events import DagsterEvent
     from dagster._core.execution.context.system import StepExecutionContext
     from dagster._core.log_manager import DagsterLogManager
     from dagster._core.types.dagster_type import DagsterType
 
     from .output import OutputContext
 
 
+@deprecated_param(
+    param="metadata",
+    breaking_version="2.0",
+    additional_warn_text="Use `definition_metadata` instead.",
+)
 class InputContext:
     """The ``context`` object available to the load_input method of :py:class:`InputManager`.
 
     Users should not instantiate this object directly. In order to construct
     an `InputContext` for testing an IO Manager's `load_input` method, use
     :py:func:`dagster.build_input_context`.
 
@@ -58,35 +64,43 @@
     def __init__(
         self,
         *,
         name: Optional[str] = None,
         job_name: Optional[str] = None,
         op_def: Optional["OpDefinition"] = None,
         config: Optional[Any] = None,
-        metadata: Optional[ArbitraryMetadataMapping] = None,
+        definition_metadata: Optional[ArbitraryMetadataMapping] = None,
         upstream_output: Optional["OutputContext"] = None,
         dagster_type: Optional["DagsterType"] = None,
         log_manager: Optional["DagsterLogManager"] = None,
         resource_config: Optional[Mapping[str, Any]] = None,
         resources: Optional[Union["Resources", Mapping[str, Any]]] = None,
         step_context: Optional["StepExecutionContext"] = None,
         asset_key: Optional[AssetKey] = None,
         partition_key: Optional[str] = None,
         asset_partitions_subset: Optional[PartitionsSubset] = None,
         asset_partitions_def: Optional["PartitionsDefinition"] = None,
         instance: Optional[DagsterInstance] = None,
+        # deprecated
+        metadata: Optional[ArbitraryMetadataMapping] = None,
     ):
         from dagster._core.definitions.resource_definition import IContainsGenerator, Resources
         from dagster._core.execution.build_resources import build_resources
 
         self._name = name
         self._job_name = job_name
         self._op_def = op_def
         self._config = config
-        self._metadata = metadata or {}
+        self._definition_metadata = (
+            normalize_renamed_param(
+                definition_metadata, "definition_metadata", metadata, "metadata"
+            )
+            or {}
+        )
+        self._user_generated_metadata = {}
         self._upstream_output = upstream_output
         self._dagster_type = dagster_type
         self._log = log_manager
         self._resource_config = resource_config
         self._step_context = step_context
         self._asset_key = asset_key
         if self._step_context and self._step_context.has_partition_key:
@@ -177,23 +191,30 @@
 
     @public
     @property
     def config(self) -> Any:
         """The config attached to the input that we're loading."""
         return self._config
 
+    @deprecated(breaking_version="2.0.0", additional_warn_text="Use definition_metadata instead")
     @public
     @property
     def metadata(self) -> Optional[ArbitraryMetadataMapping]:
-        """A dict of metadata that is assigned to the InputDefinition that we're loading for.
+        """Deprecated: Use definitiion_metadata instead."""
+        return self._definition_metadata
+
+    @public
+    @property
+    def definition_metadata(self) -> ArbitraryMetadataMapping:
+        """A dict of metadata that is assigned to the InputDefinition that we're loading.
         This property only contains metadata passed in explicitly with :py:class:`AssetIn`
-        or :py:class:`In`. To access metadata of an upstream asset or operation definition,
-        use the metadata in :py:attr:`.InputContext.upstream_output`.
+        or :py:class:`In`. To access metadata of an upstream asset or op definition,
+        use the definition_metadata in :py:attr:`.InputContext.upstream_output`.
         """
-        return self._metadata
+        return self._definition_metadata
 
     @public
     @property
     def upstream_output(self) -> Optional["OutputContext"]:
         """Info about the output that produced the object we're loading."""
         return self._upstream_output
 
@@ -469,15 +490,18 @@
         The asset observation will be yielded from the run and appear in the event log.
         Only valid if the context has an asset key.
         """
         from dagster._core.definitions.metadata import normalize_metadata
         from dagster._core.events import DagsterEvent
 
         metadata = check.mapping_param(metadata, "metadata", key_type=str)
-        self._metadata = {**self._metadata, **normalize_metadata(metadata)}
+        self._user_generated_metadata = {
+            **self._user_generated_metadata,
+            **normalize_metadata(metadata),
+        }
         if self.has_asset_key:
             check.opt_str_param(description, "description")
 
             observation = AssetObservation(
                 asset_key=self.asset_key,
                 description=description,
                 partition=self.asset_partition_key if self.has_asset_partitions else None,
@@ -509,46 +533,60 @@
                 context = build_input_context()
                 mgr.load_input(context)
                 observations = context.get_observations()
                 ...
         """
         return self._observations
 
-    def consume_metadata(self) -> Mapping[str, MetadataValue]:
-        result = self._metadata
-        self._metadata = {}
+    def consume_logged_metadata(self) -> Mapping[str, MetadataValue]:
+        """Pops and yields all user-generated metadata entries that have been recorded from this context.
+
+        If consume_logged_metadata has not yet been called, this will yield all logged events since
+        the call to `load_input`. If consume_logged_metadata has been called, it will yield all
+        events since the last time consume_logged_metadata was called. Designed for internal
+        use. Users should never need to invoke this method.
+        """
+        result = self._user_generated_metadata
+        self._user_generated_metadata = {}
         return result
 
 
+@deprecated_param(
+    param="metadata",
+    breaking_version="2.0",
+    additional_warn_text="Use `definition_metadata` instead.",
+)
 def build_input_context(
     name: Optional[str] = None,
     config: Optional[Any] = None,
-    metadata: Optional[ArbitraryMetadataMapping] = None,
+    definition_metadata: Optional[ArbitraryMetadataMapping] = None,
     upstream_output: Optional["OutputContext"] = None,
     dagster_type: Optional["DagsterType"] = None,
     resource_config: Optional[Mapping[str, Any]] = None,
     resources: Optional[Mapping[str, Any]] = None,
     op_def: Optional["OpDefinition"] = None,
     step_context: Optional["StepExecutionContext"] = None,
     asset_key: Optional[CoercibleToAssetKey] = None,
     partition_key: Optional[str] = None,
     asset_partition_key_range: Optional[PartitionKeyRange] = None,
     asset_partitions_def: Optional["PartitionsDefinition"] = None,
     instance: Optional[DagsterInstance] = None,
+    # deprecated
+    metadata: Optional[ArbitraryMetadataMapping] = None,
 ) -> "InputContext":
     """Builds input context from provided parameters.
 
     ``build_input_context`` can be used as either a function, or a context manager. If resources
     that are also context managers are provided, then ``build_input_context`` must be used as a
     context manager.
 
     Args:
         name (Optional[str]): The name of the input that we're loading.
         config (Optional[Any]): The config attached to the input that we're loading.
-        metadata (Optional[Dict[str, Any]]): A dict of metadata that is assigned to the
+        definition_metadata (Optional[Dict[str, Any]]): A dict of metadata that is assigned to the
             InputDefinition that we're loading for.
         upstream_output (Optional[OutputContext]): Info about the output that produced the object
             we're loading.
         dagster_type (Optional[DagsterType]): The type of this input.
         resource_config (Optional[Dict[str, Any]]): The resource config to make available from the
             input context. This usually corresponds to the config provided to the resource that
             loads the input manager.
@@ -575,15 +613,22 @@
     from dagster._core.definitions import OpDefinition, PartitionsDefinition
     from dagster._core.execution.context.output import OutputContext
     from dagster._core.execution.context.system import StepExecutionContext
     from dagster._core.execution.context_creation_job import initialize_console_manager
     from dagster._core.types.dagster_type import DagsterType
 
     name = check.opt_str_param(name, "name")
-    metadata = check.opt_mapping_param(metadata, "metadata", key_type=str)
+    check.opt_mapping_param(definition_metadata, "definition_metadata", key_type=str)
+    check.opt_mapping_param(metadata, "metadata", key_type=str)
+    definition_metadata = normalize_renamed_param(
+        definition_metadata,
+        "definition_metadata",
+        metadata,
+        "metadata",
+    )
     upstream_output = check.opt_inst_param(upstream_output, "upstream_output", OutputContext)
     dagster_type = check.opt_inst_param(dagster_type, "dagster_type", DagsterType)
     resource_config = check.opt_mapping_param(resource_config, "resource_config", key_type=str)
     resources = check.opt_mapping_param(resources, "resources", key_type=str)
     op_def = check.opt_inst_param(op_def, "op_def", OpDefinition)
     step_context = check.opt_inst_param(step_context, "step_context", StepExecutionContext)
     asset_key = AssetKey.from_coercible(asset_key) if asset_key else None
@@ -603,15 +648,15 @@
     else:
         asset_partitions_subset = None
 
     return InputContext(
         name=name,
         job_name=None,
         config=config,
-        metadata=metadata,
+        definition_metadata=definition_metadata,
         upstream_output=upstream_output,
         dagster_type=dagster_type,
         log_manager=initialize_console_manager(None),
         resource_config=resource_config,
         resources=resources,
         step_context=step_context,
         op_def=op_def,
```

### Comparing `dagster-1.6.9/dagster/_core/execution/context/invocation.py` & `dagster-1.7.0/dagster/_core/execution/context/invocation.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/context/logger.py` & `dagster-1.7.0/dagster/_core/execution/context/logger.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/context/output.py` & `dagster-1.7.0/dagster/_core/execution/context/output.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Optional,
     Sequence,
     Union,
     cast,
 )
 
 import dagster._check as check
-from dagster._annotations import public
+from dagster._annotations import deprecated, deprecated_param, public
 from dagster._core.definitions.asset_layer import AssetOutputInfo
 from dagster._core.definitions.events import (
     AssetKey,
     AssetMaterialization,
     AssetObservation,
     CoercibleToAssetKey,
 )
@@ -26,14 +26,15 @@
     MetadataValue,
     RawMetadataValue,
 )
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
 from dagster._core.definitions.time_window_partitions import TimeWindow
 from dagster._core.errors import DagsterInvalidMetadata, DagsterInvariantViolationError
 from dagster._core.execution.plan.utils import build_resources_for_manager
+from dagster._utils.warnings import normalize_renamed_param
 
 if TYPE_CHECKING:
     from dagster._core.definitions import JobDefinition, PartitionsDefinition
     from dagster._core.definitions.op_definition import OpDefinition
     from dagster._core.definitions.resource_definition import Resources
     from dagster._core.events import DagsterEvent
     from dagster._core.execution.context.system import StepExecutionContext
@@ -42,14 +43,19 @@
     from dagster._core.log_manager import DagsterLogManager
     from dagster._core.system_config.objects import ResolvedRunConfig
     from dagster._core.types.dagster_type import DagsterType
 
 RUN_ID_PLACEHOLDER = "__EPHEMERAL_RUN_ID"
 
 
+@deprecated_param(
+    param="metadata",
+    breaking_version="2.0",
+    additional_warn_text="Use `definition_metadata` instead.",
+)
 class OutputContext:
     """The context object that is available to the `handle_output` method of an :py:class:`IOManager`.
 
     Users should not instantiate this object directly. To construct an
     `OutputContext` for testing an IO Manager's `handle_output` method, use
     :py:func:`dagster.build_output_context`.
 
@@ -63,15 +69,16 @@
                     ...
     """
 
     _step_key: Optional[str]
     _name: Optional[str]
     _job_name: Optional[str]
     _run_id: Optional[str]
-    _metadata: ArbitraryMetadataMapping
+    _definition_metadata: ArbitraryMetadataMapping
+    _output_metadata: ArbitraryMetadataMapping
     _user_generated_metadata: Mapping[str, MetadataValue]
     _mapping_key: Optional[str]
     _config: object
     _op_def: Optional["OpDefinition"]
     _dagster_type: Optional["DagsterType"]
     _log: Optional["DagsterLogManager"]
     _version: Optional[str]
@@ -88,36 +95,43 @@
 
     def __init__(
         self,
         step_key: Optional[str] = None,
         name: Optional[str] = None,
         job_name: Optional[str] = None,
         run_id: Optional[str] = None,
-        metadata: Optional[ArbitraryMetadataMapping] = None,
+        definition_metadata: Optional[ArbitraryMetadataMapping] = None,
         mapping_key: Optional[str] = None,
         config: object = None,
         dagster_type: Optional["DagsterType"] = None,
         log_manager: Optional["DagsterLogManager"] = None,
         version: Optional[str] = None,
         resource_config: Optional[Mapping[str, object]] = None,
         resources: Optional[Union["Resources", Mapping[str, object]]] = None,
         step_context: Optional["StepExecutionContext"] = None,
         op_def: Optional["OpDefinition"] = None,
         asset_info: Optional[AssetOutputInfo] = None,
         warn_on_step_context_use: bool = False,
         partition_key: Optional[str] = None,
+        output_metadata: Optional[Mapping[str, RawMetadataValue]] = None,
+        # deprecated
+        metadata: Optional[ArbitraryMetadataMapping] = None,
     ):
         from dagster._core.definitions.resource_definition import IContainsGenerator, Resources
         from dagster._core.execution.build_resources import build_resources
 
         self._step_key = step_key
         self._name = name
         self._job_name = job_name
         self._run_id = run_id
-        self._metadata = metadata or {}
+        normalized_metadata = normalize_renamed_param(
+            definition_metadata, "definition_metadata", metadata, "metadata"
+        )
+        self._definition_metadata = normalized_metadata or {}
+        self._output_metadata = output_metadata or {}
         self._mapping_key = mapping_key
         self._config = config
         self._op_def = op_def
         self._dagster_type = dagster_type
         self._log = log_manager
         self._version = version
         self._resource_config = resource_config
@@ -204,21 +218,43 @@
             raise DagsterInvariantViolationError(
                 "Attempting to access run_id, "
                 "but it was not provided when constructing the OutputContext"
             )
 
         return self._run_id
 
+    @deprecated(breaking_version="2.0.0", additional_warn_text="Use definition_metadata instead")
     @public
     @property
     def metadata(self) -> Optional[ArbitraryMetadataMapping]:
+        """Deprecated: used definition_metadata instead."""
+        return self._definition_metadata
+
+    @public
+    @property
+    def definition_metadata(self) -> ArbitraryMetadataMapping:
         """A dict of the metadata that is assigned to the OutputDefinition that produced
-        the output.
+        the output. Metadata is assigned to an OutputDefinition either directly on the OutputDefinition
+        or in the @asset decorator.
         """
-        return self._metadata
+        return self._definition_metadata
+
+    @public
+    @property
+    def output_metadata(self) -> ArbitraryMetadataMapping:
+        """A dict of the metadata that is assigned to the output at execution time."""
+        if self._warn_on_step_context_use:
+            warnings.warn(
+                "You are using InputContext.upstream_output.output_metadata."
+                "Output metadata is not available when accessed from the InputContext."
+                "https://github.com/dagster-io/dagster/issues/20094"
+            )
+            return {}
+
+        return self._output_metadata
 
     @public
     @property
     def mapping_key(self) -> Optional[str]:
         """The key that identifies a unique mapped output. None for regular outputs."""
         return self._mapping_key
 
@@ -324,15 +360,15 @@
         return self._asset_info.key
 
     @public
     @property
     def asset_partitions_def(self) -> "PartitionsDefinition":
         """The PartitionsDefinition on the asset corresponding to this output."""
         asset_key = self.asset_key
-        result = self.step_context.job_def.asset_layer.partitions_def_for_asset(asset_key)
+        result = self.step_context.job_def.asset_layer.get(asset_key).partitions_def
         if result is None:
             raise DagsterInvariantViolationError(
                 f"Attempting to access partitions def for asset {asset_key}, but it is not"
                 " partitioned"
             )
 
         return result
@@ -721,14 +757,15 @@
     step_output_handle: "StepOutputHandle",
     run_id: Optional[str],
     log_manager: Optional["DagsterLogManager"],
     step_context: Optional["StepExecutionContext"],
     resources: Optional["Resources"],
     version: Optional[str],
     warn_on_step_context_use: bool = False,
+    output_metadata: Optional[Mapping[str, RawMetadataValue]] = None,
 ) -> "OutputContext":
     """Args:
     run_id (str): The run ID of the run that produced the output, not necessarily the run that
         the context will be used in.
     """
     step = execution_plan.get_step_by_key(step_output_handle.step_key)
     # get config
@@ -747,17 +784,19 @@
     resource_config = resolved_run_config.resources[io_manager_key].config
 
     node_handle = execution_plan.get_step_by_key(step.key).node_handle
     asset_info = job_def.asset_layer.asset_info_for_output(
         node_handle=node_handle, output_name=step_output.name
     )
     if asset_info is not None:
-        metadata = job_def.asset_layer.metadata_for_asset(asset_info.key) or output_def.metadata
+        definition_metadata = (
+            job_def.asset_layer.get(asset_info.key).metadata or output_def.metadata
+        )
     else:
-        metadata = output_def.metadata
+        definition_metadata = output_def.metadata
 
     if step_context:
         check.invariant(
             not resources,
             "Expected either resources or step context to be set, but "
             "received both. If step context is provided, resources for IO manager will be "
             "retrieved off of that.",
@@ -765,26 +804,27 @@
         resources = build_resources_for_manager(io_manager_key, step_context)
 
     return OutputContext(
         step_key=step_output_handle.step_key,
         name=step_output_handle.output_name,
         job_name=job_def.name,
         run_id=run_id,
-        metadata=metadata,
+        definition_metadata=definition_metadata,
         mapping_key=step_output_handle.mapping_key,
         config=output_config,
         op_def=job_def.get_node(step.node_handle).definition,  # type: ignore  # (should be OpDefinition not NodeDefinition)
         dagster_type=output_def.dagster_type,
         log_manager=log_manager,
         version=version,
         step_context=step_context,
         resource_config=resource_config,
         resources=resources,
         asset_info=asset_info,
         warn_on_step_context_use=warn_on_step_context_use,
+        output_metadata=output_metadata,
     )
 
 
 def step_output_version(
     job_def: "JobDefinition",
     execution_plan: "ExecutionPlan",
     resolved_run_config: "ResolvedRunConfig",
@@ -798,39 +838,46 @@
     return (
         step_output_versions[step_output_handle]
         if step_output_handle in step_output_versions
         else None
     )
 
 
+@deprecated_param(
+    param="metadata",
+    breaking_version="2.0",
+    additional_warn_text="Use `definition_metadata` instead.",
+)
 def build_output_context(
     step_key: Optional[str] = None,
     name: Optional[str] = None,
-    metadata: Optional[Mapping[str, RawMetadataValue]] = None,
+    definition_metadata: Optional[Mapping[str, RawMetadataValue]] = None,
     run_id: Optional[str] = None,
     mapping_key: Optional[str] = None,
     config: Optional[Any] = None,
     dagster_type: Optional["DagsterType"] = None,
     version: Optional[str] = None,
     resource_config: Optional[Mapping[str, object]] = None,
     resources: Optional[Mapping[str, object]] = None,
     op_def: Optional["OpDefinition"] = None,
     asset_key: Optional[CoercibleToAssetKey] = None,
     partition_key: Optional[str] = None,
+    # deprecated
+    metadata: Optional[Mapping[str, RawMetadataValue]] = None,
 ) -> "OutputContext":
     """Builds output context from provided parameters.
 
     ``build_output_context`` can be used as either a function, or a context manager. If resources
     that are also context managers are provided, then ``build_output_context`` must be used as a
     context manager.
 
     Args:
         step_key (Optional[str]): The step_key for the compute step that produced the output.
         name (Optional[str]): The name of the output that produced the output.
-        metadata (Optional[Mapping[str, Any]]): A dict of the metadata that is assigned to the
+        definition_metadata (Optional[Mapping[str, Any]]): A dict of the metadata that is assigned to the
             OutputDefinition that produced the output.
         mapping_key (Optional[str]): The key that identifies a unique mapped output. None for regular outputs.
         config (Optional[Any]): The configuration for the output.
         dagster_type (Optional[DagsterType]): The type of this output.
         version (Optional[str]): (Experimental) The version of the output.
         resource_config (Optional[Mapping[str, Any]]): The resource config to make available from the
             input context. This usually corresponds to the config provided to the resource that
@@ -838,14 +885,15 @@
         resources (Optional[Resources]): The resources to make available from the context.
             For a given key, you can provide either an actual instance of an object, or a resource
             definition.
         op_def (Optional[OpDefinition]): The definition of the op that produced the output.
         asset_key: Optional[Union[AssetKey, Sequence[str], str]]: The asset key corresponding to the
             output.
         partition_key: Optional[str]: String value representing partition key to execute with.
+        metadata (Optional[Mapping[str, Any]]): Deprecated. Use definition_metadata instead.
 
     Examples:
         .. code-block:: python
 
             build_output_context()
 
             with build_output_context(resources={"foo": context_manager_resource}) as context:
@@ -854,15 +902,22 @@
     """
     from dagster._core.definitions import OpDefinition
     from dagster._core.execution.context_creation_job import initialize_console_manager
     from dagster._core.types.dagster_type import DagsterType
 
     step_key = check.opt_str_param(step_key, "step_key")
     name = check.opt_str_param(name, "name")
-    metadata = check.opt_mapping_param(metadata, "metadata", key_type=str)
+    check.opt_mapping_param(definition_metadata, "definition_metadata", key_type=str)
+    check.opt_mapping_param(metadata, "metadata", key_type=str)
+    definition_metadata = normalize_renamed_param(
+        definition_metadata,
+        "definition_metadata",
+        metadata,
+        "metadata",
+    )
     run_id = check.opt_str_param(run_id, "run_id", default=RUN_ID_PLACEHOLDER)
     mapping_key = check.opt_str_param(mapping_key, "mapping_key")
     dagster_type = check.opt_inst_param(dagster_type, "dagster_type", DagsterType)
     version = check.opt_str_param(version, "version")
     resource_config = check.opt_mapping_param(resource_config, "resource_config", key_type=str)
     resources = check.opt_mapping_param(resources, "resources", key_type=str)
     op_def = check.opt_inst_param(op_def, "op_def", OpDefinition)
@@ -870,15 +925,15 @@
     partition_key = check.opt_str_param(partition_key, "partition_key")
 
     return OutputContext(
         step_key=step_key,
         name=name,
         job_name=None,
         run_id=run_id,
-        metadata=metadata,
+        definition_metadata=definition_metadata,
         mapping_key=mapping_key,
         config=config,
         dagster_type=dagster_type,
         log_manager=initialize_console_manager(None),
         version=version,
         resource_config=resource_config,
         resources=resources,
```

### Comparing `dagster-1.6.9/dagster/_core/execution/context/system.py` & `dagster-1.7.0/dagster/_core/execution/context/system.py`

 * *Files 1% similar despite different names*

```diff
@@ -31,14 +31,15 @@
     extract_data_version_from_entry,
 )
 from dagster._core.definitions.dependency import OpNode
 from dagster._core.definitions.events import AssetKey, AssetLineageInfo
 from dagster._core.definitions.hook_definition import HookDefinition
 from dagster._core.definitions.job_base import IJob
 from dagster._core.definitions.job_definition import JobDefinition
+from dagster._core.definitions.metadata import RawMetadataValue
 from dagster._core.definitions.multi_dimensional_partitions import MultiPartitionsDefinition
 from dagster._core.definitions.op_definition import OpDefinition
 from dagster._core.definitions.partition import PartitionsDefinition, PartitionsSubset
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
 from dagster._core.definitions.partition_mapping import (
     PartitionMapping,
     infer_partition_mapping,
@@ -76,14 +77,15 @@
 if TYPE_CHECKING:
     from dagster._core.definitions.data_version import (
         DataVersion,
     )
     from dagster._core.definitions.dependency import NodeHandle
     from dagster._core.definitions.resource_definition import Resources
     from dagster._core.event_api import EventLogRecord
+    from dagster._core.events import DagsterEventType
     from dagster._core.execution.plan.plan import ExecutionPlan
     from dagster._core.execution.plan.state import KnownExecutionState
     from dagster._core.instance import DagsterInstance
 
     from .hook import HookContext
 
 
@@ -488,18 +490,21 @@
         return TypeCheckContext(
             self.run_id, self.log, self._execution_data.scoped_resources_builder, dagster_type
         )
 
 
 @dataclass
 class InputAssetVersionInfo:
-    # This is the storage id of the last materialization of any partition of an asset. Thus it is
-    # computed the same way for both partitioned and non-partitioned assets.
+    # This is the storage id of the last materialization/observation of any partition of an asset.
+    # Thus it is computed the same way for both partitioned and non-partitioned assets.
     storage_id: int
 
+    # This is the event type of the event referenced by storage_id
+    event_type: "DagsterEventType"
+
     # If the input asset is partitioned, this is a hash of the sorted data versions of each dependency
     # partition. If the input asset is not partitioned, this is the data version of the asset. It
     # can be none if we are sourcing a materialization from before data versions.
     data_version: Optional["DataVersion"]
 
     # This is the run_id on the event that the storage_id references
     run_id: str
@@ -548,30 +553,30 @@
         step_launcher_resources = [
             resource for resource in resources_iter if isinstance(resource, StepLauncher)
         ]
 
         self._step_launcher: Optional[StepLauncher] = None
         if len(step_launcher_resources) > 1:
             raise DagsterInvariantViolationError(
-                "Multiple required resources for {described_op} have inherited StepLauncher"
-                "There should be at most one step launcher resource per {node_type}.".format(
-                    described_op=self.describe_op(), node_type=self.op_def.node_type_str
-                )
+                f"Multiple required resources for {self.describe_op()} have inherited StepLauncher"
+                f"There should be at most one step launcher resource per {self.op_def.node_type_str}."
             )
         elif len(step_launcher_resources) == 1:
             self._step_launcher = step_launcher_resources[0]
 
         self._step_exception: Optional[BaseException] = None
 
         self._step_output_capture: Optional[Dict[StepOutputHandle, Any]] = None
+        self._step_output_metadata_capture: Optional[Dict[StepOutputHandle, Any]] = None
         # Enable step output capture if there are any hooks which will receive them.
         # Expect in the future that hooks may control whether or not they get outputs,
         # but for now presence of any will cause output capture.
         if self.job_def.get_all_hooks_for_handle(self.node_handle):
             self._step_output_capture = {}
+            self._step_output_metadata_capture = {}
 
         self._output_metadata: Dict[str, Any] = {}
         self._seen_outputs: Dict[str, Union[str, Set[str]]] = {}
 
         self._input_asset_version_info: Dict[AssetKey, Optional["InputAssetVersionInfo"]] = {}
         self._is_external_input_asset_version_info_loaded = False
         self._data_version_cache: Dict[AssetKey, "DataVersion"] = {}
@@ -640,32 +645,37 @@
             .output_def_named(step_output.name)
             .io_manager_key
         )
 
         output_manager = getattr(self.resources, io_manager_key)
         return check.inst(output_manager, IOManager)
 
-    def get_output_context(self, step_output_handle: StepOutputHandle) -> OutputContext:
+    def get_output_context(
+        self,
+        step_output_handle: StepOutputHandle,
+        output_metadata: Optional[Mapping[str, RawMetadataValue]] = None,
+    ) -> OutputContext:
         return get_output_context(
             self.execution_plan,
             self.job_def,
             self.resolved_run_config,
             step_output_handle,
             self._get_source_run_id(step_output_handle),
             log_manager=self.log,
             step_context=self,
             resources=None,
             version=self.execution_plan.get_version_for_step_output_handle(step_output_handle),
+            output_metadata=output_metadata,
         )
 
     def for_input_manager(
         self,
         name: str,
         config: Any,
-        metadata: Any,
+        definition_metadata: Any,
         dagster_type: DagsterType,
         source_handle: Optional[StepOutputHandle] = None,
         resource_config: Any = None,
         resources: Optional["Resources"] = None,
         artificial_output_context: Optional["OutputContext"] = None,
     ) -> InputContext:
         if source_handle and artificial_output_context:
@@ -699,22 +709,22 @@
         asset_partitions_subset = (
             self.asset_partitions_subset_for_input(name)
             if self.has_asset_partitions_for_input(name)
             else None
         )
 
         asset_partitions_def = (
-            self.job_def.asset_layer.partitions_def_for_asset(asset_key) if asset_key else None
+            self.job_def.asset_layer.get(asset_key).partitions_def if asset_key else None
         )
         return InputContext(
             job_name=self.job_def.name,
             name=name,
             op_def=self.op_def,
             config=config,
-            metadata=metadata,
+            definition_metadata=definition_metadata,
             upstream_output=upstream_output,
             dagster_type=dagster_type,
             log_manager=self.log,
             step_context=self,
             resource_config=resource_config,
             resources=resources,
             asset_key=asset_key,
@@ -887,14 +897,18 @@
         return self._step_exception
 
     @property
     def step_output_capture(self) -> Optional[Dict[StepOutputHandle, Any]]:
         return self._step_output_capture
 
     @property
+    def step_output_metadata_capture(self) -> Optional[Dict[StepOutputHandle, Any]]:
+        return self._step_output_metadata_capture
+
+    @property
     def previous_attempt_count(self) -> int:
         return self.get_known_state().get_retry_state().get_attempt_count(self._step.key)
 
     @property
     def op_config(self) -> Any:
         op_config = self.resolved_run_config.ops.get(str(self.node_handle))
         return op_config.config if op_config else None
@@ -927,18 +941,18 @@
             self.is_op_in_graph
             and self.job_def.asset_layer.assets_defs_by_node_handle.get(self.node_handle)
             is not None
         )
 
     @property
     def is_asset_check_step(self) -> bool:
-        """Whether this step corresponds to an asset check."""
-        return (
-            self.job_def.asset_layer.asset_checks_defs_by_node_handle.get(self.node_handle)
-            is not None
+        """Whether this step corresponds to at least one asset check."""
+        return any(
+            self.job_def.asset_layer.asset_check_key_for_output(self.node_handle, output.name)
+            for output in self.step.step_outputs
         )
 
     def set_data_version(self, asset_key: AssetKey, data_version: "DataVersion") -> None:
         self._data_version_cache[asset_key] = data_version
 
     def has_data_version(self, asset_key: AssetKey) -> bool:
         return asset_key in self._data_version_cache
@@ -963,15 +977,15 @@
     def fetch_external_input_asset_version_info(self) -> None:
         output_keys = self.get_output_asset_keys()
 
         all_dep_keys: List[AssetKey] = []
         for output_key in output_keys:
             if output_key not in self.job_def.asset_layer.asset_deps:
                 continue
-            dep_keys = self.job_def.asset_layer.upstream_assets_for_asset(output_key)
+            dep_keys = self.job_def.asset_layer.get(output_key).parent_keys
             for key in dep_keys:
                 if key not in all_dep_keys and key not in output_keys:
                     all_dep_keys.append(key)
 
         self._input_asset_version_info = {}
         for key in all_dep_keys:
             self._fetch_input_asset_version_info(key)
@@ -1009,22 +1023,26 @@
                 if len(input_keys) < SKIP_PARTITION_DATA_VERSION_DEPENDENCY_THRESHOLD:
                     data_version = self._get_partitions_data_version_from_keys(key, input_keys)
                 else:
                     data_version = extract_data_version_from_entry(event.event_log_entry)
             else:
                 data_version = extract_data_version_from_entry(event.event_log_entry)
             self._input_asset_version_info[key] = InputAssetVersionInfo(
-                storage_id, data_version, event.run_id, event.timestamp
+                storage_id,
+                check.not_none(event.event_log_entry.dagster_event).event_type,
+                data_version,
+                event.run_id,
+                event.timestamp,
             )
 
     def partition_mapping_for_input(self, input_name: str) -> Optional[PartitionMapping]:
         asset_layer = self.job_def.asset_layer
         upstream_asset_key = asset_layer.asset_key_for_input(self.node_handle, input_name)
         if upstream_asset_key:
-            upstream_asset_partitions_def = asset_layer.partitions_def_for_asset(upstream_asset_key)
+            upstream_asset_partitions_def = asset_layer.get(upstream_asset_key).partitions_def
             assets_def = asset_layer.assets_def_for_node(self.node_handle)
             partitions_def = assets_def.partitions_def if assets_def else None
             explicit_partition_mapping = self.job_def.asset_layer.partition_mapping_for_node_input(
                 self.node_handle, upstream_asset_key
             )
             return infer_partition_mapping(
                 explicit_partition_mapping,
@@ -1093,26 +1111,27 @@
 
     def has_asset_partitions_for_input(self, input_name: str) -> bool:
         asset_layer = self.job_def.asset_layer
         upstream_asset_key = asset_layer.asset_key_for_input(self.node_handle, input_name)
 
         return (
             upstream_asset_key is not None
-            and asset_layer.partitions_def_for_asset(upstream_asset_key) is not None
+            and asset_layer.has(upstream_asset_key)
+            and asset_layer.get(upstream_asset_key).partitions_def is not None
         )
 
     def asset_partition_key_range_for_input(self, input_name: str) -> PartitionKeyRange:
         subset = self.asset_partitions_subset_for_input(input_name)
 
         asset_layer = self.job_def.asset_layer
         upstream_asset_key = check.not_none(
             asset_layer.asset_key_for_input(self.node_handle, input_name)
         )
         upstream_asset_partitions_def = check.not_none(
-            asset_layer.partitions_def_for_asset(upstream_asset_key)
+            asset_layer.get(upstream_asset_key).partitions_def
         )
 
         partition_key_ranges = subset.get_partition_key_ranges(
             partitions_def=cast(PartitionsDefinition, upstream_asset_partitions_def),
             dynamic_partitions_store=self.instance,
         )
 
@@ -1128,15 +1147,15 @@
         self, input_name: str, *, require_valid_partitions: bool = True
     ) -> PartitionsSubset:
         asset_layer = self.job_def.asset_layer
         assets_def = asset_layer.assets_def_for_node(self.node_handle)
         upstream_asset_key = asset_layer.asset_key_for_input(self.node_handle, input_name)
 
         if upstream_asset_key is not None:
-            upstream_asset_partitions_def = asset_layer.partitions_def_for_asset(upstream_asset_key)
+            upstream_asset_partitions_def = asset_layer.get(upstream_asset_key).partitions_def
 
             if upstream_asset_partitions_def is not None:
                 partitions_def = assets_def.partitions_def if assets_def else None
                 partitions_subset = (
                     partitions_def.empty_subset().with_partition_key_range(
                         partitions_def,
                         self.asset_partition_key_range,
@@ -1260,15 +1279,15 @@
         """
         asset_layer = self.job_def.asset_layer
         upstream_asset_key = asset_layer.asset_key_for_input(self.node_handle, input_name)
 
         if upstream_asset_key is None:
             raise ValueError("The input has no corresponding asset")
 
-        upstream_asset_partitions_def = asset_layer.partitions_def_for_asset(upstream_asset_key)
+        upstream_asset_partitions_def = asset_layer.get(upstream_asset_key).partitions_def
 
         if not upstream_asset_partitions_def:
             raise ValueError(
                 "Tried to get asset partitions for an input that does not correspond to a "
                 "partitioned asset."
             )
 
@@ -1307,15 +1326,15 @@
         """Returns True if this step observes a source asset."""
         asset_layer = self.job_def.asset_layer
         if asset_layer is None:
             return False
         asset_key = asset_layer.asset_key_for_output(self.node_handle, output_name)
         if asset_key is None:
             return False
-        return asset_layer.is_observable_for_asset(asset_key)
+        return asset_layer.get(asset_key).is_observable
 
 
 class TypeCheckContext:
     """The ``context`` object available to a type check function on a DagsterType."""
 
     def __init__(
         self,
```

### Comparing `dagster-1.6.9/dagster/_core/execution/context_creation_job.py` & `dagster-1.7.0/dagster/_core/execution/context_creation_job.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/execute_in_process.py` & `dagster-1.7.0/dagster/_core/execution/execute_in_process.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/execute_in_process_result.py` & `dagster-1.7.0/dagster/_core/execution/execute_in_process_result.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/execution_result.py` & `dagster-1.7.0/dagster/_core/execution/execution_result.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/host_mode.py` & `dagster-1.7.0/dagster/_core/execution/host_mode.py`

 * *Files 1% similar despite different names*

```diff
@@ -183,17 +183,15 @@
             dagster_run,
         )
         raise DagsterInvariantViolationError(message)
 
     check.invariant(
         dagster_run.status == DagsterRunStatus.NOT_STARTED
         or dagster_run.status == DagsterRunStatus.STARTING,
-        desc="Pipeline run {} ({}) in state {}, expected NOT_STARTED or STARTING".format(
-            dagster_run.job_name, dagster_run.run_id, dagster_run.status
-        ),
+        desc=f"Pipeline run {dagster_run.job_name} ({dagster_run.run_id}) in state {dagster_run.status}, expected NOT_STARTED or STARTING",
     )
 
     recon_job = recon_job.get_subset(
         op_selection=dagster_run.resolved_op_selection,
         asset_selection=dagster_run.asset_selection,
     )
```

### Comparing `dagster-1.6.9/dagster/_core/execution/job_backfill.py` & `dagster-1.7.0/dagster/_core/execution/job_backfill.py`

 * *Files 3% similar despite different names*

```diff
@@ -3,25 +3,25 @@
 from typing import Callable, Iterable, Mapping, Optional, Sequence, Tuple, cast
 
 import dagster._check as check
 from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.errors import DagsterBackfillFailedError
 from dagster._core.execution.plan.resume_retry import ReexecutionStrategy
 from dagster._core.execution.plan.state import KnownExecutionState
-from dagster._core.host_representation import (
+from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation import (
     CodeLocation,
     ExternalJob,
     ExternalPartitionSet,
 )
-from dagster._core.host_representation.external_data import (
+from dagster._core.remote_representation.external_data import (
     ExternalPartitionExecutionParamData,
     ExternalPartitionSetExecutionParamData,
 )
-from dagster._core.host_representation.origin import ExternalPartitionSetOrigin
-from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.origin import RemotePartitionSetOrigin
 from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus, RunsFilter
 from dagster._core.storage.tags import (
     PARENT_RUN_ID_TAG,
     PARTITION_NAME_TAG,
     PARTITION_SET_TAG,
     ROOT_RUN_ID_TAG,
 )
@@ -100,22 +100,22 @@
             instance.update_backfill(backfill.with_status(BulkActionStatus.COMPLETED))
             yield None
 
 
 def _check_repo_has_partition_set(
     workspace_process_context: IWorkspaceProcessContext, backfill_job: PartitionBackfill
 ) -> None:
-    origin = cast(ExternalPartitionSetOrigin, backfill_job.partition_set_origin)
+    origin = cast(RemotePartitionSetOrigin, backfill_job.partition_set_origin)
 
-    location_name = origin.external_repository_origin.code_location_origin.location_name
+    location_name = origin.repository_origin.code_location_origin.location_name
 
     workspace = workspace_process_context.create_request_context()
     code_location = workspace.get_code_location(location_name)
 
-    repo_name = origin.external_repository_origin.repository_name
+    repo_name = origin.repository_origin.repository_name
     if not code_location.has_repository(repo_name):
         raise DagsterBackfillFailedError(
             f"Could not find repository {repo_name} in location {code_location.name} to "
             f"run backfill {backfill_job.backfill_id}."
         )
 
     partition_set_name = origin.partition_set_name
@@ -171,17 +171,17 @@
 def submit_backfill_runs(
     instance: DagsterInstance,
     create_workspace: Callable[[], BaseWorkspaceRequestContext],
     backfill_job: PartitionBackfill,
     partition_names: Optional[Sequence[str]] = None,
 ) -> Iterable[Optional[str]]:
     """Returns the run IDs of the submitted runs."""
-    origin = cast(ExternalPartitionSetOrigin, backfill_job.partition_set_origin)
+    origin = cast(RemotePartitionSetOrigin, backfill_job.partition_set_origin)
 
-    repository_origin = origin.external_repository_origin
+    repository_origin = origin.repository_origin
     repo_name = repository_origin.repository_name
     location_name = repository_origin.code_location_origin.location_name
 
     if not partition_names:
         partition_names = cast(Sequence[str], backfill_job.partition_names)
 
     workspace = create_workspace()
```

### Comparing `dagster-1.6.9/dagster/_core/execution/job_execution_result.py` & `dagster-1.7.0/dagster/_core/execution/job_execution_result.py`

 * *Files 0% similar despite different names*

```diff
@@ -142,15 +142,15 @@
         step_output_handle = step_output_data.step_output_handle
         manager = context.get_io_manager(step_output_handle)
         manager_key = context.execution_plan.get_manager_key(step_output_handle, self.job_def)
         res = manager.load_input(
             context.for_input_manager(
                 name=None,
                 config=None,
-                metadata=None,
+                definition_metadata=None,
                 dagster_type=dagster_type,
                 source_handle=step_output_handle,
                 resource_config=context.resolved_run_config.resources[manager_key].config,
                 resources=build_resources_for_manager(manager_key, context),
             )
         )
         return res
```

### Comparing `dagster-1.6.9/dagster/_core/execution/memoization.py` & `dagster-1.7.0/dagster/_core/execution/memoization.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/active.py` & `dagster-1.7.0/dagster/_core/execution/plan/active.py`

 * *Files 1% similar despite different names*

```diff
@@ -301,15 +301,15 @@
         if not steps:
             return None
 
         return steps[0]
 
     def get_step_by_key(self, step_key: str) -> ExecutionStep:
         step = self._plan.get_step_by_key(step_key)
-        return cast(ExecutionStep, check.inst(step, ExecutionStep))
+        return check.inst(step, ExecutionStep)
 
     def get_steps_to_execute(
         self,
         limit: Optional[int] = None,
     ) -> Sequence[ExecutionStep]:
         check.invariant(
             self._context_guard,
@@ -546,16 +546,16 @@
                     ],
                 ).append(dagster_event.step_output_data.step_output_handle.mapping_key)
 
     def verify_complete(self, job_context: IPlanContext, step_key: str) -> None:
         """Ensure that a step has reached a terminal state, if it has not mark it as an unexpected failure."""
         if step_key in self._in_flight:
             job_context.log.error(
-                "Step {key} finished without success or failure event. Downstream steps will not"
-                " execute.".format(key=step_key)
+                f"Step {step_key} finished without success or failure event. Downstream steps will not"
+                " execute."
             )
             self.mark_unknown_state(step_key)
 
     # factored out for test
     def mark_unknown_state(self, step_key: str) -> None:
         # note the step so that we throw upon plan completion
         self._unknown_state.add(step_key)
```

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/compute_generator.py` & `dagster-1.7.0/dagster/_core/execution/plan/compute_generator.py`

 * *Files 6% similar despite different names*

```diff
@@ -32,20 +32,20 @@
 from dagster._core.definitions.op_definition import OpDefinition
 from dagster._core.definitions.result import AssetResult, ObserveResult
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.types.dagster_type import DagsterTypeKind, is_generic_output_annotation
 from dagster._utils import is_named_tuple_instance
 from dagster._utils.warnings import disable_dagster_warnings
 
-from ..context.compute import OpExecutionContext
+from ..context.compute import ExecutionContextTypes
 
 
 def create_op_compute_wrapper(
     op_def: OpDefinition,
-) -> Callable[[OpExecutionContext, Mapping[str, InputDefinition]], Any]:
+) -> Callable[[ExecutionContextTypes, Mapping[str, InputDefinition]], Any]:
     compute_fn = cast(DecoratedOpFunction, op_def.compute_fn)
     fn = compute_fn.decorated_fn
     input_defs = op_def.input_defs
     output_defs = op_def.output_defs
     context_arg_provided = compute_fn.has_context_arg()
     config_arg_cls = compute_fn.get_config_arg().annotation if compute_fn.has_config_arg() else None
     resource_arg_mapping = {arg.name: arg.name for arg in compute_fn.get_resource_args()}
@@ -54,15 +54,15 @@
         input_def.name
         for input_def in input_defs
         if not input_def.dagster_type.kind == DagsterTypeKind.NOTHING
     ]
 
     @wraps(fn)
     def compute(
-        context: OpExecutionContext,
+        context: ExecutionContextTypes,
         input_defs: Mapping[str, InputDefinition],
     ) -> Union[Iterator[Output], AsyncIterator[Output]]:
         kwargs = {}
         for input_name in input_names:
             kwargs[input_name] = input_defs[input_name]
 
         if (
@@ -91,56 +91,66 @@
                 resource_arg_mapping,
             )
 
     return compute
 
 
 async def _coerce_async_op_to_async_gen(
-    awaitable: Awaitable[Any], context: OpExecutionContext, output_defs: Sequence[OutputDefinition]
+    awaitable: Awaitable[Any],
+    context: ExecutionContextTypes,
+    output_defs: Sequence[OutputDefinition],
 ) -> AsyncIterator[Any]:
     result = await awaitable
     for event in validate_and_coerce_op_result_to_iterator(result, context, output_defs):
         yield event
 
 
 def invoke_compute_fn(
     fn: Callable[..., Any],
-    context: OpExecutionContext,
+    context: ExecutionContextTypes,
     kwargs: Mapping[str, Any],
     context_arg_provided: bool,
     config_arg_cls: Optional[Type[Config]],
     resource_args: Optional[Dict[str, str]] = None,
 ) -> Any:
     args_to_pass = {**kwargs}
     if config_arg_cls:
         # config_arg_cls is either a Config class or a primitive type
         if issubclass(config_arg_cls, Config):
-            to_pass = config_arg_cls._get_non_default_public_field_values_cls(context.op_config)  # noqa: SLF001
+            to_pass = config_arg_cls._get_non_default_public_field_values_cls(  # noqa: SLF001
+                context.op_execution_context.op_config
+            )
             args_to_pass["config"] = config_arg_cls(**to_pass)
         else:
-            args_to_pass["config"] = context.op_config
+            args_to_pass["config"] = context.op_execution_context.op_config
     if resource_args:
         for resource_name, arg_name in resource_args.items():
             args_to_pass[arg_name] = context.resources.original_resource_dict[resource_name]
 
     return fn(context, **args_to_pass) if context_arg_provided else fn(**args_to_pass)
 
 
 def _coerce_op_compute_fn_to_iterator(
-    fn, output_defs, context, context_arg_provided, kwargs, config_arg_class, resource_arg_mapping
+    fn,
+    output_defs,
+    context: ExecutionContextTypes,
+    context_arg_provided,
+    kwargs,
+    config_arg_class,
+    resource_arg_mapping,
 ):
     result = invoke_compute_fn(
         fn, context, kwargs, context_arg_provided, config_arg_class, resource_arg_mapping
     )
     for event in validate_and_coerce_op_result_to_iterator(result, context, output_defs):
         yield event
 
 
 def _zip_and_iterate_op_result(
-    result: Any, context: OpExecutionContext, output_defs: Sequence[OutputDefinition]
+    result: Any, context: ExecutionContextTypes, output_defs: Sequence[OutputDefinition]
 ) -> Iterator[Tuple[int, Any, OutputDefinition]]:
     # Filtering the expected output defs here is an unfortunate temporary solution to deal with the
     # change in expected outputs that occurs as a result of putting `AssetCheckResults` onto
     # `MaterializeResults`. Prior to this, `AssetCheckResults` were yielded/returned directly, and
     # thus were expected to always be included in the result tuple. Thus we need to remove them from
     # the expected output defs if they have been included indirectly via embedding in a
     # `MaterializeResult`.
@@ -159,30 +169,32 @@
     else:
         yield 0, output_defs[0], result
 
 
 # Filter out output_defs corresponding to asset check results that already exist on a
 # MaterializeResult.
 def _filter_expected_output_defs(
-    result: Any, context: OpExecutionContext, output_defs: Sequence[OutputDefinition]
+    result: Any, context: ExecutionContextTypes, output_defs: Sequence[OutputDefinition]
 ) -> Sequence[OutputDefinition]:
     result_tuple = (
         (result,) if not isinstance(result, tuple) or is_named_tuple_instance(result) else result
     )
     asset_results = [x for x in result_tuple if isinstance(x, AssetResult)]
     remove_outputs = [
-        r.get_spec_python_identifier(asset_key=x.asset_key or context.asset_key)
+        r.get_spec_python_identifier(
+            asset_key=x.asset_key or context.op_execution_context.asset_key
+        )
         for x in asset_results
         for r in x.check_results or []
     ]
     return [out for out in output_defs if out.name not in remove_outputs]
 
 
 def _validate_multi_return(
-    context: OpExecutionContext,
+    context: ExecutionContextTypes,
     result: Any,
     output_defs: Sequence[OutputDefinition],
 ) -> Any:
     # special cases for implicit/explicit returned None
     if result is None:
         # extrapolate None -> (None, None, ...) when appropriate
         if all(
@@ -236,27 +248,29 @@
             f"Bad state: Output was explicitly named '{output.output_name}', "
             "which does not match the output definition specified for position "
             f"{position}: '{output_def.name}'."
         )
 
 
 def validate_and_coerce_op_result_to_iterator(
-    result: Any, context: OpExecutionContext, output_defs: Sequence[OutputDefinition]
+    result: Any,
+    context: ExecutionContextTypes,
+    output_defs: Sequence[OutputDefinition],
 ) -> Iterator[Any]:
     if inspect.isgenerator(result):
         # this happens when a user explicitly returns a generator in the op
         for event in result:
             yield event
     elif isinstance(result, (AssetMaterialization, ExpectationResult)):
         raise DagsterInvariantViolationError(
             f"Error in {context.describe_op()}: If you are "
             "returning an AssetMaterialization "
             "or an ExpectationResult from "
             f"{context.op_def.node_type_str} you must yield them "
-            "directly, or log them using the OpExecutionContext.log_event method to avoid "
+            "directly, or log them using the context.log_event method to avoid "
             "ambiguity with an implied result from returning a "
             "value. Check out the docs on logging events here: "
             "https://docs.dagster.io/concepts/ops-jobs-graphs/op-events#op-events-and-exceptions"
         )
     # These don't correspond to output defs so pass them through
     elif isinstance(result, (AssetCheckResult, ObserveResult)):
         yield result
@@ -266,15 +280,15 @@
             f" {type(result)}. {context.op_def.node_type_str.capitalize()} is explicitly defined to"
             " return no results."
         )
     # `requires_typed_event_stream` is a mode where we require users to return/yield exactly the
     # results that will be registered in the instance, without additional fancy inference (like
     # wrapping `None` in an `Output`). We therefore skip any return-specific validation for this
     # mode and treat returned values as if they were yielded.
-    elif output_defs and context.requires_typed_event_stream:
+    elif output_defs and context.op_execution_context.requires_typed_event_stream:
         # If nothing was returned, treat it as an empty tuple instead of a `(None,)`.
         # This is important for delivering the correct error message when an output is missing.
         if result is None:
             result_tuple = tuple()
         elif not isinstance(result, tuple) or is_named_tuple_instance(result):
             result_tuple = (result,)
         else:
```

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/execute_plan.py` & `dagster-1.7.0/dagster/_core/execution/plan/execute_plan.py`

 * *Files 1% similar despite different names*

```diff
@@ -77,17 +77,17 @@
                     resource_key
                     for resource_key in step_context.required_resource_keys
                     if not hasattr(step_context.resources, resource_key)
                 ]
                 check.invariant(
                     len(missing_resources) == 0,
                     (
-                        "Expected step context for solid {solid_name} to have all required"
-                        " resources, but missing {missing_resources}."
-                    ).format(solid_name=step_context.op.name, missing_resources=missing_resources),
+                        f"Expected step context for solid {step_context.op.name} to have all required"
+                        f" resources, but missing {missing_resources}."
+                    ),
                 )
 
                 with ExitStack() as step_stack:
                     if not isinstance(compute_log_manager, CapturedLogManager):
                         # capture all of the logs for individual steps
                         try:
                             step_stack.enter_context(
@@ -98,18 +98,18 @@
                             yield DagsterEvent.legacy_compute_log_step_event(step_context)
                         except Exception:
                             yield from _handle_compute_log_setup_error(step_context, sys.exc_info())
 
                         for step_event in check.generator(
                             dagster_event_sequence_for_step(step_context)
                         ):
-                            check.inst(step_event, DagsterEvent)
-                            step_event_list.append(step_event)
-                            yield step_event
-                            active_execution.handle_event(step_event)
+                            dagster_event = check.inst(step_event, DagsterEvent)
+                            step_event_list.append(dagster_event)
+                            yield dagster_event
+                            active_execution.handle_event(dagster_event)
 
                         active_execution.verify_complete(job_context, step.key)
 
                         try:
                             step_stack.close()
                         except Exception:
                             yield from _handle_compute_log_teardown_error(
@@ -117,18 +117,18 @@
                             )
                     else:
                         # we have already set up the log capture at the process level, just handle the
                         # step events
                         for step_event in check.generator(
                             dagster_event_sequence_for_step(step_context)
                         ):
-                            check.inst(step_event, DagsterEvent)
-                            step_event_list.append(step_event)
-                            yield step_event
-                            active_execution.handle_event(step_event)
+                            dagster_event = check.inst(step_event, DagsterEvent)
+                            step_event_list.append(dagster_event)
+                            yield dagster_event
+                            active_execution.handle_event(dagster_event)
 
                         active_execution.verify_complete(job_context, step.key)
 
                 # process skips from failures or uncovered inputs
                 for event in active_execution.plan_events_iterator(job_context):
                     step_event_list.append(event)
                     yield event
@@ -191,20 +191,16 @@
             # catch hook execution error and field a failure event instead of failing the pipeline run
             yield DagsterEvent.hook_errored(step_context, hook_execution_error)
             continue
 
         check.invariant(
             isinstance(hook_execution_result, HookExecutionResult),
             (
-                "Error in hook {hook_name}: hook unexpectedly returned result {result} of "
-                "type {type_}. Should be a HookExecutionResult"
-            ).format(
-                hook_name=hook_def.name,
-                result=hook_execution_result,
-                type_=type(hook_execution_result),
+                f"Error in hook {hook_def.name}: hook unexpectedly returned result {hook_execution_result} of "
+                f"type {type(hook_execution_result)}. Should be a HookExecutionResult"
             ),
         )
         if hook_execution_result and hook_execution_result.is_skipped:
             # when the triggering condition didn't meet in the hook_fn, for instance,
             # a @success_hook decorated user-defined function won't run on a failed solid
             # but internally the hook_fn still runs, so we yield HOOK_SKIPPED event instead
             yield DagsterEvent.hook_skipped(step_context, hook_def)
```

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/execute_step.py` & `dagster-1.7.0/dagster/_core/execution/plan/execute_step.py`

 * *Files 0% similar despite different names*

```diff
@@ -57,15 +57,15 @@
     DagsterExecutionHandleOutputError,
     DagsterInvariantViolationError,
     DagsterStepOutputNotFoundError,
     DagsterTypeCheckDidNotPass,
     DagsterTypeCheckError,
     user_code_error_boundary,
 )
-from dagster._core.events import DagsterEvent
+from dagster._core.events import DagsterEvent, DagsterEventBatchMetadata, generate_event_batch_id
 from dagster._core.execution.context.compute import enter_execution_context
 from dagster._core.execution.context.output import OutputContext
 from dagster._core.execution.context.system import StepExecutionContext, TypeCheckContext
 from dagster._core.execution.plan.compute import execute_core_compute
 from dagster._core.execution.plan.inputs import StepInputData
 from dagster._core.execution.plan.objects import StepSuccessData, TypeCheckData
 from dagster._core.execution.plan.outputs import StepOutputData, StepOutputHandle
@@ -241,27 +241,25 @@
             # contrast, if both A and B are yielded, A should never precede B.
             asset_layer = step_context.job_def.asset_layer
             node_handle = step_context.node_handle
             asset_info = asset_layer.asset_info_for_output(node_handle, output_def.name)
             if (
                 asset_info is not None
                 and asset_info.is_required
-                and asset_layer.has_assets_def_for_asset(asset_info.key)
+                and asset_layer.has(asset_info.key)
             ):
-                assets_def = asset_layer.assets_def_for_asset(asset_info.key)
-                if assets_def is not None:
-                    all_dependent_keys = asset_layer.downstream_assets_for_asset(asset_info.key)
+                if asset_layer.has(asset_info.key):
+                    assets_def = asset_layer.get(asset_info.key).assets_def
+                    all_dependent_keys = asset_layer.get(asset_info.key).child_keys
                     step_local_asset_keys = step_context.get_output_asset_keys()
                     step_local_dependent_keys = all_dependent_keys & step_local_asset_keys
                     for dependent_key in step_local_dependent_keys:
                         output_name = assets_def.get_output_name_for_asset_key(dependent_key)
                         # Need to skip self-dependent assets (possible with partitions)
-                        self_dep = dependent_key in asset_layer.upstream_assets_for_asset(
-                            asset_info.key
-                        )
+                        self_dep = dependent_key in asset_layer.get(asset_info.key).parent_keys
                         if not self_dep and step_context.has_seen_output(output_name):
                             raise DagsterInvariantViolationError(
                                 f'Asset "{dependent_key.to_user_string()}" was yielded before its'
                                 f' dependency "{asset_info.key.to_user_string()}".Multiassets'
                                 " yielding multiple asset outputs must yield them in topological"
                                 " order."
                             )
@@ -307,17 +305,15 @@
         step_output_def = step_context.op_def.output_def_named(step_output.name)
         if not step_context.has_seen_output(step_output_def.name) and not step_output_def.optional:
             asset_layer = step_context.job_def.asset_layer
             asset_key = asset_layer.asset_key_for_output(
                 step_context.node_handle, step_output_def.name
             )
             # We require explicitly returned/yielded for asset observations
-            is_observable_asset = asset_key is not None and asset_layer.is_observable_for_asset(
-                asset_key
-            )
+            is_observable_asset = asset_key is not None and asset_layer.get(asset_key).is_observable
 
             if step_output_def.dagster_type.is_nothing and not is_observable_asset:
                 step_context.log.info(
                     f'Emitting implicit Nothing for output "{step_output_def.name}" on {op_label}'
                 )
                 yield Output(output_name=step_output_def.name, value=None)
             elif not step_output_def.is_dynamic:
@@ -331,20 +327,16 @@
 
 def do_type_check(context: TypeCheckContext, dagster_type: DagsterType, value: Any) -> TypeCheck:
     type_check = dagster_type.type_check(context, value)
     if not isinstance(type_check, TypeCheck):
         return TypeCheck(
             success=False,
             description=(
-                "Type checks must return TypeCheck. Type check for type {type_name} returned "
-                "value of type {return_type} when checking runtime value of type {dagster_type}."
-            ).format(
-                type_name=dagster_type.display_name,
-                return_type=type(type_check),
-                dagster_type=type(value),
+                f"Type checks must return TypeCheck. Type check for type {dagster_type.display_name} returned "
+                f"value of type {type(type_check)} when checking runtime value of type {type(value)}."
             ),
         )
     return type_check
 
 
 def _create_step_input_event(
     step_context: StepExecutionContext, input_name: str, type_check: TypeCheck, success: bool
@@ -566,16 +558,20 @@
     )
 
     # If we are executing using the execute_in_process API, then we allow for the outputs of ops
     # to be directly captured to a dictionary after they are computed.
     if step_context.output_capture is not None:
         step_context.output_capture[step_output_handle] = output.value
     # capture output at the step level for threading the computed output values to hook context
-    if step_context.step_output_capture is not None:
+    if (
+        step_context.step_output_capture is not None
+        and step_context.step_output_metadata_capture is not None
+    ):
         step_context.step_output_capture[step_output_handle] = output.value
+        step_context.step_output_metadata_capture[step_output_handle] = output.metadata
 
     version = (
         resolve_step_output_versions(
             step_context.job_def, step_context.execution_plan, step_context.resolved_run_config
         ).get(step_output_handle)
         if MEMOIZED_RUN_TAG in step_context.job.get_definition().tags
         else None
@@ -620,15 +616,15 @@
     # Clear any cached record associated with this asset, since we are about to generate a new
     # materialization.
     step_context.wipe_input_asset_version_info(asset_key)
     tags: Dict[str, str]
     if (
         execution_type == AssetExecutionType.MATERIALIZATION
         and step_context.is_external_input_asset_version_info_loaded
-        and asset_key in step_context.job_def.asset_layer.asset_keys
+        and asset_key in step_context.job_def.asset_layer.executable_asset_keys
     ):
         assert isinstance(output, Output)
         code_version = _get_code_version(asset_key, step_context)
         input_provenance_data = _get_input_provenance_data(asset_key, step_context)
         cached_data_version = (
             step_context.get_data_version(asset_key)
             if step_context.has_data_version(asset_key)
@@ -662,14 +658,15 @@
 
     backfill_id = step_context.get_tag(BACKFILL_ID_TAG)
     if backfill_id:
         tags[BACKFILL_ID_TAG] = backfill_id
 
     if execution_type == AssetExecutionType.MATERIALIZATION:
         event_class = AssetMaterialization
+        event_class = AssetMaterialization
     elif execution_type == AssetExecutionType.OBSERVATION:
         event_class = AssetObservation
     else:
         check.failed(f"Unexpected asset execution type {execution_type}")
 
     if asset_partitions:
         for partition in asset_partitions:
@@ -689,29 +686,29 @@
     else:
         with disable_dagster_warnings():
             yield event_class(asset_key=asset_key, metadata=all_metadata, tags=tags)
 
 
 def _get_code_version(asset_key: AssetKey, step_context: StepExecutionContext) -> str:
     return (
-        step_context.job_def.asset_layer.code_version_for_asset(asset_key)
+        step_context.job_def.asset_layer.get(asset_key).code_version
         or step_context.dagster_run.run_id
     )
 
 
 class _InputProvenanceData(TypedDict):
     data_version: DataVersion
     storage_id: Optional[int]
 
 
 def _get_input_provenance_data(
     asset_key: AssetKey, step_context: StepExecutionContext
 ) -> Mapping[AssetKey, _InputProvenanceData]:
     input_provenance: Dict[AssetKey, _InputProvenanceData] = {}
-    deps = step_context.job_def.asset_layer.upstream_assets_for_asset(asset_key)
+    deps = step_context.job_def.asset_layer.get(asset_key).parent_keys
     for key in deps:
         # For deps external to this step, this will retrieve the cached record that was stored prior
         # to step execution. For inputs internal to this step, it may trigger a query to retrieve
         # the most recent materialization record (it will retrieve a cached record if it's already
         # been asked for). For this to be correct, the output materializations for the step must be
         # generated in topological order -- we assume this.
         version_info = step_context.get_input_asset_version_info(key)
@@ -762,15 +759,15 @@
 def _store_output(
     step_context: StepExecutionContext,
     step_output_handle: StepOutputHandle,
     output: Union[Output, DynamicOutput],
 ) -> Iterator[DagsterEvent]:
     output_def = step_context.op_def.output_def_named(step_output_handle.output_name)
     output_manager = step_context.get_io_manager(step_output_handle)
-    output_context = step_context.get_output_context(step_output_handle)
+    output_context = step_context.get_output_context(step_output_handle, output.metadata)
 
     manager_materializations = []
     manager_metadata: Dict[str, MetadataValue] = {}
 
     # don't store asset check outputs, asset observation outputs, or Nothing type outputs
     step_output = step_context.step.step_output_named(step_output_handle.output_name)
     if (
@@ -895,16 +892,14 @@
 
     asset_key, partitions = _asset_key_and_partitions_for_output(output_context)
     if asset_key:
         asset_layer = step_context.job_def.asset_layer
         assets_def = asset_layer.assets_def_for_node(step_context.node_handle)
         if assets_def is not None:
             execution_type = assets_def.execution_type
-        elif asset_key in asset_layer.source_assets_by_key:
-            execution_type = asset_layer.source_assets_by_key[asset_key].execution_type
         else:
             # This is a situation that shouldn't really ever occur, but appears to be able to happen
             # when multiple output names point to the same asset key, which also shouldn't occur,
             # but we don't validate against. If we start validating that each output should
             # correspond to only one asset, then we can start raising an error here instead of a
             # warning.
             warnings.warn(
@@ -920,30 +915,37 @@
         )
 
         check.invariant(
             execution_type in {AssetExecutionType.MATERIALIZATION, AssetExecutionType.OBSERVATION},
             f"Unexpected asset execution type {execution_type}",
         )
 
-        yield from (
-            (
-                _dagster_event_for_asset_event(step_context, event)
-                for event in _get_output_asset_events(
-                    asset_key,
-                    partitions,
-                    output,
-                    output_def,
-                    manager_metadata,
-                    step_context,
-                    execution_type,
-                )
+        asset_events = list(
+            _get_output_asset_events(
+                asset_key,
+                partitions,
+                output,
+                output_def,
+                manager_metadata,
+                step_context,
+                execution_type,
             )
         )
 
+        batch_id = generate_event_batch_id()
+        last_index = len(asset_events) - 1
+        for i, asset_event in enumerate(asset_events):
+            batch_metadata = (
+                DagsterEventBatchMetadata(batch_id, i == last_index) if partitions else None
+            )
+            yield _dagster_event_for_asset_event(step_context, asset_event, batch_metadata)
+
 
 def _dagster_event_for_asset_event(
-    step_context: StepExecutionContext, asset_event: Union[AssetMaterialization, AssetObservation]
+    step_context: StepExecutionContext,
+    asset_event: Union[AssetMaterialization, AssetObservation],
+    batch_metadata: Optional[DagsterEventBatchMetadata],
 ):
     if isinstance(asset_event, AssetMaterialization):
-        return DagsterEvent.asset_materialization(step_context, asset_event)
+        return DagsterEvent.asset_materialization(step_context, asset_event, batch_metadata)
     else:  # observation
-        return DagsterEvent.asset_observation(step_context, asset_event)
+        return DagsterEvent.asset_observation(step_context, asset_event, batch_metadata)
```

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/external_step.py` & `dagster-1.7.0/dagster/_core/execution/plan/external_step.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/handle.py` & `dagster-1.7.0/dagster/_core/execution/plan/handle.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/inputs.py` & `dagster-1.7.0/dagster/_core/execution/plan/inputs.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,14 +14,15 @@
     cast,
 )
 
 from typing_extensions import TypeAlias
 
 import dagster._check as check
 from dagster._core.definitions import InputDefinition, JobDefinition, NodeHandle
+from dagster._core.definitions.utils import DEFAULT_IO_MANAGER_KEY
 from dagster._core.definitions.version_strategy import ResourceVersionContext
 from dagster._core.errors import (
     DagsterExecutionLoadInputError,
     DagsterInvariantViolationError,
     DagsterTypeLoadingError,
     user_code_error_boundary,
 )
@@ -117,18 +118,20 @@
         job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
     ) -> Optional[str]:
         """See resolve_step_versions in resolve_versions.py for explanation of step_versions."""
         raise NotImplementedError()
 
 
-@whitelist_for_serdes(storage_field_names={"node_handle": "solid_handle"})
-class FromSourceAsset(
+@whitelist_for_serdes(
+    storage_name="FromSourceAsset", storage_field_names={"node_handle": "solid_handle"}
+)
+class FromLoadableAsset(
     NamedTuple(
-        "_FromSourceAsset",
+        "_FromLoadableAsset",
         [
             ("node_handle", NodeHandle),
             ("input_name", str),
         ],
     ),
     StepInputSource,
 ):
@@ -149,47 +152,50 @@
             self.node_handle, input_name=self.input_name
         )
         assert input_asset_key is not None
 
         input_manager_key = (
             input_def.input_manager_key
             if input_def.input_manager_key
-            else asset_layer.io_manager_key_for_asset(input_asset_key)
+            else asset_layer.get(input_asset_key).io_manager_key
         )
 
         op_config = step_context.resolved_run_config.ops.get(str(self.node_handle))
         config_data = op_config.inputs.get(self.input_name) if op_config else None
 
         loader = getattr(step_context.resources, input_manager_key)
         resources = build_resources_for_manager(input_manager_key, step_context)
         resource_config = step_context.resolved_run_config.resources[input_manager_key].config
         load_input_context = step_context.for_input_manager(
             input_def.name,
             config_data,
-            metadata=input_def.metadata,
+            definition_metadata=input_def.metadata,
             dagster_type=input_def.dagster_type,
             resource_config=resource_config,
             resources=resources,
             artificial_output_context=OutputContext(
                 resources=resources,
                 asset_info=AssetOutputInfo(
                     key=input_asset_key,
-                    partitions_def=asset_layer.partitions_def_for_asset(input_asset_key),
+                    partitions_def=asset_layer.get(input_asset_key).partitions_def,
                 ),
                 name=input_asset_key.path[-1],
                 step_key="none",
-                metadata=asset_layer.metadata_for_asset(input_asset_key),
+                definition_metadata=asset_layer.get(input_asset_key).metadata,
                 resource_config=resource_config,
                 log_manager=step_context.log,
             ),
         )
 
         yield from _load_input_with_input_manager(loader, load_input_context)
 
-        metadata = load_input_context.consume_metadata()
+        metadata = {
+            **load_input_context.definition_metadata,
+            **load_input_context.consume_logged_metadata(),
+        }
 
         yield DagsterEvent.loaded_input(
             step_context,
             input_name=input_def.name,
             manager_key=input_manager_key,
             metadata=metadata,
         )
@@ -243,15 +249,19 @@
                 " using FromSourceAsset",
             )
 
         input_def = job_def.get_node(self.node_handle).input_def_named(self.input_name)
         if input_def.input_manager_key is not None:
             input_manager_key = input_def.input_manager_key
         else:
-            input_manager_key = job_def.asset_layer.io_manager_key_for_asset(input_asset_key)
+            input_manager_key = (
+                job_def.asset_layer.get(input_asset_key).io_manager_key
+                if job_def.asset_layer.has(input_asset_key)
+                else DEFAULT_IO_MANAGER_KEY
+            )
 
         if input_manager_key is None:
             check.failed(
                 f"Must have an io_manager associated with asset {input_asset_key} to load it using"
                 " FromSourceAsset"
             )
         return {input_manager_key}
@@ -294,23 +304,26 @@
         input_manager_key = check.not_none(input_def.input_manager_key)
 
         loader = getattr(step_context.resources, input_manager_key)
 
         load_input_context = step_context.for_input_manager(
             input_def.name,
             config_data,
-            metadata=input_def.metadata,
+            definition_metadata=input_def.metadata,
             dagster_type=input_def.dagster_type,
             resource_config=step_context.resolved_run_config.resources[input_manager_key].config,
             resources=build_resources_for_manager(input_manager_key, step_context),
         )
 
         yield from _load_input_with_input_manager(loader, load_input_context)
 
-        metadata = load_input_context.consume_metadata()
+        metadata = {
+            **load_input_context.definition_metadata,
+            **load_input_context.consume_logged_metadata(),
+        }
 
         yield DagsterEvent.loaded_input(
             step_context,
             input_name=input_def.name,
             manager_key=input_manager_key,
             metadata=metadata,
         )
@@ -480,15 +493,18 @@
                 f'"{manager_key}" is an IOManager.',
             )
         load_input_context = self.get_load_context(
             step_context, input_def, io_manager_key=manager_key
         )
         yield from _load_input_with_input_manager(input_manager, load_input_context)
 
-        metadata = load_input_context.consume_metadata()
+        metadata = {
+            **load_input_context.definition_metadata,
+            **load_input_context.consume_logged_metadata(),
+        }
 
         yield DagsterEvent.loaded_input(
             step_context,
             input_name=input_def.name,
             manager_key=manager_key,
             upstream_output_name=source_handle.output_name,
             upstream_step_key=source_handle.step_key,
```

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/instance_concurrency_context.py` & `dagster-1.7.0/dagster/_core/execution/plan/instance_concurrency_context.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/local_external_step_main.py` & `dagster-1.7.0/dagster/_core/execution/plan/local_external_step_main.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/objects.py` & `dagster-1.7.0/dagster/_core/execution/plan/objects.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/outputs.py` & `dagster-1.7.0/dagster/_core/execution/plan/outputs.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/plan.py` & `dagster-1.7.0/dagster/_core/execution/plan/plan.py`

 * *Files 1% similar despite different names*

```diff
@@ -58,29 +58,29 @@
 from .compute import create_step_outputs
 from .inputs import (
     FromConfig,
     FromDefaultValue,
     FromDirectInputValue,
     FromDynamicCollect,
     FromInputManager,
+    FromLoadableAsset,
     FromMultipleSources,
     FromMultipleSourcesLoadSingleSource,
     FromPendingDynamicStepOutput,
-    FromSourceAsset,
     FromStepOutput,
     FromUnresolvedStepOutput,
     StepInput,
     StepInputSource,
     StepInputSourceUnion,
     StepInputUnion,
     UnresolvedCollectStepInput,
     UnresolvedMappedStepInput,
 )
 from .outputs import StepOutput, StepOutputHandle, UnresolvedStepOutputHandle
-from .state import KnownExecutionState, StepOutputVersionData
+from .state import KnownExecutionState
 from .step import (
     ExecutionStep,
     IExecutionStep,
     StepKind,
     UnresolvedCollectExecutionStep,
     UnresolvedMappedExecutionStep,
 )
@@ -437,15 +437,15 @@
         not dependency_structure.has_deps(input_handle)
         and
         #  make sure input is unconnected in the outer dependency structure too
         not node.container_maps_input(input_handle.input_name)
     ):
         # can only load from source asset if assets defs are available
         if asset_layer.asset_key_for_input(handle, input_handle.input_name):
-            return FromSourceAsset(node_handle=handle, input_name=input_name)
+            return FromLoadableAsset(node_handle=handle, input_name=input_name)
         elif input_def.input_manager_key:
             return FromInputManager(node_handle=handle, input_name=input_name)
 
     if dependency_structure.has_direct_dep(input_handle):
         node_output_handle = dependency_structure.get_direct_dep(input_handle)
         step_output_handle = step_output_map[node_output_handle]
         if isinstance(step_output_handle, UnresolvedStepOutputHandle):
@@ -622,15 +622,15 @@
                 source_to_load_from = source
         else:
             check.invariant(f"Expected NodeOutput, got {node_output}")
 
     if source_to_load_from is None:
         asset_key_for_input = asset_layer.asset_key_for_input(node_handle, input_handle.input_name)
         if asset_key_for_input:
-            source_to_load_from = FromSourceAsset(node_handle=node_handle, input_name=input_name)
+            source_to_load_from = FromLoadableAsset(node_handle=node_handle, input_name=input_name)
             sources.append(source_to_load_from)
         else:
             check.failed("Unexpected: no sources to load from and no asset key to load from")
 
     return FromMultipleSourcesLoadSingleSource(
         sources=sources, source_to_load_from=source_to_load_from
     )
@@ -710,17 +710,15 @@
 
     @property
     def steps(self) -> Sequence[IExecutionStep]:
         return list(self.step_dict.values())
 
     @property
     def step_output_versions(self) -> Mapping[StepOutputHandle, str]:
-        return StepOutputVersionData.get_version_dict_from_list(
-            self.known_state.step_output_versions if self.known_state else []
-        )
+        return self.known_state.step_output_versions if self.known_state else {}
 
     @property
     def step_keys_to_execute(self) -> Sequence[str]:
         return [handle.to_key() for handle in self.step_handles_to_execute]
 
     def get_step_output(self, step_output_handle: StepOutputHandle) -> StepOutput:
         check.inst_param(step_output_handle, "step_output_handle", StepOutputHandle)
@@ -745,15 +743,15 @@
         check.str_param(key, "key")
         if key not in self.step_dict_by_key:
             check.failed(f"plan has no step with key {key}")
         return self.step_dict_by_key[key]
 
     def get_executable_step_by_key(self, key: str) -> ExecutionStep:
         step = self.get_step_by_key(key)
-        return cast(ExecutionStep, check.inst(step, ExecutionStep))
+        return check.inst(step, ExecutionStep)
 
     def get_all_steps_in_topo_order(self) -> Sequence[IExecutionStep]:
         return [step for step_level in self.get_all_steps_by_level() for step in step_level]
 
     def get_all_steps_by_level(self) -> Sequence[Sequence[IExecutionStep]]:
         return [
             [self.get_step_by_key(step_key) for step_key in sorted(step_key_level)]
@@ -863,19 +861,18 @@
             step_handles_to_execute,
             self.known_state,
         )
 
         # If step output versions were provided when constructing the subset plan, add them to the
         # known state.
         if len(step_output_versions) > 0:
-            versions = StepOutputVersionData.get_version_list_from_dict(step_output_versions)  # type: ignore  # (possible none)
             if self.known_state:
-                known_state = self.known_state._replace(step_output_versions=versions)
+                known_state = self.known_state._replace(step_output_versions=step_output_versions)
             else:
-                known_state = KnownExecutionState(step_output_versions=versions)
+                known_state = KnownExecutionState(step_output_versions=step_output_versions)  # type: ignore  # (possible none)
         else:
             known_state = self.known_state
 
         return ExecutionPlan(
             self.step_dict,
             executable_map,
             resolvable_map,
@@ -1122,39 +1119,36 @@
                 )
                 for step_output_snap in output_snaps
             ]
 
             if step_snap.kind == StepKind.COMPUTE:
                 step: IExecutionStep = ExecutionStep(
                     check.inst(
-                        cast(
-                            Union[StepHandle, ResolvedFromDynamicStepHandle],
-                            step_snap.step_handle,
-                        ),
-                        ttype=(StepHandle, ResolvedFromDynamicStepHandle),
+                        step_snap.step_handle,
+                        (StepHandle, ResolvedFromDynamicStepHandle),
                     ),
                     job_name,
                     step_inputs,  # type: ignore  # (plain StepInput only)
                     step_outputs,
                     step_snap.tags,
                 )
             elif step_snap.kind == StepKind.UNRESOLVED_MAPPED:
                 step = UnresolvedMappedExecutionStep(
                     check.inst(
-                        cast(UnresolvedStepHandle, step_snap.step_handle),
-                        ttype=UnresolvedStepHandle,
+                        step_snap.step_handle,
+                        UnresolvedStepHandle,
                     ),
                     job_name,
                     step_inputs,  # type: ignore  # (StepInput or UnresolvedMappedStepInput only)
                     step_outputs,
                     step_snap.tags,
                 )
             elif step_snap.kind == StepKind.UNRESOLVED_COLLECT:
                 step = UnresolvedCollectExecutionStep(
-                    check.inst(cast(StepHandle, step_snap.step_handle), ttype=StepHandle),
+                    check.inst(step_snap.step_handle, StepHandle),
                     job_name,
                     step_inputs,  # type: ignore  # (StepInput or UnresolvedCollectStepInput only)
                     step_outputs,
                     step_snap.tags,
                 )
             else:
                 raise Exception(f"Unexpected step kind {step_snap.kind}")
```

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/state.py` & `dagster-1.7.0/dagster/_core/execution/plan/state.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 from collections import defaultdict
 from typing import (
     TYPE_CHECKING,
+    Any,
     Dict,
     List,
     Mapping,
     NamedTuple,
     Optional,
     Sequence,
     Set,
@@ -24,41 +25,27 @@
 from dagster._core.execution.plan.handle import StepHandle, UnresolvedStepHandle
 from dagster._core.execution.plan.outputs import StepOutputHandle
 from dagster._core.execution.plan.step import ResolvedFromDynamicStepHandle
 from dagster._core.execution.retries import RetryState
 from dagster._core.instance import DagsterInstance
 from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._serdes import whitelist_for_serdes
+from dagster._serdes.serdes import (
+    FieldSerializer,
+    UnknownSerdesValue,
+    UnpackContext,
+    WhitelistMap,
+    pack_value,
+)
 
 if TYPE_CHECKING:
     from dagster._core.execution.plan.plan import StepHandleUnion
 
 
 @whitelist_for_serdes
-class StepOutputVersionData(NamedTuple):
-    step_output_handle: StepOutputHandle
-    version: str
-
-    @staticmethod
-    def get_version_list_from_dict(
-        step_output_versions: Mapping[StepOutputHandle, str],
-    ) -> Sequence["StepOutputVersionData"]:
-        return [
-            StepOutputVersionData(step_output_handle=step_output_handle, version=version)
-            for step_output_handle, version in step_output_versions.items()
-        ]
-
-    @staticmethod
-    def get_version_dict_from_list(
-        step_output_versions: Sequence["StepOutputVersionData"],
-    ) -> Mapping[StepOutputHandle, str]:
-        return {data.step_output_handle: data.version for data in step_output_versions}
-
-
-@whitelist_for_serdes
 class PastExecutionState(
     NamedTuple(
         "_PastExecutionState",
         [
             ("run_id", str),
             ("produced_outputs", Set[StepOutputHandle]),
             # PastExecutionState, but no cycles allowed in NT
@@ -83,40 +70,75 @@
             check.opt_inst_param(parent_state, "parent_state", PastExecutionState),
         )
 
     def get_parent_state(self) -> Optional["PastExecutionState"]:
         return cast(Optional[PastExecutionState], self.parent_state)
 
 
-@whitelist_for_serdes
+# Previously, step_output_versions was stored as a list of StepOutputVersionData objects. It
+# would have to be converted to a dict for use. The sole purpose of the `StepOutputVersion` objects
+# was to make the dict key-value pairs serializable. Using a custom field serializer allows us to
+# avoid this extra complexity.
+class StepOutputVersionSerializer(FieldSerializer):
+    def pack(
+        self, value: Mapping[StepOutputHandle, str], whitelist_map: WhitelistMap, descent_path: str
+    ) -> Sequence[Dict[str, Any]]:
+        return [
+            {
+                "__class__": "StepOutputVersionData",  # this class no longer exists
+                "step_output_handle": pack_value(
+                    k, whitelist_map, f"{descent_path}.{k.step_key}/{k.output_name}"
+                ),
+                "version": v,
+            }
+            for k, v in value.items()
+        ]
+
+    def unpack(
+        self,
+        value: Sequence[UnknownSerdesValue],
+        whitelist_map: WhitelistMap,
+        context: UnpackContext,
+    ) -> Mapping[StepOutputHandle, str]:
+        mapping: Dict[StepOutputHandle, str] = {}
+        for unknown_serdes_value in value:
+            item = unknown_serdes_value.value
+            step_output_handle = cast(StepOutputHandle, item["step_output_handle"])
+            version = cast(str, item["version"])
+            mapping[step_output_handle] = version
+            context.clear_ignored_unknown_values(unknown_serdes_value)
+        return mapping
+
+
+@whitelist_for_serdes(field_serializers={"step_output_versions": StepOutputVersionSerializer})
 class KnownExecutionState(
     NamedTuple(
         "_KnownExecutionState",
         [
             # step_key -> count
             ("previous_retry_attempts", Mapping[str, int]),
             # step_key -> output_name -> mapping_keys
             ("dynamic_mappings", Mapping[str, Mapping[str, Optional[Sequence[str]]]]),
             # step_output_handle -> version
-            ("step_output_versions", Sequence[StepOutputVersionData]),
+            ("step_output_versions", Mapping[StepOutputHandle, str]),
             ("ready_outputs", Set[StepOutputHandle]),
             ("parent_state", Optional[PastExecutionState]),
         ],
     )
 ):
     """A snapshot for the parts of an on going execution that need to be handed down when delegating
     step execution to another machine/process. This includes things like previous retries and
     resolved dynamic outputs.
     """
 
     def __new__(
         cls,
         previous_retry_attempts: Optional[Mapping[str, int]] = None,
         dynamic_mappings: Optional[Mapping[str, Mapping[str, Optional[Sequence[str]]]]] = None,
-        step_output_versions: Optional[Sequence[StepOutputVersionData]] = None,
+        step_output_versions: Optional[Mapping[StepOutputHandle, str]] = None,
         ready_outputs: Optional[Set[StepOutputHandle]] = None,
         parent_state: Optional[PastExecutionState] = None,
     ):
         dynamic_mappings = check.opt_mapping_param(
             dynamic_mappings,
             "dynamic_mappings",
             key_type=str,
@@ -130,16 +152,18 @@
             check.opt_mapping_param(
                 previous_retry_attempts,
                 "previous_retry_attempts",
                 key_type=str,
                 value_type=int,
             ),
             dynamic_mappings,
-            check.opt_sequence_param(
-                step_output_versions, "step_output_versions", of_type=StepOutputVersionData
+            check.opt_mapping_param(
+                step_output_versions,
+                "step_output_versions",
+                key_type=StepOutputHandle,
             ),
             check.opt_set_param(ready_outputs, "ready_outputs", StepOutputHandle),
             check.opt_inst_param(parent_state, "parent_state", PastExecutionState),
         )
 
     def get_retry_state(self) -> RetryState:
         return RetryState(self.previous_retry_attempts)
@@ -212,15 +236,15 @@
 
 def _derive_state_of_past_run(
     instance: DagsterInstance,
     parent_run: DagsterRun,
 ) -> Tuple[
     Sequence[str], Mapping[str, Mapping[str, Optional[Sequence[str]]]], Set[StepOutputHandle]
 ]:
-    from dagster._core.host_representation import ExternalExecutionPlan
+    from dagster._core.remote_representation import ExternalExecutionPlan
 
     check.inst_param(instance, "instance", DagsterInstance)
     check.opt_inst_param(parent_run, "parent_run", DagsterRun)
 
     parent_run_id = parent_run.run_id
     parent_run_logs = instance.all_logs(
         parent_run_id,
```

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/step.py` & `dagster-1.7.0/dagster/_core/execution/plan/step.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
     Union,
     cast,
 )
 
 from typing_extensions import TypeGuard
 
 import dagster._check as check
-from dagster._core.definitions.utils import validate_tags
+from dagster._core.definitions.utils import normalize_tags
 from dagster._serdes.serdes import EnumSerializer, whitelist_for_serdes
 from dagster._utils.merger import merge_dicts
 
 from .handle import ResolvedFromDynamicStepHandle, StepHandle, UnresolvedStepHandle
 from .inputs import StepInput, UnresolvedCollectStepInput, UnresolvedMappedStepInput
 from .outputs import StepOutput
 
@@ -150,15 +150,17 @@
                 si.name: si
                 for si in check.sequence_param(step_inputs, "step_inputs", of_type=StepInput)
             },
             step_output_dict={
                 so.name: so
                 for so in check.sequence_param(step_outputs, "step_outputs", of_type=StepOutput)
             },
-            tags=validate_tags(check.opt_mapping_param(tags, "tags", key_type=str)),
+            tags=normalize_tags(
+                check.opt_mapping_param(tags, "tags", key_type=str), warn_on_deprecated_tags=False
+            ).tags,
             logging_tags=merge_dicts(
                 {
                     "step_key": handle.to_key(),
                     "job_name": job_name,
                     "op_name": handle.node_handle.name,
                 },
                 check.opt_mapping_param(logging_tags, "logging_tags"),
```

### Comparing `dagster-1.6.9/dagster/_core/execution/plan/utils.py` & `dagster-1.7.0/dagster/_core/execution/plan/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/poll_compute_logs.py` & `dagster-1.7.0/dagster/_core/execution/poll_compute_logs.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/resolve_versions.py` & `dagster-1.7.0/dagster/_core/execution/resolve_versions.py`

 * *Files 1% similar despite different names*

```diff
@@ -169,15 +169,15 @@
     return step_versions
 
 
 def resolve_step_output_versions(
     pipeline_def: JobDefinition,
     execution_plan: "ExecutionPlan",
     resolved_run_config: ResolvedRunConfig,
-):
+) -> Mapping[StepOutputHandle, Optional[str]]:
     step_versions = resolve_step_versions(pipeline_def, execution_plan, resolved_run_config)
     return {
         StepOutputHandle(step.key, output_name): join_and_hash(output_name, step_versions[step.key])
         for step in execution_plan.steps
         if is_executable_step(step)  # type: ignore
         for output_name in step.step_output_dict.keys()
     }
```

### Comparing `dagster-1.6.9/dagster/_core/execution/resources_init.py` & `dagster-1.7.0/dagster/_core/execution/resources_init.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/retries.py` & `dagster-1.7.0/dagster/_core/execution/retries.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/run_cancellation_thread.py` & `dagster-1.7.0/dagster/_core/execution/run_cancellation_thread.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,30 +1,27 @@
 import threading
-from typing import Tuple, cast
+from typing import Tuple
 
 import dagster._check as check
 from dagster._core.instance import DagsterInstance, InstanceRef
 from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._utils import send_interrupt
 
 
 def _kill_on_cancel(instance_ref: InstanceRef, run_id, shutdown_event):
     check.inst_param(instance_ref, "instance_ref", InstanceRef)
     check.str_param(run_id, "run_id")
 
     with DagsterInstance.from_ref(instance_ref) as instance:
         while not shutdown_event.is_set():
             shutdown_event.wait(instance.cancellation_thread_poll_interval_seconds)
-            run = cast(
+            run = check.inst(
+                instance.get_run_by_id(run_id),
                 DagsterRun,
-                check.inst(
-                    instance.get_run_by_id(run_id),
-                    DagsterRun,
-                    "Run not found for cancellation thread",
-                ),
+                "Run not found for cancellation thread",
             )
             if run.status in [
                 DagsterRunStatus.CANCELING,
                 DagsterRunStatus.CANCELED,
             ]:
                 print(  # noqa: T201
                     f"Detected run status {run.status}, sending interrupt to main thread"
```

### Comparing `dagster-1.6.9/dagster/_core/execution/stats.py` & `dagster-1.7.0/dagster/_core/execution/stats.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/submit_asset_runs.py` & `dagster-1.7.0/dagster/_core/execution/submit_asset_runs.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,24 +1,25 @@
 import logging
 import time
 from typing import Dict, Iterator, List, NamedTuple, Optional, Sequence, Tuple, cast
 
 import dagster._check as check
-from dagster._core.definitions.assets_job import is_base_asset_job_name
+from dagster._core.definitions.asset_job import is_base_asset_job_name
 from dagster._core.definitions.events import AssetKey
-from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
 from dagster._core.definitions.partition import PartitionsDefinition
+from dagster._core.definitions.remote_asset_graph import RemoteAssetGraph
 from dagster._core.definitions.run_request import RunRequest
 from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.errors import (
     DagsterCodeLocationLoadError,
+    DagsterInvalidSubsetError,
     DagsterUserCodeUnreachableError,
 )
-from dagster._core.host_representation import ExternalExecutionPlan, ExternalJob
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation import ExternalExecutionPlan, ExternalJob
 from dagster._core.snap import ExecutionPlanSnapshot
 from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._core.workspace.context import BaseWorkspaceRequestContext, IWorkspaceProcessContext
 from dagster._utils import SingleInstigatorDebugCrashFlags, check_for_debug_crash, hash_collection
 
 EXECUTION_PLAN_CREATION_RETRIES = 1
 
@@ -26,15 +27,15 @@
 class RunRequestExecutionData(NamedTuple):
     external_job: ExternalJob
     external_execution_plan: ExternalExecutionPlan
     partitions_def: Optional[PartitionsDefinition]
 
 
 def _get_implicit_job_name_for_assets(
-    asset_graph: ExternalAssetGraph, asset_keys: Sequence[AssetKey]
+    asset_graph: RemoteAssetGraph, asset_keys: Sequence[AssetKey]
 ) -> Optional[str]:
     job_names = set(asset_graph.get_materialization_job_names(asset_keys[0]))
     for asset_key in asset_keys[1:]:
         job_names &= set(asset_graph.get_materialization_job_names(asset_key))
 
     return next(job_name for job_name in job_names if is_base_asset_job_name(job_name))
 
@@ -49,15 +50,15 @@
                 asset_key = check.not_none(output.properties).asset_key
                 if asset_key:
                     output_asset_keys.add(asset_key)
     return all(key in output_asset_keys for key in asset_selection)
 
 
 def _get_job_execution_data_from_run_request(
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     run_request: RunRequest,
     instance: DagsterInstance,
     workspace: BaseWorkspaceRequestContext,
     run_request_execution_data_cache: Dict[int, RunRequestExecutionData],
 ) -> RunRequestExecutionData:
     repo_handle = asset_graph.get_repository_handle(
         cast(Sequence[AssetKey], run_request.asset_selection)[0]
@@ -76,14 +77,15 @@
         check.failed("Expected RunRequest to have an asset selection")
 
     pipeline_selector = JobSubsetSelector(
         location_name=location_name,
         repository_name=repo_handle.repository_name,
         job_name=job_name,
         asset_selection=run_request.asset_selection,
+        asset_check_selection=run_request.asset_check_keys,
         op_selection=None,
     )
 
     selector_id = hash_collection(pipeline_selector)
 
     if selector_id not in run_request_execution_data_cache:
         code_location = workspace.get_code_location(repo_handle.code_location_origin.location_name)
@@ -110,73 +112,76 @@
 
 def _create_asset_run(
     run_id: Optional[str],
     run_request: RunRequest,
     run_request_index: int,
     instance: DagsterInstance,
     run_request_execution_data_cache: Dict[int, RunRequestExecutionData],
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     workspace_process_context: IWorkspaceProcessContext,
     debug_crash_flags: SingleInstigatorDebugCrashFlags,
     logger: logging.Logger,
 ) -> DagsterRun:
     """Creates a run on the instance for the given run request. Ensures that the created run results
     in an ExecutionPlan that targets the given asset selection. If it does not, attempts to create
     a valid ExecutionPlan by reloading the workspace.
     """
     from dagster._daemon.controller import RELOAD_WORKSPACE_INTERVAL
 
     if not run_request.asset_selection:
         check.failed("Expected RunRequest to have an asset selection")
 
     for _ in range(EXECUTION_PLAN_CREATION_RETRIES + 1):
-        # create a new request context for each run in case the code location server
-        # is swapped out in the middle of the submission process
-        workspace = workspace_process_context.create_request_context()
-        execution_data = _get_job_execution_data_from_run_request(
-            asset_graph,
-            run_request,
-            instance,
-            workspace=workspace,
-            run_request_execution_data_cache=run_request_execution_data_cache,
-        )
-        check_for_debug_crash(debug_crash_flags, "EXECUTION_PLAN_CREATED")
-        check_for_debug_crash(debug_crash_flags, f"EXECUTION_PLAN_CREATED_{run_request_index}")
-
-        # retry until the execution plan targets the asset selection
-        if _execution_plan_targets_asset_selection(
-            execution_data.external_execution_plan.execution_plan_snapshot,
-            check.not_none(run_request.asset_selection),
-        ):
-            external_job = execution_data.external_job
-            external_execution_plan = execution_data.external_execution_plan
-            partitions_def = execution_data.partitions_def
-
-            run = instance.create_run(
-                job_snapshot=external_job.job_snapshot,
-                execution_plan_snapshot=external_execution_plan.execution_plan_snapshot,
-                parent_job_snapshot=external_job.parent_job_snapshot,
-                job_name=external_job.name,
-                run_id=run_id,
-                resolved_op_selection=None,
-                op_selection=None,
-                run_config={},
-                step_keys_to_execute=None,
-                tags=run_request.tags,
-                root_run_id=None,
-                parent_run_id=None,
-                status=DagsterRunStatus.NOT_STARTED,
-                external_job_origin=external_job.get_external_origin(),
-                job_code_origin=external_job.get_python_origin(),
-                asset_selection=frozenset(run_request.asset_selection),
-                asset_check_selection=None,
-                asset_job_partitions_def=partitions_def,
+        try:
+            # create a new request context for each run in case the code location server
+            # is swapped out in the middle of the submission process
+            workspace = workspace_process_context.create_request_context()
+            execution_data = _get_job_execution_data_from_run_request(
+                asset_graph,
+                run_request,
+                instance,
+                workspace=workspace,
+                run_request_execution_data_cache=run_request_execution_data_cache,
             )
+            check_for_debug_crash(debug_crash_flags, "EXECUTION_PLAN_CREATED")
+            check_for_debug_crash(debug_crash_flags, f"EXECUTION_PLAN_CREATED_{run_request_index}")
 
-            return run
+            # retry until the execution plan targets the asset selection
+            if _execution_plan_targets_asset_selection(
+                execution_data.external_execution_plan.execution_plan_snapshot,
+                check.not_none(run_request.asset_selection),
+            ):
+                external_job = execution_data.external_job
+                external_execution_plan = execution_data.external_execution_plan
+                partitions_def = execution_data.partitions_def
+
+                run = instance.create_run(
+                    job_snapshot=external_job.job_snapshot,
+                    execution_plan_snapshot=external_execution_plan.execution_plan_snapshot,
+                    parent_job_snapshot=external_job.parent_job_snapshot,
+                    job_name=external_job.name,
+                    run_id=run_id,
+                    resolved_op_selection=None,
+                    op_selection=None,
+                    run_config={},
+                    step_keys_to_execute=None,
+                    tags=run_request.tags,
+                    root_run_id=None,
+                    parent_run_id=None,
+                    status=DagsterRunStatus.NOT_STARTED,
+                    external_job_origin=external_job.get_external_origin(),
+                    job_code_origin=external_job.get_python_origin(),
+                    asset_selection=frozenset(run_request.asset_selection),
+                    asset_check_selection=None,
+                    asset_job_partitions_def=partitions_def,
+                )
+
+                return run
+        except DagsterInvalidSubsetError:
+            pass
 
         logger.warning(
             "Execution plan is out of sync with the workspace. Pausing run submission for "
             f"{RELOAD_WORKSPACE_INTERVAL} to allow the execution plan to rebuild with the updated workspace."
         )
         # Sleep for RELOAD_WORKSPACE_INTERVAL seconds since the workspace can be refreshed
         # at most once every interval
@@ -184,28 +189,28 @@
         # Clear the execution plan cache as this data is no longer valid
         run_request_execution_data_cache = {}
 
         # If the execution plan does not targets the asset selection, the asset graph
         # likely is outdated and targeting the wrong job, refetch the asset
         # graph from the workspace
         workspace = workspace_process_context.create_request_context()
-        asset_graph = ExternalAssetGraph.from_workspace(workspace)
+        asset_graph = workspace.asset_graph
 
     check.failed(
         f"Failed to target asset selection {run_request.asset_selection} in run after retrying."
     )
 
 
 def submit_asset_run(
     run_id: Optional[str],
     run_request: RunRequest,
     run_request_index: int,
     instance: DagsterInstance,
     workspace_process_context: IWorkspaceProcessContext,
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     run_request_execution_data_cache: Dict[int, RunRequestExecutionData],
     debug_crash_flags: SingleInstigatorDebugCrashFlags,
     logger: logging.Logger,
 ) -> DagsterRun:
     """Submits a run for a run request that targets an asset selection. If the run already exists,
     submits the existing run. If the run does not exist, creates a new run and submits it, ensuring
     that the created run targets the given asset selection.
@@ -270,15 +275,15 @@
 
 def submit_asset_runs_in_chunks(
     run_requests: Sequence[RunRequest],
     reserved_run_ids: Optional[Sequence[str]],
     chunk_size: int,
     instance: DagsterInstance,
     workspace_process_context: IWorkspaceProcessContext,
-    asset_graph: ExternalAssetGraph,
+    asset_graph: RemoteAssetGraph,
     debug_crash_flags: SingleInstigatorDebugCrashFlags,
     logger: logging.Logger,
     backfill_id: Optional[str] = None,
 ) -> Iterator[Optional[SubmitRunRequestChunkResult]]:
     """Submits runs for a sequence of run requests that target asset selections in chunks. Yields
     None after each run is submitted to allow the daemon to heartbeat, and yields a list of tuples
     of the run request and the submitted run after each chunk is submitted to allow the caller to
@@ -289,15 +294,15 @@
 
     run_request_execution_data_cache = {}
     for chunk_start in range(0, len(run_requests), chunk_size):
         run_request_chunk = run_requests[chunk_start : chunk_start + chunk_size]
         chunk_submitted_runs: List[Tuple[RunRequest, DagsterRun]] = []
         retryable_error_raised = False
 
-        logger.critical(f"{chunk_size}, {chunk_start}, {len(run_request_chunk)}")
+        logger.debug(f"{chunk_size}, {chunk_start}, {len(run_request_chunk)}")
 
         # submit each run in the chunk
         for chunk_idx, run_request in enumerate(run_request_chunk):
             run_request_idx = chunk_start + chunk_idx
             run_id = reserved_run_ids[run_request_idx] if reserved_run_ids else None
             try:
                 submitted_run = submit_asset_run(
```

### Comparing `dagster-1.6.9/dagster/_core/execution/tags.py` & `dagster-1.7.0/dagster/_core/execution/tags.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/validate_run_config.py` & `dagster-1.7.0/dagster/_core/execution/validate_run_config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/watch_orphans.py` & `dagster-1.7.0/dagster/_core/execution/watch_orphans.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/execution/with_resources.py` & `dagster-1.7.0/dagster/_core/execution/with_resources.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/executor/base.py` & `dagster-1.7.0/dagster/_core/executor/base.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/executor/child_process_executor.py` & `dagster-1.7.0/dagster/_core/executor/child_process_executor.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/executor/in_process.py` & `dagster-1.7.0/dagster/_core/executor/in_process.py`

 * *Files 5% similar despite different names*

```diff
@@ -67,12 +67,10 @@
                         output_capture=plan_context.output_capture,
                     ),
                 )
             )
 
         yield DagsterEvent.engine_event(
             plan_context,
-            "Finished steps in process (pid: {pid}) in {duration_ms}".format(
-                pid=os.getpid(), duration_ms=format_duration(timer_result.millis)
-            ),
+            f"Finished steps in process (pid: {os.getpid()}) in {format_duration(timer_result.millis)}",
             event_specific_data=EngineEventData.in_process(os.getpid(), step_keys_to_execute),
         )
```

### Comparing `dagster-1.6.9/dagster/_core/executor/init.py` & `dagster-1.7.0/dagster/_core/executor/init.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/executor/multiprocess.py` & `dagster-1.7.0/dagster/_core/executor/multiprocess.py`

 * *Files 1% similar despite different names*

```diff
@@ -317,17 +317,15 @@
                     ),
                     subprocess_error_infos=list(errs.values()),
                 )
 
         if timer_result:
             yield DagsterEvent.engine_event(
                 plan_context,
-                "Multiprocess executor: parent process exiting after {duration} (pid: {pid})".format(
-                    duration=format_duration(timer_result.millis), pid=os.getpid()
-                ),
+                f"Multiprocess executor: parent process exiting after {format_duration(timer_result.millis)} (pid: {os.getpid()})",
                 event_specific_data=EngineEventData.multiprocess(os.getpid()),
             )
 
 
 def execute_step_out_of_process(
     multiproc_ctx: MultiprocessingBaseContext,
     recon_job: ReconstructableJob,
```

### Comparing `dagster-1.6.9/dagster/_core/executor/step_delegating/step_delegating_executor.py` & `dagster-1.7.0/dagster/_core/executor/step_delegating/step_delegating_executor.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/executor/step_delegating/step_handler/base.py` & `dagster-1.7.0/dagster/_core/executor/step_delegating/step_handler/base.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/host_representation/__init__.py` & `dagster-1.7.0/dagster/_core/remote_representation/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -19,41 +19,42 @@
     ExternalExecutionParamsErrorData as ExternalExecutionParamsErrorData,
     ExternalJobData as ExternalJobData,
     ExternalJobRef as ExternalJobRef,
     ExternalJobSubsetResult as ExternalJobSubsetResult,
     ExternalPartitionConfigData as ExternalPartitionConfigData,
     ExternalPartitionExecutionErrorData as ExternalPartitionExecutionErrorData,
     ExternalPartitionNamesData as ExternalPartitionNamesData,
-    ExternalPartitionSetData as ExternalPartitionSetData,
     ExternalPartitionSetExecutionParamData as ExternalPartitionSetExecutionParamData,
     ExternalPartitionTagsData as ExternalPartitionTagsData,
     ExternalPresetData as ExternalPresetData,
     ExternalRepositoryData as ExternalRepositoryData,
     ExternalRepositoryErrorData as ExternalRepositoryErrorData,
-    ExternalScheduleData as ExternalScheduleData,
     ExternalScheduleExecutionErrorData as ExternalScheduleExecutionErrorData,
     ExternalSensorExecutionErrorData as ExternalSensorExecutionErrorData,
     ExternalTargetData as ExternalTargetData,
+    PartitionSetSnap as PartitionSetSnap,
+    ScheduleSnap as ScheduleSnap,
+    SensorSnap as SensorSnap,
     external_job_data_from_def as external_job_data_from_def,
     external_repository_data_from_def as external_repository_data_from_def,
 )
 from .handle import (
     JobHandle as JobHandle,
     RepositoryHandle as RepositoryHandle,
 )
 from .historical import HistoricalJob as HistoricalJob
 from .origin import (
     IN_PROCESS_NAME as IN_PROCESS_NAME,
     CodeLocationOrigin as CodeLocationOrigin,
-    ExternalInstigatorOrigin as ExternalInstigatorOrigin,
-    ExternalJobOrigin as ExternalJobOrigin,
-    ExternalRepositoryOrigin as ExternalRepositoryOrigin,
     GrpcServerCodeLocationOrigin as GrpcServerCodeLocationOrigin,
     InProcessCodeLocationOrigin as InProcessCodeLocationOrigin,
     ManagedGrpcPythonEnvCodeLocationOrigin as ManagedGrpcPythonEnvCodeLocationOrigin,
+    RemoteInstigatorOrigin as RemoteInstigatorOrigin,
+    RemoteJobOrigin as RemoteJobOrigin,
+    RemoteRepositoryOrigin as RemoteRepositoryOrigin,
 )
 
 # ruff: isort: split
 from .code_location import (
     CodeLocation as CodeLocation,
     GrpcServerCodeLocation as GrpcServerCodeLocation,
     InProcessCodeLocation as InProcessCodeLocation,
```

### Comparing `dagster-1.6.9/dagster/_core/host_representation/code_location.py` & `dagster-1.7.0/dagster/_core/remote_representation/code_location.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,41 +20,45 @@
 from dagster._api.snapshot_repository import sync_get_streaming_external_repositories_data_grpc
 from dagster._api.snapshot_schedule import sync_get_external_schedule_execution_data_grpc
 from dagster._core.code_pointer import CodePointer
 from dagster._core.definitions.partition import PartitionsDefinition
 from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.definitions.repository_definition import RepositoryDefinition
 from dagster._core.definitions.selector import JobSubsetSelector
-from dagster._core.errors import DagsterInvariantViolationError, DagsterUserCodeProcessError
+from dagster._core.errors import (
+    DagsterInvalidSubsetError,
+    DagsterInvariantViolationError,
+    DagsterUserCodeProcessError,
+)
 from dagster._core.execution.api import create_execution_plan
 from dagster._core.execution.plan.state import KnownExecutionState
-from dagster._core.host_representation import ExternalJobSubsetResult
-from dagster._core.host_representation.external import (
+from dagster._core.instance import DagsterInstance
+from dagster._core.libraries import DagsterLibraryRegistry
+from dagster._core.origin import RepositoryPythonOrigin
+from dagster._core.remote_representation import ExternalJobSubsetResult
+from dagster._core.remote_representation.external import (
     ExternalExecutionPlan,
     ExternalJob,
     ExternalPartitionSet,
     ExternalRepository,
 )
-from dagster._core.host_representation.external_data import (
+from dagster._core.remote_representation.external_data import (
     ExternalPartitionNamesData,
     ExternalScheduleExecutionErrorData,
     ExternalSensorExecutionErrorData,
     external_partition_set_name_for_job_name,
     external_repository_data_from_def,
 )
-from dagster._core.host_representation.grpc_server_registry import GrpcServerRegistry
-from dagster._core.host_representation.handle import JobHandle, RepositoryHandle
-from dagster._core.host_representation.origin import (
+from dagster._core.remote_representation.grpc_server_registry import GrpcServerRegistry
+from dagster._core.remote_representation.handle import JobHandle, RepositoryHandle
+from dagster._core.remote_representation.origin import (
     CodeLocationOrigin,
     GrpcServerCodeLocationOrigin,
     InProcessCodeLocationOrigin,
 )
-from dagster._core.instance import DagsterInstance
-from dagster._core.libraries import DagsterLibraryRegistry
-from dagster._core.origin import RepositoryPythonOrigin
 from dagster._core.snap.execution_plan_snapshot import snapshot_from_execution_plan
 from dagster._grpc.impl import (
     get_external_schedule_execution,
     get_external_sensor_execution,
     get_notebook_data,
     get_partition_config,
     get_partition_names,
@@ -65,15 +69,15 @@
 from dagster._serdes import deserialize_value
 from dagster._seven.compat.pendulum import PendulumDateTime
 from dagster._utils.merger import merge_dicts
 
 if TYPE_CHECKING:
     from dagster._core.definitions.schedule_definition import ScheduleExecutionData
     from dagster._core.definitions.sensor_definition import SensorExecutionData
-    from dagster._core.host_representation import (
+    from dagster._core.remote_representation import (
         ExternalPartitionConfigData,
         ExternalPartitionExecutionErrorData,
         ExternalPartitionSetExecutionParamData,
         ExternalPartitionTagsData,
     )
 
 
@@ -142,18 +146,22 @@
             )
 
         repo_handle = self.get_repository(selector.repository_name).handle
 
         subset_result = self.get_subset_external_job_result(selector)
         external_data = subset_result.external_job_data
         if external_data is None:
-            check.failed(
-                f"Failed to fetch subset data, success: {subset_result.success} error:"
-                f" {subset_result.error}"
-            )
+            error = check.not_none(subset_result.error)
+            if error.cls_name == "DagsterInvalidSubsetError":
+                raise DagsterInvalidSubsetError(check.not_none(error.message))
+            else:
+                check.failed(
+                    f"Failed to fetch subset data, success: {subset_result.success} error:"
+                    f" {error}"
+                )
 
         return ExternalJob(external_data, repo_handle)
 
     @abstractmethod
     def get_subset_external_job_result(
         self, selector: JobSubsetSelector
     ) -> ExternalJobSubsetResult:
@@ -396,14 +404,15 @@
 
         return get_external_pipeline_subset_result(
             self._get_repo_def(selector.repository_name),
             selector.job_name,
             selector.op_selection,
             selector.asset_selection,
             selector.asset_check_selection,
+            include_parent_snapshot=True,
         )
 
     def get_external_execution_plan(
         self,
         external_job: ExternalJob,
         run_config: Mapping[str, object],
         step_keys_to_execute: Optional[Sequence[str]],
@@ -528,14 +537,15 @@
         last_run_key: Optional[str],
         cursor: Optional[str],
         log_key: Optional[Sequence[str]],
         last_sensor_start_time: Optional[float],
     ) -> "SensorExecutionData":
         result = get_external_sensor_execution(
             self._get_repo_def(repository_handle.repository_name),
+            self.origin,
             instance.get_ref(),
             name,
             last_tick_completion_time,
             last_run_key,
             cursor,
             log_key,
             last_sensor_start_time,
@@ -804,21 +814,33 @@
             selector.location_name == self.name,
             f"PipelineSelector location_name mismatch, got {selector.location_name} expected"
             f" {self.name}",
         )
 
         external_repository = self.get_repository(selector.repository_name)
         job_handle = JobHandle(selector.job_name, external_repository.handle)
-        return sync_get_external_job_subset_grpc(
+        subset = sync_get_external_job_subset_grpc(
             self.client,
             job_handle.get_external_origin(),
-            selector.op_selection,
-            selector.asset_selection,
-            selector.asset_check_selection,
+            include_parent_snapshot=False,
+            op_selection=selector.op_selection,
+            asset_selection=selector.asset_selection,
+            asset_check_selection=selector.asset_check_selection,
         )
+        if subset.external_job_data:
+            full_job = self.get_repository(selector.repository_name).get_full_external_job(
+                selector.job_name
+            )
+            subset = subset._replace(
+                external_job_data=subset.external_job_data._replace(
+                    parent_job_snapshot=full_job.job_snapshot
+                )
+            )
+
+        return subset
 
     def get_external_partition_config(
         self,
         repository_handle: RepositoryHandle,
         partition_set_name: str,
         partition_name: str,
         instance: DagsterInstance,
```

### Comparing `dagster-1.6.9/dagster/_core/host_representation/external.py` & `dagster-1.7.0/dagster/_core/remote_representation/external.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 from datetime import datetime
+from functools import cached_property
 from threading import RLock
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Callable,
     Dict,
     Iterable,
@@ -32,52 +33,54 @@
 )
 from dagster._core.definitions.sensor_definition import (
     DEFAULT_SENSOR_DAEMON_INTERVAL,
     DefaultSensorStatus,
     SensorType,
 )
 from dagster._core.execution.plan.handle import ResolvedFromDynamicStepHandle, StepHandle
-from dagster._core.host_representation.origin import (
-    ExternalInstigatorOrigin,
-    ExternalJobOrigin,
-    ExternalPartitionSetOrigin,
-    ExternalRepositoryOrigin,
-)
 from dagster._core.instance import DagsterInstance
 from dagster._core.origin import JobPythonOrigin, RepositoryPythonOrigin
+from dagster._core.remote_representation.origin import (
+    RemoteInstigatorOrigin,
+    RemoteJobOrigin,
+    RemotePartitionSetOrigin,
+    RemoteRepositoryOrigin,
+)
 from dagster._core.snap import ExecutionPlanSnapshot
+from dagster._core.snap.job_snapshot import JobSnapshot
 from dagster._core.utils import toposort
 from dagster._serdes import create_snapshot_id
 from dagster._utils.cached_method import cached_method
 from dagster._utils.schedules import schedule_execution_time_iterator
 
 from .external_data import (
     DEFAULT_MODE_NAME,
     EnvVarConsumer,
     ExternalAssetCheck,
     ExternalAssetNode,
     ExternalJobData,
     ExternalJobRef,
-    ExternalPartitionSetData,
     ExternalPresetData,
     ExternalRepositoryData,
     ExternalResourceData,
     ExternalResourceValue,
-    ExternalScheduleData,
-    ExternalSensorData,
     ExternalSensorMetadata,
     ExternalTargetData,
     NestedResource,
+    PartitionSetSnap,
     ResourceJobUsageEntry,
+    ScheduleSnap,
+    SensorSnap,
 )
 from .handle import InstigatorHandle, JobHandle, PartitionSetHandle, RepositoryHandle
 from .job_index import JobIndex
 from .represented import RepresentedJob
 
 if TYPE_CHECKING:
+    from dagster._core.definitions.remote_asset_graph import RemoteAssetGraph
     from dagster._core.scheduler.instigation import InstigatorState
     from dagster._core.snap.execution_plan_snapshot import ExecutionStepSnap
 
 
 class ExternalRepository:
     """ExternalRepository is a object that represents a loaded repository definition that
     is resident in another process or container. Host processes such as dagster-webserver use
@@ -181,23 +184,21 @@
 
     def get_default_auto_materialize_sensor_name(self):
         return "default_auto_materialize_sensor"
 
     @property
     @cached_method
     def _external_sensors(self) -> Dict[str, "ExternalSensor"]:
-        from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
-
         sensor_datas = {
             external_sensor_data.name: ExternalSensor(external_sensor_data, self._handle)
             for external_sensor_data in self.external_repository_data.external_sensor_datas
         }
 
         if self._instance.auto_materialize_use_sensors:
-            asset_graph = ExternalAssetGraph.from_external_repository(self)
+            asset_graph = self.asset_graph
 
             has_any_auto_observe_source_assets = False
 
             existing_auto_materialize_sensors = {
                 sensor_name: sensor
                 for sensor_name, sensor in sensor_datas.items()
                 if sensor.sensor_type == SensorType.AUTO_MATERIALIZE
@@ -208,23 +209,22 @@
                 covered_asset_keys = covered_asset_keys.union(
                     check.not_none(sensor.asset_selection).resolve(asset_graph)
                 )
 
             default_sensor_asset_keys = set()
 
             for asset_key in asset_graph.materializable_asset_keys:
-                policy = asset_graph.get_auto_materialize_policy(asset_key)
-                if not policy:
+                if not asset_graph.get(asset_key).auto_materialize_policy:
                     continue
 
                 if asset_key not in covered_asset_keys:
                     default_sensor_asset_keys.add(asset_key)
 
             for asset_key in asset_graph.observable_asset_keys:
-                if asset_graph.get_auto_observe_interval_minutes(asset_key) is None:
+                if asset_graph.get(asset_key).auto_observe_interval_minutes is None:
                     continue
 
                 has_any_auto_observe_source_assets = True
 
                 if asset_key not in covered_asset_keys:
                     default_sensor_asset_keys.add(asset_key)
 
@@ -237,15 +237,15 @@
                 )
 
                 for sensor in existing_auto_materialize_sensors.values():
                     default_sensor_asset_selection = (
                         default_sensor_asset_selection - check.not_none(sensor.asset_selection)
                     )
 
-                default_sensor_data = ExternalSensorData(
+                default_sensor_data = SensorSnap(
                     name=self.get_default_auto_materialize_sensor_name(),
                     job_name=None,
                     op_selection=None,
                     asset_selection=default_sensor_asset_selection,
                     mode=None,
                     min_interval=30,
                     description=None,
@@ -329,15 +329,15 @@
 
     @property
     def selector_id(self) -> str:
         return create_snapshot_id(
             RepositorySelector(self._handle.location_name, self._handle.repository_name)
         )
 
-    def get_external_origin(self) -> ExternalRepositoryOrigin:
+    def get_external_origin(self) -> RemoteRepositoryOrigin:
         return self.handle.get_external_origin()
 
     def get_python_origin(self) -> RepositoryPythonOrigin:
         return self.handle.get_python_origin()
 
     def get_external_origin_id(self) -> str:
         """A means of identifying the repository this ExternalRepository represents based on
@@ -369,14 +369,26 @@
             return self._asset_check_jobs.get(job_name, [])
         else:
             return self.external_repository_data.external_asset_checks or []
 
     def get_display_metadata(self) -> Mapping[str, str]:
         return self.handle.display_metadata
 
+    @cached_property
+    def asset_graph(self) -> "RemoteAssetGraph":
+        """Returns a repository scoped RemoteAssetGraph."""
+        from dagster._core.definitions.remote_asset_graph import RemoteAssetGraph
+
+        return RemoteAssetGraph.from_repository_handles_and_external_asset_nodes(
+            repo_handle_external_asset_nodes=[
+                (self.handle, asset_node) for asset_node in self.get_external_asset_nodes()
+            ],
+            external_asset_checks=self.get_external_asset_checks(),
+        )
+
 
 class ExternalJob(RepresentedJob):
     """ExternalJob is a object that represents a loaded job definition that
     is resident in another process or container. Host processes such as dagster-webserver use
     objects such as these to interact with user-defined artifacts.
     """
 
@@ -512,14 +524,18 @@
         return self._job_index.job_snapshot.tags
 
     @property
     def metadata(self) -> Mapping[str, MetadataValue]:
         return self._job_index.job_snapshot.metadata
 
     @property
+    def job_snapshot(self) -> JobSnapshot:
+        return self._job_index.job_snapshot
+
+    @property
     def computed_job_snapshot_id(self) -> str:
         return self._snapshot_id
 
     @property
     def identifying_job_snapshot_id(self) -> str:
         return self._snapshot_id
 
@@ -527,15 +543,15 @@
     def handle(self) -> JobHandle:
         return self._handle
 
     def get_python_origin(self) -> JobPythonOrigin:
         repository_python_origin = self.repository_handle.get_python_origin()
         return JobPythonOrigin(self.name, repository_python_origin)
 
-    def get_external_origin(self) -> ExternalJobOrigin:
+    def get_external_origin(self) -> RemoteJobOrigin:
         return self.handle.get_external_origin()
 
     def get_external_origin_id(self) -> str:
         return self.get_external_origin().get_id()
 
 
 class ExternalExecutionPlan:
@@ -690,17 +706,17 @@
 
     @property
     def is_dagster_maintained(self) -> bool:
         return self._external_resource_data.dagster_maintained
 
 
 class ExternalSchedule:
-    def __init__(self, external_schedule_data: ExternalScheduleData, handle: RepositoryHandle):
+    def __init__(self, external_schedule_data: ScheduleSnap, handle: RepositoryHandle):
         self._external_schedule_data = check.inst_param(
-            external_schedule_data, "external_schedule_data", ExternalScheduleData
+            external_schedule_data, "external_schedule_data", ScheduleSnap
         )
         self._handle = InstigatorHandle(
             self._external_schedule_data.name, check.inst_param(handle, "handle", RepositoryHandle)
         )
 
     @property
     def name(self) -> str:
@@ -738,15 +754,15 @@
     def environment_vars(self) -> Optional[Mapping[str, str]]:
         return self._external_schedule_data.environment_vars
 
     @property
     def handle(self) -> InstigatorHandle:
         return self._handle
 
-    def get_external_origin(self) -> ExternalInstigatorOrigin:
+    def get_external_origin(self) -> RemoteInstigatorOrigin:
         return self.handle.get_external_origin()
 
     def get_external_origin_id(self) -> str:
         return self.get_external_origin().get_id()
 
     @property
     def selector(self) -> InstigatorSelector:
@@ -815,17 +831,17 @@
     ) -> Iterator[datetime]:
         return schedule_execution_time_iterator(
             start_timestamp, self.cron_schedule, self.execution_timezone, ascending
         )
 
 
 class ExternalSensor:
-    def __init__(self, external_sensor_data: ExternalSensorData, handle: RepositoryHandle):
+    def __init__(self, external_sensor_data: SensorSnap, handle: RepositoryHandle):
         self._external_sensor_data = check.inst_param(
-            external_sensor_data, "external_sensor_data", ExternalSensorData
+            external_sensor_data, "external_sensor_data", SensorSnap
         )
         self._handle = InstigatorHandle(
             self._external_sensor_data.name, check.inst_param(handle, "handle", RepositoryHandle)
         )
 
     @property
     def name(self) -> str:
@@ -872,25 +888,25 @@
     @property
     def description(self) -> Optional[str]:
         return self._external_sensor_data.description
 
     @property
     def min_interval_seconds(self) -> int:
         if (
-            isinstance(self._external_sensor_data, ExternalSensorData)
+            isinstance(self._external_sensor_data, SensorSnap)
             and self._external_sensor_data.min_interval
         ):
             return self._external_sensor_data.min_interval
         return DEFAULT_SENSOR_DAEMON_INTERVAL
 
     @property
     def run_tags(self) -> Mapping[str, str]:
         return self._external_sensor_data.run_tags
 
-    def get_external_origin(self) -> ExternalInstigatorOrigin:
+    def get_external_origin(self) -> RemoteInstigatorOrigin:
         return self._handle.get_external_origin()
 
     def get_external_origin_id(self) -> str:
         return self.get_external_origin().get_id()
 
     @property
     def selector(self) -> InstigatorSelector:
@@ -966,19 +982,17 @@
 
     @property
     def default_status(self) -> DefaultSensorStatus:
         return self._external_sensor_data.default_status or DefaultSensorStatus.STOPPED
 
 
 class ExternalPartitionSet:
-    def __init__(
-        self, external_partition_set_data: ExternalPartitionSetData, handle: RepositoryHandle
-    ):
+    def __init__(self, external_partition_set_data: PartitionSetSnap, handle: RepositoryHandle):
         self._external_partition_set_data = check.inst_param(
-            external_partition_set_data, "external_partition_set_data", ExternalPartitionSetData
+            external_partition_set_data, "external_partition_set_data", PartitionSetSnap
         )
         self._handle = PartitionSetHandle(
             external_partition_set_data.name, check.inst_param(handle, "handle", RepositoryHandle)
         )
 
     @property
     def name(self) -> str:
@@ -996,15 +1010,15 @@
     def job_name(self) -> str:
         return self._external_partition_set_data.job_name
 
     @property
     def repository_handle(self) -> RepositoryHandle:
         return self._handle.repository_handle
 
-    def get_external_origin(self) -> ExternalPartitionSetOrigin:
+    def get_external_origin(self) -> RemotePartitionSetOrigin:
         return self._handle.get_external_origin()
 
     def get_external_origin_id(self) -> str:
         return self.get_external_origin().get_id()
 
     def has_partition_name_data(self) -> bool:
         # Partition sets from older versions of Dagster as well as partition sets using
```

### Comparing `dagster-1.6.9/dagster/_core/host_representation/external_data.py` & `dagster-1.7.0/dagster/_core/remote_representation/external_data.py`

 * *Files 3% similar despite different names*

```diff
@@ -6,15 +6,14 @@
 
 import inspect
 import json
 from abc import ABC, abstractmethod
 from collections import defaultdict
 from enum import Enum
 from typing import (
-    TYPE_CHECKING,
     Any,
     Dict,
     Iterable,
     List,
     Mapping,
     NamedTuple,
     Optional,
@@ -23,15 +22,15 @@
     Tuple,
     Type,
     Union,
     cast,
 )
 
 import pendulum
-from typing_extensions import Final
+from typing_extensions import Final, Self
 
 from dagster import (
     StaticPartitionsDefinition,
     _check as check,
 )
 from dagster._config.pythonic_config import (
     ConfigurableIOManagerFactoryResourceDefinition,
@@ -43,26 +42,24 @@
     AssetSelection,
     JobDefinition,
     PartitionsDefinition,
     RepositoryDefinition,
     ScheduleDefinition,
 )
 from dagster._core.definitions.asset_check_spec import AssetCheckKey
-from dagster._core.definitions.asset_checks import AssetChecksDefinition
+from dagster._core.definitions.asset_graph import AssetGraph
+from dagster._core.definitions.asset_job import is_base_asset_job_name
 from dagster._core.definitions.asset_sensor_definition import AssetSensorDefinition
 from dagster._core.definitions.asset_spec import (
     SYSTEM_METADATA_KEY_ASSET_EXECUTION_TYPE,
     AssetExecutionType,
 )
 from dagster._core.definitions.assets import (
-    AssetOwner,
     AssetsDefinition,
-    UserAssetOwner,
 )
-from dagster._core.definitions.assets_job import is_base_asset_job_name
 from dagster._core.definitions.auto_materialize_policy import AutoMaterializePolicy
 from dagster._core.definitions.auto_materialize_sensor_definition import (
     AutoMaterializeSensorDefinition,
 )
 from dagster._core.definitions.backfill_policy import BackfillPolicy
 from dagster._core.definitions.definition_config_schema import ConfiguredDefinitionConfigSchema
 from dagster._core.definitions.dependency import (
@@ -75,15 +72,14 @@
 from dagster._core.definitions.events import AssetKey
 from dagster._core.definitions.freshness_policy import FreshnessPolicy
 from dagster._core.definitions.graph_definition import GraphDefinition
 from dagster._core.definitions.metadata import (
     MetadataFieldSerializer,
     MetadataMapping,
     MetadataValue,
-    RawMetadataMapping,
     TextMetadataValue,
     normalize_metadata,
 )
 from dagster._core.definitions.multi_dimensional_partitions import MultiPartitionsDefinition
 from dagster._core.definitions.op_definition import OpDefinition
 from dagster._core.definitions.partition import DynamicPartitionsDefinition, ScheduleType
 from dagster._core.definitions.partition_mapping import (
@@ -105,69 +101,66 @@
 from dagster._core.storage.io_manager import IOManagerDefinition
 from dagster._serdes import whitelist_for_serdes
 from dagster._serdes.serdes import (
     is_whitelisted_for_serdes_object,
 )
 from dagster._utils.error import SerializableErrorInfo
 
-if TYPE_CHECKING:
-    from dagster._core.definitions.asset_layer import AssetOutputInfo
-
 DEFAULT_MODE_NAME = "default"
 DEFAULT_PRESET_NAME = "default"
 
 
 @whitelist_for_serdes(storage_field_names={"external_job_datas": "external_pipeline_datas"})
 class ExternalRepositoryData(
     NamedTuple(
         "_ExternalRepositoryData",
         [
             ("name", str),
-            ("external_schedule_datas", Sequence["ExternalScheduleData"]),
-            ("external_partition_set_datas", Sequence["ExternalPartitionSetData"]),
-            ("external_sensor_datas", Sequence["ExternalSensorData"]),
+            ("external_schedule_datas", Sequence["ScheduleSnap"]),
+            ("external_partition_set_datas", Sequence["PartitionSetSnap"]),
+            ("external_sensor_datas", Sequence["SensorSnap"]),
             ("external_asset_graph_data", Sequence["ExternalAssetNode"]),
             ("external_job_datas", Optional[Sequence["ExternalJobData"]]),
             ("external_job_refs", Optional[Sequence["ExternalJobRef"]]),
             ("external_resource_data", Optional[Sequence["ExternalResourceData"]]),
             ("external_asset_checks", Optional[Sequence["ExternalAssetCheck"]]),
             ("metadata", Optional[MetadataMapping]),
             ("utilized_env_vars", Optional[Mapping[str, Sequence["EnvVarConsumer"]]]),
         ],
     )
 ):
     def __new__(
         cls,
         name: str,
-        external_schedule_datas: Sequence["ExternalScheduleData"],
-        external_partition_set_datas: Sequence["ExternalPartitionSetData"],
-        external_sensor_datas: Optional[Sequence["ExternalSensorData"]] = None,
+        external_schedule_datas: Sequence["ScheduleSnap"],
+        external_partition_set_datas: Sequence["PartitionSetSnap"],
+        external_sensor_datas: Optional[Sequence["SensorSnap"]] = None,
         external_asset_graph_data: Optional[Sequence["ExternalAssetNode"]] = None,
         external_job_datas: Optional[Sequence["ExternalJobData"]] = None,
         external_job_refs: Optional[Sequence["ExternalJobRef"]] = None,
         external_resource_data: Optional[Sequence["ExternalResourceData"]] = None,
         external_asset_checks: Optional[Sequence["ExternalAssetCheck"]] = None,
         metadata: Optional[MetadataMapping] = None,
         utilized_env_vars: Optional[Mapping[str, Sequence["EnvVarConsumer"]]] = None,
     ):
         return super(ExternalRepositoryData, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
             external_schedule_datas=check.sequence_param(
-                external_schedule_datas, "external_schedule_datas", of_type=ExternalScheduleData
+                external_schedule_datas, "external_schedule_datas", of_type=ScheduleSnap
             ),
             external_partition_set_datas=check.sequence_param(
                 external_partition_set_datas,
                 "external_partition_set_datas",
-                of_type=ExternalPartitionSetData,
+                of_type=PartitionSetSnap,
             ),
             external_sensor_datas=check.opt_sequence_param(
                 external_sensor_datas,
                 "external_sensor_datas",
-                of_type=ExternalSensorData,
+                of_type=SensorSnap,
             ),
             external_asset_graph_data=check.opt_sequence_param(
                 external_asset_graph_data,
                 "external_asset_graph_dats",
                 of_type=ExternalAssetNode,
             ),
             external_job_datas=check.opt_nullable_sequence_param(
@@ -240,15 +233,15 @@
         check.str_param(name, "name")
         for external_partition_set_data in self.external_partition_set_datas:
             if external_partition_set_data.name == name:
                 return True
 
         return False
 
-    def get_external_partition_set_data(self, name) -> "ExternalPartitionSetData":
+    def get_external_partition_set_data(self, name) -> "PartitionSetSnap":
         check.str_param(name, "name")
 
         for external_partition_set_data in self.external_partition_set_datas:
             if external_partition_set_data.name == name:
                 return external_partition_set_data
 
         check.failed("Could not find external partition set data named " + name)
@@ -418,70 +411,86 @@
             ),
             mode=check.str_param(mode, "mode"),
             tags=check.opt_mapping_param(tags, "tags", key_type=str, value_type=str),
         )
 
 
 @whitelist_for_serdes(
+    storage_name="ExternalScheduleData",
     storage_field_names={"job_name": "pipeline_name", "op_selection": "solid_selection"},
     skip_when_empty_fields={"default_status"},
 )
-class ExternalScheduleData(
+class ScheduleSnap(
     NamedTuple(
-        "_ExternalScheduleData",
+        "_ScheduleSnap",
         [
             ("name", str),
             ("cron_schedule", Union[str, Sequence[str]]),
             ("job_name", str),
             ("op_selection", Optional[Sequence[str]]),
             ("mode", Optional[str]),
-            ("environment_vars", Optional[Mapping[str, str]]),
+            ("environment_vars", Mapping[str, str]),
             ("partition_set_name", Optional[str]),
             ("execution_timezone", Optional[str]),
             ("description", Optional[str]),
             ("default_status", Optional[DefaultScheduleStatus]),
         ],
     )
 ):
     def __new__(
         cls,
-        name,
-        cron_schedule,
-        job_name,
-        op_selection,
-        mode,
-        environment_vars,
-        partition_set_name,
-        execution_timezone,
-        description=None,
-        default_status=None,
+        name: str,
+        cron_schedule: Union[str, Sequence[str]],
+        job_name: str,
+        op_selection: Optional[Sequence[str]],
+        mode: Optional[str],
+        environment_vars: Optional[Mapping[str, str]],
+        partition_set_name: Optional[str],
+        execution_timezone: Optional[str],
+        description: Optional[str] = None,
+        default_status: Optional[DefaultScheduleStatus] = None,
     ):
         cron_schedule = check.inst_param(cron_schedule, "cron_schedule", (str, Sequence))
         if not isinstance(cron_schedule, str):
             cron_schedule = check.sequence_param(cron_schedule, "cron_schedule", of_type=str)
 
-        return super(ExternalScheduleData, cls).__new__(
+        return super(ScheduleSnap, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
             cron_schedule=cron_schedule,
             job_name=check.str_param(job_name, "job_name"),
-            op_selection=check.opt_nullable_list_param(op_selection, "op_selection", str),
+            op_selection=check.opt_nullable_sequence_param(op_selection, "op_selection", str),
             mode=check.opt_str_param(mode, "mode"),
-            environment_vars=check.opt_dict_param(environment_vars, "environment_vars"),
+            environment_vars=check.opt_mapping_param(environment_vars, "environment_vars"),
             partition_set_name=check.opt_str_param(partition_set_name, "partition_set_name"),
             execution_timezone=check.opt_str_param(execution_timezone, "execution_timezone"),
             description=check.opt_str_param(description, "description"),
             # Leave default_status as None if it's STOPPED to maintain stable back-compat IDs
             default_status=(
                 DefaultScheduleStatus.RUNNING
                 if default_status == DefaultScheduleStatus.RUNNING
                 else None
             ),
         )
 
+    @classmethod
+    def from_def(cls, schedule_def: ScheduleDefinition) -> Self:
+        return cls(
+            name=schedule_def.name,
+            cron_schedule=schedule_def.cron_schedule,
+            job_name=schedule_def.job_name,
+            op_selection=schedule_def._target.op_selection,  # noqa: SLF001
+            mode=DEFAULT_MODE_NAME,
+            environment_vars=schedule_def.environment_vars,
+            partition_set_name=None,
+            execution_timezone=schedule_def.execution_timezone,
+            description=schedule_def.description,
+            default_status=schedule_def.default_status,
+        )
+
 
 @whitelist_for_serdes
 class ExternalScheduleExecutionErrorData(
     NamedTuple("_ExternalScheduleExecutionErrorData", [("error", Optional[SerializableErrorInfo])])
 ):
     def __new__(cls, error: Optional[SerializableErrorInfo]):
         return super(ExternalScheduleExecutionErrorData, cls).__new__(
@@ -520,20 +529,21 @@
             asset_keys=check.opt_nullable_sequence_param(
                 asset_keys, "asset_keys", of_type=AssetKey
             ),
         )
 
 
 @whitelist_for_serdes(
+    storage_name="ExternalSensorData",
     storage_field_names={"job_name": "pipeline_name", "op_selection": "solid_selection"},
     skip_when_empty_fields={"default_status", "sensor_type"},
 )
-class ExternalSensorData(
+class SensorSnap(
     NamedTuple(
-        "_ExternalSensorData",
+        "_SensorSnap",
         [
             ("name", str),
             ("job_name", Optional[str]),
             ("op_selection", Optional[Sequence[str]]),
             ("mode", Optional[str]),
             ("min_interval", Optional[int]),
             ("description", Optional[str]),
@@ -577,15 +587,15 @@
         if asset_selection is not None:
             check.opt_inst_param(asset_selection, "asset_selection", AssetSelection)
             check.invariant(
                 is_whitelisted_for_serdes_object(asset_selection),
                 "asset_selection must be serializable",
             )
 
-        return super(ExternalSensorData, cls).__new__(
+        return super(SensorSnap, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
             job_name=check.opt_str_param(job_name, "job_name"),  # keep legacy field populated
             op_selection=check.opt_nullable_sequence_param(
                 op_selection, "op_selection", str
             ),  # keep legacy field populated
             mode=check.opt_str_param(mode, "mode"),  # keep legacy field populated
@@ -602,14 +612,66 @@
                 else None
             ),
             sensor_type=sensor_type,
             asset_selection=asset_selection,
             run_tags=run_tags or {},
         )
 
+    @classmethod
+    def from_def(cls, sensor_def: SensorDefinition, repository_def: RepositoryDefinition) -> Self:
+        first_target = sensor_def.targets[0] if sensor_def.targets else None
+
+        asset_keys = None
+        if isinstance(sensor_def, AssetSensorDefinition):
+            asset_keys = [sensor_def.asset_key]
+
+        if sensor_def.asset_selection is not None:
+            target_dict = {
+                base_asset_job_name: ExternalTargetData(
+                    job_name=base_asset_job_name, mode=DEFAULT_MODE_NAME, op_selection=None
+                )
+                for base_asset_job_name in repository_def.get_implicit_asset_job_names()
+            }
+
+            serializable_asset_selection = (
+                sensor_def.asset_selection.to_serializable_asset_selection(
+                    repository_def.asset_graph
+                )
+            )
+        else:
+            target_dict = {
+                target.job_name: ExternalTargetData(
+                    job_name=target.job_name,
+                    mode=DEFAULT_MODE_NAME,
+                    op_selection=target.op_selection,
+                )
+                for target in sensor_def.targets
+            }
+
+            serializable_asset_selection = None
+
+        return cls(
+            name=sensor_def.name,
+            job_name=first_target.job_name if first_target else None,
+            mode=None,
+            op_selection=first_target.op_selection if first_target else None,
+            target_dict=target_dict,
+            min_interval=sensor_def.minimum_interval_seconds,
+            description=sensor_def.description,
+            metadata=ExternalSensorMetadata(asset_keys=asset_keys),
+            default_status=sensor_def.default_status,
+            sensor_type=sensor_def.sensor_type,
+            asset_selection=serializable_asset_selection,
+            run_tags=(
+                sensor_def.run_tags
+                if isinstance(sensor_def, AutoMaterializeSensorDefinition)
+                else None
+            ),
+        )
+
 
 @whitelist_for_serdes
 class ExternalRepositoryErrorData(
     NamedTuple("_ExternalRepositoryErrorData", [("error", Optional[SerializableErrorInfo])])
 ):
     def __new__(cls, error: Optional[SerializableErrorInfo]):
         return super(ExternalRepositoryErrorData, cls).__new__(
@@ -825,19 +887,20 @@
     NamedTuple("_ExternalDynamicPartitionsDefinitionData", [("name", str)]),
 ):
     def get_partitions_definition(self):
         return DynamicPartitionsDefinition(name=self.name)
 
 
 @whitelist_for_serdes(
-    storage_field_names={"job_name": "pipeline_name", "op_selection": "solid_selection"}
+    storage_name="ExternalPartitionSetData",
+    storage_field_names={"job_name": "pipeline_name", "op_selection": "solid_selection"},
 )
-class ExternalPartitionSetData(
+class PartitionSetSnap(
     NamedTuple(
-        "_ExternalPartitionSetData",
+        "_PartitionSetSnap",
         [
             ("name", str),
             ("job_name", str),
             ("op_selection", Optional[Sequence[str]]),
             ("mode", Optional[str]),
             ("external_partitions_data", Optional[ExternalPartitionsDefinitionData]),
         ],
@@ -847,27 +910,57 @@
         cls,
         name: str,
         job_name: str,
         op_selection: Optional[Sequence[str]],
         mode: Optional[str],
         external_partitions_data: Optional[ExternalPartitionsDefinitionData] = None,
     ):
-        return super(ExternalPartitionSetData, cls).__new__(
+        return super(PartitionSetSnap, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
             job_name=check.str_param(job_name, "job_name"),
             op_selection=check.opt_nullable_sequence_param(op_selection, "op_selection", str),
             mode=check.opt_str_param(mode, "mode"),
             external_partitions_data=check.opt_inst_param(
                 external_partitions_data,
                 "external_partitions_data",
                 ExternalPartitionsDefinitionData,
             ),
         )
 
+    @classmethod
+    def from_job_def(cls, job_def: JobDefinition) -> Self:
+        check.inst_param(job_def, "job_def", JobDefinition)
+        partitions_def = check.not_none(job_def.partitions_def)
+
+        partitions_def_data: Optional[ExternalPartitionsDefinitionData] = None
+        if isinstance(partitions_def, TimeWindowPartitionsDefinition):
+            partitions_def_data = external_time_window_partitions_definition_from_def(
+                partitions_def
+            )
+        elif isinstance(partitions_def, StaticPartitionsDefinition):
+            partitions_def_data = external_static_partitions_definition_from_def(partitions_def)
+        elif (
+            isinstance(partitions_def, DynamicPartitionsDefinition)
+            and partitions_def.name is not None
+        ):
+            partitions_def_data = external_dynamic_partitions_definition_from_def(partitions_def)
+        elif isinstance(partitions_def, MultiPartitionsDefinition):
+            partitions_def_data = external_multi_partitions_definition_from_def(partitions_def)
+        else:
+            partitions_def_data = None
+
+        return cls(
+            name=external_partition_set_name_for_job_name(job_def.name),
+            job_name=job_def.name,
+            op_selection=None,
+            mode=DEFAULT_MODE_NAME,
+            external_partitions_data=partitions_def_data,
+        )
+
 
 @whitelist_for_serdes
 class ExternalPartitionNamesData(
     NamedTuple("_ExternalPartitionNamesData", [("partition_names", Sequence[str])])
 ):
     def __new__(cls, partition_names: Optional[Sequence[str]] = None):
         return super(ExternalPartitionNamesData, cls).__new__(
@@ -1123,55 +1216,58 @@
             ),
             sensors_using=list(
                 check.opt_sequence_param(sensors_using, "sensors_using", of_type=str)
             ),
         )
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(storage_field_names={"execution_set_identifier": "atomic_execution_unit_id"})
 class ExternalAssetCheck(
     NamedTuple(
         "_ExternalAssetCheck",
         [
             ("name", str),
             ("asset_key", AssetKey),
             ("description", Optional[str]),
-            ("atomic_execution_unit_id", Optional[str]),
+            ("execution_set_identifier", Optional[str]),
             ("job_names", Sequence[str]),
         ],
     )
 ):
     """Serializable data associated with an asset check."""
 
     def __new__(
         cls,
         name: str,
         asset_key: AssetKey,
         description: Optional[str],
-        atomic_execution_unit_id: Optional[str] = None,
+        execution_set_identifier: Optional[str] = None,
         job_names: Optional[Sequence[str]] = None,
     ):
         return super(ExternalAssetCheck, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
             asset_key=check.inst_param(asset_key, "asset_key", AssetKey),
             description=check.opt_str_param(description, "description"),
-            atomic_execution_unit_id=check.opt_str_param(
-                atomic_execution_unit_id, "automic_execution_unit_id"
+            execution_set_identifier=check.opt_str_param(
+                execution_set_identifier, "execution_set_identifier"
             ),
             job_names=check.opt_sequence_param(job_names, "job_names", of_type=str),
         )
 
     @property
     def key(self) -> AssetCheckKey:
         return AssetCheckKey(asset_key=self.asset_key, name=self.name)
 
 
 @whitelist_for_serdes(
-    storage_field_names={"metadata": "metadata_entries"},
+    storage_field_names={
+        "metadata": "metadata_entries",
+        "execution_set_identifier": "atomic_execution_unit_id",
+    },
     field_serializers={"metadata": MetadataFieldSerializer},
 )
 class ExternalAssetNode(
     NamedTuple(
         "_ExternalAssetNode",
         [
             ("asset_key", AssetKey),
@@ -1188,22 +1284,23 @@
             # the op
             ("op_description", Optional[str]),
             ("job_names", Sequence[str]),
             ("partitions_def_data", Optional[ExternalPartitionsDefinitionData]),
             ("output_name", Optional[str]),
             ("output_description", Optional[str]),
             ("metadata", Mapping[str, MetadataValue]),
-            ("group_name", Optional[str]),
+            ("tags", Optional[Mapping[str, str]]),
+            ("group_name", str),
             ("freshness_policy", Optional[FreshnessPolicy]),
             ("is_source", bool),
             ("is_observable", bool),
             # If a set of assets can't be materialized independently from each other, they will all
-            # have the same atomic_execution_unit_id. This ID should be stable across reloads and
+            # have the same execution_set_identifier. This ID should be stable across reloads and
             # unique deployment-wide.
-            ("atomic_execution_unit_id", Optional[str]),
+            ("execution_set_identifier", Optional[str]),
             ("required_top_level_resources", Optional[Sequence[str]]),
             ("auto_materialize_policy", Optional[AutoMaterializePolicy]),
             ("backfill_policy", Optional[BackfillPolicy]),
             ("auto_observe_interval_minutes", Optional[float]),
             ("owners", Optional[Sequence[str]]),
         ],
     )
@@ -1227,26 +1324,29 @@
         graph_name: Optional[str] = None,
         op_description: Optional[str] = None,
         job_names: Optional[Sequence[str]] = None,
         partitions_def_data: Optional[ExternalPartitionsDefinitionData] = None,
         output_name: Optional[str] = None,
         output_description: Optional[str] = None,
         metadata: Optional[Mapping[str, MetadataValue]] = None,
+        tags: Optional[Mapping[str, str]] = None,
         group_name: Optional[str] = None,
         freshness_policy: Optional[FreshnessPolicy] = None,
         is_source: Optional[bool] = None,
         is_observable: bool = False,
-        atomic_execution_unit_id: Optional[str] = None,
+        execution_set_identifier: Optional[str] = None,
         required_top_level_resources: Optional[Sequence[str]] = None,
         auto_materialize_policy: Optional[AutoMaterializePolicy] = None,
         backfill_policy: Optional[BackfillPolicy] = None,
         auto_observe_interval_minutes: Optional[float] = None,
         owners: Optional[Sequence[str]] = None,
     ):
-        metadata = normalize_metadata(check.opt_mapping_param(metadata, "metadata", key_type=str))
+        metadata = normalize_metadata(
+            check.opt_mapping_param(metadata, "metadata", key_type=str), allow_invalid=True
+        )
 
         # backcompat logic for execution type specified via metadata
         if SYSTEM_METADATA_KEY_ASSET_EXECUTION_TYPE in metadata:
             val = metadata[SYSTEM_METADATA_KEY_ASSET_EXECUTION_TYPE]
             if not isinstance(val, TextMetadataValue):
                 check.failed(
                     f"Expected metadata value for key {SYSTEM_METADATA_KEY_ASSET_EXECUTION_TYPE} to be a TextMetadataValue, got {val}"
@@ -1306,22 +1406,25 @@
             job_names=check.opt_sequence_param(job_names, "job_names", of_type=str),
             partitions_def_data=check.opt_inst_param(
                 partitions_def_data, "partitions_def_data", ExternalPartitionsDefinitionData
             ),
             output_name=check.opt_str_param(output_name, "output_name"),
             output_description=check.opt_str_param(output_description, "output_description"),
             metadata=metadata,
-            group_name=check.opt_str_param(group_name, "group_name"),
+            tags=check.opt_mapping_param(tags, "tags", key_type=str, value_type=str),
+            # Newer code always passes a string group name when constructing these, but we assign
+            # the default here for backcompat.
+            group_name=check.opt_str_param(group_name, "group_name") or DEFAULT_GROUP_NAME,
             freshness_policy=check.opt_inst_param(
                 freshness_policy, "freshness_policy", FreshnessPolicy
             ),
             is_source=check.bool_param(is_source, "is_source"),
             is_observable=check.bool_param(is_observable, "is_observable"),
-            atomic_execution_unit_id=check.opt_str_param(
-                atomic_execution_unit_id, "atomic_execution_unit_id"
+            execution_set_identifier=check.opt_str_param(
+                execution_set_identifier, "execution_set_identifier"
             ),
             required_top_level_resources=check.opt_sequence_param(
                 required_top_level_resources, "required_top_level_resources", of_type=str
             ),
             auto_materialize_policy=check.opt_inst_param(
                 auto_materialize_policy,
                 "auto_materialize_policy",
@@ -1334,14 +1437,22 @@
                 auto_observe_interval_minutes, "auto_observe_interval_minutes"
             ),
             owners=check.opt_sequence_param(owners, "owners", of_type=str),
             execution_type=check.inst_param(execution_type, "execution_type", AssetExecutionType),
         )
 
     @property
+    def is_materializable(self) -> bool:
+        return self.execution_type == AssetExecutionType.MATERIALIZATION
+
+    @property
+    def is_external(self) -> bool:
+        return self.execution_type != AssetExecutionType.MATERIALIZATION
+
+    @property
     def is_executable(self) -> bool:
         return self.execution_type != AssetExecutionType.UNEXECUTABLE
 
 
 ResourceJobUsageMap = Dict[str, List[ResourceJobUsageEntry]]
 
 
@@ -1397,23 +1508,25 @@
         job_datas = None
         job_refs = sorted(
             list(map(external_job_ref_from_def, jobs)),
             key=lambda pd: pd.name,
         )
     else:
         job_datas = sorted(
-            list(map(external_job_data_from_def, jobs)),
+            list(
+                map(lambda job: external_job_data_from_def(job, include_parent_snapshot=True), jobs)
+            ),
             key=lambda pd: pd.name,
         )
         job_refs = None
 
     resource_datas = repository_def.get_top_level_resources()
     asset_graph = external_asset_nodes_from_defs(
         jobs,
-        assets_defs_by_key=repository_def.assets_defs_by_key,
+        repository_def.asset_graph,
     )
 
     nested_resource_map = _get_nested_resources_map(
         resource_datas, repository_def.get_resource_key_mapping()
     )
     inverted_nested_resources_map: Dict[str, Dict[str, str]] = defaultdict(dict)
     for resource_key, nested_resources in nested_resource_map.items():
@@ -1441,33 +1554,31 @@
                 resource_sensor_usage_map[resource_key].append(sensor.name)
 
     resource_job_usage_map: ResourceJobUsageMap = _get_resource_job_usage(jobs)
 
     return ExternalRepositoryData(
         name=repository_def.name,
         external_schedule_datas=sorted(
-            list(map(external_schedule_data_from_def, repository_def.schedule_defs)),
+            [ScheduleSnap.from_def(schedule_def) for schedule_def in repository_def.schedule_defs],
             key=lambda sd: sd.name,
         ),
-        # `PartitionSetDefinition` has been deleted, so we now construct `ExternalPartitonSetData`
+        # `PartitionSetDefinition` has been deleted, so we now construct `PartitionSetSnap`
         # from jobs instead of going through the intermediary `PartitionSetDefinition`. Eventually
-        # we will remove `ExternalPartitionSetData` as well.
+        # we will remove `PartitionSetSnap` as well.
         external_partition_set_datas=sorted(
-            filter(
-                None,
-                [
-                    external_partition_set_data_from_def(job_def)
-                    for job_def in repository_def.get_all_jobs()
-                ],
-            ),
-            key=lambda psd: psd.name,
+            [
+                PartitionSetSnap.from_job_def(job_def)
+                for job_def in repository_def.get_all_jobs()
+                if job_def.partitions_def is not None
+            ],
+            key=lambda pss: pss.name,
         ),
         external_sensor_datas=sorted(
             [
-                external_sensor_data_from_def(sensor_def, repository_def)
+                SensorSnap.from_def(sensor_def, repository_def)
                 for sensor_def in repository_def.sensor_defs
             ],
             key=lambda sd: sd.name,
         ),
         external_asset_graph_data=asset_graph,
         external_job_datas=job_datas,
         external_job_refs=job_refs,
@@ -1498,290 +1609,193 @@
         },
     )
 
 
 def external_asset_checks_from_defs(
     job_defs: Sequence[JobDefinition],
 ) -> Sequence[ExternalAssetCheck]:
-    nodes_by_check_key: Dict[
-        AssetCheckKey, List[Union[AssetsDefinition, AssetChecksDefinition]]
-    ] = {}
+    nodes_by_check_key: Dict[AssetCheckKey, List[AssetsDefinition]] = {}
     job_names_by_check_key: Dict[AssetCheckKey, List[str]] = {}
 
     for job_def in job_defs:
         asset_layer = job_def.asset_layer
-        for asset_check_def in asset_layer.asset_checks_defs:
-            for spec in asset_check_def.specs:
-                nodes_by_check_key.setdefault(spec.key, []).append(asset_check_def)
-                job_names_by_check_key.setdefault(spec.key, []).append(job_def.name)
         for asset_def in asset_layer.assets_defs_by_node_handle.values():
             for spec in asset_def.check_specs:
                 nodes_by_check_key.setdefault(spec.key, []).append(asset_def)
                 job_names_by_check_key.setdefault(spec.key, []).append(job_def.name)
 
     external_checks = []
     for check_key, nodes in nodes_by_check_key.items():
         first_node = nodes[0]
         # The same check may appear multiple times in different jobs, but it should come from the
         # same definition.
-        if isinstance(first_node, AssetChecksDefinition):
-            check.is_list(
-                nodes,
-                of_type=AssetChecksDefinition,
-                additional_message=f"Check {check_key} is redefined in an AssetsDefinition and an AssetChecksDefinition",
-            )
-            atomic_execution_unit_id = None
-        elif isinstance(first_node, AssetsDefinition):
-            check.is_list(
-                nodes,
-                of_type=AssetsDefinition,
-                additional_message=f"Check {check_key} is redefined in an AssetsDefinition and an AssetChecksDefinition",
-            )
+        check.is_list(
+            nodes,
+            of_type=AssetsDefinition,
+            additional_message=f"Check {check_key} is redefined in an AssetsDefinition and an AssetChecksDefinition",
+        )
 
-            # Executing individual checks isn't supported in graph assets
-            if isinstance(first_node.node_def, GraphDefinition):
-                atomic_execution_unit_id = first_node.unique_id
-            else:
-                atomic_execution_unit_id = (
-                    first_node.unique_id if not first_node.can_subset else None
-                )
+        # Executing individual checks isn't supported in graph assets
+        if isinstance(first_node.node_def, GraphDefinition):
+            execution_set_identifier = first_node.unique_id
         else:
-            check.failed(f"Unexpected node type {first_node}")
+            execution_set_identifier = first_node.unique_id if not first_node.can_subset else None
 
         spec = first_node.get_spec_for_check_key(check_key)
         external_checks.append(
             ExternalAssetCheck(
                 name=check_key.name,
                 asset_key=check_key.asset_key,
                 description=spec.description,
-                atomic_execution_unit_id=atomic_execution_unit_id,
+                execution_set_identifier=execution_set_identifier,
                 job_names=job_names_by_check_key[check_key],
             )
         )
 
     return sorted(external_checks, key=lambda check: (check.asset_key, check.name))
 
 
 def external_asset_nodes_from_defs(
     job_defs: Sequence[JobDefinition],
-    assets_defs_by_key: Mapping[AssetKey, AssetsDefinition],
+    asset_graph: AssetGraph,
 ) -> Sequence[ExternalAssetNode]:
-    node_defs_by_asset_key: Dict[AssetKey, List[Tuple[NodeOutputHandle, JobDefinition]]] = (
-        defaultdict(list)
-    )
-    asset_info_by_asset_key: Dict[AssetKey, AssetOutputInfo] = dict()
-    freshness_policy_by_asset_key: Dict[AssetKey, FreshnessPolicy] = dict()
-    metadata_by_asset_key: Dict[AssetKey, RawMetadataMapping] = dict()
-    auto_materialize_policy_by_asset_key: Dict[AssetKey, AutoMaterializePolicy] = dict()
-    backfill_policy_by_asset_key: Dict[AssetKey, Optional[BackfillPolicy]] = dict()
-
-    deps: Dict[AssetKey, Dict[AssetKey, ExternalAssetDependency]] = defaultdict(dict)
-    dep_by: Dict[AssetKey, Dict[AssetKey, ExternalAssetDependedBy]] = defaultdict(dict)
-    all_upstream_asset_keys: Set[AssetKey] = set()
-    op_names_by_asset_key: Dict[AssetKey, Sequence[str]] = {}
-    code_version_by_asset_key: Dict[AssetKey, Optional[str]] = dict()
-    group_name_by_asset_key: Dict[AssetKey, str] = {}
-    descriptions_by_asset_key: Dict[AssetKey, str] = {}
-    atomic_execution_unit_ids_by_key: Dict[Union[AssetKey, AssetCheckKey], str] = {}
-    owners_by_asset_key: Dict[AssetKey, Sequence[AssetOwner]] = {}
-    execution_types_by_asset_key: Dict[AssetKey, AssetExecutionType] = {}
-    is_observable_by_key: Dict[AssetKey, bool] = {}
-    auto_observe_interval_minutes_by_key: Dict[AssetKey, Optional[Union[int, float]]] = {}
-
+    # First iterate over all job defs to identify a "primary node" for each materializable asset
+    # key. This is the node that will be used to populate the ExternalAssetNode. We need to identify
+    # a primary node because the same asset can be materialized as part of multiple jobs.
+    primary_node_pairs_by_asset_key: Dict[AssetKey, Tuple[NodeOutputHandle, JobDefinition]] = {}
+    job_defs_by_asset_key: Dict[AssetKey, List[JobDefinition]] = {}
     for job_def in job_defs:
         asset_layer = job_def.asset_layer
         asset_info_by_node_output = asset_layer.asset_info_by_node_output_handle
-
         for node_output_handle, asset_info in asset_info_by_node_output.items():
+            asset_key = asset_info.key
             if not asset_info.is_required:
                 continue
-            output_key = asset_info.key
-            if output_key not in op_names_by_asset_key:
-                op_names_by_asset_key[output_key] = [
-                    str(handle)
-                    for handle in asset_layer.dependency_node_handles_by_asset_key.get(
-                        output_key, []
-                    )
-                ]
-            code_version_by_asset_key[output_key] = asset_info.code_version
-            upstream_asset_keys = asset_layer.upstream_assets_for_asset(output_key)
-            all_upstream_asset_keys.update(upstream_asset_keys)
-            node_defs_by_asset_key[output_key].append((node_output_handle, job_def))
-            asset_info_by_asset_key[output_key] = asset_info
-            execution_types_by_asset_key[output_key] = asset_layer.execution_type_for_asset(
-                output_key
-            )
-
-            for upstream_key in upstream_asset_keys:
-                partition_mapping = asset_layer.partition_mapping_for_node_input(
-                    node_output_handle.node_handle, upstream_key
-                )
-                deps[output_key][upstream_key] = ExternalAssetDependency(
-                    upstream_asset_key=upstream_key,
-                    partition_mapping=(
-                        partition_mapping
-                        if partition_mapping is None
-                        or isinstance(partition_mapping, get_builtin_partition_mapping_types())
-                        else None
-                    ),
-                )
-                dep_by[upstream_key][output_key] = ExternalAssetDependedBy(
-                    downstream_asset_key=output_key
-                )
-
-        for assets_def in asset_layer.assets_defs_by_key.values():
-            metadata_by_asset_key.update(assets_def.metadata_by_key)
-            freshness_policy_by_asset_key.update(assets_def.freshness_policies_by_key)
-            auto_materialize_policy_by_asset_key.update(assets_def.auto_materialize_policies_by_key)
-            backfill_policy_by_asset_key.update(
-                {key: assets_def.backfill_policy for key in assets_def.keys}
+            if asset_key not in primary_node_pairs_by_asset_key:
+                primary_node_pairs_by_asset_key[asset_key] = (node_output_handle, job_def)
+            job_defs_by_asset_key.setdefault(asset_key, []).append(job_def)
+
+    # Build index of execution set identifiers. Only assets that are part of non-subsettable assets
+    # have a defined execution set identifier.
+    execution_set_identifiers_by_asset_key: Dict[AssetKey, str] = {}
+    for assets_def in asset_graph.assets_defs:
+        if (len(assets_def.keys) > 1 or assets_def.check_keys) and not assets_def.can_subset:
+            execution_set_identifiers_by_asset_key.update(
+                {k: assets_def.unique_id for k in assets_def.keys}
+            )
+
+    external_asset_nodes: List[ExternalAssetNode] = []
+    for key in sorted(asset_graph.all_asset_keys):
+        asset_node = asset_graph.get(key)
+
+        # Materializable assets (which are always part of at least one job, due to asset base jobs)
+        # have various fields related to their op/output/jobs etc defined. External assets have null
+        # values for all these fields.
+        if key in primary_node_pairs_by_asset_key:
+            output_handle, job_def = primary_node_pairs_by_asset_key[key]
+
+            root_node_handle = output_handle.node_handle
+            while True:
+                if root_node_handle.parent is None:
+                    break
+                root_node_handle = root_node_handle.parent
+            node_def = job_def.graph.get_node(output_handle.node_handle).definition
+            node_handles = job_def.asset_layer.dependency_node_handles_by_asset_key.get(key, [])
+
+            # graph_name is only set for assets that are produced by nested ops.
+            graph_name = (
+                root_node_handle.name if root_node_handle != output_handle.node_handle else None
+            )
+            op_names = sorted([str(handle) for handle in node_handles])
+            op_name = graph_name or next(iter(op_names), None) or node_def.name
+            job_names = sorted([jd.name for jd in job_defs_by_asset_key[key]])
+            compute_kind = node_def.tags.get("kind")
+            node_definition_name = node_def.name
+
+            # Confusingly, the `name` field sometimes mismatches the `name` field on the
+            # OutputDefinition. We need to fix this.
+            output_name = node_def.output_def_named(output_handle.output_name).name
+            required_top_level_resources = (
+                sorted(node_def.required_resource_keys)
+                if isinstance(node_def, OpDefinition)
+                else []
             )
-            descriptions_by_asset_key.update(assets_def.descriptions_by_key)
-            owners_by_asset_key.update(assets_def.owners_by_key)
-            is_observable_by_key.update({key: assets_def.is_observable for key in assets_def.keys})
-            auto_observe_interval_minutes_by_key.update(
-                {key: assets_def.auto_observe_interval_minutes for key in assets_def.keys}
-            )
-            if len(assets_def.keys) > 1 and not assets_def.can_subset:
-                atomic_execution_unit_id = assets_def.unique_id
-
-                for asset_key in assets_def.keys:
-                    atomic_execution_unit_ids_by_key[asset_key] = atomic_execution_unit_id
-            if len(assets_def.keys) == 1 and assets_def.check_keys and not assets_def.can_subset:
-                atomic_execution_unit_ids_by_key[assets_def.key] = assets_def.unique_id
-
-        group_name_by_asset_key.update(asset_layer.group_names_by_assets())
-
-    asset_nodes: List[ExternalAssetNode] = []
-
-    for asset_key, node_tuple_list in node_defs_by_asset_key.items():
-        node_output_handle, job_def = node_tuple_list[0]
-
-        node_def = job_def.graph.get_node(node_output_handle.node_handle).definition
-        output_def = node_def.output_def_named(node_output_handle.output_name)
-
-        asset_info = asset_info_by_asset_key[asset_key]
-
-        required_top_level_resources: List[str] = []
-        if isinstance(node_def, OpDefinition):
-            required_top_level_resources = list(node_def.required_resource_keys)
-
-        asset_metadata = (
-            normalize_metadata(
-                metadata_by_asset_key[asset_key],
-                allow_invalid=True,
-            )
-            if asset_key in metadata_by_asset_key
-            else output_def.metadata
-        )
-
-        job_names = [job_def.name for _, job_def in node_tuple_list]
-
-        partitions_def_data: Optional[ExternalPartitionsDefinitionData] = None
 
-        partitions_def = asset_info.partitions_def
-        if partitions_def:
-            partitions_def_data = external_partitions_definition_from_def(partitions_def)
-
-        # if the asset is produced by an op at the top level of the graph, graph_name should be None
-        graph_name = None
-        node_handle = node_output_handle.node_handle
-        while node_handle.parent:
-            node_handle = node_handle.parent
-            graph_name = node_handle.name
+        else:
+            graph_name = None
+            op_names = []
+            op_name = None
+            job_names = []
+            compute_kind = None
+            node_definition_name = None
+            output_name = None
+            required_top_level_resources = []
+
+        # Partition mappings are only exposed on the ExternalAssetNode if at least one asset is
+        # partitioned and the partition mapping is one of the builtin types.
+        partition_mappings: Dict[AssetKey, Optional[PartitionMapping]] = {}
+        builtin_partition_mapping_types = get_builtin_partition_mapping_types()
+        for pk in asset_node.parent_keys:
+            partition_mapping = asset_graph.get_partition_mapping(key, pk)
+            if (asset_node.partitions_def or asset_graph.get(pk).partitions_def) and isinstance(
+                partition_mapping, builtin_partition_mapping_types
+            ):
+                partition_mappings[pk] = partition_mapping
 
-        asset_nodes.append(
+        external_asset_nodes.append(
             ExternalAssetNode(
-                asset_key=asset_key,
-                dependencies=list(deps[asset_key].values()),
-                depended_by=list(dep_by[asset_key].values()),
-                execution_type=execution_types_by_asset_key[asset_key],
-                compute_kind=node_def.tags.get("kind"),
-                # backcompat
-                op_name=graph_name
-                or next(iter(op_names_by_asset_key[asset_key]), None)
-                or node_def.name,
+                asset_key=key,
+                dependencies=[
+                    ExternalAssetDependency(
+                        upstream_asset_key=pk, partition_mapping=partition_mappings.get(pk)
+                    )
+                    for pk in sorted(asset_node.parent_keys)
+                ],
+                depended_by=[ExternalAssetDependedBy(k) for k in sorted(asset_node.child_keys)],
+                execution_type=asset_node.execution_type,
+                compute_kind=compute_kind,
+                op_name=op_name,
+                op_names=op_names,
+                code_version=asset_node.code_version,
+                node_definition_name=node_definition_name,
                 graph_name=graph_name,
-                op_names=op_names_by_asset_key[asset_key],
-                code_version=code_version_by_asset_key.get(asset_key),
-                op_description=descriptions_by_asset_key.get(asset_key),
-                node_definition_name=node_def.name,
+                op_description=asset_node.description,
                 job_names=job_names,
-                partitions_def_data=partitions_def_data,
-                output_name=output_def.name,
-                metadata=asset_metadata,
-                is_source=execution_types_by_asset_key.get(asset_key)
-                != AssetExecutionType.MATERIALIZATION,
-                is_observable=is_observable_by_key.get(asset_key, False),
-                auto_observe_interval_minutes=auto_observe_interval_minutes_by_key.get(asset_key),
-                # assets defined by Out(asset_key="k") do not have any group
-                # name specified we default to DEFAULT_GROUP_NAME here to ensure
-                # such assets are part of the default group
-                group_name=group_name_by_asset_key.get(asset_key, DEFAULT_GROUP_NAME),
-                freshness_policy=freshness_policy_by_asset_key.get(asset_key),
-                auto_materialize_policy=auto_materialize_policy_by_asset_key.get(asset_key),
-                backfill_policy=backfill_policy_by_asset_key.get(asset_key),
-                atomic_execution_unit_id=atomic_execution_unit_ids_by_key.get(asset_key),
+                partitions_def_data=(
+                    external_partitions_definition_from_def(asset_node.partitions_def)
+                    if asset_node.partitions_def
+                    else None
+                ),
+                output_name=output_name,
+                metadata=asset_node.metadata,
+                tags=asset_node.tags,
+                group_name=asset_node.group_name,
+                freshness_policy=asset_node.freshness_policy,
+                is_source=asset_node.is_external,
+                is_observable=asset_node.is_observable,
+                execution_set_identifier=execution_set_identifiers_by_asset_key.get(key),
                 required_top_level_resources=required_top_level_resources,
-                owners=[
-                    owner.email if isinstance(owner, UserAssetOwner) else owner.team
-                    for owner in owners_by_asset_key.get(asset_key, [])
-                ],
+                auto_materialize_policy=asset_node.auto_materialize_policy,
+                backfill_policy=asset_node.backfill_policy,
+                auto_observe_interval_minutes=asset_node.auto_observe_interval_minutes,
+                owners=asset_node.owners,
             )
         )
 
-    # Ensure any external assets that are have no nodes in any job are included in the asset graph
-    for asset in assets_defs_by_key.values():
-        for key in [key for key in asset.keys if key not in node_defs_by_asset_key]:
-            # This is in place to preserve an implicit behavior in the Dagster UI where stub
-            # dependencies were rendered as if they weren't part of the default asset group.
-            group_name = (
-                None
-                if asset.is_auto_created_stub
-                else group_name_by_asset_key.get(key, DEFAULT_GROUP_NAME)
-            )
-
-            asset_nodes.append(
-                ExternalAssetNode(
-                    asset_key=key,
-                    dependencies=list(deps[key].values()),
-                    depended_by=list(dep_by[key].values()),
-                    execution_type=asset.execution_type,
-                    job_names=[],
-                    op_description=asset.descriptions_by_key.get(key),
-                    metadata=asset.metadata_by_key.get(key),
-                    group_name=group_name,
-                    is_source=True,
-                    is_observable=asset.is_observable,
-                    auto_observe_interval_minutes=asset.auto_observe_interval_minutes,
-                    partitions_def_data=(
-                        external_partitions_definition_from_def(asset.partitions_def)
-                        if asset.partitions_def
-                        else None
-                    ),
-                    freshness_policy=asset.freshness_policies_by_key.get(key),
-                )
-            )
-
-    defined = set()
-    for node in asset_nodes:
-        if node.asset_key in defined:
-            check.failed(f"Produced multiple ExternalAssetNodes for key {node.asset_key}")
-        else:
-            defined.add(node.asset_key)
-
-    return asset_nodes
+    return external_asset_nodes
 
 
-def external_job_data_from_def(job_def: JobDefinition) -> ExternalJobData:
+def external_job_data_from_def(
+    job_def: JobDefinition, include_parent_snapshot: bool
+) -> ExternalJobData:
     check.inst_param(job_def, "job_def", JobDefinition)
     return ExternalJobData(
         name=job_def.name,
         job_snapshot=job_def.get_job_snapshot(),
-        parent_job_snapshot=job_def.get_parent_job_snapshot(),
+        parent_job_snapshot=job_def.get_parent_job_snapshot() if include_parent_snapshot else None,
         active_presets=active_presets_from_job_def(job_def),
     )
 
 
 def external_job_ref_from_def(job_def: JobDefinition) -> ExternalJobRef:
     check.inst_param(job_def, "job_def", JobDefinition)
 
@@ -1940,17 +1954,17 @@
         schedules_using=resource_schedule_usage_map.get(name, []),
         sensors_using=resource_sensor_usage_map.get(name, []),
         resource_type=resource_type,
         dagster_maintained=dagster_maintained,
     )
 
 
-def external_schedule_data_from_def(schedule_def: ScheduleDefinition) -> ExternalScheduleData:
+def external_schedule_data_from_def(schedule_def: ScheduleDefinition) -> ScheduleSnap:
     check.inst_param(schedule_def, "schedule_def", ScheduleDefinition)
-    return ExternalScheduleData(
+    return ScheduleSnap(
         name=schedule_def.name,
         cron_schedule=schedule_def.cron_schedule,
         job_name=schedule_def.job_name,
         op_selection=schedule_def._target.op_selection,  # noqa: SLF001
         mode=DEFAULT_MODE_NAME,
         environment_vars=schedule_def.environment_vars,
         partition_set_name=None,
@@ -2030,15 +2044,15 @@
             "Dagster does not support dynamic partitions definitions without a name parameter."
         )
     return ExternalDynamicPartitionsDefinitionData(name=partitions_def.name)
 
 
 def external_partition_set_data_from_def(
     job_def: JobDefinition,
-) -> Optional[ExternalPartitionSetData]:
+) -> Optional[PartitionSetSnap]:
     check.inst_param(job_def, "job_def", JobDefinition)
 
     partitions_def = job_def.partitions_def
     if partitions_def is None:
         return None
 
     partitions_def_data: Optional[ExternalPartitionsDefinitionData] = None
@@ -2051,15 +2065,15 @@
     ):
         partitions_def_data = external_dynamic_partitions_definition_from_def(partitions_def)
     elif isinstance(partitions_def, MultiPartitionsDefinition):
         partitions_def_data = external_multi_partitions_definition_from_def(partitions_def)
     else:
         partitions_def_data = None
 
-    return ExternalPartitionSetData(
+    return PartitionSetSnap(
         name=external_partition_set_name_for_job_name(job_def.name),
         job_name=job_def.name,
         op_selection=None,
         mode=DEFAULT_MODE_NAME,
         external_partitions_data=partitions_def_data,
     )
 
@@ -2072,64 +2086,14 @@
 
 
 def job_name_for_external_partition_set_name(name: str) -> str:
     job_name_len = len(name) - len(EXTERNAL_PARTITION_SET_NAME_SUFFIX)
     return name[:job_name_len]
 
 
-def external_sensor_data_from_def(
-    sensor_def: SensorDefinition, repository_def: RepositoryDefinition
-) -> ExternalSensorData:
-    first_target = sensor_def.targets[0] if sensor_def.targets else None
-
-    asset_keys = None
-    if isinstance(sensor_def, AssetSensorDefinition):
-        asset_keys = [sensor_def.asset_key]
-
-    if sensor_def.asset_selection is not None:
-        target_dict = {
-            base_asset_job_name: ExternalTargetData(
-                job_name=base_asset_job_name, mode=DEFAULT_MODE_NAME, op_selection=None
-            )
-            for base_asset_job_name in repository_def.get_implicit_asset_job_names()
-        }
-
-        serializable_asset_selection = sensor_def.asset_selection.to_serializable_asset_selection(
-            repository_def.asset_graph
-        )
-    else:
-        target_dict = {
-            target.job_name: ExternalTargetData(
-                job_name=target.job_name,
-                mode=DEFAULT_MODE_NAME,
-                op_selection=target.op_selection,
-            )
-            for target in sensor_def.targets
-        }
-
-        serializable_asset_selection = None
-
-    return ExternalSensorData(
-        name=sensor_def.name,
-        job_name=first_target.job_name if first_target else None,
-        mode=None,
-        op_selection=first_target.op_selection if first_target else None,
-        target_dict=target_dict,
-        min_interval=sensor_def.minimum_interval_seconds,
-        description=sensor_def.description,
-        metadata=ExternalSensorMetadata(asset_keys=asset_keys),
-        default_status=sensor_def.default_status,
-        sensor_type=sensor_def.sensor_type,
-        asset_selection=serializable_asset_selection,
-        run_tags=(
-            sensor_def.run_tags if isinstance(sensor_def, AutoMaterializeSensorDefinition) else None
-        ),
-    )
-
-
 def active_presets_from_job_def(job_def: JobDefinition) -> Sequence[ExternalPresetData]:
     check.inst_param(job_def, "job_def", JobDefinition)
     if job_def.run_config is None:
         return []
     else:
         return [
             ExternalPresetData(
```

### Comparing `dagster-1.6.9/dagster/_core/host_representation/feature_flags.py` & `dagster-1.7.0/dagster/_core/remote_representation/feature_flags.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/host_representation/grpc_server_registry.py` & `dagster-1.7.0/dagster/_core/remote_representation/grpc_server_registry.py`

 * *Files 0% similar despite different names*

```diff
@@ -14,19 +14,19 @@
 )
 
 import pendulum
 from typing_extensions import TypeGuard
 
 import dagster._check as check
 from dagster._core.errors import DagsterUserCodeProcessError, DagsterUserCodeUnreachableError
-from dagster._core.host_representation.origin import (
+from dagster._core.instance import InstanceRef
+from dagster._core.remote_representation.origin import (
     CodeLocationOrigin,
     ManagedGrpcPythonEnvCodeLocationOrigin,
 )
-from dagster._core.instance import InstanceRef
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
 from dagster._grpc.server import GrpcServerProcess
 from dagster._utils.error import SerializableErrorInfo, serializable_error_info_from_exc_info
 
 if TYPE_CHECKING:
     from dagster._grpc.client import DagsterGrpcClient
```

### Comparing `dagster-1.6.9/dagster/_core/host_representation/grpc_server_state_subscriber.py` & `dagster-1.7.0/dagster/_core/remote_representation/grpc_server_state_subscriber.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/host_representation/handle.py` & `dagster-1.7.0/dagster/_core/remote_representation/handle.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,34 +1,34 @@
 from typing import TYPE_CHECKING, Mapping, NamedTuple
 
 import dagster._check as check
 from dagster._core.definitions.selector import JobSubsetSelector
-from dagster._core.host_representation.origin import (
+from dagster._core.origin import RepositoryPythonOrigin
+from dagster._core.remote_representation.origin import (
     CodeLocationOrigin,
-    ExternalRepositoryOrigin,
+    RemoteRepositoryOrigin,
 )
-from dagster._core.origin import RepositoryPythonOrigin
 
 if TYPE_CHECKING:
-    from dagster._core.host_representation.code_location import CodeLocation
+    from dagster._core.remote_representation.code_location import CodeLocation
 
 
 class RepositoryHandle(
     NamedTuple(
         "_RepositoryHandle",
         [
             ("repository_name", str),
             ("code_location_origin", CodeLocationOrigin),
             ("repository_python_origin", RepositoryPythonOrigin),
             ("display_metadata", Mapping[str, str]),
         ],
     )
 ):
     def __new__(cls, repository_name: str, code_location: "CodeLocation"):
-        from dagster._core.host_representation.code_location import CodeLocation
+        from dagster._core.remote_representation.code_location import CodeLocation
 
         check.inst_param(code_location, "code_location", CodeLocation)
         return super(RepositoryHandle, cls).__new__(
             cls,
             check.str_param(repository_name, "repository_name"),
             code_location.origin,
             code_location.get_repository_python_origin(repository_name),
@@ -36,15 +36,15 @@
         )
 
     @property
     def location_name(self) -> str:
         return self.code_location_origin.location_name
 
     def get_external_origin(self):
-        return ExternalRepositoryOrigin(
+        return RemoteRepositoryOrigin(
             self.code_location_origin,
             self.repository_name,
         )
 
     def get_python_origin(self):
         return self.repository_python_origin
```

### Comparing `dagster-1.6.9/dagster/_core/host_representation/historical.py` & `dagster-1.7.0/dagster/_core/remote_representation/historical.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/host_representation/job_index.py` & `dagster-1.7.0/dagster/_core/remote_representation/job_index.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/host_representation/origin.py` & `dagster-1.7.0/dagster/_core/remote_representation/origin.py`

 * *Files 5% similar despite different names*

```diff
@@ -27,20 +27,20 @@
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
 from dagster._serdes import (
     create_snapshot_id,
     whitelist_for_serdes,
 )
 
 if TYPE_CHECKING:
-    from dagster._core.host_representation.code_location import (
+    from dagster._core.instance import DagsterInstance
+    from dagster._core.remote_representation.code_location import (
         CodeLocation,
         GrpcServerCodeLocation,
         InProcessCodeLocation,
     )
-    from dagster._core.instance import DagsterInstance
     from dagster._grpc.client import DagsterGrpcClient
 
 # This is a hard-coded name for the special "in-process" location.
 # This is typically only used for test, although we may allow
 # users to load user code into a host process as well. We want
 # to encourage the user code to be in user processes as much
 # as possible since that it how this system will be used in prod.
@@ -195,15 +195,15 @@
     def is_reload_supported(self) -> bool:
         return False
 
     def get_display_metadata(self) -> Mapping[str, Any]:
         return {}
 
     def create_location(self, instance: "DagsterInstance") -> "InProcessCodeLocation":
-        from dagster._core.host_representation.code_location import (
+        from dagster._core.remote_representation.code_location import (
             InProcessCodeLocation,
         )
 
         return InProcessCodeLocation(self, instance=instance)
 
     def reload_location(self, instance: "DagsterInstance") -> "InProcessCodeLocation":
         raise NotImplementedError
@@ -343,15 +343,15 @@
             "host": self.host,
             "port": str(self.port) if self.port else None,
             "socket": self.socket,
         }
         return {key: value for key, value in metadata.items() if value is not None}
 
     def reload_location(self, instance: "DagsterInstance") -> "GrpcServerCodeLocation":
-        from dagster._core.host_representation.code_location import (
+        from dagster._core.remote_representation.code_location import (
             GrpcServerCodeLocation,
         )
 
         try:
             self.create_client().reload_code(timeout=instance.code_server_reload_timeout)
         except Exception as e:
             # Handle case when this is called against `dagster api grpc` servers that don't have this API method implemented
@@ -362,15 +362,15 @@
                 pass
             else:
                 raise
 
         return GrpcServerCodeLocation(self, instance=instance)
 
     def create_location(self, instance: "DagsterInstance") -> "GrpcServerCodeLocation":
-        from dagster._core.host_representation.code_location import (
+        from dagster._core.remote_representation.code_location import (
             GrpcServerCodeLocation,
         )
 
         return GrpcServerCodeLocation(self, instance=instance)
 
     def create_client(self) -> "DagsterGrpcClient":
         from dagster._grpc.client import DagsterGrpcClient
@@ -391,27 +391,30 @@
             self.create_client().shutdown_server()
         except DagsterUserCodeUnreachableError:
             # Server already shutdown
             pass
 
 
 # Different storage field name for backcompat
-@whitelist_for_serdes(storage_field_names={"code_location_origin": "repository_location_origin"})
-class ExternalRepositoryOrigin(
+@whitelist_for_serdes(
+    storage_name="ExternalRepositoryOrigin",
+    storage_field_names={"code_location_origin": "repository_location_origin"},
+)
+class RemoteRepositoryOrigin(
     NamedTuple(
         "_ExternalRepositoryOrigin",
         [("code_location_origin", CodeLocationOrigin), ("repository_name", str)],
     )
 ):
     """Serializable representation of an ExternalRepository that can be used to
     uniquely it or reload it in across process boundaries.
     """
 
     def __new__(cls, code_location_origin: CodeLocationOrigin, repository_name: str):
-        return super(ExternalRepositoryOrigin, cls).__new__(
+        return super(RemoteRepositoryOrigin, cls).__new__(
             cls,
             check.inst_param(code_location_origin, "code_location_origin", CodeLocationOrigin),
             check.str_param(repository_name, "repository_name"),
         )
 
     def get_id(self) -> str:
         return create_snapshot_id(self)
@@ -420,125 +423,135 @@
         return create_snapshot_id(
             RepositorySelector(self.code_location_origin.location_name, self.repository_name)
         )
 
     def get_label(self) -> str:
         return f"{self.repository_name}@{self.code_location_origin.location_name}"
 
-    def get_job_origin(self, job_name: str) -> "ExternalJobOrigin":
-        return ExternalJobOrigin(self, job_name)
+    def get_job_origin(self, job_name: str) -> "RemoteJobOrigin":
+        return RemoteJobOrigin(self, job_name)
 
-    def get_instigator_origin(self, instigator_name: str) -> "ExternalInstigatorOrigin":
-        return ExternalInstigatorOrigin(self, instigator_name)
+    def get_instigator_origin(self, instigator_name: str) -> "RemoteInstigatorOrigin":
+        return RemoteInstigatorOrigin(self, instigator_name)
 
-    def get_partition_set_origin(self, partition_set_name: str) -> "ExternalPartitionSetOrigin":
-        return ExternalPartitionSetOrigin(self, partition_set_name)
+    def get_partition_set_origin(self, partition_set_name: str) -> "RemotePartitionSetOrigin":
+        return RemotePartitionSetOrigin(self, partition_set_name)
 
 
 @whitelist_for_serdes(
-    storage_name="ExternalPipelineOrigin", storage_field_names={"job_name": "pipeline_name"}
+    storage_name="ExternalPipelineOrigin",
+    storage_field_names={
+        "repository_origin": "external_repository_origin",
+        "job_name": "pipeline_name",
+    },
 )
-class ExternalJobOrigin(
+class RemoteJobOrigin(
     NamedTuple(
-        "_ExternalJobOrigin",
-        [("external_repository_origin", ExternalRepositoryOrigin), ("job_name", str)],
+        "_RemoteJobOrigin",
+        [("repository_origin", RemoteRepositoryOrigin), ("job_name", str)],
     )
 ):
-    """Serializable representation of an ExternalPipeline that can be used to
+    """Serializable representation of an ExternalJob that can be used to
     uniquely it or reload it in across process boundaries.
     """
 
-    def __new__(cls, external_repository_origin: ExternalRepositoryOrigin, job_name: str):
-        return super(ExternalJobOrigin, cls).__new__(
+    def __new__(cls, repository_origin: RemoteRepositoryOrigin, job_name: str):
+        return super(RemoteJobOrigin, cls).__new__(
             cls,
             check.inst_param(
-                external_repository_origin,
-                "external_repository_origin",
-                ExternalRepositoryOrigin,
+                repository_origin,
+                "repository_origin",
+                RemoteRepositoryOrigin,
             ),
             check.str_param(job_name, "job_name"),
         )
 
     def get_id(self) -> str:
         return create_snapshot_id(self)
 
     @property
     def location_name(self) -> str:
-        return self.external_repository_origin.code_location_origin.location_name
+        return self.repository_origin.code_location_origin.location_name
 
 
 @whitelist_for_serdes(
     # ExternalInstigatorOrigin used to be called ExternalJobOrigin, before the concept of "job" was
     # introduced in 0.12.0. For clarity, we changed the name of the namedtuple with `0.14.0`, but we
     # need to maintain the serialized format in order to avoid changing the origin id that is stored in
     # our schedule storage.  This registers the serialized ExternalJobOrigin named tuple class to be
     # deserialized as an ExternalInstigatorOrigin, using its corresponding serializer for serdes.
     storage_name="ExternalJobOrigin",
-    storage_field_names={"instigator_name": "job_name"},
+    storage_field_names={
+        "repository_origin": "external_repository_origin",
+        "instigator_name": "job_name",
+    },
 )
-class ExternalInstigatorOrigin(
+class RemoteInstigatorOrigin(
     NamedTuple(
-        "_ExternalInstigatorOrigin",
-        [("external_repository_origin", ExternalRepositoryOrigin), ("instigator_name", str)],
+        "_RemoteInstigatorOrigin",
+        [("repository_origin", RemoteRepositoryOrigin), ("instigator_name", str)],
     )
 ):
     """Serializable representation of an ExternalJob that can be used to
     uniquely it or reload it in across process boundaries.
     """
 
-    def __new__(cls, external_repository_origin: ExternalRepositoryOrigin, instigator_name: str):
-        return super(ExternalInstigatorOrigin, cls).__new__(
+    def __new__(cls, repository_origin: RemoteRepositoryOrigin, instigator_name: str):
+        return super(RemoteInstigatorOrigin, cls).__new__(
             cls,
             check.inst_param(
-                external_repository_origin,
-                "external_repository_origin",
-                ExternalRepositoryOrigin,
+                repository_origin,
+                "repository_origin",
+                RemoteRepositoryOrigin,
             ),
             check.str_param(instigator_name, "instigator_name"),
         )
 
     def get_selector(self) -> InstigatorSelector:
         return InstigatorSelector(
-            self.external_repository_origin.code_location_origin.location_name,
-            self.external_repository_origin.repository_name,
+            self.repository_origin.code_location_origin.location_name,
+            self.repository_origin.repository_name,
             self.instigator_name,
         )
 
     def get_id(self) -> str:
         return create_snapshot_id(self)
 
 
-@whitelist_for_serdes
-class ExternalPartitionSetOrigin(
+@whitelist_for_serdes(
+    storage_name="ExternalPartitionSetOrigin",
+    storage_field_names={"repository_origin": "external_repository_origin"},
+)
+class RemotePartitionSetOrigin(
     NamedTuple(
         "_PartitionSetOrigin",
-        [("external_repository_origin", ExternalRepositoryOrigin), ("partition_set_name", str)],
+        [("repository_origin", RemoteRepositoryOrigin), ("partition_set_name", str)],
     )
 ):
     """Serializable representation of an ExternalPartitionSet that can be used to
     uniquely it or reload it in across process boundaries.
     """
 
-    def __new__(cls, external_repository_origin: ExternalRepositoryOrigin, partition_set_name: str):
-        return super(ExternalPartitionSetOrigin, cls).__new__(
+    def __new__(cls, repository_origin: RemoteRepositoryOrigin, partition_set_name: str):
+        return super(RemotePartitionSetOrigin, cls).__new__(
             cls,
             check.inst_param(
-                external_repository_origin,
-                "external_repository_origin",
-                ExternalRepositoryOrigin,
+                repository_origin,
+                "repository_origin",
+                RemoteRepositoryOrigin,
             ),
             check.str_param(partition_set_name, "partition_set_name"),
         )
 
     def get_id(self) -> str:
         return create_snapshot_id(self)
 
     @property
     def selector(self) -> PartitionSetSelector:
         return PartitionSetSelector(
-            self.external_repository_origin.code_location_origin.location_name,
-            self.external_repository_origin.repository_name,
+            self.repository_origin.code_location_origin.location_name,
+            self.repository_origin.repository_name,
             self.partition_set_name,
         )
 
     def get_selector_id(self) -> str:
         return create_snapshot_id(self.selector)
```

### Comparing `dagster-1.6.9/dagster/_core/host_representation/represented.py` & `dagster-1.7.0/dagster/_core/remote_representation/represented.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/instance/__init__.py` & `dagster-1.7.0/dagster/_core/instance/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,14 +12,15 @@
 from types import TracebackType
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Any,
     Callable,
     Dict,
+    Final,
     Generic,
     Iterable,
     List,
     Mapping,
     Optional,
     Sequence,
     Set,
@@ -68,15 +69,15 @@
     PARTITION_NAME_TAG,
     RESUME_RETRY_TAG,
     ROOT_RUN_ID_TAG,
     RUN_FAILURE_REASON_TAG,
 )
 from dagster._serdes import ConfigurableClass
 from dagster._seven import get_current_datetime_in_utc
-from dagster._utils import PrintFn, traced
+from dagster._utils import PrintFn, is_uuid, traced
 from dagster._utils.error import serializable_error_info_from_exc_info
 from dagster._utils.merger import merge_dicts
 from dagster._utils.warnings import (
     deprecation_warning,
     experimental_warning,
 )
 
@@ -99,14 +100,21 @@
 # Our internal guts can handle empty strings for job name and run id
 # However making these named constants for documentation, to encode where we are making the assumption,
 # and to allow us to change this more easily in the future, provided we are disciplined about
 # actually using this constants.
 RUNLESS_RUN_ID = ""
 RUNLESS_JOB_NAME = ""
 
+# Sets the number of events that will be buffered before being written to the event log. Only
+# applies to explicitly batched events. Currently this defaults to 0, which turns off batching
+# entirely (multiple store_event calls are made instead of store_event_batch). This makes batching
+# opt-in.
+EVENT_BATCH_SIZE: Final = int(os.getenv("DAGSTER_EVENT_BATCH_SIZE", "0"))
+
+
 if TYPE_CHECKING:
     from dagster._core.debug import DebugRunPayload
     from dagster._core.definitions.asset_check_spec import AssetCheckKey
     from dagster._core.definitions.job_definition import (
         JobDefinition,
     )
     from dagster._core.definitions.partition import PartitionsDefinition
@@ -118,31 +126,32 @@
         AssetRecordsFilter,
         EventHandlerFn,
         RunStatusChangeRecordsFilter,
     )
     from dagster._core.events import (
         AssetMaterialization,
         DagsterEvent,
+        DagsterEventBatchMetadata,
         DagsterEventType,
         EngineEventData,
     )
     from dagster._core.events.log import EventLogEntry
     from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
     from dagster._core.execution.plan.plan import ExecutionPlan
     from dagster._core.execution.plan.resume_retry import ReexecutionStrategy
     from dagster._core.execution.stats import RunStepKeyStatsSnapshot
-    from dagster._core.host_representation import (
+    from dagster._core.launcher import RunLauncher
+    from dagster._core.remote_representation import (
         CodeLocation,
         ExternalJob,
-        ExternalJobOrigin,
         ExternalSensor,
         HistoricalJob,
+        RemoteJobOrigin,
     )
-    from dagster._core.host_representation.external import ExternalSchedule
-    from dagster._core.launcher import RunLauncher
+    from dagster._core.remote_representation.external import ExternalSchedule
     from dagster._core.run_coordinator import RunCoordinator
     from dagster._core.scheduler import Scheduler, SchedulerDebugInfo
     from dagster._core.scheduler.instigation import (
         InstigatorState,
         InstigatorStatus,
         InstigatorTick,
         TickData,
@@ -178,14 +187,18 @@
     from dagster._core.workspace.workspace import IWorkspace
     from dagster._daemon.types import DaemonHeartbeat, DaemonStatus
 
 
 DagsterInstanceOverrides: TypeAlias = Mapping[str, Any]
 
 
+def _is_batch_writing_enabled() -> bool:
+    return EVENT_BATCH_SIZE > 0
+
+
 def _check_run_equality(
     pipeline_run: DagsterRun, candidate_run: DagsterRun
 ) -> Mapping[str, Tuple[Any, Any]]:
     field_diff: Dict[str, Tuple[Any, Any]] = {}
     for field in pipeline_run._fields:
         expected_value = getattr(pipeline_run, field)
         candidate_value = getattr(candidate_run, field)
@@ -220,26 +233,29 @@
         self._instance = instance
         super(_EventListenerLogHandler, self).__init__()
 
     def emit(self, record: logging.LogRecord) -> None:
         from dagster._core.events import EngineEventData
         from dagster._core.events.log import StructuredLoggerMessage, construct_event_record
 
+        record_metadata = get_log_record_metadata(record)
         event = construct_event_record(
             StructuredLoggerMessage(
                 name=record.name,
                 message=record.msg,
                 level=record.levelno,
-                meta=get_log_record_metadata(record),
+                meta=record_metadata,
                 record=record,
             )
         )
 
         try:
-            self._instance.handle_new_event(event)
+            self._instance.handle_new_event(
+                event, batch_metadata=record_metadata["dagster_event_batch_metadata"]
+            )
         except Exception as e:
             sys.stderr.write(f"Exception while writing logger call to event log: {e}\n")
             if event.dagster_event:
                 # Swallow user-generated log failures so that the entire step/run doesn't fail, but
                 # raise failures writing system-generated log events since they are the source of
                 # truth for the state of the run
                 raise
@@ -475,14 +491,17 @@
         if self.run_retries_enabled:
             check.invariant(
                 self.event_log_storage.supports_event_consumer_queries(),
                 "Run retries are enabled, but the configured event log storage does not support"
                 " them. Consider switching to Postgres or Mysql.",
             )
 
+        # Used for batched event handling
+        self._event_buffer: Dict[str, List[EventLogEntry]] = defaultdict(list)
+
     # ctors
 
     @public
     @staticmethod
     def ephemeral(
         tempdir: Optional[str] = None,
         preload: Optional[Sequence["DebugRunPayload"]] = None,
@@ -549,25 +568,25 @@
             )
 
         dagster_home_path = os.path.expanduser(dagster_home_path)
 
         if not os.path.isabs(dagster_home_path):
             raise DagsterInvariantViolationError(
                 (
-                    '$DAGSTER_HOME "{}" must be an absolute path. Dagster requires this '
+                    f'$DAGSTER_HOME "{dagster_home_path}" must be an absolute path. Dagster requires this '
                     "environment variable to be set to an existing directory in your filesystem."
-                ).format(dagster_home_path)
+                )
             )
 
         if not (os.path.exists(dagster_home_path) and os.path.isdir(dagster_home_path)):
             raise DagsterInvariantViolationError(
                 (
-                    '$DAGSTER_HOME "{}" is not a directory or does not exist. Dagster requires this'
+                    f'$DAGSTER_HOME "{dagster_home_path}" is not a directory or does not exist. Dagster requires this'
                     " environment variable to be set to an existing directory in your filesystem"
-                ).format(dagster_home_path)
+                )
             )
 
         return DagsterInstance.from_config(dagster_home_path)
 
     @public
     @staticmethod
     def local_temp(
@@ -1054,15 +1073,15 @@
 
     @traced
     def has_snapshot(self, snapshot_id: str) -> bool:
         return self._run_storage.has_snapshot(snapshot_id)
 
     @traced
     def get_historical_job(self, snapshot_id: str) -> "HistoricalJob":
-        from dagster._core.host_representation import HistoricalJob
+        from dagster._core.remote_representation import HistoricalJob
 
         snapshot = self._run_storage.get_job_snapshot(snapshot_id)
         parent_snapshot = (
             self._run_storage.get_job_snapshot(snapshot.lineage_snapshot.parent_snapshot_id)
             if snapshot.lineage_snapshot
             else None
         )
@@ -1085,15 +1104,15 @@
         self, run_id: str, step_keys: Optional[Sequence[str]] = None
     ) -> Sequence["RunStepKeyStatsSnapshot"]:
         return self._event_storage.get_step_stats_for_run(run_id, step_keys)
 
     @traced
     def get_run_tags(
         self,
-        tag_keys: Optional[Sequence[str]] = None,
+        tag_keys: Sequence[str],
         value_prefix: Optional[str] = None,
         limit: Optional[int] = None,
     ) -> Sequence[Tuple[str, Set[str]]]:
         return self._run_storage.get_run_tags(
             tag_keys=tag_keys, value_prefix=value_prefix, limit=limit
         )
 
@@ -1114,15 +1133,15 @@
         resolved_op_selection: Optional[AbstractSet[str]] = None,
         status: Optional[Union[DagsterRunStatus, str]] = None,
         tags: Optional[Mapping[str, str]] = None,
         root_run_id: Optional[str] = None,
         parent_run_id: Optional[str] = None,
         op_selection: Optional[Sequence[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
-        external_job_origin: Optional["ExternalJobOrigin"] = None,
+        external_job_origin: Optional["RemoteJobOrigin"] = None,
         job_code_origin: Optional[JobPythonOrigin] = None,
         repository_load_data: Optional["RepositoryLoadData"] = None,
     ) -> DagsterRun:
         from dagster._core.definitions.job_definition import JobDefinition
         from dagster._core.execution.api import create_execution_plan
         from dagster._core.execution.plan.plan import ExecutionPlan
         from dagster._core.snap import snapshot_from_execution_plan
@@ -1197,15 +1216,15 @@
         parent_run_id: Optional[str],
         job_snapshot: Optional["JobSnapshot"],
         execution_plan_snapshot: Optional["ExecutionPlanSnapshot"],
         parent_job_snapshot: Optional["JobSnapshot"],
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
         asset_check_selection: Optional[AbstractSet["AssetCheckKey"]] = None,
         op_selection: Optional[Sequence[str]] = None,
-        external_job_origin: Optional["ExternalJobOrigin"] = None,
+        external_job_origin: Optional["RemoteJobOrigin"] = None,
         job_code_origin: Optional[JobPythonOrigin] = None,
     ) -> DagsterRun:
         # https://github.com/dagster-io/dagster/issues/2403
         if tags and IS_AIRFLOW_INGEST_PIPELINE_STR in tags:
             if AIRFLOW_EXECUTION_DATE_STR not in tags:
                 tags = {
                     **tags,
@@ -1273,28 +1292,24 @@
     ) -> str:
         from dagster._core.snap import JobSnapshot, create_job_snapshot_id
 
         check.inst_param(job_snapshot, "job_snapshot", JobSnapshot)
         check.opt_inst_param(parent_job_snapshot, "parent_job_snapshot", JobSnapshot)
 
         if job_snapshot.lineage_snapshot:
-            if not self._run_storage.has_job_snapshot(
-                job_snapshot.lineage_snapshot.parent_snapshot_id
-            ):
-                check.invariant(
-                    create_job_snapshot_id(parent_job_snapshot)  # type: ignore  # (possible none)
-                    == job_snapshot.lineage_snapshot.parent_snapshot_id,
-                    "Parent pipeline snapshot id out of sync with passed parent pipeline snapshot",
-                )
+            parent_snapshot_id = create_job_snapshot_id(check.not_none(parent_job_snapshot))
 
-                returned_job_snapshot_id = self._run_storage.add_job_snapshot(
-                    parent_job_snapshot  # type: ignore  # (possible none)
+            if job_snapshot.lineage_snapshot.parent_snapshot_id != parent_snapshot_id:
+                warnings.warn(
+                    f"Stored parent snapshot ID {parent_snapshot_id} did not match the parent snapshot ID {job_snapshot.lineage_snapshot.parent_snapshot_id} on the subsetted job"
                 )
-                check.invariant(
-                    job_snapshot.lineage_snapshot.parent_snapshot_id == returned_job_snapshot_id
+
+            if not self._run_storage.has_job_snapshot(parent_snapshot_id):
+                self._run_storage.add_job_snapshot(
+                    check.not_none(parent_job_snapshot), parent_snapshot_id
                 )
 
         job_snapshot_id = create_job_snapshot_id(job_snapshot)
         if not self._run_storage.has_job_snapshot(job_snapshot_id):
             returned_job_snapshot_id = self._run_storage.add_job_snapshot(job_snapshot)
             check.invariant(job_snapshot_id == returned_job_snapshot_id)
 
@@ -1462,46 +1477,49 @@
         execution_plan_snapshot: Optional["ExecutionPlanSnapshot"],
         job_snapshot: Optional["JobSnapshot"],
         parent_job_snapshot: Optional["JobSnapshot"],
         asset_selection: Optional[AbstractSet[AssetKey]],
         asset_check_selection: Optional[AbstractSet["AssetCheckKey"]],
         resolved_op_selection: Optional[AbstractSet[str]],
         op_selection: Optional[Sequence[str]],
-        external_job_origin: Optional["ExternalJobOrigin"],
+        external_job_origin: Optional["RemoteJobOrigin"],
         job_code_origin: Optional[JobPythonOrigin],
         asset_job_partitions_def: Optional["PartitionsDefinition"] = None,
     ) -> DagsterRun:
         from dagster._core.definitions.asset_check_spec import AssetCheckKey
-        from dagster._core.definitions.utils import validate_tags
-        from dagster._core.host_representation.origin import ExternalJobOrigin
+        from dagster._core.definitions.utils import normalize_tags
+        from dagster._core.remote_representation.origin import RemoteJobOrigin
         from dagster._core.snap import ExecutionPlanSnapshot, JobSnapshot
 
         check.str_param(job_name, "job_name")
         check.opt_str_param(
             run_id, "run_id"
         )  # will be assigned to make_new_run_id() lower in callstack
         check.opt_mapping_param(run_config, "run_config", key_type=str)
 
         check.opt_inst_param(status, "status", DagsterRunStatus)
         check.opt_mapping_param(tags, "tags", key_type=str)
 
-        validated_tags = validate_tags(tags)
+        validated_tags = normalize_tags(tags, warn_on_deprecated_tags=False).tags
 
         check.opt_str_param(root_run_id, "root_run_id")
         check.opt_str_param(parent_run_id, "parent_run_id")
 
         # If step_keys_to_execute is None, then everything is executed.  In some cases callers
         # are still exploding and sending the full list of step keys even though that is
         # unnecessary.
 
         check.opt_sequence_param(step_keys_to_execute, "step_keys_to_execute")
         check.opt_inst_param(
             execution_plan_snapshot, "execution_plan_snapshot", ExecutionPlanSnapshot
         )
 
+        if run_id and not is_uuid(run_id):
+            check.failed(f"run_id must be a valid UUID. Got {run_id}")
+
         if root_run_id or parent_run_id:
             check.invariant(
                 root_run_id and parent_run_id,
                 "If root_run_id or parent_run_id is passed, this is a re-execution scenario and"
                 " root_run_id and parent_run_id must both be passed.",
             )
 
@@ -1569,15 +1587,15 @@
         #
         # There are cases (notably in _logged_execute_job with Reconstructable jobs)
         # where job_code_origin and is not. In some cloud test cases only
         # external_job_origin is passed But they are almost always passed together.
         # If these are not set the created run will never be able to be relaunched from
         # the information just in the run or in another process.
 
-        check.opt_inst_param(external_job_origin, "external_job_origin", ExternalJobOrigin)
+        check.opt_inst_param(external_job_origin, "external_job_origin", RemoteJobOrigin)
         check.opt_inst_param(job_code_origin, "job_code_origin", JobPythonOrigin)
 
         dagster_run = self._construct_run_with_snapshots(
             job_name=job_name,
             run_id=run_id,  # type: ignore  # (possible none)
             run_config=run_config,
             asset_selection=asset_selection,
@@ -1616,15 +1634,15 @@
         run_config: Optional[Mapping[str, Any]] = None,
         use_parent_run_tags: bool = False,
     ) -> DagsterRun:
         from dagster._core.execution.plan.resume_retry import (
             ReexecutionStrategy,
         )
         from dagster._core.execution.plan.state import KnownExecutionState
-        from dagster._core.host_representation import CodeLocation, ExternalJob
+        from dagster._core.remote_representation import CodeLocation, ExternalJob
 
         check.inst_param(parent_run, "parent_run", DagsterRun)
         check.inst_param(code_location, "code_location", CodeLocation)
         check.inst_param(external_job, "external_job", ExternalJob)
         check.inst_param(strategy, "strategy", ReexecutionStrategy)
         check.opt_mapping_param(extra_tags, "extra_tags", key_type=str)
         check.opt_mapping_param(run_config, "run_config", key_type=str)
@@ -1744,19 +1762,16 @@
         def get_run() -> DagsterRun:
             candidate_run = self.get_run_by_id(dagster_run.run_id)
 
             field_diff = _check_run_equality(dagster_run, candidate_run)  # type: ignore  # (possible none)
 
             if field_diff:
                 raise DagsterRunConflict(
-                    "Found conflicting existing run with same id {run_id}. Runs differ in:"
-                    "\n{field_diff}".format(
-                        run_id=dagster_run.run_id,
-                        field_diff=_format_field_diff(field_diff),
-                    ),
+                    f"Found conflicting existing run with same id {dagster_run.run_id}. Runs differ in:"
+                    f"\n{_format_field_diff(field_diff)}",
                 )
             return candidate_run  # type: ignore  # (possible none)
 
         if self.has_run(dagster_run.run_id):
             return get_run()
 
         try:
@@ -2355,24 +2370,70 @@
         handlers: List[logging.Handler] = [self._get_event_log_handler()]
         handlers.extend(self._get_yaml_python_handlers())
         return handlers
 
     def store_event(self, event: "EventLogEntry") -> None:
         self._event_storage.store_event(event)
 
-    def handle_new_event(self, event: "EventLogEntry") -> None:
-        run_id = event.run_id
+    def handle_new_event(
+        self,
+        event: "EventLogEntry",
+        *,
+        batch_metadata: Optional["DagsterEventBatchMetadata"] = None,
+    ) -> None:
+        """Handle a new event by storing it and notifying subscribers.
 
-        self._event_storage.store_event(event)
+        Events may optionally be sent with `batch_metadata`. If batch writing is enabled, then
+        events sent with `batch_metadata` will not trigger an immediate write. Instead, they will be
+        kept in a batch-specific buffer (identified by `batch_metadata.id`) until either the buffer
+        reaches the EVENT_BATCH_SIZE or the end of the batch is reached (signaled by
+        `batch_metadata.is_end`). When this point is reached, all events in the buffer will be sent
+        to the storage layer in a single batch. If an error occurrs during batch writing, then we
+        fall back to iterative individual event writes.
+
+        Args:
+            event (EventLogEntry): The event to handle.
+            batch_metadata (Optional[DagsterEventBatchMetadata]): Metadata for batch writing.
+        """
+        if batch_metadata is None or not _is_batch_writing_enabled():
+            events = [event]
+        else:
+            batch_id, is_batch_end = batch_metadata.id, batch_metadata.is_end
+            self._event_buffer[batch_id].append(event)
+            if is_batch_end or len(self._event_buffer[batch_id]) == EVENT_BATCH_SIZE:
+                events = self._event_buffer[batch_id]
+                del self._event_buffer[batch_id]
+            else:
+                return
+
+        if len(events) == 1:
+            self._event_storage.store_event(events[0])
+        else:
+            try:
+                self._event_storage.store_event_batch(events)
+
+            # Fall back to storing events one by one if writing a batch fails. We catch a generic
+            # Exception because that is the parent class of the actually received error,
+            # dagster_cloud_cli.core.errors.GraphQLStorageError, which we cannot import here due to
+            # it living in a cloud package.
+            except Exception as e:
+                sys.stderr.write(f"Exception while storing event batch: {e}\n")
+                sys.stderr.write(
+                    "Falling back to storing multiple single-event storage requests...\n"
+                )
+                for event in events:
+                    self._event_storage.store_event(event)
 
-        if event.is_dagster_event and event.get_dagster_event().is_job_event:
-            self._run_storage.handle_run_event(run_id, event.get_dagster_event())
+        for event in events:
+            run_id = event.run_id
+            if event.is_dagster_event and event.get_dagster_event().is_job_event:
+                self._run_storage.handle_run_event(run_id, event.get_dagster_event())
 
-        for sub in self._subscribers[run_id]:
-            sub(event)
+            for sub in self._subscribers[run_id]:
+                sub(event)
 
     def add_event_listener(self, run_id: str, cb) -> None:
         self._subscribers[run_id].append(cb)
 
     def report_engine_event(
         self,
         message: str,
@@ -2527,31 +2588,28 @@
         ``DagsterInstance.create_run()``) *before* this method is called, and
         should be in the ``PipelineRunStatus.NOT_STARTED`` state. They also must have a non-null
         ExternalPipelineOrigin.
 
         Args:
             run_id (str): The id of the run.
         """
-        from dagster._core.host_representation import ExternalJobOrigin
         from dagster._core.run_coordinator import SubmitRunContext
 
         run = self.get_run_by_id(run_id)
         if run is None:
             raise DagsterInvariantViolationError(
                 f"Could not load run {run_id} that was passed to submit_run"
             )
 
-        check.inst(
+        check.not_none(
             run.external_job_origin,
-            ExternalJobOrigin,
             "External pipeline origin must be set for submitted runs",
         )
-        check.inst(
+        check.not_none(
             run.job_code_origin,
-            JobPythonOrigin,
             "Python origin must be set for submitted runs",
         )
 
         try:
             submitted_run = self.run_coordinator.submit_run(
                 SubmitRunContext(run, workspace=workspace)
             )
```

### Comparing `dagster-1.6.9/dagster/_core/instance/config.py` & `dagster-1.7.0/dagster/_core/instance/config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/instance/ref.py` & `dagster-1.7.0/dagster/_core/instance/ref.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/instance_for_test.py` & `dagster-1.7.0/dagster/_core/instance_for_test.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/launcher/base.py` & `dagster-1.7.0/dagster/_core/launcher/base.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/launcher/default_run_launcher.py` & `dagster-1.7.0/dagster/_core/launcher/default_run_launcher.py`

 * *Files 0% similar despite different names*

```diff
@@ -96,30 +96,30 @@
                 DagsterLaunchFailedError(
                     res.message, serializable_error_info=res.serializable_error_info
                 )
             )
 
     def launch_run(self, context: LaunchRunContext) -> None:
         # defer for perf
-        from dagster._core.host_representation.code_location import (
+        from dagster._core.remote_representation.code_location import (
             GrpcServerCodeLocation,
         )
 
         run = context.dagster_run
 
         check.inst_param(run, "run", DagsterRun)
 
         if not context.workspace:
             raise DagsterInvariantViolationError(
                 "DefaultRunLauncher requires a workspace to be included in its LaunchRunContext"
             )
 
         external_job_origin = check.not_none(run.external_job_origin)
         code_location = context.workspace.get_code_location(
-            external_job_origin.external_repository_origin.code_location_origin.location_name
+            external_job_origin.repository_origin.code_location_origin.location_name
         )
 
         check.inst(
             code_location,
             GrpcServerCodeLocation,
             "DefaultRunLauncher: Can't launch runs for pipeline not loaded from a GRPC server",
         )
```

### Comparing `dagster-1.6.9/dagster/_core/launcher/sync_in_memory_run_launcher.py` & `dagster-1.7.0/dagster/_core/launcher/sync_in_memory_run_launcher.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/log_manager.py` & `dagster-1.7.0/dagster/_core/log_manager.py`

 * *Files 13% similar despite different names*

```diff
@@ -16,15 +16,15 @@
 
 import dagster._check as check
 from dagster._core.utils import coerce_valid_log_level, make_new_run_id
 from dagster._utils.log import get_dagster_logger
 
 if TYPE_CHECKING:
     from dagster import DagsterInstance
-    from dagster._core.events import DagsterEvent
+    from dagster._core.events import DagsterEvent, DagsterEventBatchMetadata
     from dagster._core.storage.dagster_run import DagsterRun
 
 # Python's logging system allows you to attach arbitrary values to a log message/record by passing a
 # dictionary as `extra` to a logging method. The keys of extra are "splatted" directly into the
 # `logging.LogRecord` created by this call-- i.e. `foo` will be set as an attribute on the
 # `LogRecord`, not `extra`. The lack of an intervening abstraction between attached data and the
 # `LogRecord` necessitates providing our own. There are only types of data that we attach: (1) a
@@ -42,14 +42,31 @@
     setattr(record, LOG_RECORD_EVENT_ATTR, event)
 
 
 def has_log_record_event(record: logging.LogRecord) -> bool:
     return hasattr(record, LOG_RECORD_EVENT_ATTR)
 
 
+LOG_RECORD_EVENT_BATCH_METADATA_ATTR: Final = "dagster_event_batch_metadata"
+
+
+def get_log_record_event_batch_metadata(record: logging.LogRecord) -> "DagsterEventBatchMetadata":
+    return cast("DagsterEventBatchMetadata", getattr(record, LOG_RECORD_EVENT_BATCH_METADATA_ATTR))
+
+
+def set_log_record_event_batch_metadata(
+    record: logging.LogRecord, event: "DagsterEventBatchMetadata"
+) -> None:
+    setattr(record, LOG_RECORD_EVENT_BATCH_METADATA_ATTR, event)
+
+
+def has_log_record_event_batch_metadata(record: logging.LogRecord) -> bool:
+    return hasattr(record, LOG_RECORD_EVENT_BATCH_METADATA_ATTR)
+
+
 LOG_RECORD_METADATA_ATTR: Final = "dagster_meta"
 
 
 def get_log_record_metadata(record: logging.LogRecord) -> "DagsterLogRecordMetadata":
     return getattr(record, LOG_RECORD_METADATA_ATTR)
 
 
@@ -89,14 +106,15 @@
     job_name: Optional[str]
     job_tags: Mapping[str, str]
     step_key: Optional[str]
     op_name: Optional[str]
     resource_name: Optional[str]
     resource_fn_name: Optional[str]
     dagster_event: Optional["DagsterEvent"]
+    dagster_event_batch_metadata: Optional["DagsterEventBatchMetadata"]
     orig_message: str
     log_message_id: str
     log_timestamp: str
 
 
 def construct_log_record_message(metadata: DagsterLogRecordMetadata) -> str:
     from dagster._core.events import EVENT_TYPE_TO_DISPLAY_STRING
@@ -137,41 +155,45 @@
         if error:
             error_display_string = getattr(data, "error_display_string", error.to_string())
             return f"\n\n{error_display_string}"
     return None
 
 
 def construct_log_record_metadata(
-    handler_metadata: DagsterLogHandlerMetadata, orig_message: str, event: Optional["DagsterEvent"]
+    handler_metadata: DagsterLogHandlerMetadata,
+    orig_message: str,
+    event: Optional["DagsterEvent"],
+    event_batch_metadata: Optional["DagsterEventBatchMetadata"],
 ) -> DagsterLogRecordMetadata:
     step_key = handler_metadata["step_key"] or (event.step_key if event else None)
     timestamp = datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None).isoformat()
     return DagsterLogRecordMetadata(
         run_id=handler_metadata["run_id"],
         job_name=handler_metadata["job_name"],
         job_tags=handler_metadata["job_tags"],
         op_name=handler_metadata["op_name"],
         resource_name=handler_metadata["resource_name"],
         resource_fn_name=handler_metadata["resource_fn_name"],
         orig_message=orig_message,
         log_message_id=make_new_run_id(),
         log_timestamp=timestamp,
         dagster_event=event,
+        dagster_event_batch_metadata=event_batch_metadata,
         step_key=step_key,
     )
 
 
 class DagsterLogHandler(logging.Handler):
     """Internal class used to turn regular logs into Dagster logs by adding Dagster-specific
-    metadata (such as pipeline_name or step_key), as well as reformatting the underlying message.
+    metadata (such as job_name or step_key), as well as reformatting the underlying message.
 
     Note: The `loggers` argument will be populated with the set of @loggers supplied to the current
-    pipeline run. These essentially work as handlers (they do not create their own log messages,
-    they simply re-log messages that are created from context.log.x() calls), which is why they are
-    referenced from within this handler class.
+    run. These essentially work as handlers (they do not create their own log messages, they simply
+    re-log messages that are created from context.log.x() calls), which is why they are referenced
+    from within this handler class.
     """
 
     def __init__(
         self,
         metadata: DagsterLogHandlerMetadata,
         loggers: Sequence[logging.Logger],
         handlers: Sequence[logging.Handler],
@@ -208,15 +230,22 @@
             "asctime",
         ]
         return {k: v for k, v in record.__dict__.items() if k not in ref_attrs}
 
     def _convert_record(self, record: logging.LogRecord) -> logging.LogRecord:
         # If this was a logged DagsterEvent, the event will be stored on the record
         event = get_log_record_event(record) if has_log_record_event(record) else None
-        metadata = construct_log_record_metadata(self._metadata, record.getMessage(), event)
+        event_batch_metadata = (
+            get_log_record_event_batch_metadata(record)
+            if has_log_record_event_batch_metadata(record)
+            else None
+        )
+        metadata = construct_log_record_metadata(
+            self._metadata, record.getMessage(), event, event_batch_metadata
+        )
         message = construct_log_record_message(metadata)
 
         # update the message to be formatted like other dagster logs
         set_log_record_metadata(record, metadata)
         record.msg = message
         record.args = ()
         return record
@@ -352,28 +381,46 @@
             logger.addHandler(self._dagster_handler)
 
     def end_python_log_capture(self) -> None:
         for logger in self._managed_loggers:
             logger.removeHandler(self._dagster_handler)
 
     def log_dagster_event(
-        self, level: Union[str, int], msg: str, dagster_event: "DagsterEvent"
+        self,
+        level: Union[str, int],
+        msg: str,
+        dagster_event: "DagsterEvent",
+        batch_metadata: Optional["DagsterEventBatchMetadata"] = None,
     ) -> None:
         """Log a DagsterEvent at the given level. Attributes about the context it was logged in
         (such as the asset or job name) will be automatically attached to the created record.
 
         Args:
             level (str, int): either a string representing the desired log level ("INFO", "WARN"),
                 or an integer level such as logging.INFO or logging.DEBUG.
             msg (str): message describing the event
             dagster_event (DagsterEvent): DagsterEvent that will be logged
+            batch_metadata (BatchMetadata): Metadata about the batch that the event is a part of.
         """
-        self.log(level=level, msg=msg, extra={LOG_RECORD_EVENT_ATTR: dagster_event})
+        self.log(
+            level=level,
+            msg=msg,
+            extra={
+                LOG_RECORD_EVENT_ATTR: dagster_event,
+                LOG_RECORD_EVENT_BATCH_METADATA_ATTR: batch_metadata,
+            },
+        )
 
-    def log(self, level: Union[str, int], msg: object, *args: Any, **kwargs: Any) -> None:
+    def log(
+        self,
+        level: Union[str, int],
+        msg: object,
+        *args: Any,
+        **kwargs: Any,
+    ) -> None:
         """Log a message at the given level. Attributes about the context it was logged in (such as
         the asset or job name) will be automatically attached to the created record.
 
         Args:
             level (str, int): either a string representing the desired log level ("INFO", "WARN"),
                 or an integer level such as logging.INFO or logging.DEBUG.
             msg (str): the message to be logged
```

### Comparing `dagster-1.6.9/dagster/_core/nux.py` & `dagster-1.7.0/dagster/_core/nux.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/op_concurrency_limits_counter.py` & `dagster-1.7.0/dagster/_core/op_concurrency_limits_counter.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/origin.py` & `dagster-1.7.0/dagster/_core/origin.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/pipes/client.py` & `dagster-1.7.0/dagster/_core/pipes/client.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/pipes/context.py` & `dagster-1.7.0/dagster/_core/pipes/context.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/pipes/subprocess.py` & `dagster-1.7.0/dagster/_core/pipes/subprocess.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/pipes/utils.py` & `dagster-1.7.0/dagster/_core/pipes/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/run_coordinator/base.py` & `dagster-1.7.0/dagster/_core/run_coordinator/base.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/run_coordinator/default_run_coordinator.py` & `dagster-1.7.0/dagster/_core/run_coordinator/default_run_coordinator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/run_coordinator/queued_run_coordinator.py` & `dagster-1.7.0/dagster/_core/run_coordinator/queued_run_coordinator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/scheduler/__init__.py` & `dagster-1.7.0/dagster/_core/scheduler/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/scheduler/execution.py` & `dagster-1.7.0/dagster/_core/scheduler/execution.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/scheduler/instigation.py` & `dagster-1.7.0/dagster/_core/scheduler/instigation.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 # re-export
 from dagster._core.definitions.run_request import (
     InstigatorType as InstigatorType,
     SkipReason as SkipReason,
 )
 from dagster._core.definitions.selector import InstigatorSelector, RepositorySelector
 from dagster._core.definitions.sensor_definition import SensorType
-from dagster._core.host_representation.origin import ExternalInstigatorOrigin
+from dagster._core.remote_representation.origin import RemoteInstigatorOrigin
 from dagster._serdes import create_snapshot_id
 from dagster._serdes.errors import DeserializationError
 from dagster._serdes.serdes import (
     EnumSerializer,
     deserialize_value,
     whitelist_for_serdes,
 )
@@ -208,31 +208,31 @@
         "instigator_data": "job_specific_data",
     },
 )
 class InstigatorState(
     NamedTuple(
         "_InstigationState",
         [
-            ("origin", ExternalInstigatorOrigin),
+            ("origin", RemoteInstigatorOrigin),
             ("instigator_type", InstigatorType),
             ("status", InstigatorStatus),
             ("instigator_data", Optional[InstigatorData]),
         ],
     )
 ):
     def __new__(
         cls,
-        origin: ExternalInstigatorOrigin,
+        origin: RemoteInstigatorOrigin,
         instigator_type: InstigatorType,
         status: InstigatorStatus,
         instigator_data: Optional[InstigatorData] = None,
     ):
         return super(InstigatorState, cls).__new__(
             cls,
-            check.inst_param(origin, "origin", ExternalInstigatorOrigin),
+            check.inst_param(origin, "origin", RemoteInstigatorOrigin),
             check.inst_param(instigator_type, "instigator_type", InstigatorType),
             check.inst_param(status, "status", InstigatorStatus),
             check_instigator_data(instigator_type, instigator_data),
         )
 
     @property
     def is_running(self) -> bool:
@@ -244,37 +244,37 @@
 
     @property
     def instigator_name(self) -> str:
         return self.origin.instigator_name
 
     @property
     def repository_origin_id(self) -> str:
-        return self.origin.external_repository_origin.get_id()
+        return self.origin.repository_origin.get_id()
 
     @property
     def repository_selector(self) -> RepositorySelector:
         return RepositorySelector(
-            self.origin.external_repository_origin.code_location_origin.location_name,
-            self.origin.external_repository_origin.repository_name,
+            self.origin.repository_origin.code_location_origin.location_name,
+            self.origin.repository_origin.repository_name,
         )
 
     @property
     def repository_selector_id(self) -> str:
         return create_snapshot_id(self.repository_selector)
 
     @property
     def instigator_origin_id(self) -> str:
         return self.origin.get_id()
 
     @property
     def selector_id(self) -> str:
         return create_snapshot_id(
             InstigatorSelector(
-                self.origin.external_repository_origin.code_location_origin.location_name,
-                self.origin.external_repository_origin.repository_name,
+                self.origin.repository_origin.code_location_origin.location_name,
+                self.origin.repository_origin.repository_name,
                 self.origin.instigator_name,
             )
         )
 
     def with_status(self, status: InstigatorStatus) -> "InstigatorState":
         check.inst_param(status, "status", InstigatorStatus)
         return InstigatorState(
```

### Comparing `dagster-1.6.9/dagster/_core/scheduler/scheduler.py` & `dagster-1.7.0/dagster/_core/scheduler/scheduler.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 
 from typing_extensions import Self
 
 import dagster._check as check
 from dagster._config import Field, IntSource
 from dagster._core.definitions.run_request import InstigatorType
 from dagster._core.errors import DagsterError
-from dagster._core.host_representation import ExternalSchedule
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation import ExternalSchedule
 from dagster._core.scheduler.instigation import (
     InstigatorState,
     InstigatorStatus,
     ScheduleInstigatorData,
 )
 from dagster._serdes import ConfigurableClass
 from dagster._serdes.config_class import ConfigurableClassData
```

### Comparing `dagster-1.6.9/dagster/_core/secrets/env_file.py` & `dagster-1.7.0/dagster/_core/secrets/env_file.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/selector/subset_selector.py` & `dagster-1.7.0/dagster/_core/selector/subset_selector.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,15 +13,14 @@
     List,
     Mapping,
     MutableSet,
     NamedTuple,
     Optional,
     Sequence,
     Set,
-    Tuple,
     TypeVar,
 )
 
 from typing_extensions import Literal, TypeAlias
 
 from dagster._core.definitions.asset_check_spec import AssetCheckKey
 from dagster._core.definitions.dependency import DependencyStructure
@@ -29,15 +28,14 @@
 from dagster._core.errors import DagsterExecutionStepNotFoundError, DagsterInvalidSubsetError
 from dagster._utils import check
 
 if TYPE_CHECKING:
     from dagster._core.definitions.assets import AssetsDefinition
     from dagster._core.definitions.graph_definition import GraphDefinition
     from dagster._core.definitions.job_definition import JobDefinition
-    from dagster._core.definitions.source_asset import SourceAsset
 
 MAX_NUM = sys.maxsize
 
 T = TypeVar("T")
 T_Hashable = TypeVar("T_Hashable", bound=Hashable)
 Direction: TypeAlias = Literal["downstream", "upstream"]
 DependencyGraph: TypeAlias = Mapping[Direction, Mapping[T_Hashable, AbstractSet[T_Hashable]]]
@@ -96,32 +94,30 @@
         asset_selection (FrozenSet[AssetKey]): The set of assets to be materialized within the job.
         parent_job_def (JobDefinition): The definition of the full job. This is used for constructing
             pipeline snapshot lineage.
     """
 
     def __new__(
         cls,
-        asset_selection: AbstractSet[AssetKey],
+        asset_selection: Optional[AbstractSet[AssetKey]],
         asset_check_selection: Optional[AbstractSet[AssetCheckKey]],
         parent_job_def: "JobDefinition",
     ):
         from dagster._core.definitions.job_definition import JobDefinition
 
-        check.opt_set_param(asset_check_selection, "asset_check_selection", AssetCheckKey)
-
         return super(AssetSelectionData, cls).__new__(
             cls,
-            asset_selection=check.set_param(asset_selection, "asset_selection", AssetKey),
+            asset_selection=check.opt_set_param(asset_selection, "asset_selection", AssetKey),
             asset_check_selection=asset_check_selection,
             parent_job_def=check.inst_param(parent_job_def, "parent_job_def", JobDefinition),
         )
 
 
 def generate_asset_dep_graph(
-    assets_defs: Iterable["AssetsDefinition"], source_assets: Iterable["SourceAsset"]
+    assets_defs: Iterable["AssetsDefinition"],
 ) -> DependencyGraph[AssetKey]:
     upstream: Dict[AssetKey, Set[AssetKey]] = {}
     downstream: Dict[AssetKey, Set[AssetKey]] = {}
     for assets_def in assets_defs:
         for asset_key in assets_def.keys:
             upstream[asset_key] = set()
             downstream[asset_key] = downstream.get(asset_key, set())
@@ -278,15 +274,21 @@
     names = [asset_key.to_user_string() for asset_key in asset.keys]
     connected_names = [
         n for name in names for n in fetch_connected(name, graph, direction=direction, depth=depth)
     ]
     return frozenset(name_to_definition_map[n] for n in connected_names)
 
 
-def parse_clause(clause: str) -> Optional[Tuple[int, str, int]]:
+class GraphSelectionClause(NamedTuple):
+    up_depth: int
+    item_name: str
+    down_depth: int
+
+
+def parse_clause(clause: str) -> Optional[GraphSelectionClause]:
     def _get_depth(part: str) -> int:
         if part == "":
             return 0
         elif "*" in part:
             return MAX_NUM
         elif set(part) == set("+"):
             return len(part)
@@ -299,15 +301,15 @@
     if len(parts) != 3:
         return None
 
     ancestor_part, item_name, descendant_part = parts
     up_depth = _get_depth(ancestor_part)
     down_depth = _get_depth(descendant_part)
 
-    return (up_depth, item_name, down_depth)
+    return GraphSelectionClause(up_depth, item_name, down_depth)
 
 
 def parse_items_from_selection(selection: Sequence[str]) -> Sequence[str]:
     items: List[str] = []
     for clause in selection:
         parts = parse_clause(clause)
         if parts is None:
@@ -474,15 +476,15 @@
     """
     check.sequence_param(asset_selection, "asset_selection", of_type=str)
 
     # special case: select *
     if len(asset_selection) == 1 and asset_selection[0] == "*":
         return {key for ad in assets_defs for key in ad.keys}
 
-    graph = generate_asset_dep_graph(assets_defs, [])
+    graph = generate_asset_dep_graph(assets_defs)
     assets_set: Set[AssetKey] = set()
 
     # loop over clauses
     for clause in asset_selection:
         subset = clause_to_subset(graph, clause, AssetKey.from_user_string)
         if len(subset) == 0 and raise_on_clause_has_no_matches:
             raise DagsterInvalidSubsetError(
```

### Comparing `dagster-1.6.9/dagster/_core/snap/__init__.py` & `dagster-1.7.0/dagster/_core/snap/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/snap/dagster_types.py` & `dagster-1.7.0/dagster/_core/snap/dagster_types.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/snap/dep_snapshot.py` & `dagster-1.7.0/dagster/_core/snap/dep_snapshot.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/snap/execution_plan_snapshot.py` & `dagster-1.7.0/dagster/_core/snap/execution_plan_snapshot.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/snap/job_snapshot.py` & `dagster-1.7.0/dagster/_core/snap/job_snapshot.py`

 * *Files 2% similar despite different names*

```diff
@@ -305,17 +305,15 @@
     )
 
 
 def _construct_scalar_union_from_snap(config_type_snap, config_snap_map):
     check.list_param(config_type_snap.type_param_keys, "type_param_keys", str)
     check.invariant(
         len(config_type_snap.type_param_keys) == 2,
-        "Expect SCALAR_UNION to provide a scalar key and a non scalar key. Snapshot Provided: {}".format(
-            config_type_snap.type_param_keys
-        ),
+        f"Expect SCALAR_UNION to provide a scalar key and a non scalar key. Snapshot Provided: {config_type_snap.type_param_keys}",
     )
 
     return ScalarUnion(
         scalar_type=construct_config_type_from_snap(
             config_snap_map[config_type_snap.type_param_keys[0]], config_snap_map
         ),
         non_scalar_schema=construct_config_type_from_snap(
@@ -324,33 +322,29 @@
     )
 
 
 def _construct_array_from_snap(config_type_snap, config_snap_map):
     check.list_param(config_type_snap.type_param_keys, "type_param_keys", str)
     check.invariant(
         len(config_type_snap.type_param_keys) == 1,
-        "Expect ARRAY to provide a single inner type. Snapshot provided: {}".format(
-            config_type_snap.type_param_keys
-        ),
+        f"Expect ARRAY to provide a single inner type. Snapshot provided: {config_type_snap.type_param_keys}",
     )
 
     return Array(
         inner_type=construct_config_type_from_snap(
             config_snap_map[config_type_snap.type_param_keys[0]], config_snap_map
         )
     )
 
 
 def _construct_map_from_snap(config_type_snap, config_snap_map):
     check.list_param(config_type_snap.type_param_keys, "type_param_keys", str)
     check.invariant(
         len(config_type_snap.type_param_keys) == 2,
-        "Expect map to provide exactly two types (key, value). Snapshot provided: {}".format(
-            config_type_snap.type_param_keys
-        ),
+        f"Expect map to provide exactly two types (key, value). Snapshot provided: {config_type_snap.type_param_keys}",
     )
 
     return Map(
         key_type=construct_config_type_from_snap(
             config_snap_map[config_type_snap.type_param_keys[0]],
             config_snap_map,
         ),
@@ -363,17 +357,15 @@
     )
 
 
 def _construct_noneable_from_snap(config_type_snap, config_snap_map):
     check.list_param(config_type_snap.type_param_keys, "type_param_keys", str)
     check.invariant(
         len(config_type_snap.type_param_keys) == 1,
-        "Expect NONEABLE to provide a single inner type. Snapshot provided: {}".format(
-            config_type_snap.type_param_keys
-        ),
+        f"Expect NONEABLE to provide a single inner type. Snapshot provided: {config_type_snap.type_param_keys}",
     )
     return Noneable(
         construct_config_type_from_snap(
             config_snap_map[config_type_snap.type_param_keys[0]], config_snap_map
         )
     )
```

### Comparing `dagster-1.6.9/dagster/_core/snap/mode.py` & `dagster-1.7.0/dagster/_core/snap/mode.py`

 * *Files 0% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 from dagster._config import ConfigFieldSnap, snap_from_field
 from dagster._core.definitions import LoggerDefinition, ResourceDefinition
 from dagster._core.definitions.job_definition import JobDefinition
 from dagster._serdes import whitelist_for_serdes
 
 
 def build_mode_def_snap(job_def: JobDefinition) -> "ModeDefSnap":
-    from dagster._core.host_representation.external_data import DEFAULT_MODE_NAME
+    from dagster._core.remote_representation.external_data import DEFAULT_MODE_NAME
 
     check.inst_param(job_def, "job_def", JobDefinition)
 
     root_config_key = job_def.run_config_schema.config_type.key
     return ModeDefSnap(
         name=DEFAULT_MODE_NAME,
         description=None,
```

### Comparing `dagster-1.6.9/dagster/_core/snap/node.py` & `dagster-1.7.0/dagster/_core/snap/node.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/snap/snap_to_yaml.py` & `dagster-1.7.0/dagster/_core/snap/snap_to_yaml.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/DEVELOPING.md` & `dagster-1.7.0/dagster/_core/storage/DEVELOPING.md`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/README.md` & `dagster-1.7.0/dagster/_core/storage/alembic/README.md`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/env.py` & `dagster-1.7.0/dagster/_core/storage/alembic/env.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/001_initial_1.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/001_initial_1.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/004_add_snapshots_to_run_storage.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/004_add_snapshots_to_run_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/005_add_asset_key_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/005_add_asset_key_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/005_add_asset_key_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/005_add_asset_key_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/006_scheduler_update_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/006_scheduler_update_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/007_create_run_id_idx_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/007_create_run_id_idx_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/007_create_run_id_idx_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/007_create_run_id_idx_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/008_add_run_tags_index_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/008_add_run_tags_index_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/008_add_run_tags_index_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/008_add_run_tags_index_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/009_add_partition_column_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/009_add_partition_column_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/009_add_partition_column_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/009_add_partition_column_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_1.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_1.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_2.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_2.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/017_add_run_status_index_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/017_add_run_status_index_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/017_add_run_status_index_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/017_add_run_status_index_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/021_add_column_mode_mysql.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/021_add_column_mode_mysql.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/021_add_column_mode_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/021_add_column_mode_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/021_add_column_mode_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/021_add_column_mode_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_mysql.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_mysql.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_postgres.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_sqlite.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/026_convert_start_end_times_format_mysql.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/026_convert_start_end_times_format_mysql.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/030_add_columns_action_type_and_selector_id_.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/030_add_columns_action_type_and_selector_id_.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/031_add_kvs_table.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/031_add_kvs_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/033_add_asset_event_tags_table.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/033_add_asset_event_tags_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/036_add_dynamic_partitions_table.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/036_add_dynamic_partitions_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/037_d9092588866f_add_primary_key_cols.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/037_d9092588866f_add_primary_key_cols.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/038_701913684cb4_add_postgres_pks.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/038_701913684cb4_add_postgres_pks.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/039_d3a4c9e87af3_add_asset_daemon_asset_evaluations_table.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/039_d3a4c9e87af3_add_asset_daemon_asset_evaluations_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/040_add_in_progress_step_table.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/040_add_in_progress_step_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/041_add_asset_check_executions_table.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/041_add_asset_check_executions_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/alembic/versions/042_46b412388816_add_concurrency_limits_table.py` & `dagster-1.7.0/dagster/_core/storage/alembic/versions/042_46b412388816_add_concurrency_limits_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/asset_check_execution_record.py` & `dagster-1.7.0/dagster/_core/storage/asset_check_execution_record.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/asset_value_loader.py` & `dagster-1.7.0/dagster/_core/storage/asset_value_loader.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from contextlib import ExitStack
 from typing import Any, Dict, Mapping, Optional, Type, cast
 
 import dagster._check as check
-from dagster._annotations import public
+from dagster._annotations import deprecated_param, public
 from dagster._core.definitions.assets import AssetsDefinition
 from dagster._core.definitions.events import AssetKey, CoercibleToAssetKey
 from dagster._core.definitions.job_definition import (
     default_job_io_manager_with_fs_io_manager_schema,
 )
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
 from dagster._core.definitions.resource_definition import ResourceDefinition
@@ -15,14 +15,15 @@
 from dagster._core.execution.context.input import build_input_context
 from dagster._core.execution.context.output import build_output_context
 from dagster._core.execution.resources_init import get_transitive_required_resource_keys
 from dagster._core.instance import DagsterInstance
 from dagster._core.instance.config import is_dagster_home_set
 from dagster._core.types.dagster_type import resolve_dagster_type
 from dagster._utils.merger import merge_dicts
+from dagster._utils.warnings import normalize_renamed_param
 
 from .io_manager import IOManager
 
 
 class AssetValueLoader:
     """Caches resource definitions that are used to load asset values across multiple load
     invocations.
@@ -61,56 +62,63 @@
                 )
             )
             ._asdict()
             .items()
         ):
             self._resource_instance_cache[built_resource_key] = built_resource
 
+    @deprecated_param(
+        param="metadata",
+        breaking_version="2.0",
+        additional_warn_text="Use `input_definition_metadata` instead.",
+    )
     @public
     def load_asset_value(
         self,
         asset_key: CoercibleToAssetKey,
         *,
         python_type: Optional[Type[object]] = None,
         partition_key: Optional[str] = None,
-        metadata: Optional[Dict[str, Any]] = None,
+        input_definition_metadata: Optional[Dict[str, Any]] = None,
         resource_config: Optional[Mapping[str, Any]] = None,
+        # deprecated
+        metadata: Optional[Dict[str, Any]] = None,
     ) -> object:
         """Loads the contents of an asset as a Python object.
 
         Invokes `load_input` on the :py:class:`IOManager` associated with the asset.
 
         Args:
             asset_key (Union[AssetKey, Sequence[str], str]): The key of the asset to load.
             python_type (Optional[Type]): The python type to load the asset as. This is what will
                 be returned inside `load_input` by `context.dagster_type.typing_type`.
             partition_key (Optional[str]): The partition of the asset to load.
-            metadata (Optional[Dict[str, Any]]): Input metadata to pass to the :py:class:`IOManager`
+            input_definition_metadata (Optional[Dict[str, Any]]): Input metadata to pass to the :py:class:`IOManager`
                 (is equivalent to setting the metadata argument in `In` or `AssetIn`).
             resource_config (Optional[Any]): A dictionary of resource configurations to be passed
                 to the :py:class:`IOManager`.
 
         Returns:
             The contents of an asset as a Python object.
         """
         asset_key = AssetKey.from_coercible(asset_key)
         resource_config = resource_config or {}
-        output_metadata = {}
+        output_definition_metadata = {}
 
         if asset_key in self._assets_defs_by_key:
             assets_def = self._assets_defs_by_key[asset_key]
 
             resource_defs = merge_dicts(
                 {DEFAULT_IO_MANAGER_KEY: default_job_io_manager_with_fs_io_manager_schema},
                 assets_def.resource_defs,
             )
             io_manager_key = assets_def.get_io_manager_key_for_asset_key(asset_key)
             io_manager_def = resource_defs[io_manager_key]
             name = assets_def.get_output_name_for_asset_key(asset_key)
-            output_metadata = assets_def.metadata_by_key[asset_key]
+            output_definition_metadata = assets_def.metadata_by_key[asset_key]
             op_def = assets_def.get_op_def_for_asset_key(asset_key)
             asset_partitions_def = assets_def.partitions_def
         else:
             check.failed(f"Asset key {asset_key} not found")
 
         required_resource_keys = get_transitive_required_resource_keys(
             io_manager_def.required_resource_keys, resource_defs
@@ -131,30 +139,32 @@
 
         input_context = build_input_context(
             name=None,
             asset_key=asset_key,
             dagster_type=resolve_dagster_type(python_type),
             upstream_output=build_output_context(
                 name=name,
-                metadata=output_metadata,
+                definition_metadata=output_definition_metadata,
                 asset_key=asset_key,
                 op_def=op_def,
                 resource_config=resource_config,
             ),
             resources=self._resource_instance_cache,
             resource_config=io_manager_config[io_manager_key].config,
             partition_key=partition_key,
             asset_partition_key_range=(
                 PartitionKeyRange(partition_key, partition_key)
                 if partition_key is not None
                 else None
             ),
             asset_partitions_def=asset_partitions_def,
             instance=self._instance,
-            metadata=metadata,
+            definition_metadata=normalize_renamed_param(
+                input_definition_metadata, "input_definition_metadata", metadata, "metadata"
+            ),
         )
 
         return io_manager.load_input(input_context)
 
     def __enter__(self):
         return self
```

### Comparing `dagster-1.6.9/dagster/_core/storage/base_storage.py` & `dagster-1.7.0/dagster/_core/storage/base_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/branching/branching_io_manager.py` & `dagster-1.7.0/dagster/_core/storage/branching/branching_io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/captured_log_manager.py` & `dagster-1.7.0/dagster/_core/storage/captured_log_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/cloud_storage_compute_log_manager.py` & `dagster-1.7.0/dagster/_core/storage/cloud_storage_compute_log_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/compute_log_manager.py` & `dagster-1.7.0/dagster/_core/storage/compute_log_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/config.py` & `dagster-1.7.0/dagster/_core/storage/config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/dagster_run.py` & `dagster-1.7.0/dagster/_core/storage/dagster_run.py`

 * *Files 2% similar despite different names*

```diff
@@ -33,16 +33,16 @@
     RESUME_RETRY_TAG,
     SCHEDULE_NAME_TAG,
     SENSOR_NAME_TAG,
     TICK_ID_TAG,
 )
 
 if TYPE_CHECKING:
-    from dagster._core.host_representation.external import ExternalSchedule, ExternalSensor
-    from dagster._core.host_representation.origin import ExternalJobOrigin
+    from dagster._core.remote_representation.external import ExternalSchedule, ExternalSensor
+    from dagster._core.remote_representation.origin import RemoteJobOrigin
 
 
 @whitelist_for_serdes(storage_name="PipelineRunStatus")
 class DagsterRunStatus(Enum):
     """The status of run execution."""
 
     # Runs waiting to be launched by the Dagster Daemon.
@@ -261,36 +261,43 @@
     },
 )
 class DagsterRun(
     NamedTuple(
         "_DagsterRun",
         [
             ("job_name", PublicAttr[str]),
-            ("run_id", str),
-            ("run_config", Mapping[str, object]),
+            ("run_id", PublicAttr[str]),
+            ("run_config", PublicAttr[Mapping[str, object]]),
             ("asset_selection", Optional[AbstractSet[AssetKey]]),
             ("asset_check_selection", Optional[AbstractSet[AssetCheckKey]]),
             ("op_selection", Optional[Sequence[str]]),
             ("resolved_op_selection", Optional[AbstractSet[str]]),
             ("step_keys_to_execute", Optional[Sequence[str]]),
             ("status", DagsterRunStatus),
-            ("tags", Mapping[str, str]),
+            ("tags", PublicAttr[Mapping[str, str]]),
             ("root_run_id", Optional[str]),
             ("parent_run_id", Optional[str]),
             ("job_snapshot_id", Optional[str]),
             ("execution_plan_snapshot_id", Optional[str]),
-            ("external_job_origin", Optional["ExternalJobOrigin"]),
+            ("external_job_origin", Optional["RemoteJobOrigin"]),
             ("job_code_origin", Optional[JobPythonOrigin]),
             ("has_repository_load_data", bool),
             ("run_op_concurrency", Optional[RunOpConcurrency]),
         ],
     )
 ):
     """Serializable internal representation of a dagster run, as stored in a
     :py:class:`~dagster._core.storage.runs.RunStorage`.
+
+    Attributes:
+        job_name (str): The name of the job executed in this run
+        run_id (str): The ID of the run
+        run_config (Mapping[str, object]): The config for the run
+        tags (Mapping[str, str]): The tags applied to the run
+
     """
 
     def __new__(
         cls,
         job_name: str,
         run_id: Optional[str] = None,
         run_config: Optional[Mapping[str, object]] = None,
@@ -301,15 +308,15 @@
         step_keys_to_execute: Optional[Sequence[str]] = None,
         status: Optional[DagsterRunStatus] = None,
         tags: Optional[Mapping[str, str]] = None,
         root_run_id: Optional[str] = None,
         parent_run_id: Optional[str] = None,
         job_snapshot_id: Optional[str] = None,
         execution_plan_snapshot_id: Optional[str] = None,
-        external_job_origin: Optional["ExternalJobOrigin"] = None,
+        external_job_origin: Optional["RemoteJobOrigin"] = None,
         job_code_origin: Optional[JobPythonOrigin] = None,
         has_repository_load_data: Optional[bool] = None,
         run_op_concurrency: Optional[RunOpConcurrency] = None,
     ):
         check.invariant(
             (root_run_id is not None and parent_run_id is not None)
             or (root_run_id is None and parent_run_id is None),
@@ -330,21 +337,21 @@
         )
         asset_check_selection = check.opt_nullable_set_param(
             asset_check_selection, "asset_check_selection", of_type=AssetCheckKey
         )
 
         # Placing this with the other imports causes a cyclic import
         # https://github.com/dagster-io/dagster/issues/3181
-        from dagster._core.host_representation.origin import ExternalJobOrigin
+        from dagster._core.remote_representation.origin import RemoteJobOrigin
 
         if status == DagsterRunStatus.QUEUED:
             check.inst_param(
                 external_job_origin,
                 "external_job_origin",
-                ExternalJobOrigin,
+                RemoteJobOrigin,
                 "external_job_origin is required for queued runs",
             )
 
         if run_id is None:
             run_id = make_new_run_id()
 
         return super(DagsterRun, cls).__new__(
@@ -364,15 +371,15 @@
             root_run_id=check.opt_str_param(root_run_id, "root_run_id"),
             parent_run_id=check.opt_str_param(parent_run_id, "parent_run_id"),
             job_snapshot_id=check.opt_str_param(job_snapshot_id, "job_snapshot_id"),
             execution_plan_snapshot_id=check.opt_str_param(
                 execution_plan_snapshot_id, "execution_plan_snapshot_id"
             ),
             external_job_origin=check.opt_inst_param(
-                external_job_origin, "external_job_origin", ExternalJobOrigin
+                external_job_origin, "external_job_origin", RemoteJobOrigin
             ),
             job_code_origin=check.opt_inst_param(
                 job_code_origin, "job_code_origin", JobPythonOrigin
             ),
             has_repository_load_data=check.opt_bool_param(
                 has_repository_load_data, "has_repository_load_data", default=False
             ),
@@ -381,28 +388,26 @@
             ),
         )
 
     def with_status(self, status: DagsterRunStatus) -> Self:
         if status == DagsterRunStatus.QUEUED:
             # Placing this with the other imports causes a cyclic import
             # https://github.com/dagster-io/dagster/issues/3181
-            from dagster._core.host_representation.origin import ExternalJobOrigin
 
-            check.inst(
+            check.not_none(
                 self.external_job_origin,
-                ExternalJobOrigin,
                 "external_pipeline_origin is required for queued runs",
             )
 
         return self._replace(status=status)
 
-    def with_job_origin(self, origin: "ExternalJobOrigin") -> Self:
-        from dagster._core.host_representation.origin import ExternalJobOrigin
+    def with_job_origin(self, origin: "RemoteJobOrigin") -> Self:
+        from dagster._core.remote_representation.origin import RemoteJobOrigin
 
-        check.inst_param(origin, "origin", ExternalJobOrigin)
+        check.inst_param(origin, "origin", RemoteJobOrigin)
         return self._replace(external_job_origin=origin)
 
     def with_tags(self, tags: Mapping[str, str]) -> Self:
         return self._replace(tags=tags)
 
     def get_root_run_id(self) -> Optional[str]:
         return self.tags.get(ROOT_RUN_ID_TAG)
@@ -412,15 +417,15 @@
 
     def tags_for_storage(self) -> Mapping[str, str]:
         repository_tags = {}
         if self.external_job_origin:
             # tag the run with a label containing the repository name / location name, to allow for
             # per-repository filtering of runs from the Dagster UI.
             repository_tags[REPOSITORY_LABEL_TAG] = (
-                self.external_job_origin.external_repository_origin.get_label()
+                self.external_job_origin.repository_origin.get_label()
             )
 
         if not self.tags:
             return repository_tags
 
         return {**repository_tags, **self.tags}
```

### Comparing `dagster-1.6.9/dagster/_core/storage/db_io_manager.py` & `dagster-1.7.0/dagster/_core/storage/db_io_manager.py`

 * *Files 2% similar despite different names*

```diff
@@ -168,15 +168,15 @@
 
         with self._db_client.connect(context, table_slice) as conn:
             return self._handlers_by_type[load_type].load_input(context, table_slice, conn)
 
     def _get_table_slice(
         self, context: Union[OutputContext, InputContext], output_context: OutputContext
     ) -> TableSlice:
-        output_context_metadata = output_context.metadata or {}
+        output_context_metadata = output_context.definition_metadata or {}
 
         schema: str
         table: str
         partition_dimensions: List[TablePartitionDimension] = []
         if context.has_asset_key:
             asset_key_path = context.asset_key.path
             table = asset_key_path[-1]
@@ -255,15 +255,15 @@
                 schema = "public"
 
         return TableSlice(
             table=table,
             schema=schema,
             database=self._database,
             partition_dimensions=partition_dimensions,
-            columns=(context.metadata or {}).get("columns"),
+            columns=(context.definition_metadata or {}).get("columns"),
         )
 
     def _check_supported_type(self, obj_type):
         if obj_type not in self._handlers_by_type:
             msg = (
                 f"{self._io_manager_name} does not have a handler for type '{obj_type}'. Has"
                 " handlers for types"
```

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/__init__.py` & `dagster-1.7.0/dagster/_core/storage/event_log/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/base.py` & `dagster-1.7.0/dagster/_core/storage/event_log/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -192,14 +192,18 @@
     def store_event(self, event: "EventLogEntry") -> None:
         """Store an event corresponding to a pipeline run.
 
         Args:
             event (EventLogEntry): The event to store.
         """
 
+    def store_event_batch(self, events: Sequence["EventLogEntry"]) -> None:
+        for event in events:
+            self.store_event(event)
+
     @abstractmethod
     def delete_events(self, run_id: str) -> None:
         """Remove events for a given run id."""
 
     @abstractmethod
     def upgrade(self) -> None:
         """This method should perform any schema migrations necessary to bring an
```

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/in_memory.py` & `dagster-1.7.0/dagster/_core/storage/event_log/in_memory.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/migration.py` & `dagster-1.7.0/dagster/_core/storage/event_log/migration.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/polling_event_watcher.py` & `dagster-1.7.0/dagster/_core/storage/event_log/polling_event_watcher.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/schema.py` & `dagster-1.7.0/dagster/_core/storage/event_log/schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/sql_event_log.py` & `dagster-1.7.0/dagster/_core/storage/event_log/sql_event_log.py`

 * *Files 1% similar despite different names*

```diff
@@ -179,44 +179,54 @@
         out-of-date instance of the storage up to date.
         """
 
     @abstractmethod
     def has_table(self, table_name: str) -> bool:
         """This method checks if a table exists in the database."""
 
-    def prepare_insert_event(self, event):
+    def prepare_insert_event(self, event: EventLogEntry) -> Any:
         """Helper method for preparing the event log SQL insertion statement.  Abstracted away to
         have a single place for the logical table representation of the event, while having a way
         for SQL backends to implement different execution implementations for `store_event`. See
         the `dagster-postgres` implementation which overrides the generic SQL implementation of
         `store_event`.
         """
+        # https://stackoverflow.com/a/54386260/324449
+        return SqlEventLogStorageTable.insert().values(**self._event_to_row(event))
+
+    def prepare_insert_event_batch(self, events: Sequence[EventLogEntry]) -> Any:
+        # https://stackoverflow.com/a/54386260/324449
+        return SqlEventLogStorageTable.insert().values(
+            [self._event_to_row(event) for event in events]
+        )
+
+    def _event_to_row(self, event: EventLogEntry) -> Dict[str, Any]:
         dagster_event_type = None
         asset_key_str = None
         partition = None
         step_key = event.step_key
         if event.is_dagster_event:
-            dagster_event_type = event.dagster_event.event_type_value
-            step_key = event.dagster_event.step_key
-            if event.dagster_event.asset_key:
-                check.inst_param(event.dagster_event.asset_key, "asset_key", AssetKey)
-                asset_key_str = event.dagster_event.asset_key.to_string()
-            if event.dagster_event.partition:
-                partition = event.dagster_event.partition
-
-        # https://stackoverflow.com/a/54386260/324449
-        return SqlEventLogStorageTable.insert().values(
-            run_id=event.run_id,
-            event=serialize_value(event),
-            dagster_event_type=dagster_event_type,
-            timestamp=self._event_insert_timestamp(event),
-            step_key=step_key,
-            asset_key=asset_key_str,
-            partition=partition,
-        )
+            dagster_event = event.get_dagster_event()
+            dagster_event_type = dagster_event.event_type_value
+            step_key = dagster_event.step_key
+            if dagster_event.asset_key:
+                check.inst_param(dagster_event.asset_key, "asset_key", AssetKey)
+                asset_key_str = dagster_event.asset_key.to_string()
+            if dagster_event.partition:
+                partition = dagster_event.partition
+
+        return {
+            "run_id": event.run_id,
+            "event": serialize_value(event),
+            "dagster_event_type": dagster_event_type,
+            "timestamp": self._event_insert_timestamp(event),
+            "step_key": step_key,
+            "asset_key": asset_key_str,
+            "partition": partition,
+        }
 
     def has_asset_key_col(self, column_name: str) -> bool:
         with self.index_connection() as conn:
             column_names = [x.get("name") for x in db.inspect(conn).get_columns(AssetKeyTable.name)]
             return column_name in column_names
 
     def has_asset_key_index_cols(self) -> bool:
@@ -385,49 +395,48 @@
                             # set in order to be stored correctly
                             event_timestamp=datetime.utcfromtimestamp(event_timestamp),
                         )
                         for tag in added_tags
                     ],
                 )
 
-    def store_asset_event_tags(self, event: EventLogEntry, event_id: int) -> None:
-        check.inst_param(event, "event", EventLogEntry)
-        check.int_param(event_id, "event_id")
+    def store_asset_event_tags(
+        self, events: Sequence[EventLogEntry], event_ids: Sequence[int]
+    ) -> None:
+        check.sequence_param(events, "events", EventLogEntry)
+        check.sequence_param(event_ids, "event_ids", int)
 
+        all_values = [
+            dict(
+                event_id=event_id,
+                asset_key=check.not_none(event.get_dagster_event().asset_key).to_string(),
+                key=key,
+                value=value,
+                event_timestamp=self._event_insert_timestamp(event),
+            )
+            for event_id, event in zip(event_ids, events)
+            for key, value in self._tags_for_asset_event(event).items()
+        ]
+
+        # Only execute if tags table exists. This is to support OSS users who have not yet run the
+        # migration to create the table. On read, we will throw an error if the table does not
+        # exist.
+        if len(all_values) > 0 and self.has_table(AssetEventTagsTable.name):
+            with self.index_connection() as conn:
+                conn.execute(AssetEventTagsTable.insert(), all_values)
+
+    def _tags_for_asset_event(self, event: EventLogEntry) -> Mapping[str, str]:
         if event.dagster_event and event.dagster_event.asset_key:
             if event.dagster_event.is_step_materialization:
-                tags = event.dagster_event.step_materialization_data.materialization.tags
-            elif event.dagster_event.is_asset_observation:
-                tags = event.dagster_event.asset_observation_data.asset_observation.tags
-            else:
-                tags = None
-
-            if not tags or not self.has_table(AssetEventTagsTable.name):
-                # If tags table does not exist, silently exit. This is to support OSS
-                # users who have not yet run the migration to create the table.
-                # On read, we will throw an error if the table does not exist.
-                return
-
-            check.inst_param(event.dagster_event.asset_key, "asset_key", AssetKey)
-            asset_key_str = event.dagster_event.asset_key.to_string()
-
-            with self.index_connection() as conn:
-                conn.execute(
-                    AssetEventTagsTable.insert(),
-                    [
-                        dict(
-                            event_id=event_id,
-                            asset_key=asset_key_str,
-                            key=key,
-                            value=value,
-                            event_timestamp=self._event_insert_timestamp(event),
-                        )
-                        for key, value in tags.items()
-                    ],
+                return (
+                    event.get_dagster_event().step_materialization_data.materialization.tags or {}
                 )
+            elif event.dagster_event.is_asset_observation:
+                return event.get_dagster_event().asset_observation_data.asset_observation.tags
+        return {}
 
     def store_event(self, event: EventLogEntry) -> None:
         """Store an event corresponding to a pipeline run.
 
         Args:
             event (EventLogEntry): The event to store.
         """
@@ -449,15 +458,15 @@
             self.store_asset_event(event, event_id)
 
             if event_id is None:
                 raise DagsterInvariantViolationError(
                     "Cannot store asset event tags for null event id."
                 )
 
-            self.store_asset_event_tags(event, event_id)
+            self.store_asset_event_tags([event], [event_id])
 
         if event.is_dagster_event and event.dagster_event_type in ASSET_CHECK_EVENTS:
             self.store_asset_check_event(event, event_id)
 
     def get_records_for_run(
         self,
         run_id,
```

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/sqlite/alembic/alembic.ini` & `dagster-1.7.0/dagster/_core/storage/event_log/sqlite/alembic/alembic.ini`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/sqlite/consolidated_sqlite_event_log.py` & `dagster-1.7.0/dagster/_core/storage/event_log/sqlite/consolidated_sqlite_event_log.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/event_log/sqlite/sqlite_event_log.py` & `dagster-1.7.0/dagster/_core/storage/event_log/sqlite/sqlite_event_log.py`

 * *Files 0% similar despite different names*

```diff
@@ -259,15 +259,15 @@
             self.store_asset_event(event, event_id)
 
             if event_id is None:
                 raise DagsterInvariantViolationError(
                     "Cannot store asset event tags for null event id."
                 )
 
-            self.store_asset_event_tags(event, event_id)
+            self.store_asset_event_tags([event], [event_id])
 
         if event.is_dagster_event and event.dagster_event_type in ASSET_CHECK_EVENTS:
             self.store_asset_check_event(event, None)
 
         if event.is_dagster_event and event.dagster_event_type in EVENT_TYPE_TO_PIPELINE_RUN_STATUS:
             # should mirror run status change events in the index shard
             with self.index_connection() as conn:
```

### Comparing `dagster-1.6.9/dagster/_core/storage/file_manager.py` & `dagster-1.7.0/dagster/_core/storage/file_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/fs_io_manager.py` & `dagster-1.7.0/dagster/_core/storage/fs_io_manager.py`

 * *Files 2% similar despite different names*

```diff
@@ -304,16 +304,16 @@
     def handle_output(self, context: OutputContext, obj: object):
         """Pickle the data and store the object to a custom file path.
 
         This method emits an AssetMaterialization event so the assets will be tracked by the
         Asset Catalog.
         """
         check.inst_param(context, "context", OutputContext)
-        metadata = context.metadata
-        path = check.str_param(metadata.get("path"), "metadata.path")  # type: ignore  # (possible none)
+        metadata = context.definition_metadata
+        path = check.str_param(metadata.get("path"), "metadata.path")
 
         filepath = self._get_path(path)
 
         # Ensure path exists
         mkdir_p(os.path.dirname(filepath))
         context.log.debug(f"Writing file at: {filepath}")
 
@@ -324,16 +324,16 @@
             asset_key=AssetKey([context.job_name, context.step_key, context.name]),
             metadata={"path": MetadataValue.path(os.path.abspath(filepath))},
         )
 
     def load_input(self, context: InputContext) -> object:
         """Unpickle the file from a given file path and Load it to a data object."""
         check.inst_param(context, "context", InputContext)
-        metadata = context.upstream_output.metadata  # type: ignore  # (possible none)
-        path = check.str_param(metadata.get("path"), "metadata.path")  # type: ignore  # (possible none)
+        metadata = context.upstream_output.definition_metadata  # type: ignore  # (possible none)
+        path = check.str_param(metadata.get("path"), "metadata.path")
         filepath = self._get_path(path)
         context.log.debug(f"Loading file from: {filepath}")
 
         with open(filepath, self.read_mode) as read_obj:
             return pickle.load(read_obj)
```

### Comparing `dagster-1.6.9/dagster/_core/storage/input_manager.py` & `dagster-1.7.0/dagster/_core/storage/input_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/io_manager.py` & `dagster-1.7.0/dagster/_core/storage/io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/legacy_storage.py` & `dagster-1.7.0/dagster/_core/storage/legacy_storage.py`

 * *Files 0% similar despite different names*

```diff
@@ -42,16 +42,16 @@
     from dagster._core.definitions.asset_check_spec import AssetCheckKey
     from dagster._core.definitions.run_request import InstigatorType
     from dagster._core.event_api import AssetRecordsFilter, RunStatusChangeRecordsFilter
     from dagster._core.events import DagsterEvent, DagsterEventType
     from dagster._core.events.log import EventLogEntry
     from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
     from dagster._core.execution.stats import RunStepKeyStatsSnapshot
-    from dagster._core.host_representation.origin import ExternalJobOrigin
     from dagster._core.instance import DagsterInstance
+    from dagster._core.remote_representation.origin import RemoteJobOrigin
     from dagster._core.scheduler.instigation import (
         AutoMaterializeAssetEvaluationRecord,
         InstigatorState,
         InstigatorStatus,
         InstigatorTick,
         TickData,
         TickStatus,
@@ -236,15 +236,15 @@
     ) -> Sequence["RunRecord"]:
         return self._storage.run_storage.get_run_records(
             filters, limit, order_by, ascending, cursor, bucket_by
         )
 
     def get_run_tags(
         self,
-        tag_keys: Optional[Sequence[str]] = None,
+        tag_keys: Sequence[str],
         value_prefix: Optional[str] = None,
         limit: Optional[int] = None,
     ) -> Sequence[Tuple[str, Set[str]]]:
         return self._storage.run_storage.get_run_tags(tag_keys, value_prefix, limit)
 
     def get_run_tag_keys(self) -> Sequence[str]:
         return self._storage.run_storage.get_run_tag_keys()
@@ -340,15 +340,15 @@
 
     def get_cursor_values(self, keys: Set[str]) -> Mapping[str, str]:
         return self._storage.run_storage.get_cursor_values(keys)
 
     def set_cursor_values(self, pairs: Mapping[str, str]) -> None:
         return self._storage.run_storage.set_cursor_values(pairs)
 
-    def replace_job_origin(self, run: "DagsterRun", job_origin: "ExternalJobOrigin") -> None:
+    def replace_job_origin(self, run: "DagsterRun", job_origin: "RemoteJobOrigin") -> None:
         return self._storage.run_storage.replace_job_origin(run, job_origin)
 
 
 class LegacyEventLogStorage(EventLogStorage, ConfigurableClass):
     def __init__(self, storage: DagsterStorage, inst_data: Optional[ConfigurableClassData] = None):
         self._storage = check.inst_param(storage, "storage", DagsterStorage)
         self._inst_data = check.opt_inst_param(inst_data, "inst_data", ConfigurableClassData)
```

### Comparing `dagster-1.6.9/dagster/_core/storage/local_compute_log_manager.py` & `dagster-1.7.0/dagster/_core/storage/local_compute_log_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/mem_io_manager.py` & `dagster-1.7.0/dagster/_core/storage/mem_io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/memoizable_io_manager.py` & `dagster-1.7.0/dagster/_core/storage/memoizable_io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/migration/bigint_migration.py` & `dagster-1.7.0/dagster/_core/storage/migration/bigint_migration.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/migration/utils.py` & `dagster-1.7.0/dagster/_core/storage/migration/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/noop_compute_log_manager.py` & `dagster-1.7.0/dagster/_core/storage/noop_compute_log_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/output_manager.py` & `dagster-1.7.0/dagster/_core/storage/output_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/partition_status_cache.py` & `dagster-1.7.0/dagster/_core/storage/partition_status_cache.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/root.py` & `dagster-1.7.0/dagster/_core/storage/root.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/runs/base.py` & `dagster-1.7.0/dagster/_core/storage/runs/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 from dagster._core.storage.sql import AlembicVersion
 from dagster._daemon.types import DaemonHeartbeat
 from dagster._utils import PrintFn
 
 from ..daemon_cursor import DaemonCursorStorage
 
 if TYPE_CHECKING:
-    from dagster._core.host_representation.origin import ExternalJobOrigin
+    from dagster._core.remote_representation.origin import RemoteJobOrigin
 
 
 class RunGroupInfo(TypedDict):
     count: int
     runs: Sequence[DagsterRun]
 
 
@@ -157,22 +157,22 @@
         Returns:
             List[RunRecord]: List of run records stored in the run storage.
         """
 
     @abstractmethod
     def get_run_tags(
         self,
-        tag_keys: Optional[Sequence[str]] = None,
+        tag_keys: Sequence[str],
         value_prefix: Optional[str] = None,
         limit: Optional[int] = None,
     ) -> Sequence[Tuple[str, Set[str]]]:
         """Get a list of tag keys and the values that have been associated with them.
 
         Args:
-            tag_keys (Optional[Sequence[str]]): tag keys to filter by.
+            tag_keys (Sequence[str]): tag keys to filter by.
 
         Returns:
             List[Tuple[str, Set[str]]]
         """
 
     @abstractmethod
     def get_run_tag_keys(self) -> Sequence[str]:
@@ -379,8 +379,8 @@
     def update_backfill(self, partition_backfill: PartitionBackfill):
         """Update a partition backfill in run storage."""
 
     def alembic_version(self) -> Optional[AlembicVersion]:
         return None
 
     @abstractmethod
-    def replace_job_origin(self, run: "DagsterRun", job_origin: "ExternalJobOrigin") -> None: ...
+    def replace_job_origin(self, run: "DagsterRun", job_origin: "RemoteJobOrigin") -> None: ...
```

### Comparing `dagster-1.6.9/dagster/_core/storage/runs/in_memory.py` & `dagster-1.7.0/dagster/_core/storage/runs/in_memory.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/runs/migration.py` & `dagster-1.7.0/dagster/_core/storage/runs/migration.py`

 * *Files 1% similar despite different names*

```diff
@@ -200,15 +200,15 @@
 
 
 def write_repo_tag(conn: Connection, run: DagsterRun) -> None:
     if not run.external_job_origin:
         # nothing to do
         return
 
-    repository_label = run.external_job_origin.external_repository_origin.get_label()
+    repository_label = run.external_job_origin.repository_origin.get_label()
     try:
         conn.execute(
             RunTagsTable.insert().values(
                 run_id=run.run_id,
                 key=REPOSITORY_LABEL_TAG,
                 value=repository_label,
             )
```

### Comparing `dagster-1.6.9/dagster/_core/storage/runs/schema.py` & `dagster-1.7.0/dagster/_core/storage/runs/schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/runs/sql_run_storage.py` & `dagster-1.7.0/dagster/_core/storage/runs/sql_run_storage.py`

 * *Files 0% similar despite different names*

```diff
@@ -36,15 +36,15 @@
 from dagster._core.events import (
     EVENT_TYPE_TO_PIPELINE_RUN_STATUS,
     DagsterEvent,
     DagsterEventType,
     RunFailureReason,
 )
 from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
-from dagster._core.host_representation.origin import ExternalJobOrigin
+from dagster._core.remote_representation.origin import RemoteJobOrigin
 from dagster._core.snap import (
     ExecutionPlanSnapshot,
     JobSnapshot,
     create_execution_plan_snapshot_id,
     create_job_snapshot_id,
 )
 from dagster._core.storage.sql import SqlAlchemyQuery
@@ -434,26 +434,25 @@
                 end_time=check.opt_inst(row["end_time"], float) if "end_time" in row else None,
             )
             for row in rows
         ]
 
     def get_run_tags(
         self,
-        tag_keys: Optional[Sequence[str]] = None,
+        tag_keys: Sequence[str],
         value_prefix: Optional[str] = None,
         limit: Optional[int] = None,
     ) -> Sequence[Tuple[str, Set[str]]]:
         result = defaultdict(set)
         query = (
             db_select([RunTagsTable.c.key, RunTagsTable.c.value])
             .distinct()
             .order_by(RunTagsTable.c.key, RunTagsTable.c.value)
+            .where(RunTagsTable.c.key.in_(tag_keys))
         )
-        if tag_keys:
-            query = query.where(RunTagsTable.c.key.in_(tag_keys))
         if value_prefix:
             query = query.where(RunTagsTable.c.value.startswith(value_prefix))
         if limit:
             query = query.limit(limit)
         rows = self.fetchall(query)
         for r in rows:
             result[r["key"]].add(r["value"])
@@ -920,16 +919,16 @@
                 conn.execute(
                     KeyValueStoreTable.update()
                     .where(KeyValueStoreTable.c.key.in_(pairs.keys()))
                     .values(value=db.sql.case(pairs, value=KeyValueStoreTable.c.key))
                 )
 
     # Migrating run history
-    def replace_job_origin(self, run: DagsterRun, job_origin: ExternalJobOrigin) -> None:
-        new_label = job_origin.external_repository_origin.get_label()
+    def replace_job_origin(self, run: DagsterRun, job_origin: RemoteJobOrigin) -> None:
+        new_label = job_origin.repository_origin.get_label()
         with self.connect() as conn:
             conn.execute(
                 RunsTable.update()
                 .where(RunsTable.c.run_id == run.run_id)
                 .values(
                     run_body=serialize_value(run.with_job_origin(job_origin)),
                 )
```

### Comparing `dagster-1.6.9/dagster/_core/storage/runs/sqlite/alembic/alembic.ini` & `dagster-1.7.0/dagster/_core/storage/runs/sqlite/alembic/alembic.ini`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/runs/sqlite/sqlite_run_storage.py` & `dagster-1.7.0/dagster/_core/storage/runs/sqlite/sqlite_run_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/schedules/base.py` & `dagster-1.7.0/dagster/_core/storage/schedules/base.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/schedules/migration.py` & `dagster-1.7.0/dagster/_core/storage/schedules/migration.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/schedules/schema.py` & `dagster-1.7.0/dagster/_core/storage/schedules/schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/schedules/sql_schedule_storage.py` & `dagster-1.7.0/dagster/_core/storage/schedules/sql_schedule_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/schedules/sqlite/alembic/alembic.ini` & `dagster-1.7.0/dagster/_core/storage/schedules/sqlite/alembic/alembic.ini`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/schedules/sqlite/sqlite_schedule_storage.py` & `dagster-1.7.0/dagster/_core/storage/schedules/sqlite/sqlite_schedule_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/sql.py` & `dagster-1.7.0/dagster/_core/storage/sql.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/sqlalchemy_compat.py` & `dagster-1.7.0/dagster/_core/storage/sqlalchemy_compat.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/sqlite.py` & `dagster-1.7.0/dagster/_core/storage/sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/sqlite_storage.py` & `dagster-1.7.0/dagster/_core/storage/sqlite_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/tags.py` & `dagster-1.7.0/dagster/_core/storage/tags.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/temp_file_manager.py` & `dagster-1.7.0/dagster/_core/storage/temp_file_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/storage/upath_io_manager.py` & `dagster-1.7.0/dagster/_core/storage/upath_io_manager.py`

 * *Files 1% similar despite different names*

```diff
@@ -276,16 +276,16 @@
             path (UPath): The path to the partition.
             backcompat_path (Optional[UPath]): The path to the partition in the backcompat location.
 
         Returns:
             Any: The object loaded from the partition.
         """
         allow_missing_partitions = (
-            context.metadata.get("allow_missing_partitions", False)
-            if context.metadata is not None
+            context.definition_metadata.get("allow_missing_partitions", False)
+            if context.definition_metadata is not None
             else False
         )
 
         try:
             context.log.debug(self.get_loading_input_partition_log_message(path, partition_key))
             obj = self.load_from_path(context=context, path=path)
             return obj
@@ -352,16 +352,16 @@
                         )
                     )
 
                 results = await asyncio.gather(*tasks, return_exceptions=True)
 
                 # need to handle missing partitions here because exceptions don't get propagated from async calls
                 allow_missing_partitions = (
-                    context.metadata.get("allow_missing_partitions", False)
-                    if context.metadata is not None
+                    context.definition_metadata.get("allow_missing_partitions", False)
+                    if context.definition_metadata is not None
                     else False
                 )
 
                 results_without_errors = []
                 found_errors = False
                 for partition_key, result in zip(context.asset_partition_keys, results):
                     if isinstance(result, FileNotFoundError):
```

### Comparing `dagster-1.6.9/dagster/_core/system_config/composite_descent.py` & `dagster-1.7.0/dagster/_core/system_config/composite_descent.py`

 * *Files 1% similar despite different names*

```diff
@@ -218,15 +218,15 @@
 
         type_to_evaluate_against = define_node_shape(
             nodes=graph_def.nodes,
             ignored_nodes=None,
             dependency_structure=graph_def.dependency_structure,
             resource_defs=resource_defs,
             asset_layer=job_def.asset_layer,
-            node_input_source_assets=graph_def.node_input_source_assets,
+            input_assets=graph_def.input_assets,
         )
 
         # process against that new type
 
         evr = process_config(type_to_evaluate_against, mapped_graph_config)
 
         if not evr.success:
@@ -286,15 +286,15 @@
     type_to_evaluate_against = define_node_shape(
         nodes=graph_def.nodes,
         ignored_nodes=ignored_nodes,
         dependency_structure=graph_def.dependency_structure,
         parent_handle=current_stack.handle,
         resource_defs=resource_defs,
         asset_layer=asset_layer,
-        node_input_source_assets=graph_def.node_input_source_assets,
+        input_assets=graph_def.input_assets,
     )
 
     # process against that new type
 
     evr = process_config(type_to_evaluate_against, mapped_ops_config)
 
     if not evr.success:
```

### Comparing `dagster-1.6.9/dagster/_core/system_config/objects.py` & `dagster-1.7.0/dagster/_core/system_config/objects.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/telemetry.py` & `dagster-1.7.0/dagster/_core/telemetry.py`

 * *Files 1% similar despite different names*

```diff
@@ -52,15 +52,15 @@
 from dagster._core.execution.context.system import PlanOrchestrationContext
 from dagster._core.execution.plan.objects import StepSuccessData
 from dagster._core.instance import DagsterInstance
 from dagster._utils.merger import merge_dicts
 from dagster.version import __version__ as dagster_module_version
 
 if TYPE_CHECKING:
-    from dagster._core.host_representation.external import (
+    from dagster._core.remote_representation.external import (
         ExternalJob,
         ExternalRepository,
         ExternalResource,
     )
     from dagster._core.workspace.context import IWorkspaceProcessContext
 
 TELEMETRY_STR = ".telemetry"
@@ -138,18 +138,16 @@
 def _telemetry_wrapper(
     f: Callable[P, T], metadata: Optional[Mapping[str, str]] = None
 ) -> Callable[P, T]:
     metadata = check.opt_mapping_param(metadata, "metadata", key_type=str, value_type=str)
 
     if f.__name__ not in TELEMETRY_WHITELISTED_FUNCTIONS:
         raise DagsterInvariantViolationError(
-            "Attempted to log telemetry for function {name} that is not in telemetry whitelisted "
-            "functions list: {whitelist}.".format(
-                name=f.__name__, whitelist=TELEMETRY_WHITELISTED_FUNCTIONS
-            )
+            f"Attempted to log telemetry for function {f.__name__} that is not in telemetry whitelisted "
+            f"functions list: {TELEMETRY_WHITELISTED_FUNCTIONS}."
         )
 
     var_names = f.__code__.co_varnames
     try:
         instance_index = var_names.index("instance")
     except ValueError as e:
         raise DagsterInvariantViolationError(
@@ -457,15 +455,15 @@
 
 
 def hash_name(name: str) -> str:
     return hashlib.sha256(name.encode("utf-8")).hexdigest()
 
 
 def get_stats_from_external_repo(external_repo: "ExternalRepository") -> Mapping[str, str]:
-    from dagster._core.host_representation.external_data import (
+    from dagster._core.remote_representation.external_data import (
         ExternalDynamicPartitionsDefinitionData,
         ExternalMultiPartitionsDefinitionData,
     )
 
     num_pipelines_in_repo = len(external_repo.get_all_external_jobs())
     num_schedules_in_repo = len(external_repo.get_external_schedules())
     num_sensors_in_repo = len(external_repo.get_external_sensors())
@@ -591,15 +589,15 @@
 
 def log_external_repo_stats(
     instance: DagsterInstance,
     source: str,
     external_repo: "ExternalRepository",
     external_job: Optional["ExternalJob"] = None,
 ):
-    from dagster._core.host_representation.external import ExternalJob, ExternalRepository
+    from dagster._core.remote_representation.external import ExternalJob, ExternalRepository
 
     check.inst_param(instance, "instance", DagsterInstance)
     check.str_param(source, "source")
     check.inst_param(external_repo, "external_repo", ExternalRepository)
     check.opt_inst_param(external_job, "external_job", ExternalJob)
 
     if _get_instance_telemetry_enabled(instance):
@@ -774,19 +772,18 @@
         metadata=metadata,
     )
 
 
 TELEMETRY_TEXT = """
   %(telemetry)s
 
-  As an open source project, we collect usage statistics to inform development priorities. For more
+  As an open-source project, we collect usage statistics to inform development priorities. For more
   information, read https://docs.dagster.io/getting-started/telemetry.
 
-  We will not see or store solid definitions, pipeline definitions, modes, resources, context, or
-  any data that is processed within solids and pipelines.
+  We will not see or store any data that is processed by your code.
 
   To opt-out, add the following to $DAGSTER_HOME/dagster.yaml, creating that file if necessary:
 
     telemetry:
       enabled: false
 """ % {"telemetry": click.style("Telemetry:", fg="blue", bold=True)}
```

### Comparing `dagster-1.6.9/dagster/_core/telemetry_upload.py` & `dagster-1.7.0/dagster/_core/telemetry_upload.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/test_utils.py` & `dagster-1.7.0/dagster/_core/test_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -46,20 +46,19 @@
 from dagster._core.definitions.graph_definition import GraphDefinition
 from dagster._core.definitions.job_definition import JobDefinition
 from dagster._core.definitions.node_definition import NodeDefinition
 from dagster._core.definitions.source_asset import SourceAsset
 from dagster._core.definitions.unresolved_asset_job_definition import define_asset_job
 from dagster._core.errors import DagsterUserCodeUnreachableError
 from dagster._core.events import DagsterEvent
-from dagster._core.host_representation.origin import (
-    ExternalJobOrigin,
-    InProcessCodeLocationOrigin,
-)
 from dagster._core.instance import DagsterInstance
 from dagster._core.launcher import RunLauncher
+from dagster._core.remote_representation.origin import (
+    InProcessCodeLocationOrigin,
+)
 from dagster._core.run_coordinator import RunCoordinator, SubmitRunContext
 from dagster._core.secrets import SecretsLoader
 from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus, RunsFilter
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
 from dagster._core.workspace.context import WorkspaceProcessContext, WorkspaceRequestContext
 from dagster._core.workspace.load_target import WorkspaceLoadTarget
 from dagster._serdes import ConfigurableClass
@@ -422,15 +421,15 @@
         self._inst_data = inst_data
         self._queue = []
 
         super().__init__()
 
     def submit_run(self, context: SubmitRunContext):
         dagster_run = context.dagster_run
-        check.inst(dagster_run.external_job_origin, ExternalJobOrigin)
+        check.not_none(dagster_run.external_job_origin)
         self._queue.append(dagster_run)
         return dagster_run
 
     def queue(self):
         return self._queue
 
     @classmethod
@@ -618,24 +617,27 @@
     counts = counter.counts()
     assert counts["foo"] == 20
     assert counts["bar"] == 10
 
 
 def wait_for_futures(futures: Dict[str, Future], timeout: Optional[float] = None):
     start_time = time.time()
+    results = {}
     for target_id, future in futures.copy().items():
         if timeout is not None:
             future_timeout = max(0, timeout - (time.time() - start_time))
         else:
             future_timeout = None
 
         if not future.done():
-            future.result(timeout=future_timeout)
+            results[target_id] = future.result(timeout=future_timeout)
             del futures[target_id]
 
+    return results
+
 
 class SingleThreadPoolExecutor(ThreadPoolExecutor):
     """Utility class for testing threadpool executor logic which executes functions in a single
     thread, for easier unit testing.
     """
 
     def __init__(self):
@@ -730,15 +732,13 @@
     assets: Sequence[Union[AssetsDefinition, SourceAsset]],
     *,
     selection: Optional[CoercibleToAssetSelection] = None,
     name: str = "asset_job",
     resources: Mapping[str, object] = {},
     **kwargs: Any,
 ) -> JobDefinition:
-    assets_defs = [a for a in assets if isinstance(a, AssetsDefinition)]
-    source_assets = [a for a in assets if isinstance(a, SourceAsset)]
-    selection = selection or assets_defs
+    selection = selection or [a for a in assets if a.is_executable]
     return Definitions(
-        assets=[*assets_defs, *source_assets],
+        assets=assets,
         jobs=[define_asset_job(name, selection, **kwargs)],
         resources=resources,
     ).get_job_def(name)
```

### Comparing `dagster-1.6.9/dagster/_core/types/builtin_config_schemas.py` & `dagster-1.7.0/dagster/_core/types/builtin_config_schemas.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/types/config_schema.py` & `dagster-1.7.0/dagster/_core/types/config_schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/types/dagster_type.py` & `dagster-1.7.0/dagster/_core/types/dagster_type.py`

 * *Files 1% similar despite different names*

```diff
@@ -262,16 +262,16 @@
 
     @property
     def supports_fan_in(self) -> bool:
         return False
 
     def get_inner_type_for_fan_in(self) -> "DagsterType":
         check.failed(
-            "DagsterType {name} does not support fan-in, should have checked supports_fan_in before"
-            " calling getter.".format(name=self.display_name)
+            f"DagsterType {self.display_name} does not support fan-in, should have checked supports_fan_in before"
+            " calling getter."
         )
 
     def get_resource_requirements(
         self, _outer_context: TypingOptional[object] = None
     ) -> TypingIterator[ResourceRequirement]:
         for resource_key in sorted(list(self.required_resource_keys)):
             yield TypeResourceRequirement(key=resource_key, type_display_name=self.display_name)
@@ -326,16 +326,16 @@
 
     @abstractmethod
     def type_check_scalar_value(self, _value) -> TypeCheck:
         raise NotImplementedError()
 
 
 def _typemismatch_error_str(value: object, expected_type_desc: str) -> str:
-    return 'Value "{value}" of python type "{python_type}" must be a {type_desc}.'.format(
-        value=value, python_type=type(value).__name__, type_desc=expected_type_desc
+    return (
+        f'Value "{value}" of python type "{type(value).__name__}" must be a {expected_type_desc}.'
     )
 
 
 def _fail_if_not_of_type(
     value: object, value_type: t.Type[t.Any], value_type_desc: str
 ) -> TypeCheck:
     if not isinstance(value, value_type):
@@ -994,17 +994,17 @@
             if dagster_type.unique_name not in type_dict_by_name:
                 type_dict_by_name[dagster_type.unique_name] = dagster_type
                 continue
 
             if type_dict_by_name[dagster_type.unique_name] is not dagster_type:
                 raise DagsterInvalidDefinitionError(
                     (
-                        'You have created two dagster types with the same name "{type_name}". '
+                        f'You have created two dagster types with the same name "{dagster_type.display_name}". '
                         "Dagster types have must have unique names."
-                    ).format(type_name=dagster_type.display_name)
+                    )
                 )
 
         if isinstance(node_def, GraphDefinition):
             for child_node_def in node_def.node_defs:
                 process_node_def(child_node_def)
 
     for node_def in node_defs:
```

### Comparing `dagster-1.6.9/dagster/_core/types/decorator.py` & `dagster-1.7.0/dagster/_core/types/decorator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/types/loadable_target_origin.py` & `dagster-1.7.0/dagster/_core/types/loadable_target_origin.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/types/primitive_mapping.py` & `dagster-1.7.0/dagster/_core/types/primitive_mapping.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/types/python_dict.py` & `dagster-1.7.0/dagster/_core/types/python_dict.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/types/python_set.py` & `dagster-1.7.0/dagster/_core/types/python_set.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/types/python_tuple.py` & `dagster-1.7.0/dagster/_core/types/python_tuple.py`

 * *Files 11% similar despite different names*

```diff
@@ -49,16 +49,16 @@
                 description=f"Value should be a tuple, got a {type(value)}",
             )
 
         if len(value) != len(self.dagster_types):
             return TypeCheck(
                 success=False,
                 description=(
-                    "Tuple with key {key} requires {n} entries, received {m} values"
-                ).format(key=self.key, n=len(self.dagster_types), m=len(value)),
+                    f"Tuple with key {self.key} requires {len(self.dagster_types)} entries, received {len(value)} values"
+                ),
             )
 
         for item, dagster_type in zip(value, self.dagster_types):
             item_check = dagster_type.type_check(context, item)
             if not item_check.success:
                 return item_check
```

### Comparing `dagster-1.6.9/dagster/_core/types/transform_typing.py` & `dagster-1.7.0/dagster/_core/types/transform_typing.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/utility_ops.py` & `dagster-1.7.0/dagster/_core/utility_ops.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/utils.py` & `dagster-1.7.0/dagster/_core/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,30 @@
 import os
 import random
 import re
 import string
 import uuid
 import warnings
 from collections import OrderedDict
-from concurrent.futures import ThreadPoolExecutor
+from concurrent.futures import Future, ThreadPoolExecutor
 from contextvars import copy_context
 from typing import (
     AbstractSet,
     Any,
     Iterable,
     Mapping,
     Optional,
     Sequence,
     Tuple,
     TypedDict,
     TypeVar,
     Union,
     cast,
 )
+from weakref import WeakSet
 
 import toposort as toposort_
 from typing_extensions import Final
 
 import dagster._check as check
 from dagster._utils import library_version_from_core_version, parse_package_version
 
@@ -149,34 +150,32 @@
         thread_name_prefix: str = "",
         initializer: Any = None,
         initargs: Tuple[Any, ...] = (),
     ) -> None:
         super().__init__(max_workers, thread_name_prefix, initializer, initargs)
         # The default threadpool class doesn't track the futures it creates,
         # so if we want to be able to count the number of running futures, we need to do it ourselves.
-        self._all_futures = []
+        self._tracked_futures: WeakSet[Future] = WeakSet()
 
-    def submit(self, fn, *args, **kwargs):
+    def submit(self, fn, *args, **kwargs) -> Future:
         new_future = super().submit(fn, *args, **kwargs)
-        self._all_futures = [
-            future for future in self._all_futures if not future.done()
-        ]  # clean up done futures
-        self._all_futures.append(new_future)
+        self._tracked_futures.add(new_future)
         return new_future
 
     @property
     def max_workers(self) -> int:
         return self._max_workers
 
     @property
+    def weak_tracked_futures_count(self) -> int:
+        return len(self._tracked_futures)
+
+    @property
     def num_running_futures(self) -> int:
-        return (
-            len([future for future in self._all_futures if not future.done()])
-            - self.num_queued_futures
-        )
+        return sum(1 for f in self._tracked_futures if not f.done()) - self.num_queued_futures
 
     @property
     def num_queued_futures(self) -> int:
         return self._work_queue.qsize()
 
     def get_current_utilization_metrics(self) -> RequestUtilizationMetrics:
         return {
```

### Comparing `dagster-1.6.9/dagster/_core/workspace/autodiscovery.py` & `dagster-1.7.0/dagster/_core/workspace/autodiscovery.py`

 * *Files 3% similar despite different names*

```diff
@@ -76,40 +76,33 @@
     if len(loadable_jobs) == 1:
         return loadable_jobs
 
     elif len(loadable_jobs) > 1:
         target_type = "job" if len(loadable_jobs) > 1 else "pipeline"
         raise DagsterInvariantViolationError(
             (
-                'No repository and more than one {target_type} found in "{module_name}". If you'
-                " load a file or module directly it must have only one {target_type} in scope."
-                " Found {target_type}s defined in variables or decorated functions:"
-                " {pipeline_symbols}."
-            ).format(
-                module_name=module.__name__,
-                pipeline_symbols=repr([p.attribute for p in loadable_jobs]),
-                target_type=target_type,
+                f'No repository and more than one {target_type} found in "{module.__name__}". If you'
+                f" load a file or module directly it must have only one {target_type} in scope."
+                f" Found {target_type}s defined in variables or decorated functions:"
+                f" {[p.attribute for p in loadable_jobs]!r}."
             )
         )
 
     loadable_graphs = _loadable_targets_of_type(module, GraphDefinition)
 
     if len(loadable_graphs) == 1:
         return loadable_graphs
 
     elif len(loadable_graphs) > 1:
         raise DagsterInvariantViolationError(
             (
-                'More than one graph found in "{module_name}". '
+                f'More than one graph found in "{module.__name__}". '
                 "If you load a file or module directly and it has no repositories, jobs, or "
                 "pipelines in scope, it must have no more than one graph in scope. "
-                "Found graphs defined in variables or decorated functions: {graph_symbols}."
-            ).format(
-                module_name=module.__name__,
-                graph_symbols=repr([g.attribute for g in loadable_graphs]),
+                f"Found graphs defined in variables or decorated functions: {[g.attribute for g in loadable_graphs]!r}."
             )
         )
 
     module_assets, module_source_assets, _ = assets_from_modules([module])
     if len(module_assets) > 0 or len(module_source_assets) > 0:
         return [LoadableTarget(LOAD_ALL_ASSETS, [*module_assets, *module_source_assets])]
```

### Comparing `dagster-1.6.9/dagster/_core/workspace/config_schema.py` & `dagster-1.7.0/dagster/_core/workspace/config_schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_core/workspace/context.py` & `dagster-1.7.0/dagster/_core/workspace/context.py`

 * *Files 0% similar despite different names*

```diff
@@ -13,36 +13,36 @@
 import dagster._check as check
 from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.errors import (
     DagsterCodeLocationLoadError,
     DagsterCodeLocationNotFoundError,
 )
 from dagster._core.execution.plan.state import KnownExecutionState
-from dagster._core.host_representation import (
+from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation import (
     CodeLocation,
     CodeLocationOrigin,
     ExternalExecutionPlan,
     ExternalJob,
     ExternalPartitionSet,
     GrpcServerCodeLocation,
     RepositoryHandle,
 )
-from dagster._core.host_representation.grpc_server_registry import (
+from dagster._core.remote_representation.grpc_server_registry import (
     GrpcServerRegistry,
 )
-from dagster._core.host_representation.grpc_server_state_subscriber import (
+from dagster._core.remote_representation.grpc_server_state_subscriber import (
     LocationStateChangeEvent,
     LocationStateChangeEventType,
     LocationStateSubscriber,
 )
-from dagster._core.host_representation.origin import (
+from dagster._core.remote_representation.origin import (
     GrpcServerCodeLocationOrigin,
     ManagedGrpcPythonEnvCodeLocationOrigin,
 )
-from dagster._core.instance import DagsterInstance
 from dagster._utils.error import SerializableErrorInfo, serializable_error_info_from_exc_info
 
 from .load_target import WorkspaceLoadTarget
 from .permissions import (
     PermissionResult,
     get_location_scoped_user_permissions,
     get_user_permissions,
@@ -52,15 +52,15 @@
     CodeLocationLoadStatus,
     CodeLocationStatusEntry,
     IWorkspace,
     location_status_from_location_entry,
 )
 
 if TYPE_CHECKING:
-    from dagster._core.host_representation import (
+    from dagster._core.remote_representation import (
         ExternalPartitionConfigData,
         ExternalPartitionExecutionErrorData,
         ExternalPartitionNamesData,
         ExternalPartitionSetExecutionParamData,
         ExternalPartitionTagsData,
     )
```

### Comparing `dagster-1.6.9/dagster/_core/workspace/load.py` & `dagster-1.7.0/dagster/_core/workspace/load.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 import os
 from collections import OrderedDict
 from typing import TYPE_CHECKING, Dict, Mapping, Optional, Sequence, Tuple, Union, cast
 
 import dagster._check as check
 from dagster._core.code_pointer import rebase_file
-from dagster._core.host_representation.origin import (
+from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.origin import (
     CodeLocationOrigin,
     GrpcServerCodeLocationOrigin,
     ManagedGrpcPythonEnvCodeLocationOrigin,
 )
-from dagster._core.instance import DagsterInstance
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
 from dagster._utils.yaml_utils import load_yaml_from_path
 
 from .config_schema import ensure_workspace_config
 
 if TYPE_CHECKING:
     from .context import WorkspaceProcessContext
@@ -35,17 +35,17 @@
 
     workspace_configs = [load_yaml_from_path(yaml_path) for yaml_path in yaml_paths]
     origins_by_name: Dict[str, CodeLocationOrigin] = OrderedDict()
     for workspace_config, yaml_path in zip(workspace_configs, yaml_paths):
         check.invariant(
             workspace_config is not None,
             (
-                "Could not parse a workspace config from the yaml file at {yaml_path}. Check that "
+                f"Could not parse a workspace config from the yaml file at {os.path.abspath(yaml_path)}. Check that "
                 "the file contains valid yaml."
-            ).format(yaml_path=os.path.abspath(yaml_path)),
+            ),
         )
 
         for k, v in location_origins_from_config(cast(Dict, workspace_config), yaml_path).items():
             origins_by_name[k] = v
 
     return list(origins_by_name.values())
 
@@ -56,17 +56,15 @@
     workspace_config = ensure_workspace_config(workspace_config, yaml_path)
     location_configs = check.list_elem(workspace_config, "load_from", of_type=dict)
     location_origins: Dict[str, CodeLocationOrigin] = OrderedDict()
     for location_config in location_configs:
         origin = _location_origin_from_location_config(location_config, yaml_path)
         check.invariant(
             location_origins.get(origin.location_name) is None,
-            'Cannot have multiple locations with the same name, got multiple "{name}"'.format(
-                name=origin.location_name,
-            ),
+            f'Cannot have multiple locations with the same name, got multiple "{origin.location_name}"',
         )
 
         location_origins[origin.location_name] = origin
 
     return location_origins
```

### Comparing `dagster-1.6.9/dagster/_core/workspace/load_target.py` & `dagster-1.7.0/dagster/_core/workspace/load_target.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import os
 from abc import ABC, abstractmethod
 from typing import NamedTuple, Optional, Sequence
 
 import tomli
 
-from dagster._core.host_representation.origin import (
+from dagster._core.remote_representation.origin import (
     CodeLocationOrigin,
     GrpcServerCodeLocationOrigin,
     ManagedGrpcPythonEnvCodeLocationOrigin,
 )
 
 from .load import (
     location_origin_from_module_name,
```

### Comparing `dagster-1.6.9/dagster/_core/workspace/permissions.py` & `dagster-1.7.0/dagster/_core/workspace/permissions.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_daemon/__init__.py` & `dagster-1.7.0/dagster/_daemon/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_daemon/asset_daemon.py` & `dagster-1.7.0/dagster/_daemon/asset_daemon.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,17 +14,17 @@
 import dagster._check as check
 from dagster._core.definitions.asset_daemon_context import AssetDaemonContext
 from dagster._core.definitions.asset_daemon_cursor import (
     AssetDaemonCursor,
     LegacyAssetDaemonCursorWrapper,
     backcompat_deserialize_asset_daemon_cursor_str,
 )
-from dagster._core.definitions.asset_graph import AssetGraph
+from dagster._core.definitions.base_asset_graph import BaseAssetGraph
 from dagster._core.definitions.events import AssetKey
-from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
+from dagster._core.definitions.remote_asset_graph import RemoteAssetGraph
 from dagster._core.definitions.repository_definition.valid_definitions import (
     SINGLETON_REPOSITORY_NAME,
 )
 from dagster._core.definitions.run_request import (
     InstigatorType,
     RunRequest,
 )
@@ -33,20 +33,20 @@
     SensorType,
 )
 from dagster._core.errors import (
     DagsterCodeLocationLoadError,
     DagsterUserCodeUnreachableError,
 )
 from dagster._core.execution.submit_asset_runs import submit_asset_run
-from dagster._core.host_representation import (
+from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation import (
     ExternalSensor,
 )
-from dagster._core.host_representation.external import ExternalRepository
-from dagster._core.host_representation.origin import ExternalInstigatorOrigin
-from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.external import ExternalRepository
+from dagster._core.remote_representation.origin import RemoteInstigatorOrigin
 from dagster._core.scheduler.instigation import (
     InstigatorState,
     InstigatorStatus,
     InstigatorTick,
     SensorInstigatorData,
     TickData,
     TickStatus,
@@ -56,23 +56,23 @@
     ASSET_EVALUATION_ID_TAG,
     AUTO_MATERIALIZE_TAG,
     AUTO_OBSERVE_TAG,
     SENSOR_NAME_TAG,
 )
 from dagster._core.utils import InheritContextThreadPoolExecutor, make_new_run_id
 from dagster._core.workspace.context import IWorkspaceProcessContext
-from dagster._daemon.daemon import DaemonIterator, DagsterDaemon
+from dagster._daemon.daemon import DaemonIterator, DagsterDaemon, SpanMarker
 from dagster._daemon.sensor import is_under_min_interval, mark_sensor_state_for_tick
+from dagster._daemon.utils import DaemonErrorCapture
 from dagster._serdes import serialize_value
 from dagster._serdes.serdes import deserialize_value
 from dagster._utils import (
     SingleInstigatorDebugCrashFlags,
     check_for_debug_crash,
 )
-from dagster._utils.error import serializable_error_info_from_exc_info
 
 _LEGACY_PRE_SENSOR_AUTO_MATERIALIZE_CURSOR_KEY = "ASSET_DAEMON_CURSOR"
 _PRE_SENSOR_AUTO_MATERIALIZE_CURSOR_KEY = "ASSET_DAEMON_CURSOR_NEW"
 _PRE_SENSOR_ASSET_DAEMON_PAUSED_KEY = "ASSET_DAEMON_PAUSED"
 _MIGRATED_CURSOR_TO_SENSORS_KEY = "MIGRATED_CURSOR_TO_SENSORS"
 
 
@@ -114,15 +114,15 @@
 def set_auto_materialize_paused(instance: DagsterInstance, paused: bool):
     instance.daemon_cursor_storage.set_cursor_values(
         {_PRE_SENSOR_ASSET_DAEMON_PAUSED_KEY: "true" if paused else "false"}
     )
 
 
 def _get_pre_sensor_auto_materialize_cursor(
-    instance: DagsterInstance, full_asset_graph: Optional[AssetGraph]
+    instance: DagsterInstance, full_asset_graph: Optional[BaseAssetGraph]
 ) -> AssetDaemonCursor:
     """Gets a deserialized cursor by either reading from the new cursor key and simply deserializing
     the value, or by reading from the old cursor key and converting the legacy cursor into the
     updated format.
     """
     serialized_cursor = instance.daemon_cursor_storage.get_cursor_values(
         {_PRE_SENSOR_AUTO_MATERIALIZE_CURSOR_KEY}
@@ -141,15 +141,15 @@
             else AssetDaemonCursor.empty()
         )
     else:
         return deserialize_value(serialized_cursor, AssetDaemonCursor)
 
 
 def get_current_evaluation_id(
-    instance: DagsterInstance, sensor_origin: Optional[ExternalInstigatorOrigin]
+    instance: DagsterInstance, sensor_origin: Optional[RemoteInstigatorOrigin]
 ) -> Optional[int]:
     if not sensor_origin:
         cursor = _get_pre_sensor_auto_materialize_cursor(instance, None)
     else:
         instigator_state = check.not_none(instance.schedule_storage).get_instigator_state(
             sensor_origin.get_id(), sensor_origin.get_selector().get_id()
         )
@@ -175,15 +175,15 @@
     serialized_bytes = serialize_value(cursor).encode("utf-8")
     compressed_bytes = zlib.compress(serialized_bytes)
     encoded_cursor = base64.b64encode(compressed_bytes).decode("utf-8")
     return VERSION + encoded_cursor
 
 
 def asset_daemon_cursor_from_instigator_serialized_cursor(
-    serialized_cursor: Optional[str], asset_graph: Optional[AssetGraph]
+    serialized_cursor: Optional[str], asset_graph: Optional[BaseAssetGraph]
 ) -> AssetDaemonCursor:
     """This method decompresses the serialized cursor and returns a deserialized cursor object,
     converting from the legacy cursor format if necessary.
     """
     if serialized_cursor is None:
         return AssetDaemonCursor.empty()
 
@@ -265,23 +265,23 @@
                 exception_value, (DagsterUserCodeUnreachableError, DagsterCodeLocationLoadError)
             ):
                 try:
                     raise Exception(
                         "Unable to reach the code server. Auto-materialization will resume once the code server is available."
                     ) from exception_value
                 except:
-                    error_data = serializable_error_info_from_exc_info(sys.exc_info())
+                    error_data = DaemonErrorCapture.on_exception(sys.exc_info())
                     self.update_state(
                         TickStatus.FAILURE,
                         error=error_data,
                         # don't increment the failure count - retry until the server is available again
                         failure_count=self._tick.failure_count,
                     )
             else:
-                error_data = serializable_error_info_from_exc_info(sys.exc_info())
+                error_data = DaemonErrorCapture.on_exception(sys.exc_info())
                 self.update_state(
                     TickStatus.FAILURE, error=error_data, failure_count=self._tick.failure_count + 1
                 )
 
         check.invariant(
             self._tick.status != TickStatus.STARTED,
             "Tick must be in a terminal state when the AutoMaterializeLaunchContext is closed",
@@ -331,15 +331,15 @@
     @classmethod
     def daemon_type(cls) -> str:
         return "ASSET"
 
     def _get_print_sensor_name(self, sensor: Optional[ExternalSensor]) -> str:
         if not sensor:
             return ""
-        repo_origin = sensor.get_external_origin().external_repository_origin
+        repo_origin = sensor.get_external_origin().repository_origin
         repo_name = repo_origin.repository_name
         location_name = repo_origin.code_location_origin.location_name
         repo_name = (
             location_name
             if repo_name == SINGLETON_REPOSITORY_NAME
             else f"{repo_name}@{location_name}"
         )
@@ -410,21 +410,22 @@
                         max_workers=self._settings.get("num_workers"),
                         thread_name_prefix="asset_daemon_worker",
                     )
                 )
 
             while True:
                 start_time = pendulum.now("UTC").timestamp()
+                yield SpanMarker.START_SPAN
                 yield from self._run_iteration_impl(
                     workspace_process_context,
                     threadpool_executor=threadpool_executor,
                     amp_tick_futures=amp_tick_futures,
                     debug_crash_flags={},
                 )
-                yield None
+                yield SpanMarker.END_SPAN
                 end_time = pendulum.now("UTC").timestamp()
                 loop_duration = end_time - start_time
                 sleep_time = max(0, MIN_INTERVAL_LOOP_SECONDS - loop_duration)
                 shutdown_event.wait(sleep_time)
                 yield None
 
     def _run_iteration_impl(
@@ -481,15 +482,15 @@
                 )
             }
 
             if not self._checked_migration_to_sensors:
                 if not get_has_migrated_to_sensors(instance):
                     # Do a one-time migration to create the cursors for each sensor, based on the
                     # existing cursor for the legacy AMP tick
-                    asset_graph = ExternalAssetGraph.from_workspace(workspace)
+                    asset_graph = workspace.asset_graph
                     pre_sensor_cursor = _get_pre_sensor_auto_materialize_cursor(
                         instance, asset_graph
                     )
                     if pre_sensor_cursor != AssetDaemonCursor.empty():
                         self._logger.info(
                             "Translating legacy cursor into a new cursor for each new automation policy sensor"
                         )
@@ -643,15 +644,15 @@
         sensor: Optional[ExternalSensor],
         debug_crash_flags: SingleInstigatorDebugCrashFlags,  # TODO No longer single instigator
     ):
         evaluation_time = pendulum.now("UTC")
 
         workspace = workspace_process_context.create_request_context()
 
-        asset_graph = ExternalAssetGraph.from_workspace(workspace)
+        asset_graph = workspace.asset_graph
 
         instance: DagsterInstance = workspace_process_context.instance
         error_info = None
 
         if sensor:
             auto_materialize_instigator_state = check.not_none(
                 instance.get_instigator_state(sensor.get_external_origin_id(), sensor.selector_id)
@@ -667,33 +668,33 @@
             auto_materialize_instigator_state = None
 
         try:
             print_group_name = self._get_print_sensor_name(sensor)
 
             if sensor:
                 eligible_keys = check.not_none(sensor.asset_selection).resolve(
-                    ExternalAssetGraph.from_external_repository(check.not_none(repository))
+                    check.not_none(repository).asset_graph
                 )
             else:
                 eligible_keys = {
                     *asset_graph.materializable_asset_keys,
                     *asset_graph.external_asset_keys,
                 }
 
             auto_materialize_asset_keys = {
                 target_key
                 for target_key in eligible_keys
-                if asset_graph.get_auto_materialize_policy(target_key) is not None
+                if asset_graph.get(target_key).auto_materialize_policy is not None
             }
             num_target_assets = len(auto_materialize_asset_keys)
 
             auto_observe_asset_keys = {
                 key
                 for key in eligible_keys
-                if asset_graph.get_auto_observe_interval_minutes(key) is not None
+                if asset_graph.get(key).auto_observe_interval_minutes is not None
             }
             num_auto_observe_assets = len(auto_observe_asset_keys)
 
             if not auto_materialize_asset_keys and not auto_observe_asset_keys:
                 self._logger.debug(
                     f"No assets that require auto-materialize checks{print_group_name}"
                 )
@@ -817,26 +818,29 @@
                     auto_materialize_asset_keys,
                     stored_cursor,
                     auto_observe_asset_keys,
                     debug_crash_flags,
                     is_retry=(retry_tick is not None),
                 )
         except Exception:
-            error_info = serializable_error_info_from_exc_info(sys.exc_info())
-            self._logger.exception("Auto-materialize daemon caught an error")
+            error_info = DaemonErrorCapture.on_exception(
+                exc_info=sys.exc_info(),
+                logger=self._logger,
+                log_message="Auto-materialize daemon caught an error",
+            )
 
         yield error_info
 
     def _evaluate_auto_materialize_tick(
         self,
         tick_context: AutoMaterializeLaunchContext,
         tick: InstigatorTick,
         sensor: Optional[ExternalSensor],
         workspace_process_context: IWorkspaceProcessContext,
-        asset_graph: ExternalAssetGraph,
+        asset_graph: RemoteAssetGraph,
         auto_materialize_asset_keys: Set[AssetKey],
         stored_cursor: AssetDaemonCursor,
         auto_observe_asset_keys: Set[AssetKey],
         debug_crash_flags: SingleInstigatorDebugCrashFlags,
         is_retry: bool,
     ):
         evaluation_id = check.not_none(tick.tick_data.auto_materialize_evaluation_id)
@@ -855,15 +859,15 @@
                 evaluation_records = (
                     schedule_storage.get_auto_materialize_evaluations_for_evaluation_id(
                         evaluation_id
                     )
                 )
                 evaluations_by_asset_key = {
                     evaluation_record.asset_key: evaluation_record.get_evaluation_with_run_ids(
-                        partitions_def=asset_graph.get_partitions_def(evaluation_record.asset_key)
+                        partitions_def=asset_graph.get(evaluation_record.asset_key).partitions_def
                     )
                     for evaluation_record in evaluation_records
                 }
             else:
                 evaluations_by_asset_key = {}
         else:
             sensor_tags = {SENSOR_NAME_TAG: sensor.name, **sensor.run_tags} if sensor else {}
```

### Comparing `dagster-1.6.9/dagster/_daemon/auto_run_reexecution/auto_run_reexecution.py` & `dagster-1.7.0/dagster/_daemon/auto_run_reexecution/auto_run_reexecution.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 from dagster._core.storage.tags import (
     MAX_RETRIES_TAG,
     RETRY_NUMBER_TAG,
     RETRY_STRATEGY_TAG,
     RUN_FAILURE_REASON_TAG,
 )
 from dagster._core.workspace.context import IWorkspaceProcessContext
-from dagster._utils.error import serializable_error_info_from_exc_info
+from dagster._daemon.utils import DaemonErrorCapture
 
 DEFAULT_REEXECUTION_POLICY = ReexecutionStrategy.FROM_FAILURE
 
 
 def filter_runs_to_should_retry(
     runs: Sequence[DagsterRun], instance: DagsterInstance, default_max_retries: int
 ) -> Iterator[Tuple[DagsterRun, int]]:
@@ -109,15 +109,15 @@
     if not failed_run.external_job_origin:
         instance.report_engine_event(
             "Run does not have an external job origin, unable to retry the run.",
             failed_run,
         )
         return
 
-    origin = failed_run.external_job_origin.external_repository_origin
+    origin = failed_run.external_job_origin.repository_origin
     code_location = workspace.get_code_location(origin.code_location_origin.location_name)
     repo_name = origin.repository_name
 
     if not code_location.has_repository(repo_name):
         instance.report_engine_event(
             f"Could not find repository {repo_name} in location {code_location.name}, unable to"
             " retry the run. It was likely renamed or deleted.",
@@ -190,13 +190,13 @@
         workspace_process_context.instance.run_retries_max_retries,
     ):
         yield
 
         try:
             retry_run(run, retry_number, workspace_process_context)
         except Exception:
-            error_info = serializable_error_info_from_exc_info(sys.exc_info())
+            error_info = DaemonErrorCapture.on_exception(exc_info=sys.exc_info())
             workspace_process_context.instance.report_engine_event(
                 "Failed to retry run",
                 run,
                 engine_event_data=EngineEventData(error=error_info),
             )
```

### Comparing `dagster-1.6.9/dagster/_daemon/auto_run_reexecution/event_log_consumer.py` & `dagster-1.7.0/dagster/_daemon/auto_run_reexecution/event_log_consumer.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_daemon/backfill.py` & `dagster-1.7.0/dagster/_daemon/backfill.py`

 * *Files 9% similar despite different names*

```diff
@@ -2,15 +2,16 @@
 import sys
 from typing import Iterable, Mapping, Optional, Sequence, cast
 
 from dagster._core.execution.asset_backfill import execute_asset_backfill_iteration
 from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
 from dagster._core.execution.job_backfill import execute_job_backfill_iteration
 from dagster._core.workspace.context import IWorkspaceProcessContext
-from dagster._utils.error import SerializableErrorInfo, serializable_error_info_from_exc_info
+from dagster._daemon.utils import DaemonErrorCapture
+from dagster._utils.error import SerializableErrorInfo
 
 
 def execute_backfill_iteration(
     workspace_process_context: IWorkspaceProcessContext,
     logger: logging.Logger,
     debug_crash_flags: Optional[Mapping[str, int]] = None,
 ) -> Iterable[Optional[SerializableErrorInfo]]:
@@ -50,13 +51,16 @@
                     backfill, logger, workspace_process_context, instance
                 )
             else:
                 yield from execute_job_backfill_iteration(
                     backfill, logger, workspace_process_context, debug_crash_flags, instance
                 )
         except Exception:
-            error_info = serializable_error_info_from_exc_info(sys.exc_info())
+            error_info = DaemonErrorCapture.on_exception(
+                sys.exc_info(),
+                logger=logger,
+                log_message=f"Backfill failed for {backfill.backfill_id}",
+            )
             instance.update_backfill(
                 backfill.with_status(BulkActionStatus.FAILED).with_error(error_info)
             )
-            logger.error(f"Backfill failed for {backfill.backfill_id}: {error_info.to_string()}")
             yield error_info
```

### Comparing `dagster-1.6.9/dagster/_daemon/cli/__init__.py` & `dagster-1.7.0/dagster/_daemon/cli/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_daemon/controller.py` & `dagster-1.7.0/dagster/_daemon/controller.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 from types import TracebackType
 from typing import Callable, Dict, Iterable, Iterator, Mapping, Optional, Sequence, Type
 
 import pendulum
 from typing_extensions import Self
 
 import dagster._check as check
-from dagster._core.host_representation.grpc_server_registry import GrpcServerRegistry
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.grpc_server_registry import GrpcServerRegistry
 from dagster._core.workspace.context import IWorkspaceProcessContext, WorkspaceProcessContext
 from dagster._core.workspace.load_target import WorkspaceLoadTarget
 from dagster._daemon.asset_daemon import AssetDaemon
 from dagster._daemon.auto_run_reexecution.event_log_consumer import EventLogConsumerDaemon
 from dagster._daemon.daemon import (
     BackfillDaemon,
     DagsterDaemon,
@@ -44,14 +44,17 @@
 
 THREAD_CHECK_INTERVAL = 5
 
 HEARTBEAT_CHECK_INTERVAL = 60
 
 RELOAD_WORKSPACE_INTERVAL = 60
 
+# Number of seconds the workspace can fail to refresh before restarting the daemon.
+DEFAULT_WORKSPACE_FRESHNESS_TOLERANCE = 300
+
 # Amount of time that a local code server spun up by the daemon will keep running
 # after it is no longer receiving any heartbeat pings - for this duration there may be
 # multiple code server processes running
 DAEMON_GRPC_SERVER_HEARTBEAT_TTL = 20
 
 
 def _sorted_quoted(strings: Iterable[str]) -> str:
@@ -103,24 +106,25 @@
         workspace_process_context = stack.enter_context(
             WorkspaceProcessContext(
                 instance=instance,
                 workspace_load_target=workspace_load_target,
                 grpc_server_registry=grpc_server_registry,
             )
         )
+
+        configure_loggers(handler="default", formatter=log_format, log_level=log_level.upper())
+
         controller = stack.enter_context(
             DagsterDaemonController(
                 workspace_process_context,
                 daemons,
                 heartbeat_interval_seconds=heartbeat_interval_seconds,
                 heartbeat_tolerance_seconds=heartbeat_tolerance_seconds,
                 error_interval_seconds=error_interval_seconds,
                 grpc_server_registry=grpc_server_registry,
-                log_level=log_level,
-                log_format=log_format,
             )
         )
 
         yield controller
 
 
 class DagsterDaemonController(AbstractContextManager):
@@ -141,17 +145,14 @@
         self,
         workspace_process_context: IWorkspaceProcessContext,
         daemons: Sequence[DagsterDaemon],
         grpc_server_registry: Optional[GrpcServerRegistry] = None,
         heartbeat_interval_seconds: float = DEFAULT_HEARTBEAT_INTERVAL_SECONDS,
         heartbeat_tolerance_seconds: float = DEFAULT_DAEMON_HEARTBEAT_TOLERANCE_SECONDS,
         error_interval_seconds: int = DEFAULT_DAEMON_ERROR_INTERVAL_SECONDS,
-        handler: str = "default",
-        log_level: str = "info",
-        log_format: str = "colored",
     ):
         self._daemon_uuid = str(uuid.uuid4())
 
         self._daemons = {}
         self._daemon_threads = {}
 
         self._workspace_process_context = workspace_process_context
@@ -169,16 +170,14 @@
         self._grpc_server_registry = grpc_server_registry
 
         if not self._daemons:
             raise Exception("No daemons configured on the DagsterInstance")
 
         self._daemon_shutdown_event = threading.Event()
 
-        configure_loggers(handler=handler, formatter=log_format, log_level=log_level.upper())
-
         self._logger = logging.getLogger("dagster.daemon")
         self._logger.info(
             "Instance is configured with the following daemons: %s",
             _sorted_quoted(type(daemon).__name__ for daemon in self.daemons),
         )
 
         self._last_healthy_heartbeat_times = {}
@@ -266,45 +265,61 @@
         if no_heartbeat_daemons:
             self._logger.warning(
                 "The following threads have not sent heartbeats in more than"
                 f" {self._heartbeat_tolerance_seconds} seconds: {no_heartbeat_daemons}."
                 " They may be running more slowly than expected or hanging."
             )
 
+    def check_workspace_freshness(self, last_workspace_update_time: float) -> float:
+        nowish = pendulum.now("UTC").float_timestamp
+        try:
+            if (nowish - last_workspace_update_time) > RELOAD_WORKSPACE_INTERVAL:
+                if self._grpc_server_registry:
+                    self._grpc_server_registry.clear_all_grpc_endpoints()
+                self._workspace_process_context.refresh_workspace()
+                return pendulum.now("UTC").float_timestamp
+        except Exception:
+            if (nowish - last_workspace_update_time) > DEFAULT_WORKSPACE_FRESHNESS_TOLERANCE:
+                self._logger.exception("Daemon controller surpassed workspace freshness tolerance.")
+                raise
+            else:
+                self._logger.exception(
+                    "Daemon controller failed to refresh workspace. Still within freshness tolerance."
+                )
+        return last_workspace_update_time
+
     def check_daemon_loop(self) -> None:
         start_time = time.time()
         last_heartbeat_check_time = start_time
         last_workspace_update_time = start_time
         while True:
             with raise_interrupts_as(KeyboardInterrupt):
                 time.sleep(THREAD_CHECK_INTERVAL)
                 self.check_daemon_threads()
 
                 # periodically refresh the shared workspace context
-                if (time.time() - last_workspace_update_time) > RELOAD_WORKSPACE_INTERVAL:
-                    if self._grpc_server_registry:
-                        self._grpc_server_registry.clear_all_grpc_endpoints()
-                    self._workspace_process_context.refresh_workspace()
-                    last_workspace_update_time = time.time()
+                last_workspace_update_time = self.check_workspace_freshness(
+                    last_workspace_update_time
+                )
 
                 if self._instance.daemon_skip_heartbeats_without_errors:
                     # If we're skipping heartbeats without errors, we just check the threads.
                     # If there's no errors, the daemons won't be writing heartbeats.
                     continue
 
-                now = time.time()
+                now = pendulum.now("UTC").float_timestamp
                 # Give the daemon enough time to send an initial heartbeat before checking
                 if (
                     (now - start_time) < 2 * self._heartbeat_interval_seconds
                     or now - last_heartbeat_check_time < HEARTBEAT_CHECK_INTERVAL
                 ):
                     continue
 
                 self.check_daemon_heartbeats()
-                last_heartbeat_check_time = time.time()
+                last_heartbeat_check_time = pendulum.now("UTC").float_timestamp
 
     def __exit__(
         self,
         exception_type: Type[BaseException],
         exception_value: Exception,
         traceback: TracebackType,
     ) -> None:
```

### Comparing `dagster-1.6.9/dagster/_daemon/daemon.py` & `dagster-1.7.0/dagster/_daemon/daemon.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 import logging
 import sys
 import time
 import uuid
 from abc import ABC, abstractmethod
 from collections import deque
 from contextlib import AbstractContextManager, ExitStack
+from enum import Enum
 from threading import Event
 from typing import TYPE_CHECKING, Any, Generator, Generic, Mapping, Optional, TypeVar, Union
 
 import pendulum
 from typing_extensions import TypeAlias
 
 from dagster import (
@@ -23,15 +24,18 @@
 from dagster._daemon.monitoring import (
     execute_concurrency_slots_iteration,
     execute_run_monitoring_iteration,
 )
 from dagster._daemon.sensor import execute_sensor_iteration_loop
 from dagster._daemon.types import DaemonHeartbeat
 from dagster._scheduler.scheduler import execute_scheduler_iteration_loop
-from dagster._utils.error import SerializableErrorInfo, serializable_error_info_from_exc_info
+from dagster._utils.error import (
+    SerializableErrorInfo,
+    serializable_error_info_from_exc_info,
+)
 
 if TYPE_CHECKING:
     from pendulum.datetime import DateTime
 
 
 def get_default_daemon_logger(daemon_name) -> logging.Logger:
     return logging.getLogger(f"dagster.daemon.{daemon_name}")
@@ -42,16 +46,20 @@
 _telemetry_daemon_session_id = str(uuid.uuid4())
 
 
 def get_telemetry_daemon_session_id() -> str:
     return _telemetry_daemon_session_id
 
 
-# DaemonIterator = Iterator[Union[None, SerializableErrorInfo]]
-DaemonIterator: TypeAlias = Generator[Union[None, SerializableErrorInfo], None, None]
+class SpanMarker(Enum):
+    START_SPAN = "START_SPAN"
+    END_SPAN = "END_SPAN"
+
+
+DaemonIterator: TypeAlias = Generator[Union[None, SerializableErrorInfo, SpanMarker], None, None]
 
 TContext = TypeVar("TContext", bound=IWorkspaceProcessContext)
 
 
 class DagsterDaemon(AbstractContextManager, ABC, Generic[TContext]):
     _logger: logging.Logger
     _last_heartbeat_time: Optional["DateTime"]
@@ -102,16 +110,16 @@
                     except Exception:
                         self._logger.error(
                             "Failed to add heartbeat: \n%s",
                             serializable_error_info_from_exc_info(sys.exc_info()),
                         )
 
                     try:
-                        result = check.opt_inst(next(daemon_generator), SerializableErrorInfo)
-                        if result:
+                        result = next(daemon_generator)
+                        if isinstance(result, SerializableErrorInfo):
                             self._errors.appendleft((result, pendulum.now("UTC")))
                     except StopIteration:
                         self._logger.error(
                             "Daemon loop finished without raising an error - daemon loops should"
                             " run forever until they are interrupted."
                         )
                         break
@@ -217,20 +225,22 @@
     def core_loop(
         self,
         workspace_process_context: TContext,
         shutdown_event: Event,
     ) -> DaemonIterator:
         while True:
             start_time = time.time()
+            yield SpanMarker.START_SPAN
             try:
                 yield from self.run_iteration(workspace_process_context)
             except Exception:
                 error_info = serializable_error_info_from_exc_info(sys.exc_info())
                 self._logger.error("Caught error:\n%s", error_info)
                 yield error_info
+            yield SpanMarker.END_SPAN
             while time.time() - start_time < self.interval_seconds:
                 shutdown_event.wait(0.5)
                 yield None
             yield None
 
     @abstractmethod
     def run_iteration(self, workspace_process_context: TContext) -> DaemonIterator: ...
```

### Comparing `dagster-1.6.9/dagster/_daemon/monitoring/concurrency.py` & `dagster-1.7.0/dagster/_daemon/monitoring/concurrency.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_daemon/monitoring/run_monitoring.py` & `dagster-1.7.0/dagster/_daemon/monitoring/run_monitoring.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,14 +15,15 @@
     IN_PROGRESS_RUN_STATUSES,
     DagsterRunStatus,
     RunRecord,
     RunsFilter,
 )
 from dagster._core.storage.tags import MAX_RUNTIME_SECONDS_TAG
 from dagster._core.workspace.context import IWorkspace, IWorkspaceProcessContext
+from dagster._daemon.utils import DaemonErrorCapture
 from dagster._utils import DebugCrashFlags
 from dagster._utils.error import SerializableErrorInfo, serializable_error_info_from_exc_info
 
 RESUME_RUN_LOG_MESSAGE = "Launching a new run worker to resume run"
 
 
 def monitor_starting_run(
@@ -189,19 +190,19 @@
                 and run_record.dagster_run.status == DagsterRunStatus.CANCELING
             ):
                 monitor_canceling_run(instance, run_record, logger)
                 pass
             else:
                 check.invariant(False, f"Unexpected run status: {run_record.dagster_run.status}")
         except Exception:
-            error_info = serializable_error_info_from_exc_info(sys.exc_info())
-            logger.error(
-                f"Hit error while monitoring run {run_record.dagster_run.run_id}: {error_info}"
+            yield DaemonErrorCapture.on_exception(
+                exc_info=sys.exc_info(),
+                logger=logger,
+                log_message=f"Hit error while monitoring run {run_record.dagster_run.run_id}",
             )
-            yield error_info
         else:
             yield
 
 
 def check_run_timeout(
     instance: DagsterInstance, run_record: RunRecord, logger: logging.Logger
 ) -> None:
```

### Comparing `dagster-1.6.9/dagster/_daemon/run_coordinator/queued_run_coordinator_daemon.py` & `dagster-1.7.0/dagster/_daemon/run_coordinator/queued_run_coordinator_daemon.py`

 * *Files 4% similar despite different names*

```diff
@@ -30,15 +30,15 @@
     RunsFilter,
 )
 from dagster._core.storage.tags import PRIORITY_TAG
 from dagster._core.utils import InheritContextThreadPoolExecutor
 from dagster._core.workspace.context import IWorkspaceProcessContext
 from dagster._core.workspace.workspace import IWorkspace
 from dagster._daemon.daemon import DaemonIterator, IntervalDaemon
-from dagster._utils.error import serializable_error_info_from_exc_info
+from dagster._daemon.utils import DaemonErrorCapture
 from dagster._utils.tags import TagConcurrencyLimitsCounter
 
 PAGE_SIZE = 100
 CONCURRENCY_BLOCKED_MESSAGE_INTERVAL = 300
 
 
 class QueuedRunCoordinatorDaemon(IntervalDaemon):
@@ -204,17 +204,15 @@
 
         max_concurrent_runs_enabled = max_concurrent_runs != -1  # setting to -1 disables the limit
         max_runs_to_launch = max_concurrent_runs - len(in_progress_run_records)
         if max_concurrent_runs_enabled:
             # Possibly under 0 if runs were launched without queuing
             if max_runs_to_launch <= 0:
                 self._logger.info(
-                    "{} runs are currently in progress. Maximum is {}, won't launch more.".format(
-                        len(in_progress_run_records), max_concurrent_runs
-                    )
+                    f"{len(in_progress_run_records)} runs are currently in progress. Maximum is {max_concurrent_runs}, won't launch more."
                 )
                 return []
 
         cursor = None
         has_more = True
         batch: List[DagsterRun] = []
 
@@ -376,15 +374,15 @@
         instance.report_dagster_event(launch_started_event, run_id=run.run_id)
 
         run = check.not_none(instance.get_run_by_id(run.run_id))
 
         try:
             instance.run_launcher.launch_run(LaunchRunContext(dagster_run=run, workspace=workspace))
         except Exception as e:
-            error = serializable_error_info_from_exc_info(sys.exc_info())
+            error = DaemonErrorCapture.on_exception(exc_info=sys.exc_info())
 
             run = check.not_none(instance.get_run_by_id(run.run_id))
             # Make sure we don't re-enqueue a run if it has already finished or moved into STARTED:
             if run.status not in (DagsterRunStatus.QUEUED, DagsterRunStatus.STARTING):
                 self._logger.info(
                     f"Run {run.run_id} failed while being dequeued, but has already advanced to"
                     f" {run.status} - moving on. Error: {error.to_string()}"
```

### Comparing `dagster-1.6.9/dagster/_daemon/sensor.py` & `dagster-1.7.0/dagster/_daemon/sensor.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,27 +4,26 @@
 from collections import defaultdict
 from concurrent.futures import Future, ThreadPoolExecutor
 from contextlib import AbstractContextManager
 from types import TracebackType
 from typing import (
     TYPE_CHECKING,
     Dict,
-    Iterator,
     List,
     Mapping,
     NamedTuple,
     Optional,
     Sequence,
     Type,
     Union,
     cast,
 )
 
 import pendulum
-from typing_extensions import Self, TypeAlias
+from typing_extensions import Self
 
 import dagster._check as check
 import dagster._seven as seven
 from dagster._core.definitions.run_request import (
     AddDynamicPartitionsRequest,
     DagsterRunReaction,
     DeleteDynamicPartitionsRequest,
@@ -32,47 +31,49 @@
     RunRequest,
 )
 from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.definitions.sensor_definition import (
     DefaultSensorStatus,
     SensorType,
 )
-from dagster._core.definitions.utils import validate_tags
+from dagster._core.definitions.utils import normalize_tags
 from dagster._core.errors import DagsterError
-from dagster._core.host_representation.code_location import CodeLocation
-from dagster._core.host_representation.external import ExternalJob, ExternalSensor
-from dagster._core.host_representation.external_data import ExternalTargetData
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.code_location import CodeLocation
+from dagster._core.remote_representation.external import ExternalJob, ExternalSensor
+from dagster._core.remote_representation.external_data import ExternalTargetData
 from dagster._core.scheduler.instigation import (
     DynamicPartitionsRequestResult,
     InstigatorState,
     InstigatorStatus,
     InstigatorTick,
     SensorInstigatorData,
     TickData,
     TickStatus,
 )
 from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus, RunsFilter
 from dagster._core.storage.tags import RUN_KEY_TAG, SENSOR_NAME_TAG
 from dagster._core.telemetry import SENSOR_RUN_CREATED, hash_name, log_action
 from dagster._core.workspace.context import IWorkspaceProcessContext
+from dagster._daemon.utils import DaemonErrorCapture
 from dagster._scheduler.stale import resolve_stale_or_missing_assets
 from dagster._utils import DebugCrashFlags, SingleInstigatorDebugCrashFlags, check_for_debug_crash
-from dagster._utils.error import SerializableErrorInfo, serializable_error_info_from_exc_info
+from dagster._utils.error import SerializableErrorInfo
 from dagster._utils.merger import merge_dicts
 
 if TYPE_CHECKING:
     from pendulum.datetime import DateTime
 
+    from dagster._daemon.daemon import DaemonIterator
+
+
 MIN_INTERVAL_LOOP_TIME = 5
 
 FINISHED_TICK_STATES = [TickStatus.SKIPPED, TickStatus.SUCCESS, TickStatus.FAILURE]
 
-TDaemonGenerator: TypeAlias = Iterator[Optional[SerializableErrorInfo]]
-
 
 class DagsterSensorDaemonError(DagsterError):
     """Error when running the SensorDaemon."""
 
 
 class SkippedSensorRun(NamedTuple):
     """Placeholder for runs that are skipped during the run_key idempotence check."""
@@ -221,89 +222,79 @@
         traceback: TracebackType,
     ) -> None:
         if exception_type and isinstance(exception_value, KeyboardInterrupt):
             return
 
         # Log the error if the failure wasn't an interrupt or the daemon generator stopping
         if exception_value and not isinstance(exception_value, GeneratorExit):
-            error_data = serializable_error_info_from_exc_info(sys.exc_info())
-            self.update_state(TickStatus.FAILURE, error=error_data)
+            error_info = DaemonErrorCapture.on_exception(exc_info=sys.exc_info())
+            self.update_state(TickStatus.FAILURE, error=error_info)
 
         self._write()
 
         for day_offset, statuses in self._purge_settings.items():
             if day_offset <= 0:
                 continue
             self._instance.purge_ticks(
                 self._external_sensor.get_external_origin_id(),
                 selector_id=self._external_sensor.selector_id,
                 before=pendulum.now("UTC").subtract(days=day_offset).timestamp(),
                 tick_statuses=list(statuses),
             )
 
 
-VERBOSE_LOGS_INTERVAL = 60
-
-
 def execute_sensor_iteration_loop(
     workspace_process_context: IWorkspaceProcessContext,
     logger: logging.Logger,
     shutdown_event: threading.Event,
     until: Optional[float] = None,
     threadpool_executor: Optional[ThreadPoolExecutor] = None,
     submit_threadpool_executor: Optional[ThreadPoolExecutor] = None,
-) -> TDaemonGenerator:
+) -> "DaemonIterator":
     """Helper function that performs sensor evaluations on a tighter loop, while reusing grpc locations
     within a given daemon interval.  Rather than relying on the daemon machinery to run the
     iteration loop every 30 seconds, sensors are continuously evaluated, every 5 seconds. We rely on
     each sensor definition's min_interval to check that sensor evaluations are spaced appropriately.
     """
+    from dagster._daemon.daemon import SpanMarker
+
     sensor_tick_futures: Dict[str, Future] = {}
-    last_verbose_time = None
     while True:
         start_time = pendulum.now("UTC").timestamp()
         if until and start_time >= until:
             # provide a way of organically ending the loop to support test environment
             break
 
-        # occasionally enable verbose logging (doing it always would be too much)
-        verbose_logs_iteration = (
-            last_verbose_time is None or start_time - last_verbose_time > VERBOSE_LOGS_INTERVAL
-        )
+        yield SpanMarker.START_SPAN
         yield from execute_sensor_iteration(
             workspace_process_context,
             logger,
             threadpool_executor=threadpool_executor,
             submit_threadpool_executor=submit_threadpool_executor,
             sensor_tick_futures=sensor_tick_futures,
-            log_verbose_checks=verbose_logs_iteration,
         )
         # Yield to check for heartbeats in case there were no yields within
         # execute_sensor_iteration
-        yield None
+        yield SpanMarker.END_SPAN
 
         end_time = pendulum.now("UTC").timestamp()
 
-        if verbose_logs_iteration:
-            last_verbose_time = end_time
-
         loop_duration = end_time - start_time
         sleep_time = max(0, MIN_INTERVAL_LOOP_TIME - loop_duration)
         shutdown_event.wait(sleep_time)
 
         yield None
 
 
 def execute_sensor_iteration(
     workspace_process_context: IWorkspaceProcessContext,
     logger: logging.Logger,
     threadpool_executor: Optional[ThreadPoolExecutor],
     submit_threadpool_executor: Optional[ThreadPoolExecutor],
     sensor_tick_futures: Optional[Dict[str, Future]] = None,
-    log_verbose_checks: bool = True,
     debug_crash_flags: Optional[DebugCrashFlags] = None,
 ):
     instance = workspace_process_context.instance
 
     workspace_snapshot = {
         location_entry.origin.location_name: location_entry
         for location_entry in workspace_process_context.create_request_context()
@@ -332,24 +323,16 @@
                         continue
 
                     selector_id = sensor.selector_id
                     if sensor.get_current_instigator_state(
                         all_sensor_states.get(selector_id)
                     ).is_running:
                         sensors[selector_id] = sensor
-        elif location_entry.load_error:
-            if log_verbose_checks:
-                logger.warning(
-                    f"Could not load location {location_entry.origin.location_name} to check for"
-                    f" sensors due to the following error: {location_entry.load_error}"
-                )
 
     if not sensors:
-        if log_verbose_checks:
-            logger.debug("Not checking for any runs since no sensors have been started.")
         yield
         return
 
     for external_sensor in sensors.values():
         sensor_name = external_sensor.name
         sensor_debug_crash_flags = debug_crash_flags.get(sensor_name) if debug_crash_flags else None
         sensor_state = all_sensor_states.get(external_sensor.selector_id)
@@ -484,16 +467,19 @@
                 external_sensor,
                 sensor_state,
                 submit_threadpool_executor,
                 sensor_debug_crash_flags,
             )
 
     except Exception:
-        error_info = serializable_error_info_from_exc_info(sys.exc_info())
-        logger.exception(f"Sensor daemon caught an error for sensor {external_sensor.name}")
+        error_info = DaemonErrorCapture.on_exception(
+            exc_info=sys.exc_info(),
+            logger=logger,
+            log_message=f"Sensor daemon caught an error for sensor {external_sensor.name}",
+        )
 
     yield error_info
 
 
 def _sensor_instigator_data(state: InstigatorState) -> Optional[SensorInstigatorData]:
     instigator_data = state.instigator_data
     if instigator_data is None or isinstance(instigator_data, SensorInstigatorData):
@@ -551,18 +537,19 @@
 
     # reload the code_location on each submission, request_context derived data can become out date
     # * non-threaded: if number of serial submissions is too many
     # * threaded: if thread sits pending in pool too long
     code_location = _get_code_location_for_sensor(workspace_process_context, external_sensor)
     job_subset_selector = JobSubsetSelector(
         location_name=code_location.name,
-        repository_name=sensor_origin.external_repository_origin.repository_name,
+        repository_name=sensor_origin.repository_origin.repository_name,
         job_name=target_data.job_name,
         op_selection=target_data.op_selection,
         asset_selection=run_request.asset_selection,
+        asset_check_selection=run_request.asset_check_keys,
     )
     external_job = code_location.get_external_job(job_subset_selector)
     run = _get_or_create_sensor_run(
         logger,
         instance,
         code_location,
         external_sensor,
@@ -579,28 +566,31 @@
 
     error_info = None
     try:
         logger.info(f"Launching run for {external_sensor.name}")
         instance.submit_run(run.run_id, workspace_process_context.create_request_context())
         logger.info(f"Completed launch of run {run.run_id} for {external_sensor.name}")
     except Exception:
-        error_info = serializable_error_info_from_exc_info(sys.exc_info())
-        logger.error(f"Run {run.run_id} created successfully but failed to launch: {error_info}")
+        error_info = DaemonErrorCapture.on_exception(
+            exc_info=sys.exc_info(),
+            logger=logger,
+            log_message=f"Run {run.run_id} created successfully but failed to launch",
+        )
 
     check_for_debug_crash(sensor_debug_crash_flags, "RUN_LAUNCHED")
     return SubmitRunRequestResult(run_key=run_request.run_key, error_info=error_info, run=run)
 
 
 def _get_code_location_for_sensor(
     workspace_process_context: IWorkspaceProcessContext,
     external_sensor: ExternalSensor,
 ) -> CodeLocation:
     sensor_origin = external_sensor.get_external_origin()
     return workspace_process_context.create_request_context().get_code_location(
-        sensor_origin.external_repository_origin.code_location_origin.location_name
+        sensor_origin.repository_origin.code_location_origin.location_name
     )
 
 
 def _evaluate_sensor(
     workspace_process_context: IWorkspaceProcessContext,
     context: SensorLaunchContext,
     external_sensor: ExternalSensor,
@@ -925,16 +915,16 @@
             run.external_job_origin is None
             and run.tags.get(SENSOR_NAME_TAG) == external_sensor.name
         ):
             valid_runs.append(run)
         # otherwise prevent the same named sensor across repos from effecting each other
         elif (
             run.external_job_origin is not None
-            and run.external_job_origin.external_repository_origin.get_selector_id()
-            == external_sensor.get_external_origin().external_repository_origin.get_selector_id()
+            and run.external_job_origin.repository_origin.get_selector_id()
+            == external_sensor.get_external_origin().repository_origin.get_selector_id()
             and run.tags.get(SENSOR_NAME_TAG) == external_sensor.name
         ):
             valid_runs.append(run)
 
     existing_runs = {}
     for run in valid_runs:
         tags = run.tags or {}
@@ -995,15 +985,17 @@
         run_request.run_config,
         step_keys_to_execute=None,
         known_state=None,
         instance=instance,
     )
     execution_plan_snapshot = external_execution_plan.execution_plan_snapshot
 
-    job_tags = validate_tags(external_job.tags or {}, allow_reserved_tags=False)
+    job_tags = normalize_tags(
+        external_job.tags or {}, allow_reserved_tags=False, warn_on_deprecated_tags=False
+    ).tags
     tags = merge_dicts(
         merge_dicts(job_tags, run_request.tags),
         # this gets applied in the sensor definition too, but we apply it here for backcompat
         # with sensors before the tag was added to the sensor definition
         DagsterRun.tags_for_sensor(external_sensor),
     )
     if run_request.run_key:
@@ -1035,10 +1027,12 @@
         execution_plan_snapshot=execution_plan_snapshot,
         parent_job_snapshot=external_job.parent_job_snapshot,
         external_job_origin=external_job.get_external_origin(),
         job_code_origin=external_job.get_python_origin(),
         asset_selection=(
             frozenset(run_request.asset_selection) if run_request.asset_selection else None
         ),
-        asset_check_selection=None,
+        asset_check_selection=(
+            frozenset(run_request.asset_check_keys) if run_request.asset_check_keys else None
+        ),
         asset_job_partitions_def=code_location.get_asset_job_partitions_def(external_job),
     )
```

### Comparing `dagster-1.6.9/dagster/_daemon/types.py` & `dagster-1.7.0/dagster/_daemon/types.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_daemon/workspace.py` & `dagster-1.7.0/dagster/_daemon/workspace.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from abc import abstractmethod
 from typing import Mapping, Sequence
 
 from dagster._core.errors import DagsterCodeLocationLoadError
-from dagster._core.host_representation.code_location import (
+from dagster._core.remote_representation.code_location import (
     CodeLocation,
 )
 from dagster._core.workspace.workspace import (
     CodeLocationEntry,
     CodeLocationStatusEntry,
     IWorkspace,
     location_status_from_location_entry,
```

### Comparing `dagster-1.6.9/dagster/_generate/download.py` & `dagster-1.7.0/dagster/_generate/download.py`

 * *Files 0% similar despite different names*

```diff
@@ -32,14 +32,15 @@
     "feature_graph_backed_assets",
     "project_dagster_university_start",
     "project_du_dbt_starter",
     "project_fully_featured",
     "project_analytics",
     "with_airflow",
     "with_great_expectations",
+    "with_openai",
     "with_pyspark",
     "with_pyspark_emr",
     "with_wandb",
 ]
 
 
 def _get_target_for_version(version: str) -> str:
```

### Comparing `dagster-1.6.9/dagster/_generate/generate.py` & `dagster-1.7.0/dagster/_generate/generate.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/README.md` & `dagster-1.7.0/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/README.md`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_grpc/__generated__/api_pb2.py` & `dagster-1.7.0/dagster/_grpc/__generated__/api_pb2.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_grpc/__generated__/api_pb2.pyi` & `dagster-1.7.0/dagster/_grpc/__generated__/api_pb2.pyi`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_grpc/__generated__/api_pb2_grpc.py` & `dagster-1.7.0/dagster/_grpc/__generated__/api_pb2_grpc.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_grpc/__init__.py` & `dagster-1.7.0/dagster/_grpc/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_grpc/client.py` & `dagster-1.7.0/dagster/_grpc/client.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,16 +9,16 @@
 from grpc_health.v1 import health_pb2
 from grpc_health.v1.health_pb2_grpc import HealthStub
 
 import dagster._check as check
 import dagster._seven as seven
 from dagster._core.errors import DagsterUserCodeUnreachableError
 from dagster._core.events import EngineEventData
-from dagster._core.host_representation.origin import ExternalRepositoryOrigin
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation.origin import RemoteRepositoryOrigin
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
 from dagster._serdes import serialize_value
 from dagster._utils.error import serializable_error_info_from_exc_info
 
 from .__generated__ import DagsterApiStub, api_pb2
 from .server import GrpcServerProcess
 from .types import (
@@ -320,54 +320,54 @@
         return res.serialized_external_pipeline_subset_result
 
     def reload_code(self, timeout: int) -> api_pb2.ReloadCodeReply:
         return self._query("ReloadCode", api_pb2.ReloadCodeRequest, timeout=timeout)
 
     def external_repository(
         self,
-        external_repository_origin: ExternalRepositoryOrigin,
+        external_repository_origin: RemoteRepositoryOrigin,
         defer_snapshots: bool = False,
     ) -> str:
         check.inst_param(
             external_repository_origin,
             "external_repository_origin",
-            ExternalRepositoryOrigin,
+            RemoteRepositoryOrigin,
         )
 
         res = self._query(
             "ExternalRepository",
             api_pb2.ExternalRepositoryRequest,
             # rename this param name
             serialized_repository_python_origin=serialize_value(external_repository_origin),
             defer_snapshots=defer_snapshots,
         )
 
         return res.serialized_external_repository_data
 
     def external_job(
         self,
-        external_repository_origin: ExternalRepositoryOrigin,
+        external_repository_origin: RemoteRepositoryOrigin,
         job_name: str,
     ) -> api_pb2.ExternalJobReply:
         check.inst_param(
             external_repository_origin,
             "external_repository_origin",
-            ExternalRepositoryOrigin,
+            RemoteRepositoryOrigin,
         )
 
         return self._query(
             "ExternalJob",
             api_pb2.ExternalJobRequest,
             serialized_repository_origin=serialize_value(external_repository_origin),
             job_name=job_name,
         )
 
     def streaming_external_repository(
         self,
-        external_repository_origin: ExternalRepositoryOrigin,
+        external_repository_origin: RemoteRepositoryOrigin,
         defer_snapshots: bool = False,
         timeout=DEFAULT_REPOSITORY_GRPC_TIMEOUT,
     ) -> Iterator[dict]:
         for res in self._streaming_query(
             "StreamingExternalRepository",
             api_pb2.ExternalRepositoryRequest,
             # Rename parameter
```

### Comparing `dagster-1.6.9/dagster/_grpc/compile.py` & `dagster-1.7.0/dagster/_grpc/compile.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_grpc/impl.py` & `dagster-1.7.0/dagster/_grpc/impl.py`

 * *Files 1% similar despite different names*

```diff
@@ -37,29 +37,30 @@
     PartitionExecutionError,
     ScheduleExecutionError,
     SensorExecutionError,
     user_code_error_boundary,
 )
 from dagster._core.events import DagsterEvent, EngineEventData
 from dagster._core.execution.api import create_execution_plan, execute_run_iterator
-from dagster._core.host_representation import external_job_data_from_def
-from dagster._core.host_representation.external_data import (
+from dagster._core.instance import DagsterInstance
+from dagster._core.instance.ref import InstanceRef
+from dagster._core.remote_representation import external_job_data_from_def
+from dagster._core.remote_representation.external_data import (
     ExternalJobSubsetResult,
     ExternalPartitionConfigData,
     ExternalPartitionExecutionErrorData,
     ExternalPartitionExecutionParamData,
     ExternalPartitionNamesData,
     ExternalPartitionSetExecutionParamData,
     ExternalPartitionTagsData,
     ExternalScheduleExecutionErrorData,
     ExternalSensorExecutionErrorData,
     job_name_for_external_partition_set_name,
 )
-from dagster._core.instance import DagsterInstance
-from dagster._core.instance.ref import InstanceRef
+from dagster._core.remote_representation.origin import CodeLocationOrigin
 from dagster._core.snap.execution_plan_snapshot import (
     ExecutionPlanSnapshotErrorData,
     snapshot_from_execution_plan,
 )
 from dagster._core.storage.dagster_run import DagsterRun
 from dagster._grpc.types import ExecutionPlanSnapshotArgs
 from dagster._serdes import deserialize_value
@@ -202,18 +203,16 @@
             else nullcontext()
         ) as instance:
             instance = check.not_none(instance)  # noqa: PLW2901
             dagster_run = instance.get_run_by_id(execute_run_args.run_id)
 
             if not dagster_run:
                 raise DagsterRunNotFoundError(
-                    "gRPC server could not load run {run_id} in order to execute it. Make sure that"
-                    " the gRPC server has access to your run storage.".format(
-                        run_id=execute_run_args.run_id
-                    ),
+                    f"gRPC server could not load run {execute_run_args.run_id} in order to execute it. Make sure that"
+                    " the gRPC server has access to your run storage.",
                     invalid_run_id=execute_run_args.run_id,
                 )
 
             pid = os.getpid()
 
     except:
         serializable_error_info = serializable_error_info_from_exc_info(sys.exc_info())
@@ -274,23 +273,26 @@
 
 def get_external_pipeline_subset_result(
     repo_def: RepositoryDefinition,
     job_name: str,
     op_selection: Optional[Sequence[str]],
     asset_selection: Optional[AbstractSet[AssetKey]],
     asset_check_selection: Optional[AbstractSet[AssetCheckKey]],
+    include_parent_snapshot: bool,
 ):
     try:
         definition = repo_def.get_maybe_subset_job_def(
             job_name,
             op_selection=op_selection,
             asset_selection=asset_selection,
             asset_check_selection=asset_check_selection,
         )
-        external_job_data = external_job_data_from_def(definition)
+        external_job_data = external_job_data_from_def(
+            definition, include_parent_snapshot=include_parent_snapshot
+        )
         return ExternalJobSubsetResult(success=True, external_job_data=external_job_data)
     except Exception:
         return ExternalJobSubsetResult(
             success=False, error=serializable_error_info_from_exc_info(sys.exc_info())
         )
 
 
@@ -343,14 +345,15 @@
         return ExternalScheduleExecutionErrorData(
             serializable_error_info_from_exc_info(sys.exc_info())
         )
 
 
 def get_external_sensor_execution(
     repo_def: RepositoryDefinition,
+    code_location_origin: CodeLocationOrigin,
     instance_ref: Optional[InstanceRef],
     sensor_name: str,
     last_tick_completion_timestamp: Optional[float],
     last_run_key: Optional[str],
     cursor: Optional[str],
     log_key: Optional[Sequence[str]],
     last_sensor_start_timestamp: Optional[float],
@@ -376,14 +379,15 @@
             cursor=cursor,
             log_key=log_key,
             repository_name=repo_def.name,
             repository_def=repo_def,
             sensor_name=sensor_name,
             resources=resources_to_build,
             last_sensor_start_time=last_sensor_start_timestamp,
+            code_location_origin=code_location_origin,
         ) as sensor_context:
             with user_code_error_boundary(
                 SensorExecutionError,
                 lambda: (
                     f"Error occurred during the execution of evaluation_fn for sensor {sensor_def.name}"
                 ),
             ):
```

### Comparing `dagster-1.6.9/dagster/_grpc/protos/api.proto` & `dagster-1.7.0/dagster/_grpc/protos/api.proto`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_grpc/proxy_server.py` & `dagster-1.7.0/dagster/_grpc/proxy_server.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 import logging
 import sys
 import threading
 from contextlib import ExitStack
 from typing import TYPE_CHECKING, Dict, Optional
 
 import dagster._check as check
-from dagster._core.host_representation.grpc_server_registry import GrpcServerRegistry
-from dagster._core.host_representation.origin import (
+from dagster._core.instance import InstanceRef
+from dagster._core.remote_representation.grpc_server_registry import GrpcServerRegistry
+from dagster._core.remote_representation.origin import (
     ManagedGrpcPythonEnvCodeLocationOrigin,
 )
-from dagster._core.instance import InstanceRef
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
 from dagster._grpc.client import DEFAULT_GRPC_TIMEOUT
 from dagster._grpc.types import (
     SensorExecutionArgs,
 )
 from dagster._serdes import deserialize_value, serialize_value
 from dagster._utils.error import serializable_error_info_from_exc_info
```

### Comparing `dagster-1.6.9/dagster/_grpc/server.py` & `dagster-1.7.0/dagster/_grpc/server.py`

 * *Files 2% similar despite different names*

```diff
@@ -38,27 +38,27 @@
 from dagster._core.definitions.reconstruct import ReconstructableRepository
 from dagster._core.definitions.repository_definition import RepositoryDefinition
 from dagster._core.errors import (
     DagsterUserCodeLoadError,
     DagsterUserCodeUnreachableError,
     user_code_error_boundary,
 )
-from dagster._core.host_representation.external_data import (
+from dagster._core.instance import DagsterInstance, InstanceRef
+from dagster._core.libraries import DagsterLibraryRegistry
+from dagster._core.origin import DEFAULT_DAGSTER_ENTRY_POINT, get_python_environment_entry_point
+from dagster._core.remote_representation.external_data import (
     ExternalJobSubsetResult,
     ExternalPartitionExecutionErrorData,
     ExternalRepositoryErrorData,
     ExternalScheduleExecutionErrorData,
     ExternalSensorExecutionErrorData,
     external_job_data_from_def,
     external_repository_data_from_def,
 )
-from dagster._core.host_representation.origin import ExternalRepositoryOrigin
-from dagster._core.instance import DagsterInstance, InstanceRef
-from dagster._core.libraries import DagsterLibraryRegistry
-from dagster._core.origin import DEFAULT_DAGSTER_ENTRY_POINT, get_python_environment_entry_point
+from dagster._core.remote_representation.origin import RemoteRepositoryOrigin
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
 from dagster._core.utils import FuturesAwareThreadPoolExecutor, RequestUtilizationMetrics
 from dagster._core.workspace.autodiscovery import LoadableTarget
 from dagster._serdes import deserialize_value, serialize_value
 from dagster._serdes.ipc import IPCErrorMessage, open_ipc_subprocess
 from dagster._utils import (
     find_free_port,
@@ -498,15 +498,15 @@
         del self._executions[run_id]
         del self._termination_events[run_id]
         if run_id in self._termination_times:
             del self._termination_times[run_id]
 
     def _get_repo_for_origin(
         self,
-        external_repo_origin: ExternalRepositoryOrigin,
+        external_repo_origin: RemoteRepositoryOrigin,
     ) -> RepositoryDefinition:
         loaded_repos = check.not_none(self._loaded_repositories)
         if external_repo_origin.repository_name not in loaded_repos.definitions_by_name:
             raise Exception(
                 f'Could not find a repository called "{external_repo_origin.repository_name}"'
             )
         return loaded_repos.definitions_by_name[external_repo_origin.repository_name]
@@ -558,15 +558,15 @@
     ) -> api_pb2.ExecutionPlanSnapshotReply:
         execution_plan_args = deserialize_value(
             request.serialized_execution_plan_snapshot_args,
             ExecutionPlanSnapshotArgs,
         )
 
         execution_plan_snapshot_or_error = get_external_execution_plan_snapshot(
-            self._get_repo_for_origin(execution_plan_args.job_origin.external_repository_origin),
+            self._get_repo_for_origin(execution_plan_args.job_origin.repository_origin),
             execution_plan_args.job_origin.job_name,
             execution_plan_args,
         )
         return api_pb2.ExecutionPlanSnapshotReply(
             serialized_execution_plan_snapshot=serialize_value(execution_plan_snapshot_or_error)
         )
 
@@ -730,20 +730,21 @@
             job_subset_snapshot_args = deserialize_value(
                 request.serialized_pipeline_subset_snapshot_args,
                 JobSubsetSnapshotArgs,
             )
             serialized_external_pipeline_subset_result = serialize_value(
                 get_external_pipeline_subset_result(
                     self._get_repo_for_origin(
-                        job_subset_snapshot_args.job_origin.external_repository_origin
+                        job_subset_snapshot_args.job_origin.repository_origin
                     ),
                     job_subset_snapshot_args.job_origin.job_name,
                     job_subset_snapshot_args.op_selection,
                     job_subset_snapshot_args.asset_selection,
                     job_subset_snapshot_args.asset_check_selection,
+                    job_subset_snapshot_args.include_parent_snapshot,
                 )
             )
         except Exception:
             serialized_external_pipeline_subset_result = serialize_value(
                 ExternalJobSubsetResult(
                     success=False, error=serializable_error_info_from_exc_info(sys.exc_info())
                 )
@@ -755,15 +756,15 @@
 
     def _get_serialized_external_repository_data(
         self, request: api_pb2.ExternalRepositoryRequest
     ) -> str:
         try:
             repository_origin = deserialize_value(
                 request.serialized_repository_python_origin,
-                ExternalRepositoryOrigin,
+                RemoteRepositoryOrigin,
             )
 
             return serialize_value(
                 external_repository_data_from_def(
                     self._get_repo_for_origin(repository_origin),
                     defer_snapshots=request.defer_snapshots,
                 )
@@ -784,19 +785,21 @@
 
     def ExternalJob(
         self, request: api_pb2.ExternalJobRequest, _context: grpc.ServicerContext
     ) -> api_pb2.ExternalJobReply:
         try:
             repository_origin = deserialize_value(
                 request.serialized_repository_origin,
-                ExternalRepositoryOrigin,
+                RemoteRepositoryOrigin,
             )
 
             job_def = self._get_repo_for_origin(repository_origin).get_job(request.job_name)
-            ser_job_data = serialize_value(external_job_data_from_def(job_def))
+            ser_job_data = serialize_value(
+                external_job_data_from_def(job_def, include_parent_snapshot=True)
+            )
             return api_pb2.ExternalJobReply(serialized_job_data=ser_job_data)
         except Exception:
             return api_pb2.ExternalJobReply(
                 serialized_error=serialize_value(
                     serializable_error_info_from_exc_info(sys.exc_info())
                 )
             )
@@ -883,14 +886,15 @@
                 request.serialized_external_sensor_execution_args,
                 SensorExecutionArgs,
             )
 
             return serialize_value(
                 get_external_sensor_execution(
                     self._get_repo_for_origin(args.repository_origin),
+                    args.repository_origin.code_location_origin,
                     args.instance_ref,
                     args.sensor_name,
                     args.last_tick_completion_time,
                     args.last_run_key,
                     args.cursor,
                     args.log_key,
                     args.last_sensor_start_time,
@@ -1010,15 +1014,15 @@
                 request.serialized_execute_run_args,
                 ExecuteExternalJobArgs,
             )
             run_id = execute_external_job_args.run_id
 
             # reconstructable required for handing execution off to subprocess
             recon_repo = check.not_none(self._loaded_repositories).reconstructables_by_name[
-                execute_external_job_args.job_origin.external_repository_origin.repository_name
+                execute_external_job_args.job_origin.repository_origin.repository_name
             ]
             recon_job = recon_repo.get_reconstructable_job(
                 execute_external_job_args.job_origin.job_name
             )
 
         except:
             return api_pb2.StartRunReply(
```

### Comparing `dagster-1.6.9/dagster/_grpc/server_watcher.py` & `dagster-1.7.0/dagster/_grpc/server_watcher.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_grpc/types.py` & `dagster-1.7.0/dagster/_grpc/types.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,22 +4,22 @@
 
 import dagster._check as check
 from dagster._core.code_pointer import CodePointer
 from dagster._core.definitions.asset_check_spec import AssetCheckKey
 from dagster._core.definitions.events import AssetKey
 from dagster._core.execution.plan.state import KnownExecutionState
 from dagster._core.execution.retries import RetryMode
-from dagster._core.host_representation.external_data import DEFAULT_MODE_NAME
-from dagster._core.host_representation.origin import (
-    CodeLocationOrigin,
-    ExternalJobOrigin,
-    ExternalRepositoryOrigin,
-)
 from dagster._core.instance.ref import InstanceRef
 from dagster._core.origin import JobPythonOrigin, get_python_environment_entry_point
+from dagster._core.remote_representation.external_data import DEFAULT_MODE_NAME
+from dagster._core.remote_representation.origin import (
+    CodeLocationOrigin,
+    RemoteJobOrigin,
+    RemoteRepositoryOrigin,
+)
 from dagster._serdes import serialize_value, whitelist_for_serdes
 from dagster._serdes.serdes import SetToSequenceFieldSerializer
 from dagster._utils.error import SerializableErrorInfo
 
 
 @whitelist_for_serdes(
     storage_field_names={
@@ -28,43 +28,43 @@
         "op_selection": "solid_selection",
     }
 )
 class ExecutionPlanSnapshotArgs(
     NamedTuple(
         "_ExecutionPlanSnapshotArgs",
         [
-            ("job_origin", ExternalJobOrigin),
+            ("job_origin", RemoteJobOrigin),
             ("op_selection", Sequence[str]),
             ("run_config", Mapping[str, object]),
             ("step_keys_to_execute", Optional[Sequence[str]]),
             ("job_snapshot_id", str),
             ("known_state", Optional[KnownExecutionState]),
             ("instance_ref", Optional[InstanceRef]),
             ("asset_selection", Optional[AbstractSet[AssetKey]]),
             ("asset_check_selection", Optional[AbstractSet[AssetCheckKey]]),
             ("mode", str),
         ],
     )
 ):
     def __new__(
         cls,
-        job_origin: ExternalJobOrigin,
+        job_origin: RemoteJobOrigin,
         op_selection: Sequence[str],
         run_config: Mapping[str, object],
         step_keys_to_execute: Optional[Sequence[str]],
         job_snapshot_id: str,
         known_state: Optional[KnownExecutionState] = None,
         instance_ref: Optional[InstanceRef] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
         asset_check_selection: Optional[AbstractSet[AssetCheckKey]] = None,
         mode: str = DEFAULT_MODE_NAME,
     ):
         return super(ExecutionPlanSnapshotArgs, cls).__new__(
             cls,
-            job_origin=check.inst_param(job_origin, "job_origin", ExternalJobOrigin),
+            job_origin=check.inst_param(job_origin, "job_origin", RemoteJobOrigin),
             op_selection=check.opt_sequence_param(op_selection, "op_selection", of_type=str),
             run_config=check.mapping_param(run_config, "run_config", key_type=str),
             mode=check.str_param(mode, "mode"),
             step_keys_to_execute=check.opt_nullable_sequence_param(
                 step_keys_to_execute, "step_keys_to_execute", of_type=str
             ),
             job_snapshot_id=check.str_param(job_snapshot_id, "job_snapshot_id"),
@@ -196,32 +196,32 @@
         "run_id": "pipeline_run_id",
     },
 )
 class ExecuteExternalJobArgs(
     NamedTuple(
         "_ExecuteExternalJobArgs",
         [
-            ("job_origin", ExternalJobOrigin),
+            ("job_origin", RemoteJobOrigin),
             ("run_id", str),
             ("instance_ref", Optional[InstanceRef]),
         ],
     )
 ):
     def __new__(
         cls,
-        job_origin: ExternalJobOrigin,
+        job_origin: RemoteJobOrigin,
         run_id: str,
         instance_ref: Optional[InstanceRef],
     ):
         return super(ExecuteExternalJobArgs, cls).__new__(
             cls,
             job_origin=check.inst_param(
                 job_origin,
                 "job_origin",
-                ExternalJobOrigin,
+                RemoteJobOrigin,
             ),
             run_id=check.str_param(run_id, "run_id"),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
         )
 
 
 @whitelist_for_serdes(
@@ -400,81 +400,81 @@
 
 
 @whitelist_for_serdes
 class PartitionArgs(
     NamedTuple(
         "_PartitionArgs",
         [
-            ("repository_origin", ExternalRepositoryOrigin),
+            ("repository_origin", RemoteRepositoryOrigin),
             ("partition_set_name", str),
             ("partition_name", str),
             ("instance_ref", Optional[InstanceRef]),
         ],
     )
 ):
     def __new__(
         cls,
-        repository_origin: ExternalRepositoryOrigin,
+        repository_origin: RemoteRepositoryOrigin,
         partition_set_name: str,
         partition_name: str,
         instance_ref: Optional[InstanceRef] = None,
     ):
         return super(PartitionArgs, cls).__new__(
             cls,
             repository_origin=check.inst_param(
                 repository_origin,
                 "repository_origin",
-                ExternalRepositoryOrigin,
+                RemoteRepositoryOrigin,
             ),
             partition_set_name=check.str_param(partition_set_name, "partition_set_name"),
             partition_name=check.str_param(partition_name, "partition_name"),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
         )
 
 
 @whitelist_for_serdes
 class PartitionNamesArgs(
     NamedTuple(
         "_PartitionNamesArgs",
-        [("repository_origin", ExternalRepositoryOrigin), ("partition_set_name", str)],
+        [("repository_origin", RemoteRepositoryOrigin), ("partition_set_name", str)],
     )
 ):
-    def __new__(cls, repository_origin: ExternalRepositoryOrigin, partition_set_name: str):
+    def __new__(cls, repository_origin: RemoteRepositoryOrigin, partition_set_name: str):
         return super(PartitionNamesArgs, cls).__new__(
             cls,
             repository_origin=check.inst_param(
-                repository_origin, "repository_origin", ExternalRepositoryOrigin
+                repository_origin, "repository_origin", RemoteRepositoryOrigin
             ),
             partition_set_name=check.str_param(partition_set_name, "partition_set_name"),
         )
 
 
 @whitelist_for_serdes
 class PartitionSetExecutionParamArgs(
     NamedTuple(
         "_PartitionSetExecutionParamArgs",
         [
-            ("repository_origin", ExternalRepositoryOrigin),
+            ("repository_origin", RemoteRepositoryOrigin),
             ("partition_set_name", str),
             ("partition_names", Sequence[str]),
             ("instance_ref", Optional[InstanceRef]),
         ],
     )
 ):
     def __new__(
         cls,
-        repository_origin: ExternalRepositoryOrigin,
+        repository_origin: RemoteRepositoryOrigin,
         partition_set_name: str,
         partition_names: Sequence[str],
         instance_ref: Optional[InstanceRef] = None,
     ):
         return super(PartitionSetExecutionParamArgs, cls).__new__(
             cls,
             repository_origin=check.inst_param(
-                repository_origin, "repository_origin", ExternalRepositoryOrigin
+                repository_origin, "repository_origin", RemoteRepositoryOrigin
             ),
             partition_set_name=check.str_param(partition_set_name, "partition_set_name"),
             partition_names=check.sequence_param(partition_names, "partition_names", of_type=str),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
         )
 
 
@@ -487,38 +487,43 @@
     # asset_selection previously was erroneously represented as a sequence
     field_serializers={"asset_selection": SetToSequenceFieldSerializer},
 )
 class JobSubsetSnapshotArgs(
     NamedTuple(
         "_JobSubsetSnapshotArgs",
         [
-            ("job_origin", ExternalJobOrigin),
+            ("job_origin", RemoteJobOrigin),
             ("op_selection", Optional[Sequence[str]]),
             ("asset_selection", Optional[AbstractSet[AssetKey]]),
             ("asset_check_selection", Optional[AbstractSet[AssetCheckKey]]),
+            ("include_parent_snapshot", bool),
         ],
     )
 ):
     def __new__(
         cls,
-        job_origin: ExternalJobOrigin,
+        job_origin: RemoteJobOrigin,
         op_selection: Optional[Sequence[str]],
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
         asset_check_selection: Optional[AbstractSet[AssetCheckKey]] = None,
+        include_parent_snapshot: Optional[bool] = None,
     ):
         return super(JobSubsetSnapshotArgs, cls).__new__(
             cls,
-            job_origin=check.inst_param(job_origin, "job_origin", ExternalJobOrigin),
+            job_origin=check.inst_param(job_origin, "job_origin", RemoteJobOrigin),
             op_selection=check.opt_nullable_sequence_param(
                 op_selection, "op_selection", of_type=str
             ),
             asset_selection=check.opt_nullable_set_param(asset_selection, "asset_selection"),
             asset_check_selection=check.opt_nullable_set_param(
                 asset_check_selection, "asset_check_selection"
             ),
+            include_parent_snapshot=(
+                include_parent_snapshot if include_parent_snapshot is not None else True
+            ),
         )
 
 
 # Different storage field name for backcompat
 @whitelist_for_serdes(storage_field_names={"code_location_origin": "repository_location_origin"})
 class NotebookPathArgs(
     NamedTuple(
@@ -537,38 +542,38 @@
 
 
 @whitelist_for_serdes
 class ExternalScheduleExecutionArgs(
     NamedTuple(
         "_ExternalScheduleExecutionArgs",
         [
-            ("repository_origin", ExternalRepositoryOrigin),
+            ("repository_origin", RemoteRepositoryOrigin),
             ("instance_ref", Optional[InstanceRef]),
             ("schedule_name", str),
             ("scheduled_execution_timestamp", Optional[float]),
             ("scheduled_execution_timezone", Optional[str]),
             ("log_key", Optional[Sequence[str]]),
             ("timeout", Optional[int]),
         ],
     )
 ):
     def __new__(
         cls,
-        repository_origin: ExternalRepositoryOrigin,
+        repository_origin: RemoteRepositoryOrigin,
         instance_ref: Optional[InstanceRef],
         schedule_name: str,
         scheduled_execution_timestamp: Optional[float] = None,
         scheduled_execution_timezone: Optional[str] = None,
         log_key: Optional[Sequence[str]] = None,
         timeout: Optional[int] = None,
     ):
         return super(ExternalScheduleExecutionArgs, cls).__new__(
             cls,
             repository_origin=check.inst_param(
-                repository_origin, "repository_origin", ExternalRepositoryOrigin
+                repository_origin, "repository_origin", RemoteRepositoryOrigin
             ),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
             schedule_name=check.str_param(schedule_name, "schedule_name"),
             scheduled_execution_timestamp=check.opt_float_param(
                 scheduled_execution_timestamp, "scheduled_execution_timestamp"
             ),
             scheduled_execution_timezone=check.opt_str_param(
@@ -581,15 +586,15 @@
 
 
 @whitelist_for_serdes
 class SensorExecutionArgs(
     NamedTuple(
         "_SensorExecutionArgs",
         [
-            ("repository_origin", ExternalRepositoryOrigin),
+            ("repository_origin", RemoteRepositoryOrigin),
             ("instance_ref", Optional[InstanceRef]),
             ("sensor_name", str),
             ("last_tick_completion_time", Optional[float]),
             ("last_run_key", Optional[str]),
             ("cursor", Optional[str]),
             ("log_key", Optional[Sequence[str]]),
             ("timeout", Optional[int]),
@@ -597,15 +602,15 @@
             # deprecated
             ("last_completion_time", Optional[float]),
         ],
     )
 ):
     def __new__(
         cls,
-        repository_origin: ExternalRepositoryOrigin,
+        repository_origin: RemoteRepositoryOrigin,
         instance_ref: Optional[InstanceRef],
         sensor_name: str,
         last_tick_completion_time: Optional[float] = None,
         last_run_key: Optional[str] = None,
         cursor: Optional[str] = None,
         log_key: Optional[Sequence[str]] = None,
         timeout: Optional[int] = None,
@@ -619,15 +624,15 @@
         # check.invariant that would be triggered by setting both values.
         normalized_last_tick_completion_time = (
             last_tick_completion_time if last_tick_completion_time else last_completion_time
         )
         return super(SensorExecutionArgs, cls).__new__(
             cls,
             repository_origin=check.inst_param(
-                repository_origin, "repository_origin", ExternalRepositoryOrigin
+                repository_origin, "repository_origin", RemoteRepositoryOrigin
             ),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
             sensor_name=check.str_param(sensor_name, "sensor_name"),
             last_tick_completion_time=normalized_last_tick_completion_time,
             last_run_key=check.opt_str_param(last_run_key, "last_run_key"),
             cursor=check.opt_str_param(cursor, "cursor"),
             log_key=check.opt_list_param(log_key, "log_key", of_type=str),
@@ -640,27 +645,27 @@
 
 
 @whitelist_for_serdes
 class ExternalJobArgs(
     NamedTuple(
         "_ExternalJobArgs",
         [
-            ("repository_origin", ExternalRepositoryOrigin),
+            ("repository_origin", RemoteRepositoryOrigin),
             ("instance_ref", InstanceRef),
             ("name", str),
         ],
     )
 ):
     def __new__(
-        cls, repository_origin: ExternalRepositoryOrigin, instance_ref: InstanceRef, name: str
+        cls, repository_origin: RemoteRepositoryOrigin, instance_ref: InstanceRef, name: str
     ):
         return super(ExternalJobArgs, cls).__new__(
             cls,
             repository_origin=check.inst_param(
-                repository_origin, "repository_origin", ExternalRepositoryOrigin
+                repository_origin, "repository_origin", RemoteRepositoryOrigin
             ),
             instance_ref=check.inst_param(instance_ref, "instance_ref", InstanceRef),
             name=check.str_param(name, "name"),
         )
 
 
 @whitelist_for_serdes
```

### Comparing `dagster-1.6.9/dagster/_grpc/utils.py` & `dagster-1.7.0/dagster/_grpc/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_loggers/__init__.py` & `dagster-1.7.0/dagster/_loggers/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_module_alias_map.py` & `dagster-1.7.0/dagster/_module_alias_map.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_scheduler/scheduler.py` & `dagster-1.7.0/dagster/_scheduler/scheduler.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,32 +1,45 @@
 import datetime
 import logging
+import os
+import random
 import sys
 import threading
 from collections import defaultdict
 from concurrent.futures import Future, ThreadPoolExecutor
 from contextlib import AbstractContextManager, ExitStack
-from typing import TYPE_CHECKING, Dict, List, Mapping, NamedTuple, Optional, Sequence, cast
+from typing import (
+    TYPE_CHECKING,
+    Dict,
+    Generator,
+    List,
+    Mapping,
+    NamedTuple,
+    Optional,
+    Sequence,
+    Union,
+    cast,
+)
 
 import pendulum
 from typing_extensions import Self
 
 import dagster._check as check
 from dagster._core.definitions.run_request import RunRequest
 from dagster._core.definitions.schedule_definition import DefaultScheduleStatus
 from dagster._core.definitions.selector import JobSubsetSelector
-from dagster._core.definitions.utils import validate_tags
+from dagster._core.definitions.utils import normalize_tags
 from dagster._core.errors import (
     DagsterCodeLocationLoadError,
     DagsterUserCodeUnreachableError,
 )
-from dagster._core.host_representation import ExternalSchedule
-from dagster._core.host_representation.code_location import CodeLocation
-from dagster._core.host_representation.external import ExternalJob
 from dagster._core.instance import DagsterInstance
+from dagster._core.remote_representation import ExternalSchedule
+from dagster._core.remote_representation.code_location import CodeLocation
+from dagster._core.remote_representation.external import ExternalJob
 from dagster._core.scheduler.instigation import (
     InstigatorState,
     InstigatorStatus,
     InstigatorTick,
     InstigatorType,
     ScheduleInstigatorData,
     TickData,
@@ -50,15 +63,21 @@
 
     from dagster._daemon.daemon import DaemonIterator
 
 
 # how often do we update the job row in the database with the last iteration timestamp.  This
 # creates a checkpoint so that if the cron schedule changes, we don't try to backfill schedule ticks
 # from the start of the schedule, just since the last recorded iteration interval.
-LAST_RECORDED_ITERATION_INTERVAL_SECONDS = 3600
+LAST_ITERATION_CHECKPOINT_INTERVAL_SECONDS = int(
+    os.getenv("DAGSTER_SCHEDULE_CHECKPOINT_INTERVAL_SECONDS", "3600")
+)
+
+LAST_ITERATION_CHECKPOINT_JITTER_SECONDS = int(
+    os.getenv("DAGSTER_SCHEDULE_CHECKPOINT_JITTER_SECONDS", "600")
+)
 
 
 class _ScheduleLaunchContext(AbstractContextManager):
     def __init__(
         self,
         external_schedule: ExternalSchedule,
         tick: InstigatorTick,
@@ -122,32 +141,63 @@
                 selector_id=self._external_schedule.selector_id,
                 before=pendulum.now("UTC").subtract(days=day_offset).timestamp(),
                 tick_statuses=list(statuses),
             )
 
 
 SECONDS_IN_MINUTE = 60
-VERBOSE_LOGS_INTERVAL = 60
 
 
 def _get_next_scheduler_iteration_time(start_time: float) -> float:
     # Wait until at least the next minute to run again, since the minimum granularity
     # for a cron schedule is every minute
     last_minute_time = start_time - (start_time % SECONDS_IN_MINUTE)
     return last_minute_time + SECONDS_IN_MINUTE
 
 
+class ScheduleIterationTimes(NamedTuple):
+    """Timestamp information returned by each scheduler iteration that the core scheduler
+    loop can use to intelligently schedule the next tick.
+
+    last_iteration_timestamp is used by subsequent evaluations of this schedule to ensure that we
+    don't accidentally create incorrect runs after the cronstring changes (it is stored in memory
+    in these objects and is also periodically persisted on the schedule row in the database -
+    see _write_and_get_next_checkpoint_timestamp).
+
+    next_iteration_timestamp is the timestamp until which the scheduler can wait until running this
+    schedule again (assuming the cron schedule has not changed) - either because that's the next
+    time we know the schedule needs to run based on the last time we evaluated its cron string,
+    or because that's the next time we've determined that we should update the persisted
+    last_iteration_timestamp value for this schedule described above (this is written on a fixed
+    interval plus a random jitter value to ensure not every schedule tries to do this at once -
+    this value is also determined in _write_and_get_next_checkpoint_timestamp.).
+    """
+
+    cron_schedule: Union[str, Sequence[str]]
+    next_iteration_timestamp: float
+    last_iteration_timestamp: float
+
+    def should_run_next_iteration(self, schedule: ExternalSchedule, now_timestamp: float):
+        if schedule.cron_schedule != self.cron_schedule:
+            # cron schedule has changed - always run next iteration to check
+            return True
+        return now_timestamp >= self.next_iteration_timestamp
+
+
 def execute_scheduler_iteration_loop(
     workspace_process_context: IWorkspaceProcessContext,
     logger: logging.Logger,
     max_catchup_runs: int,
     max_tick_retries: int,
     shutdown_event: threading.Event,
 ) -> "DaemonIterator":
+    from dagster._daemon.daemon import SpanMarker
+
     scheduler_run_futures: Dict[str, Future] = {}
+    iteration_times: Dict[str, ScheduleIterationTimes] = {}
 
     submit_threadpool_executor = None
     threadpool_executor = None
 
     with ExitStack() as stack:
         settings = workspace_process_context.instance.get_scheduler_settings()
         if settings.get("use_threads"):
@@ -162,60 +212,53 @@
                 submit_threadpool_executor = stack.enter_context(
                     InheritContextThreadPoolExecutor(
                         max_workers=settings.get("num_submit_workers"),
                         thread_name_prefix="schedule_submit_worker",
                     )
                 )
 
-        last_verbose_time = None
         while True:
             start_time = pendulum.now("UTC").timestamp()
             end_datetime_utc = pendulum.now("UTC")
 
-            # occasionally enable verbose logging (doing it always would be too much)
-            verbose_logs_iteration = (
-                last_verbose_time is None or start_time - last_verbose_time > VERBOSE_LOGS_INTERVAL
-            )
+            yield SpanMarker.START_SPAN
             yield from launch_scheduled_runs(
                 workspace_process_context,
                 logger,
                 end_datetime_utc=end_datetime_utc,
+                iteration_times=iteration_times,
                 threadpool_executor=threadpool_executor,
                 submit_threadpool_executor=submit_threadpool_executor,
                 scheduler_run_futures=scheduler_run_futures,
                 max_catchup_runs=max_catchup_runs,
                 max_tick_retries=max_tick_retries,
-                log_verbose_checks=verbose_logs_iteration,
             )
-            yield
+            yield SpanMarker.END_SPAN
             end_time = pendulum.now("UTC").timestamp()
 
-            if verbose_logs_iteration:
-                last_verbose_time = end_time
-
             next_minute_time = _get_next_scheduler_iteration_time(start_time)
 
             if next_minute_time > end_time:
                 # Sleep until the beginning of the next minute, plus a small epsilon to
                 # be sure that we're past the start of the minute
                 shutdown_event.wait(next_minute_time - end_time + 0.001)
                 yield
 
 
 def launch_scheduled_runs(
     workspace_process_context: IWorkspaceProcessContext,
     logger: logging.Logger,
     end_datetime_utc: "DateTime",
+    iteration_times: Dict[str, ScheduleIterationTimes],
     threadpool_executor: Optional[ThreadPoolExecutor] = None,
     submit_threadpool_executor: Optional[ThreadPoolExecutor] = None,
     scheduler_run_futures: Optional[Dict[str, Future]] = None,
     max_catchup_runs: int = DEFAULT_MAX_CATCHUP_RUNS,
     max_tick_retries: int = 0,
     debug_crash_flags: Optional[DebugCrashFlags] = None,
-    log_verbose_checks: bool = True,
 ) -> "DaemonIterator":
     instance = workspace_process_context.instance
 
     workspace_snapshot = {
         location_entry.origin.location_name: location_entry
         for location_entry in workspace_process_context.create_request_context()
         .get_workspace_snapshot()
@@ -239,50 +282,39 @@
                 for schedule in repo.get_external_schedules():
                     selector_id = schedule.selector_id
                     if schedule.get_current_instigator_state(
                         all_schedule_states.get(selector_id)
                     ).is_running:
                         schedules[selector_id] = schedule
         elif location_entry.load_error:
-            if log_verbose_checks:
-                logger.warning(
-                    f"Could not load location {location_entry.origin.location_name} to check for"
-                    f" schedules due to the following error: {location_entry.load_error}"
-                )
             error_locations.add(location_entry.origin.location_name)
 
     # Remove any schedule states that were previously created with DECLARED_IN_CODE
     # and can no longer be found in the workspace (so that if they are later added
     # back again, their timestamps will start at the correct place)
     states_to_delete = [
         schedule_state
         for selector_id, schedule_state in all_schedule_states.items()
         if selector_id not in schedules
         and schedule_state.status == InstigatorStatus.DECLARED_IN_CODE
     ]
     for state in states_to_delete:
-        location_name = state.origin.external_repository_origin.code_location_origin.location_name
+        location_name = state.origin.repository_origin.code_location_origin.location_name
         # don't clean up auto running state if its location is an error state
         if location_name not in error_locations:
             logger.info(
                 f"Removing state for automatically running schedule {state.instigator_name} "
                 f"that is no longer present in {location_name}."
             )
             instance.delete_instigator_state(state.instigator_origin_id, state.selector_id)
 
     if not schedules:
-        if log_verbose_checks:
-            logger.debug("Not checking for any runs since no schedules have been started.")
         yield
         return
 
-    if log_verbose_checks:
-        schedule_names = ", ".join([schedule.name for schedule in schedules.values()])
-        logger.info(f"Checking for new runs for the following schedules: {schedule_names}")
-
     for external_schedule in schedules.values():
         error_info = None
         try:
             schedule_state = all_schedule_states.get(external_schedule.selector_id)
             if not schedule_state:
                 assert external_schedule.default_status == DefaultScheduleStatus.RUNNING
                 schedule_state = InstigatorState(
@@ -302,53 +334,103 @@
 
             if threadpool_executor:
                 if scheduler_run_futures is None:
                     check.failed(
                         "scheduler_run_futures dict must be passed with threadpool_executor"
                     )
 
-                # only allow one tick per schedule to be in flight
+                if external_schedule.selector_id in scheduler_run_futures:
+                    if scheduler_run_futures[external_schedule.selector_id].done():
+                        try:
+                            result = scheduler_run_futures[external_schedule.selector_id].result()
+                            iteration_times[external_schedule.selector_id] = result
+                        except Exception:
+                            # Log exception and continue on rather than erroring the whole scheduler loop
+                            logger.exception(
+                                f"Error getting tick result for schedule {external_schedule.name}"
+                            )
+                        del scheduler_run_futures[external_schedule.selector_id]
+                    else:
+                        # only allow one tick per schedule to be in flight
+                        continue
+
+                previous_iteration_times = iteration_times.get(external_schedule.selector_id)
                 if (
-                    external_schedule.selector_id in scheduler_run_futures
-                    and not scheduler_run_futures[external_schedule.selector_id].done()
+                    previous_iteration_times
+                    and not previous_iteration_times.should_run_next_iteration(
+                        external_schedule, end_datetime_utc.timestamp()
+                    )
                 ):
+                    # Not enough time has passed for this schedule, don't bother creating a thread
                     continue
 
                 future = threadpool_executor.submit(
                     launch_scheduled_runs_for_schedule,
                     workspace_process_context,
                     logger,
                     external_schedule,
                     schedule_state,
                     end_datetime_utc,
                     max_catchup_runs,
                     max_tick_retries,
                     tick_retention_settings,
                     schedule_debug_crash_flags,
-                    log_verbose_checks=log_verbose_checks,
                     submit_threadpool_executor=submit_threadpool_executor,
+                    in_memory_last_iteration_timestamp=(
+                        previous_iteration_times.last_iteration_timestamp
+                        if previous_iteration_times
+                        else None
+                    ),
                 )
                 scheduler_run_futures[external_schedule.selector_id] = future
                 yield
 
             else:
+                previous_iteration_times = iteration_times.get(external_schedule.selector_id)
+                if (
+                    previous_iteration_times
+                    and not previous_iteration_times.should_run_next_iteration(
+                        external_schedule, end_datetime_utc.timestamp()
+                    )
+                ):
+                    # Not enough time has passed for this schedule, don't bother executing
+                    continue
+
                 # evaluate the schedules in a loop, synchronously, yielding to allow the schedule daemon to
                 # heartbeat
-                yield from launch_scheduled_runs_for_schedule_iterator(
+                found_iteration_times = False
+                for yielded_value in launch_scheduled_runs_for_schedule_iterator(
                     workspace_process_context,
                     logger,
                     external_schedule,
                     schedule_state,
                     end_datetime_utc,
                     max_catchup_runs,
                     max_tick_retries,
                     tick_retention_settings,
                     schedule_debug_crash_flags,
-                    log_verbose_checks=log_verbose_checks,
                     submit_threadpool_executor=None,
+                    in_memory_last_iteration_timestamp=(
+                        previous_iteration_times.last_iteration_timestamp
+                        if previous_iteration_times
+                        else None
+                    ),
+                ):
+                    if isinstance(yielded_value, ScheduleIterationTimes):
+                        check.invariant(
+                            not found_iteration_times,
+                            "launch_scheduled_runs_for_schedule_iterator yielded more than one ScheduleIterationTimes",
+                        )
+                        found_iteration_times = True
+                        iteration_times[external_schedule.selector_id] = yielded_value
+                    else:
+                        yield yielded_value
+                check.invariant(
+                    found_iteration_times,
+                    "launch_scheduled_runs_for_schedule_iterator did not yield a ScheduleIterationTimes",
                 )
         except Exception:
             error_info = serializable_error_info_from_exc_info(sys.exc_info())
             logger.exception(f"Scheduler caught an error for schedule {external_schedule.name}")
         yield error_info
 
 
@@ -358,49 +440,52 @@
     external_schedule: ExternalSchedule,
     schedule_state: InstigatorState,
     end_datetime_utc: datetime.datetime,
     max_catchup_runs: int,
     max_tick_retries: int,
     tick_retention_settings: Mapping[TickStatus, int],
     schedule_debug_crash_flags: Optional[SingleInstigatorDebugCrashFlags],
-    log_verbose_checks: bool,
     submit_threadpool_executor: Optional[ThreadPoolExecutor],
-) -> None:
+    in_memory_last_iteration_timestamp: Optional[float],
+) -> ScheduleIterationTimes:
     # evaluate the tick immediately, but from within a thread.  The main thread should be able to
     # heartbeat to keep the daemon alive
-    list(
-        launch_scheduled_runs_for_schedule_iterator(
-            workspace_process_context,
-            logger,
-            external_schedule,
-            schedule_state,
-            end_datetime_utc,
-            max_catchup_runs,
-            max_tick_retries,
-            tick_retention_settings,
-            schedule_debug_crash_flags,
-            log_verbose_checks,
-            submit_threadpool_executor=submit_threadpool_executor,
-        )
-    )
+    iteration_times = None
+    for yielded_value in launch_scheduled_runs_for_schedule_iterator(
+        workspace_process_context,
+        logger,
+        external_schedule,
+        schedule_state,
+        end_datetime_utc,
+        max_catchup_runs,
+        max_tick_retries,
+        tick_retention_settings,
+        schedule_debug_crash_flags,
+        submit_threadpool_executor=submit_threadpool_executor,
+        in_memory_last_iteration_timestamp=in_memory_last_iteration_timestamp,
+    ):
+        if isinstance(yielded_value, ScheduleIterationTimes):
+            iteration_times = yielded_value
+
+    return check.not_none(iteration_times)
 
 
 def launch_scheduled_runs_for_schedule_iterator(
     workspace_process_context: IWorkspaceProcessContext,
     logger: logging.Logger,
     external_schedule: ExternalSchedule,
     schedule_state: InstigatorState,
     end_datetime_utc: datetime.datetime,
     max_catchup_runs: int,
     max_tick_retries: int,
     tick_retention_settings: Mapping[TickStatus, int],
     schedule_debug_crash_flags: Optional[SingleInstigatorDebugCrashFlags],
-    log_verbose_checks: bool,
     submit_threadpool_executor: Optional[ThreadPoolExecutor],
-) -> "DaemonIterator":
+    in_memory_last_iteration_timestamp: Optional[float],
+) -> Generator[Union[None, SerializableErrorInfo, ScheduleIterationTimes], None, None]:
     schedule_state = check.inst_param(schedule_state, "schedule_state", InstigatorState)
     end_datetime_utc = check.inst_param(end_datetime_utc, "end_datetime_utc", datetime.datetime)
     instance = workspace_process_context.instance
 
     instigator_origin_id = external_schedule.get_external_origin_id()
     ticks = instance.get_ticks(instigator_origin_id, external_schedule.selector_id, limit=1)
     latest_tick: Optional[InstigatorTick] = ticks[0] if ticks else None
@@ -414,54 +499,66 @@
             and latest_tick.failure_count <= max_tick_retries
         ):
             # Scheduler was interrupted while performing this tick, re-do it
             start_timestamp_utc = max(
                 start_timestamp_utc,
                 latest_tick.timestamp,
                 instigator_data.last_iteration_timestamp or 0.0,
+                in_memory_last_iteration_timestamp or 0.0,
             )
         else:
             start_timestamp_utc = max(
                 start_timestamp_utc,
                 latest_tick.timestamp + 1,
                 instigator_data.last_iteration_timestamp or 0.0,
+                in_memory_last_iteration_timestamp or 0.0,
             )
     else:
         start_timestamp_utc = max(
             start_timestamp_utc,
             instigator_data.last_iteration_timestamp or 0.0,
+            in_memory_last_iteration_timestamp or 0.0,
         )
 
     schedule_name = external_schedule.name
 
     timezone_str = external_schedule.execution_timezone
     if not timezone_str:
         timezone_str = "UTC"
-        if log_verbose_checks:
-            logger.warn(
-                f"Using UTC as the timezone for {external_schedule.name} as it did not specify "
-                "an execution_timezone in its definition."
-            )
 
     tick_times: List[datetime.datetime] = []
+
+    now_timestamp = end_datetime_utc.timestamp()
+
+    next_iteration_timestamp = None
+
     for next_time in external_schedule.execution_time_iterator(start_timestamp_utc):
-        if next_time.timestamp() > end_datetime_utc.timestamp():
+        next_tick_timestamp = next_time.timestamp()
+        if next_tick_timestamp > now_timestamp:
+            next_iteration_timestamp = next_tick_timestamp
             break
 
         tick_times.append(next_time)
 
     if not tick_times:
-        if log_verbose_checks:
-            logger.info(f"No new tick times to evaluate for {schedule_name}")
-
-        _log_iteration_timestamp(
+        next_checkpoint_timestamp = _write_and_get_next_checkpoint_timestamp(
             instance,
             schedule_state,
             instigator_data,
-            end_datetime_utc.timestamp(),
+            now_timestamp,
+        )
+
+        next_iteration_timestamp = min(
+            check.not_none(next_iteration_timestamp), next_checkpoint_timestamp
+        )
+
+        yield ScheduleIterationTimes(
+            cron_schedule=external_schedule.cron_schedule,
+            next_iteration_timestamp=next_iteration_timestamp,
+            last_iteration_timestamp=now_timestamp,
         )
         return
 
     if not external_schedule.partition_set_name and len(tick_times) > 1:
         logger.warning(f"{schedule_name} has no partition set, so not trying to catch up")
         tick_times = tick_times[-1:]
     elif len(tick_times) > max_catchup_runs:
@@ -535,33 +632,49 @@
                             TickStatus.FAILURE,
                             error=error_data,
                             # don't increment the failure count - retry forever until the server comes back up
                             # or the schedule is turned off
                             failure_count=tick_context.failure_count,
                         )
                         yield error_data
-                        return
-
                 else:
                     error_data = serializable_error_info_from_exc_info(sys.exc_info())
                     tick_context.update_state(
                         TickStatus.FAILURE,
                         error=error_data,
                         failure_count=tick_context.failure_count + 1,
                     )
                     yield error_data
-                    return
+
+                # Plan to run the same tick again using the schedule timestamp
+                # as both the next_iteration_timestamp and the last_iteration_timestmap
+                # (to ensure that the scheduler doesn't accidentally skip past it)
+                yield ScheduleIterationTimes(
+                    cron_schedule=external_schedule.cron_schedule,
+                    next_iteration_timestamp=schedule_time.timestamp(),
+                    last_iteration_timestamp=schedule_time.timestamp(),
+                )
+                return
 
     # now log the iteration timestamp
-    _log_iteration_timestamp(
+    next_checkpoint_timestamp = _write_and_get_next_checkpoint_timestamp(
         instance,
         schedule_state,
         instigator_data,
         end_datetime_utc.timestamp(),
     )
+    next_iteration_timestamp = min(
+        check.not_none(next_iteration_timestamp), next_checkpoint_timestamp
+    )
+    yield ScheduleIterationTimes(
+        cron_schedule=external_schedule.cron_schedule,
+        next_iteration_timestamp=next_iteration_timestamp,
+        last_iteration_timestamp=now_timestamp,
+    )
+    return
 
 
 class SubmitRunRequestResult(NamedTuple):
     run_key: Optional[str]
     error_info: Optional[SerializableErrorInfo]
     existing_run: Optional[DagsterRun]
     submitted_run: Optional[DagsterRun]
@@ -592,16 +705,16 @@
             )
         else:
             logger.info(
                 f"Run {run.run_id} already created for this execution of {external_schedule.name}"
             )
     else:
         job_subset_selector = JobSubsetSelector(
-            location_name=schedule_origin.external_repository_origin.code_location_origin.location_name,
-            repository_name=schedule_origin.external_repository_origin.repository_name,
+            location_name=schedule_origin.repository_origin.code_location_origin.location_name,
+            repository_name=schedule_origin.repository_origin.repository_name,
             job_name=external_schedule.job_name,
             op_selection=external_schedule.op_selection,
             asset_selection=run_request.asset_selection,
         )
 
         # reload the code_location on each submission, request_context derived data can become out date
         # * non-threaded: if number of serial submissions is too many
@@ -645,27 +758,27 @@
 
 def _get_code_location_for_schedule(
     workspace_process_context: IWorkspaceProcessContext,
     external_schedule: ExternalSchedule,
 ) -> CodeLocation:
     schedule_origin = external_schedule.get_external_origin()
     return workspace_process_context.create_request_context().get_code_location(
-        schedule_origin.external_repository_origin.code_location_origin.location_name
+        schedule_origin.repository_origin.code_location_origin.location_name
     )
 
 
 def _schedule_runs_at_time(
     workspace_process_context: IWorkspaceProcessContext,
     logger: logging.Logger,
     external_schedule: ExternalSchedule,
     schedule_time: datetime.datetime,
     tick_context: _ScheduleLaunchContext,
     submit_threadpool_executor: Optional[ThreadPoolExecutor],
     debug_crash_flags: Optional[SingleInstigatorDebugCrashFlags] = None,
-) -> "DaemonIterator":
+) -> Generator[Union[None, SerializableErrorInfo, ScheduleIterationTimes], None, None]:
     instance = workspace_process_context.instance
     repository_handle = external_schedule.handle.repository_handle
 
     code_location = _get_code_location_for_schedule(workspace_process_context, external_schedule)
 
     schedule_execution_data = code_location.get_external_schedule_execution_data(
         instance=instance,
@@ -776,16 +889,16 @@
     matching_runs = []
     for run in existing_runs:
         # if the run doesn't have an origin consider it a match
         if run.external_job_origin is None:
             matching_runs.append(run)
         # otherwise prevent the same named schedule (with the same execution time) across repos from effecting each other
         elif (
-            external_schedule.get_external_origin().external_repository_origin.get_selector_id()
-            == run.external_job_origin.external_repository_origin.get_selector_id()
+            external_schedule.get_external_origin().repository_origin.get_selector_id()
+            == run.external_job_origin.repository_origin.get_selector_id()
         ):
             matching_runs.append(run)
 
     if not len(matching_runs):
         return None
 
     return matching_runs[0]
@@ -809,15 +922,18 @@
         run_config,
         step_keys_to_execute=None,
         known_state=None,
     )
     execution_plan_snapshot = external_execution_plan.execution_plan_snapshot
 
     tags = merge_dicts(
-        validate_tags(external_job.tags, allow_reserved_tags=False) or {},
+        normalize_tags(
+            external_job.tags, allow_reserved_tags=False, warn_on_deprecated_tags=False
+        ).tags
+        or {},
         schedule_tags,
     )
 
     tags[SCHEDULED_EXECUTION_TIME_TAG] = to_timezone(schedule_time, "UTC").isoformat()
     if run_request.run_key:
         tags[RUN_KEY_TAG] = run_request.run_key
 
@@ -852,36 +968,50 @@
             frozenset(run_request.asset_selection) if run_request.asset_selection else None
         ),
         asset_check_selection=None,
         asset_job_partitions_def=code_location.get_asset_job_partitions_def(external_job),
     )
 
 
-def _log_iteration_timestamp(
+def _write_and_get_next_checkpoint_timestamp(
     instance: DagsterInstance,
     schedule_state: InstigatorState,
     instigator_data: ScheduleInstigatorData,
     iteration_timestamp: float,
-):
-    # Utility function that logs iteration timestamps for schedules that are running, to record a
+) -> float:
+    # Utility function that writes iteration timestamps for schedules that are running, to record a
     # successful iteration, regardless of whether or not a tick was processed or not.  This is so
     # that when a cron schedule changes, we can modify the evaluation "start time" from the moment
     # that the schedule was turned on to the last time that the schedule was processed in a valid
     # state (even in between ticks).
 
     # Rather than logging every single iteration, we log every hour.  This means that if the cron
     # schedule changes to run to a time that is less than an hour ago, when the code location is
     # deployed, a tick might be registered for that time, with a run kicking off.
+
+    # Returns the next timestamp that we should plan to log the last_iteration_timestamp - with some
+    # additional jitter so that threads won't all come back at the exact same time
+    random_jitter_offset = random.randint(0, LAST_ITERATION_CHECKPOINT_JITTER_SECONDS)
+
     if (
         not instigator_data.last_iteration_timestamp
-        or instigator_data.last_iteration_timestamp + LAST_RECORDED_ITERATION_INTERVAL_SECONDS
-        < iteration_timestamp
+        or instigator_data.last_iteration_timestamp + LAST_ITERATION_CHECKPOINT_INTERVAL_SECONDS
+        <= iteration_timestamp
     ):
         instance.update_instigator_state(
             schedule_state.with_data(
                 ScheduleInstigatorData(
                     cron_schedule=instigator_data.cron_schedule,
                     start_timestamp=instigator_data.start_timestamp,
                     last_iteration_timestamp=iteration_timestamp,
                 )
             )
         )
+        return (
+            iteration_timestamp + LAST_ITERATION_CHECKPOINT_INTERVAL_SECONDS + random_jitter_offset
+        )
+
+    return (
+        instigator_data.last_iteration_timestamp
+        + LAST_ITERATION_CHECKPOINT_INTERVAL_SECONDS
+        + random_jitter_offset
+    )
```

### Comparing `dagster-1.6.9/dagster/_scheduler/stale.py` & `dagster-1.7.0/dagster/_scheduler/stale.py`

 * *Files 18% similar despite different names*

```diff
@@ -2,29 +2,28 @@
 
 import dagster._check as check
 from dagster._core.definitions.data_version import (
     CachingStaleStatusResolver,
     StaleStatus,
 )
 from dagster._core.definitions.events import AssetKey
-from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
 from dagster._core.definitions.run_request import RunRequest
-from dagster._core.host_representation.external import (
+from dagster._core.remote_representation.external import (
     ExternalSchedule,
     ExternalSensor,
 )
 from dagster._core.workspace.context import WorkspaceProcessContext
 
 
 def resolve_stale_or_missing_assets(
     context: WorkspaceProcessContext,
     run_request: RunRequest,
     instigator: Union[ExternalSensor, ExternalSchedule],
 ) -> Sequence[AssetKey]:
-    asset_graph = ExternalAssetGraph.from_workspace(context.create_request_context())
+    asset_graph = context.create_request_context().asset_graph
     asset_selection = (
         run_request.asset_selection
         if run_request.asset_selection is not None
         else asset_graph.get_materialization_asset_keys_for_job(check.not_none(instigator.job_name))
     )
     resolver = CachingStaleStatusResolver(context.instance, asset_graph)
     stale_or_unknown_keys: List[AssetKey] = []
```

### Comparing `dagster-1.6.9/dagster/_serdes/__init__.py` & `dagster-1.7.0/dagster/_serdes/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_serdes/config_class.py` & `dagster-1.7.0/dagster/_serdes/config_class.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_serdes/ipc.py` & `dagster-1.7.0/dagster/_serdes/ipc.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_serdes/serdes.py` & `dagster-1.7.0/dagster/_serdes/serdes.py`

 * *Files 1% similar despite different names*

```diff
@@ -1118,22 +1118,22 @@
                 raise SerdesUsageError(_with_header(error_msg))
 
     if len(value_params) > len(klass._fields):
         # Ensure that remaining parameters have default values
         for extra_param_index in range(len(klass._fields), len(value_params) - 1):
             if value_params[extra_param_index].default == Parameter.empty:
                 error_msg = (
-                    'Parameter "{param_name}" is a parameter to the __new__ '
+                    f'Parameter "{value_params[extra_param_index].name}" is a parameter to the __new__ '
                     "method but is not a field in this namedtuple. The only "
                     "reason why this should exist is that "
                     "it is a field that used to exist (we refer to this as the graveyard) "
                     "but no longer does. However it might exist in historical storage. This "
                     "parameter existing ensures that serdes continues to work. However these "
                     "must come at the end and have a default value for pickling to work."
-                ).format(param_name=value_params[extra_param_index].name)
+                )
                 raise SerdesUsageError(_with_header(error_msg))
 
 
 ###################################################################################################
 # Utilities
 ###################################################################################################
```

### Comparing `dagster-1.6.9/dagster/_serdes/utils.py` & `dagster-1.7.0/dagster/_serdes/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_seven/__init__.py` & `dagster-1.7.0/dagster/_seven/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_seven/abc.py` & `dagster-1.7.0/dagster/_seven/abc.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_seven/compat/pendulum.py` & `dagster-1.7.0/dagster/_seven/compat/pendulum.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,15 +26,15 @@
 
 def pendulum_create_timezone(tz_name: str):
     if _IS_PENDULUM_3:
         from pendulum.tz.timezone import Timezone
 
         return Timezone(tz_name)
     else:
-        return pendulum.tz.timezone(tz_name)  # type: ignore
+        return pendulum.tz.timezone(tz_name)
 
 
 @contextmanager
 def mock_pendulum_timezone(override_timezone):
     if _IS_PENDULUM_1:
         with pendulum.tz.LocalTimezone.test(pendulum.Timezone.load(override_timezone)):
             yield
```

### Comparing `dagster-1.6.9/dagster/_utils/__init__.py` & `dagster-1.7.0/dagster/_utils/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 import signal
 import socket
 import subprocess
 import sys
 import tempfile
 import threading
 import time
-from collections import OrderedDict
+import uuid
 from datetime import timezone
 from enum import Enum
 from signal import Signals
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Any,
@@ -635,28 +635,31 @@
 def dict_without_keys(ddict, *keys):
     return {key: value for key, value in ddict.items() if key not in set(keys)}
 
 
 class Counter:
     def __init__(self):
         self._lock = threading.Lock()
-        self._counts = OrderedDict()
+        self._counts = {}
         super(Counter, self).__init__()
 
     def increment(self, key: str):
         with self._lock:
             self._counts[key] = self._counts.get(key, 0) + 1
 
     def counts(self) -> Mapping[str, int]:
         with self._lock:
             copy = {k: v for k, v in self._counts.items()}
         return copy
 
 
-traced_counter = contextvars.ContextVar("traced_counts", default=Counter())
+traced_counter: contextvars.ContextVar[Optional[Counter]] = contextvars.ContextVar(
+    "traced_counts",
+    default=None,
+)
 
 T_Callable = TypeVar("T_Callable", bound=Callable)
 
 
 def traced(func: T_Callable) -> T_Callable:
     """A decorator that keeps track of how many times a function is called."""
 
@@ -765,7 +768,15 @@
             line = output_stream.readline()
             if line:
                 yield line
             elif should_stop():
                 break
             else:
                 time.sleep(0.01)
+
+
+def is_uuid(value: str) -> bool:
+    try:
+        uuid.UUID(value)
+        return True
+    except ValueError:
+        return False
```

### Comparing `dagster-1.6.9/dagster/_utils/alert.py` & `dagster-1.7.0/dagster/_utils/alert.py`

 * *Files 0% similar despite different names*

```diff
@@ -14,15 +14,15 @@
     from dagster._core.definitions.selector import JobSelector, RepositorySelector
     from dagster._core.definitions.unresolved_asset_job_definition import (
         UnresolvedAssetJobDefinition,
     )
 
 
 def _default_failure_email_body(context: "RunFailureSensorContext") -> str:
-    from dagster._core.host_representation.external_data import DEFAULT_MODE_NAME
+    from dagster._core.remote_representation.external_data import DEFAULT_MODE_NAME
 
     return "<br>".join(
         [
             f"Job {context.dagster_run.job_name} failed!",
             f"Run ID: {context.dagster_run.run_id}",
             f"Mode: {DEFAULT_MODE_NAME}",
             f"Error: {context.failure_event.message}",
```

### Comparing `dagster-1.6.9/dagster/_utils/backoff.py` & `dagster-1.7.0/dagster/_utils/backoff.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/cached_method.py` & `dagster-1.7.0/dagster/_utils/cached_method.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from functools import wraps
-from typing import AbstractSet, Callable, Dict, Hashable, Mapping, Tuple, Type, TypeVar
+from typing import Callable, Dict, Hashable, Mapping, Tuple, TypeVar
 
 from typing_extensions import Concatenate, ParamSpec
 
-from dagster import _check as check
+from dagster._seven import get_arg_names
 
 S = TypeVar("S")
 T = TypeVar("T")
 T_Callable = TypeVar("T_Callable", bound=Callable)
 P = ParamSpec("P")
 
 
@@ -44,28 +44,64 @@
                     ...
 
             obj = MyClass()
             obj.a_method(arg1="a", arg2=5)
             obj.a_method(arg2=5, arg1="a")
             obj.a_method("a", 5)
 
-    With this decorator, the first two would point to the same cache entry, and non-kwarg arguments
-    are not allowed.
+    With this decorator, keyword and non-keyword arg usage is canonicalized and the above
+    calls result in the same cache entry
+
+    Using ordinal arguments rather than kwargs represents introduces about 15% more overhead
+    per call.
+
+    However, the use of _any_ @cached_method decorated method a introduces ~20x (as in 2100%)
+    overhead per call over undecorated methods, so use this carefully. The operation
+    that this caches should be expensive enough so that 15% overhead on the function
+    call is immaterial.  See for https://github.com/dagster-io/dagster/pull/20212
+    script, data, and discussion of these matters.
     """
     cache_attr_name = method.__name__ + CACHED_METHOD_FIELD_SUFFIX
 
+    arg_names = None
+
     @wraps(method)
     def _cached_method_wrapper(self: S, *args: P.args, **kwargs: P.kwargs) -> T:
         if not hasattr(self, cache_attr_name):
             cache: Dict[Hashable, T] = {}
             setattr(self, cache_attr_name, cache)
         else:
             cache = getattr(self, cache_attr_name)
 
-        key = _make_key(args, kwargs)
+        canonical_kwargs = None
+        if args:
+            # Entering this block introduces about 15% overhead per call
+            # See top-level docblock for more details.
+
+            # nonlocal required to bind to variable in enclosing scope
+            nonlocal arg_names
+            # only create the lookup table on demand to avoid overhead
+            # if the cached method is never called with positional arguments
+            arg_names = arg_names if arg_names is not None else get_arg_names(method)[1:]
+
+            translated_kwargs = {}
+            for arg_ordinal, arg_value in enumerate(args):
+                arg_name = arg_names[arg_ordinal]
+                translated_kwargs[arg_name] = arg_value
+            if kwargs:
+                # only copy if both args and kwargs were passed
+                canonical_kwargs = {**translated_kwargs, **kwargs}
+            else:
+                # no copy
+                canonical_kwargs = translated_kwargs
+        else:
+            # no copy
+            canonical_kwargs = kwargs
+
+        key = _make_key(canonical_kwargs)
         if key not in cache:
             result = method(self, *args, **kwargs)
             cache[key] = result
         return cache[key]
 
     return _cached_method_wrapper
 
@@ -85,38 +121,31 @@
         self.hashvalue = hash(tup)
 
     def __hash__(self) -> int:
         return self.hashvalue
 
 
 def _make_key(
-    args: Tuple[object, ...],
-    kwds: Mapping[str, object],
-    fasttypes: AbstractSet[Type[object]] = {int, str},
+    canonical_kwargs: Mapping[str, object],
 ) -> Hashable:
     """Adapted from https://github.com/python/cpython/blob/f9433fff476aa13af9cb314fcc6962055faa4085/Lib/functools.py#L448.
 
     Make a cache key from optionally typed positional and keyword arguments
     The key is constructed in a way that is flat as possible rather than
     as a nested structure that would take more memory.
+
     If there is only a single argument and its data type is known to cache
     its hash value, then that argument is returned without a wrapper.  This
     saves space and improves lookup speed.
     """
-    if args:
-        check.failed(
-            "@cached_method does not support non-keyword arguments, because doing so would"
-            " enable functionally identical sets of arguments to correspond to different cache"
-            " keys.",
-        )
-
     # if no args return a shared value
-    if not kwds:
+    if not canonical_kwargs:
         return NO_ARGS_HASH_VALUE
 
     # if single fast (str/int) arg, use that value for hash
-    if len(kwds) == 1:
-        k, v = next(iter(kwds.items()))
-        if type(v) in fasttypes:
+    if len(canonical_kwargs) == 1:
+        k, v = next(iter(canonical_kwargs.items()))
+        type_v = type(v)
+        if type_v is str or type_v is int:
             return f"{k}.{v}"
 
-    return _HashedSeq(tuple(sorted(kwds.items())))
+    return _HashedSeq(tuple(sorted(canonical_kwargs.items())))
```

### Comparing `dagster-1.6.9/dagster/_utils/caching_instance_queryer.py` & `dagster-1.7.0/dagster/_utils/caching_instance_queryer.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,17 +14,17 @@
     Union,
     cast,
 )
 
 import pendulum
 
 import dagster._check as check
-from dagster._core.definitions.asset_graph import AssetGraph
 from dagster._core.definitions.asset_graph_subset import AssetGraphSubset
 from dagster._core.definitions.asset_subset import AssetSubset, ValidAssetSubset
+from dagster._core.definitions.base_asset_graph import BaseAssetGraph
 from dagster._core.definitions.data_version import (
     DATA_VERSION_TAG,
     DataVersion,
     extract_data_version_from_entry,
 )
 from dagster._core.definitions.events import AssetKey, AssetKeyPartitionKey
 from dagster._core.definitions.partition import (
@@ -63,15 +63,15 @@
     Args:
         instance (DagsterInstance): The instance to query.
     """
 
     def __init__(
         self,
         instance: DagsterInstance,
-        asset_graph: AssetGraph,
+        asset_graph: BaseAssetGraph,
         evaluation_time: Optional[datetime] = None,
         logger: Optional[logging.Logger] = None,
     ):
         self._instance = instance
         self._asset_graph = asset_graph
         self._logger = logger or logging.getLogger("dagster")
 
@@ -92,15 +92,15 @@
         )
 
     @property
     def instance(self) -> DagsterInstance:
         return self._instance
 
     @property
-    def asset_graph(self) -> AssetGraph:
+    def asset_graph(self) -> BaseAssetGraph:
         return self._asset_graph
 
     @property
     def evaluation_time(self) -> datetime:
         return self._evaluation_time
 
     ####################
@@ -126,42 +126,42 @@
 
     @cached_method
     def _get_updated_cache_value(self, *, asset_key: AssetKey) -> Optional["AssetStatusCacheValue"]:
         from dagster._core.storage.partition_status_cache import (
             get_and_update_asset_status_cache_value,
         )
 
-        partitions_def = check.not_none(self.asset_graph.get_partitions_def(asset_key))
+        partitions_def = check.not_none(self.asset_graph.get(asset_key).partitions_def)
         asset_record = self.get_asset_record(asset_key)
         return get_and_update_asset_status_cache_value(
             instance=self.instance,
             asset_key=asset_key,
             partitions_def=partitions_def,
             dynamic_partitions_loader=self,
             asset_record=asset_record,
         )
 
     @cached_method
     def get_failed_or_in_progress_subset(self, *, asset_key: AssetKey) -> PartitionsSubset:
         """Returns a PartitionsSubset representing the set of partitions that are either in progress
         or whose last materialization attempt failed.
         """
-        partitions_def = check.not_none(self.asset_graph.get_partitions_def(asset_key))
+        partitions_def = check.not_none(self.asset_graph.get(asset_key).partitions_def)
         cache_value = self._get_updated_cache_value(asset_key=asset_key)
         if cache_value is None:
             return partitions_def.empty_subset()
 
         return cache_value.deserialize_failed_partition_subsets(
             partitions_def
         ) | cache_value.deserialize_in_progress_partition_subsets(partitions_def)
 
     @cached_method
     def get_materialized_asset_subset(self, *, asset_key: AssetKey) -> AssetSubset:
         """Returns an AssetSubset representing the subset of the asset that has been materialized."""
-        partitions_def = self.asset_graph.get_partitions_def(asset_key)
+        partitions_def = self.asset_graph.get(asset_key).partitions_def
         if partitions_def:
             cache_value = self._get_updated_cache_value(asset_key=asset_key)
             if cache_value is None:
                 value = partitions_def.empty_subset()
             else:
                 value = cache_value.deserialize_materialized_partition_subsets(partitions_def)
         else:
@@ -181,15 +181,15 @@
         if asset_key not in self._asset_record_cache:
             self._asset_record_cache[asset_key] = next(
                 iter(self.instance.get_asset_records([asset_key])), None
             )
         return self._asset_record_cache[asset_key]
 
     def _event_type_for_key(self, asset_key: AssetKey) -> DagsterEventType:
-        if self.asset_graph.is_observable(asset_key):
+        if self.asset_graph.get(asset_key).is_observable:
             return DagsterEventType.ASSET_OBSERVATION
         else:
             return DagsterEventType.ASSET_MATERIALIZATION
 
     @cached_method
     def _get_latest_materialization_or_observation_record(
         self, *, asset_partition: AssetKeyPartitionKey, before_cursor: Optional[int] = None
@@ -199,16 +199,16 @@
         AssetMaterialization.
         """
         # in the simple case, just use the asset record
         if (
             before_cursor is None
             and asset_partition.partition_key is None
             and not (
-                self.asset_graph.has_asset(asset_partition.asset_key)
-                and self.asset_graph.is_observable(asset_partition.asset_key)
+                self.asset_graph.has(asset_partition.asset_key)
+                and self.asset_graph.get(asset_partition.asset_key).is_observable
             )
         ):
             asset_record = self.get_asset_record(asset_partition.asset_key)
             if asset_record is None:
                 return None
             return asset_record.asset_entry.last_materialization_record
 
@@ -239,15 +239,15 @@
         asset_partition = AssetKeyPartitionKey(asset_key)
         latest_record = self._get_latest_materialization_or_observation_record(
             asset_partition=asset_partition
         )
         latest_storage_ids = {
             asset_partition: latest_record.storage_id if latest_record is not None else None
         }
-        if self.asset_graph.is_partitioned(asset_key):
+        if self.asset_graph.get(asset_key).is_partitioned:
             latest_storage_ids.update(
                 {
                     AssetKeyPartitionKey(asset_key, partition_key): storage_id
                     for partition_key, storage_id in self.instance.get_latest_storage_id_by_partition(
                         asset_key, event_type=self._event_type_for_key(asset_key)
                     ).items()
                 }
@@ -282,15 +282,15 @@
 
         Args:
             asset_partition (AssetKeyPartitionKey): The asset partition to query.
             after_cursor (Optional[int]): Filter parameter such that only records with a storage_id
                 greater than this value will be considered.
         """
         asset_key = asset_partition.asset_key
-        if self.asset_graph.has_asset(asset_key) and self.asset_graph.is_materializable(asset_key):
+        if self.asset_graph.has(asset_key) and self.asset_graph.get(asset_key).is_materializable:
             asset_record = self.get_asset_record(asset_key)
             if (
                 asset_record is None
                 or asset_record.asset_entry.last_materialization_record is None
                 or (
                     after_cursor
                     and asset_record.asset_entry.last_materialization_record.storage_id
@@ -536,30 +536,30 @@
         latest_storage_id: Optional[int],
         child_asset_key: AssetKey,
         map_old_time_partitions: bool = True,
     ) -> Tuple[AbstractSet[AssetKeyPartitionKey], Optional[int]]:
         """Finds asset partitions of the given child whose parents have been materialized since
         latest_storage_id.
         """
-        if not self.asset_graph.get_parents(child_asset_key):
+        child_asset = self.asset_graph.get(child_asset_key)
+        if not child_asset.parent_keys:
             return set(), latest_storage_id
 
-        child_partitions_def = self.asset_graph.get_partitions_def(child_asset_key)
-        child_time_partitions_def = get_time_partitions_def(child_partitions_def)
+        child_time_partitions_def = get_time_partitions_def(child_asset.partitions_def)
 
         child_asset_partitions_with_updated_parents = set()
 
         max_storage_ids = [
             self.get_latest_materialization_or_observation_storage_id(
                 AssetKeyPartitionKey(child_asset_key)
             )
         ]
-        for parent_asset_key in self.asset_graph.get_parents(child_asset_key):
+        for parent_asset_key in self.asset_graph.get(child_asset_key).parent_keys:
             # ignore non-existent parents
-            if not self.asset_graph.has_asset(parent_asset_key):
+            if not self.asset_graph.has(parent_asset_key):
                 continue
 
             # if the parent has not been updated at all since the latest_storage_id, then skip
             if not self.get_asset_partitions_updated_after_cursor(
                 asset_key=parent_asset_key,
                 asset_partitions=None,
                 after_cursor=latest_storage_id,
@@ -570,70 +570,70 @@
             # keep track of the maximum storage id that we've seen for a given parent
             max_storage_ids.append(
                 self.get_latest_materialization_or_observation_storage_id(
                     AssetKeyPartitionKey(parent_asset_key)
                 )
             )
 
-            parent_partitions_def = self.asset_graph.get_partitions_def(parent_asset_key)
+            parent_partitions_def = self.asset_graph.get(parent_asset_key).partitions_def
             if parent_partitions_def is None:
                 latest_parent_record = check.not_none(
                     self.get_latest_materialization_or_observation_record(
                         AssetKeyPartitionKey(parent_asset_key), after_cursor=latest_storage_id
                     )
                 )
                 for child_partition_key in (
                     self.asset_graph.get_child_partition_keys_of_parent(
                         dynamic_partitions_store=self,
                         parent_partition_key=None,
                         parent_asset_key=parent_asset_key,
                         child_asset_key=child_asset_key,
                         current_time=self.evaluation_time,
                     )
-                    if child_partitions_def
+                    if child_asset.partitions_def
                     else [None]
                 ):
                     if not (
                         # when mapping from unpartitioned assets to time partitioned assets, we ignore
                         # historical time partitions
                         not map_old_time_partitions
                         and child_time_partitions_def is not None
-                        and get_time_partition_key(child_partitions_def, child_partition_key)
+                        and get_time_partition_key(child_asset.partitions_def, child_partition_key)
                         != child_time_partitions_def.get_last_partition_key(
                             current_time=self.evaluation_time
                         )
                     ) and not self.is_asset_planned_for_run(
                         latest_parent_record.run_id, child_asset_key
                     ):
                         child_asset_partitions_with_updated_parents.add(
                             AssetKeyPartitionKey(child_asset_key, child_partition_key)
                         )
             else:
                 # we know a parent updated, and because the parent has a partitions def and the
                 # child does not, the child could not have been materialized in the same run
-                if child_partitions_def is None:
+                if child_asset.partitions_def is None:
                     child_asset_partitions_with_updated_parents = {
                         AssetKeyPartitionKey(child_asset_key)
                     }
                     break
                 # the set of asset partitions which have been updated since the latest storage id
                 parent_partitions_subset = self.get_asset_subset_updated_after_cursor(
                     asset_key=parent_asset_key, after_cursor=latest_storage_id
                 ).subset_value
                 # we are mapping from the partitions of the parent asset to the partitions of
                 # the child asset
                 partition_mapping = self.asset_graph.get_partition_mapping(
-                    asset_key=child_asset_key, in_asset_key=parent_asset_key
+                    asset_key=child_asset_key, parent_asset_key=parent_asset_key
                 )
                 try:
                     child_partitions_subset = (
                         partition_mapping.get_downstream_partitions_for_partitions(
                             parent_partitions_subset,
                             upstream_partitions_def=parent_partitions_def,
-                            downstream_partitions_def=child_partitions_def,
+                            downstream_partitions_def=child_asset.partitions_def,
                             dynamic_partitions_store=self,
                             current_time=self.evaluation_time,
                         )
                     )
                 except DagsterInvalidDefinitionError as e:
                     # add a more helpful error message to the stack
                     raise DagsterInvalidDefinitionError(
@@ -643,15 +643,15 @@
                 for child_partition in child_partitions_subset.get_partition_keys():
                     # we need to see if the child is planned for the same run, but this is
                     # expensive, so we try to avoid doing so in as many situations as possible
                     child_asset_partition = AssetKeyPartitionKey(child_asset_key, child_partition)
                     if (
                         # if child has a different partitions def than the parent, then it must
                         # have been executed in a different run, so it's a valid candidate
-                        child_partitions_def != parent_partitions_def
+                        child_asset.partitions_def != parent_partitions_def
                         # if child partition key is not the same as any newly materialized
                         # parent key, then it could not have been executed in the same run as
                         # its parent
                         or child_partition not in parent_partitions_subset
                         # if child partition is not failed or in progress, then if it was
                         # executed in the same run as its parent, then it must have been
                         # materialized more recently than its parent
@@ -687,15 +687,15 @@
     def _asset_partitions_data_versions(
         self,
         asset_key: AssetKey,
         asset_partitions: Optional[AbstractSet[AssetKeyPartitionKey]],
         after_cursor: Optional[int] = None,
         before_cursor: Optional[int] = None,
     ) -> Mapping[AssetKeyPartitionKey, Optional[DataVersion]]:
-        if not self.asset_graph.is_partitioned(asset_key):
+        if not self.asset_graph.get(asset_key).is_partitioned:
             asset_partition = AssetKeyPartitionKey(asset_key)
             latest_record = self.get_latest_materialization_or_observation_record(
                 asset_partition, after_cursor=after_cursor, before_cursor=before_cursor
             )
             return (
                 {asset_partition: extract_data_version_from_entry(latest_record.event_log_entry)}
                 if latest_record is not None
@@ -803,30 +803,30 @@
                 latest_storage_id = last_storage_id_by_asset_partition.get(asset_partition)
                 if latest_storage_id is not None and latest_storage_id > (after_cursor or 0):
                     updated_after_cursor.add(asset_partition)
 
         if not updated_after_cursor:
             return set()
         if after_cursor is None or (
-            not self.asset_graph.is_observable(asset_key)
+            not self.asset_graph.get(asset_key).is_observable
             and not respect_materialization_data_versions
         ):
             return updated_after_cursor
 
         # more expensive check to explicitly handle data versions
         return self._asset_partition_versions_updated_after_cursor(
             asset_key, updated_after_cursor, after_cursor
         )
 
     @cached_method
     def get_asset_subset_updated_after_cursor(
         self, *, asset_key: AssetKey, after_cursor: Optional[int]
     ) -> ValidAssetSubset:
         """Returns the AssetSubset of the given asset that has been updated after the given cursor."""
-        partitions_def = self.asset_graph.get_partitions_def(asset_key)
+        partitions_def = self.asset_graph.get(asset_key).partitions_def
         if partitions_def is None:
             return ValidAssetSubset(
                 asset_key,
                 value=self.asset_partition_has_materialization_or_observation(
                     AssetKeyPartitionKey(asset_key), after_cursor=after_cursor
                 ),
             )
@@ -851,15 +851,15 @@
             )
 
     @cached_method
     def get_asset_subset_updated_after_time(
         self, *, asset_key: AssetKey, after_time: datetime
     ) -> ValidAssetSubset:
         """Returns the AssetSubset of the given asset that has been updated after the given time."""
-        partitions_def = self.asset_graph.get_partitions_def(asset_key)
+        partitions_def = self.asset_graph.get(asset_key).partitions_def
 
         method = (
             self.instance.fetch_materializations
             if self._event_type_for_key(asset_key) == DagsterEventType.ASSET_MATERIALIZATION
             else self.instance.fetch_observations
         )
         first_event_after_time = next(
@@ -889,31 +889,31 @@
         """Returns values inside parent_asset_partitions that correspond to asset partitions that
         have been updated since the latest materialization of asset_partition.
         """
         parent_asset_partitions_by_key: Dict[AssetKey, Set[AssetKeyPartitionKey]] = defaultdict(set)
         for parent in parent_asset_partitions:
             parent_asset_partitions_by_key[parent.asset_key].add(parent)
 
-        partitions_def = self.asset_graph.get_partitions_def(asset_partition.asset_key)
+        partitions_def = self.asset_graph.get(asset_partition.asset_key).partitions_def
         updated_parents = set()
 
         for parent_key, parent_asset_partitions in parent_asset_partitions_by_key.items():
             # ignore updates to particular parents
             if parent_key in ignored_parent_keys:
                 continue
 
             # ignore non-existent parents
-            if not self.asset_graph.has_asset(parent_key):
+            if not self.asset_graph.has(parent_key):
                 continue
 
             # when mapping from unpartitioned assets to time partitioned assets, we ignore
             # historical time partitions
             if (
                 isinstance(partitions_def, TimeWindowPartitionsDefinition)
-                and not self.asset_graph.is_partitioned(parent_key)
+                and not self.asset_graph.get(parent_key).is_partitioned
                 and asset_partition.partition_key
                 != partitions_def.get_last_partition_key(
                     current_time=self.evaluation_time, dynamic_partitions_store=self
                 )
             ):
                 continue
 
@@ -945,29 +945,29 @@
     @cached_method
     def get_outdated_ancestors(
         self, *, asset_partition: AssetKeyPartitionKey
     ) -> AbstractSet[AssetKey]:
         asset_key = asset_partition.asset_key
         partition_key = asset_partition.partition_key
         if not (
-            self.asset_graph.has_asset(asset_key) and self.asset_graph.is_materializable(asset_key)
+            self.asset_graph.has(asset_key) and self.asset_graph.get(asset_key).is_materializable
         ):
             return set()
 
         parent_asset_partitions = self.asset_graph.get_parents_partitions(
             dynamic_partitions_store=self,
             current_time=self._evaluation_time,
             asset_key=asset_key,
             partition_key=partition_key,
         ).parent_partitions
 
         # the set of parent keys which we don't need to check
         ignored_parent_keys = {
             parent
-            for parent in self.asset_graph.get_parents(asset_key)
+            for parent in self.asset_graph.get(asset_key).parent_keys
             if self.have_ignorable_partition_mapping_for_outdated(asset_key, parent)
         }
 
         updated_parents = self.get_parent_asset_partitions_updated_after_child(
             asset_partition=asset_partition,
             parent_asset_partitions=parent_asset_partitions,
             respect_materialization_data_versions=self._respect_materialization_data_versions,
```

### Comparing `dagster-1.6.9/dagster/_utils/concurrency.py` & `dagster-1.7.0/dagster/_utils/concurrency.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/container.py` & `dagster-1.7.0/dagster/_utils/container.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/dagster_type.py` & `dagster-1.7.0/dagster/_utils/dagster_type.py`

 * *Files 7% similar despite different names*

```diff
@@ -50,12 +50,10 @@
         try:
             type_check = dagster_type.type_check(type_check_context, value)
         except Failure as failure:
             return TypeCheck(success=False, description=failure.description)
 
         if not isinstance(type_check, TypeCheck):
             raise DagsterInvariantViolationError(
-                "Type checks can only return TypeCheck. Type {type_name} returned {value}.".format(
-                    type_name=dagster_type.display_name, value=repr(type_check)
-                )
+                f"Type checks can only return TypeCheck. Type {dagster_type.display_name} returned {type_check!r}."
             )
         return type_check
```

### Comparing `dagster-1.6.9/dagster/_utils/env.py` & `dagster-1.7.0/dagster/_utils/env.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/error.py` & `dagster-1.7.0/dagster/_utils/error.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/external.py` & `dagster-1.7.0/dagster/_utils/external.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from typing import Optional, Sequence
 
 import dagster._check as check
 from dagster._core.definitions.selector import JobSubsetSelector
-from dagster._core.host_representation import CodeLocation
-from dagster._core.host_representation.external import ExternalJob
-from dagster._core.host_representation.origin import ExternalJobOrigin
+from dagster._core.remote_representation import CodeLocation
+from dagster._core.remote_representation.external import ExternalJob
+from dagster._core.remote_representation.origin import RemoteJobOrigin
 
 
 def external_job_from_location(
     code_location: CodeLocation,
-    external_job_origin: ExternalJobOrigin,
+    external_job_origin: RemoteJobOrigin,
     op_selection: Optional[Sequence[str]],
 ) -> ExternalJob:
     check.inst_param(code_location, "code_location", CodeLocation)
-    check.inst_param(external_job_origin, "external_pipeline_origin", ExternalJobOrigin)
+    check.inst_param(external_job_origin, "external_pipeline_origin", RemoteJobOrigin)
 
-    repo_name = external_job_origin.external_repository_origin.repository_name
+    repo_name = external_job_origin.repository_origin.repository_name
     job_name = external_job_origin.job_name
 
     check.invariant(
         code_location.has_repository(repo_name),
         f"Could not find repository {repo_name} in location {code_location.name}",
     )
     external_repo = code_location.get_repository(repo_name)
```

### Comparing `dagster-1.6.9/dagster/_utils/forked_pdb.py` & `dagster-1.7.0/dagster/_utils/forked_pdb.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/hosted_user_process.py` & `dagster-1.7.0/dagster/_utils/hosted_user_process.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,19 +6,19 @@
 
 These should only be invoked from contexts where we know this
 to be the case.
 """
 
 import dagster._check as check
 from dagster._core.definitions.reconstruct import ReconstructableJob, ReconstructableRepository
-from dagster._core.host_representation import ExternalJob
-from dagster._core.host_representation.external_data import (
+from dagster._core.origin import JobPythonOrigin, RepositoryPythonOrigin
+from dagster._core.remote_representation import ExternalJob
+from dagster._core.remote_representation.external_data import (
     external_job_data_from_def,
 )
-from dagster._core.origin import JobPythonOrigin, RepositoryPythonOrigin
 
 
 def recon_job_from_origin(origin: JobPythonOrigin) -> ReconstructableJob:
     check.inst_param(origin, "origin", JobPythonOrigin)
     recon_repo = recon_repository_from_origin(origin.repository_origin)
     return recon_repo.get_reconstructable_job(origin.job_name)
 
@@ -40,10 +40,10 @@
             op_selection=op_selection, asset_selection=asset_selection
         )
         job_def = sub_recon_job.get_definition()
     else:
         job_def = recon_job.get_definition()
 
     return ExternalJob(
-        external_job_data_from_def(job_def),
+        external_job_data_from_def(job_def, include_parent_snapshot=True),
         repository_handle=repository_handle,
     )
```

### Comparing `dagster-1.6.9/dagster/_utils/indenting_printer.py` & `dagster-1.7.0/dagster/_utils/indenting_printer.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/internal_init.py` & `dagster-1.7.0/dagster/_utils/internal_init.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/interrupts.py` & `dagster-1.7.0/dagster/_utils/interrupts.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/log.py` & `dagster-1.7.0/dagster/_utils/log.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/merger.py` & `dagster-1.7.0/dagster/_utils/merger.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/net.py` & `dagster-1.7.0/dagster/_utils/net.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/schedules.py` & `dagster-1.7.0/dagster/_utils/schedules.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 import calendar
 import datetime
 import functools
 import math
+import re
 from typing import Iterator, Optional, Sequence, Union
 
 import pendulum
 from croniter import croniter as _croniter
 
 import dagster._check as check
 from dagster._core.definitions.partition import ScheduleType
@@ -17,14 +18,18 @@
     create_pendulum_time,
     get_crontab_day_of_week,
 )
 
 # Monthly schedules with 29-31 won't reliably run every month
 MAX_DAY_OF_MONTH_WITH_GUARANTEED_MONTHLY_INTERVAL = 28
 
+CRON_RANGES = ((0, 59), (0, 23), (1, 31), (1, 12), (0, 7), (0, 59))
+CRON_STEP_SEARCH_REGEX = re.compile(r"^([^-]+)-([^-/]+)(/(\d+))?$")
+INT_REGEX = re.compile(r"^\d+$")
+
 
 class CroniterShim(_croniter):
     """Lightweight shim to enable caching certain values that may be calculated many times."""
 
     @classmethod
     @functools.lru_cache(maxsize=128)
     def expand(cls, *args, **kwargs):
@@ -626,14 +631,57 @@
                 next_date=next_date,
                 timezone_str=timezone_str,
                 repeats_every_hour=repeats_every_hour,
                 ascending=ascending,
             )
 
 
+def _has_out_of_range_cron_interval_str(cron_string: str):
+    assert CroniterShim.is_valid(cron_string)
+    try:
+        for i, cron_part in enumerate(cron_string.lower().split()):
+            expr_parts = cron_part.split(",")
+            while len(expr_parts) > 0:
+                expr = expr_parts.pop()
+                t = re.sub(
+                    r"^\*(\/.+)$", r"%d-%d\1" % (CRON_RANGES[i][0], CRON_RANGES[i][1]), str(expr)
+                )
+                m = CRON_STEP_SEARCH_REGEX.search(t)
+                if not m:
+                    # try normalizing "{start}/{step}" to "{start}-{max}/{step}".
+                    t = re.sub(r"^(.+)\/(.+)$", r"\1-%d/\2" % (CRON_RANGES[i][1]), str(expr))
+                    m = CRON_STEP_SEARCH_REGEX.search(t)
+                if m:
+                    (low, high, step) = m.group(1), m.group(2), m.group(4) or 1
+                    if i == 2 and high == "l":
+                        high = "31"
+                    if not INT_REGEX.search(low) or not INT_REGEX.search(high):
+                        continue
+                    low, high, step = map(int, [low, high, step])
+                    if step > high:
+                        return True
+    except:
+        pass
+    return False
+
+
+def has_out_of_range_cron_interval(cron_schedule: Union[str, Sequence[str]]):
+    """Utility function to detect cron schedules like '*/90 * * * *', which are valid cron schedules
+    but which evaluate to once every hour, not once every 90 minutes as might be expected.  This is
+    useful to detect so that we can issue warnings or some other kind of feedback to the user.  This
+    function does not detect cases where the step does not divide cleanly in the range, which is
+    another case that might cause some surprising behavior (e.g. '*/7 * * * *').
+    """
+    return (
+        _has_out_of_range_cron_interval_str(cron_schedule)
+        if isinstance(cron_schedule, str)
+        else any(_has_out_of_range_cron_interval_str(s) for s in cron_schedule)
+    )
+
+
 def cron_string_iterator(
     start_timestamp: float,
     cron_string: str,
     execution_timezone: Optional[str],
     ascending: bool = True,
     start_offset: int = 0,
 ) -> Iterator[datetime.datetime]:
@@ -849,7 +897,21 @@
             # Choose earliest out of all subsequent datetimes.
             earliest_next_date = min(next_dates)
             yield earliest_next_date
             # Increment all iterators that generated the earliest subsequent datetime.
             for i, next_date in enumerate(next_dates):
                 if next_date == earliest_next_date:
                     next_dates[i] = next(iterators[i])
+
+
+def get_latest_completed_cron_tick(
+    cron_string: Optional[str], current_time: datetime.datetime, timezone: Optional[str]
+) -> Optional[datetime.datetime]:
+    if not cron_string:
+        return None
+
+    cron_iter = reverse_cron_string_iterator(
+        end_timestamp=current_time.timestamp(),
+        cron_string=cron_string,
+        execution_timezone=timezone,
+    )
+    return pendulum.instance(next(cron_iter))
```

### Comparing `dagster-1.6.9/dagster/_utils/tags.py` & `dagster-1.7.0/dagster/_utils/tags.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/temp_file.py` & `dagster-1.7.0/dagster/_utils/temp_file.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/test/__init__.py` & `dagster-1.7.0/dagster/_utils/test/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/test/data_versions.py` & `dagster-1.7.0/dagster/_utils/test/data_versions.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 from typing import Any, Dict, List, Mapping, Optional, Sequence, Tuple, Union, cast, overload
 
 from typing_extensions import Literal
 
+from dagster._core.definitions.asset_graph import AssetGraph
 from dagster._core.definitions.assets import AssetsDefinition
 from dagster._core.definitions.data_version import (
     CODE_VERSION_TAG,
     DATA_VERSION_TAG,
     INPUT_DATA_VERSION_TAG_PREFIX,
     CachingStaleStatusResolver,
     DataVersion,
 )
 from dagster._core.definitions.events import AssetKey, AssetMaterialization
-from dagster._core.definitions.internal_asset_graph import InternalAssetGraph
 from dagster._core.definitions.materialize import materialize
 from dagster._core.definitions.run_config import RunConfig
 from dagster._core.definitions.source_asset import SourceAsset
 from dagster._core.execution.execute_in_process_result import ExecuteInProcessResult
 from dagster._core.instance import DagsterInstance
 from dagster._core.storage.io_manager import IOManager, io_manager
 
@@ -210,9 +210,9 @@
 
 def get_stale_status_resolver(
     instance: DagsterInstance,
     assets: Sequence[Union[AssetsDefinition, SourceAsset]],
 ) -> CachingStaleStatusResolver:
     return CachingStaleStatusResolver(
         instance=instance,
-        asset_graph=InternalAssetGraph.from_assets(assets),
+        asset_graph=AssetGraph.from_assets(assets),
     )
```

### Comparing `dagster-1.6.9/dagster/_utils/test/mysql_instance.py` & `dagster-1.7.0/dagster/_utils/test/mysql_instance.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/test/postgres_instance.py` & `dagster-1.7.0/dagster/_utils/test/postgres_instance.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/test/schedule_storage.py` & `dagster-1.7.0/dagster/_utils/test/schedule_storage.py`

 * *Files 0% similar despite different names*

```diff
@@ -9,17 +9,17 @@
     AssetConditionEvaluation,
     AssetConditionSnapshot,
     AssetSubsetWithMetadata,
 )
 from dagster._core.definitions.asset_subset import AssetSubset
 from dagster._core.definitions.events import AssetKey
 from dagster._core.definitions.metadata import MetadataValue
-from dagster._core.host_representation import (
-    ExternalRepositoryOrigin,
+from dagster._core.remote_representation import (
     ManagedGrpcPythonEnvCodeLocationOrigin,
+    RemoteRepositoryOrigin,
 )
 from dagster._core.scheduler.instigation import (
     InstigatorState,
     InstigatorStatus,
     InstigatorType,
     ScheduleInstigatorData,
     TickData,
@@ -66,15 +66,15 @@
         return True
 
     def can_get_single_tick(self):
         return True
 
     @staticmethod
     def fake_repo_target():
-        return ExternalRepositoryOrigin(
+        return RemoteRepositoryOrigin(
             ManagedGrpcPythonEnvCodeLocationOrigin(
                 LoadableTargetOrigin(
                     executable_path=sys.executable, module_name="fake", attribute="fake"
                 ),
             ),
             "fake_repo_name",
         )
```

### Comparing `dagster-1.6.9/dagster/_utils/timing.py` & `dagster-1.7.0/dagster/_utils/timing.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/typed_dict.py` & `dagster-1.7.0/dagster/_utils/typed_dict.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/typing_api.py` & `dagster-1.7.0/dagster/_utils/typing_api.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/warnings.py` & `dagster-1.7.0/dagster/_utils/warnings.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster/_utils/yaml_utils.py` & `dagster-1.7.0/dagster/_utils/yaml_utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.6.9/dagster.egg-info/PKG-INFO` & `dagster-1.7.0/dagster.egg-info/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dagster
-Version: 1.6.9
+Version: 1.7.0
 Summary: Dagster is an orchestration platform for the development, production, and observation of data assets.
 Author: Dagster Labs
 Author-email: hello@dagsterlabs.com
 License: Apache-2.0
 Project-URL: Homepage, https://dagster.io
 Project-URL: GitHub, https://github.com/dagster-io/dagster
 Project-URL: Documentation, https://docs.dagster.io
@@ -78,15 +78,15 @@
 from dagster import asset
 from pandas import DataFrame, read_html, get_dummies
 from sklearn.linear_model import LinearRegression
 
 @asset
 def country_populations() -> DataFrame:
     df = read_html("https://tinyurl.com/mry64ebh")[0]
-    df.columns = ["country", "continent", "rg", "pop2018", "pop2019", "change"]
+    df.columns = ["country", "pop2022", "pop2023", "change", "continent", "region"]
     df["change"] = df["change"].str.rstrip("%").str.replace("", "-").astype("float")
     return df
 
 @asset
 def continent_change_model(country_populations: DataFrame) -> LinearRegression:
     data = country_populations.dropna(subset=["change"])
     return LinearRegression().fit(get_dummies(data[["continent"]]), data["change"])
@@ -97,35 +97,35 @@
     result["pop_change_factor"] = continent_change_model.coef_
     return result
 ```
 
 The graph loaded into Dagster's web UI:
 
 <p align="center">
-  <img width="432" alt="An example asset graph as rendered in the Dagster UI" src="https://github.com/dagster-io/dagster/assets/654855/5b302b1b-4cc9-49bf-8689-232f7de87d31">
+  <img width="100%" alt="An example asset graph as rendered in the Dagster UI" src="https://raw.githubusercontent.com/dagster-io/dagster/master/.github/example-lineage.png">
 </p>
 
 Dagster is built to be used at every stage of the data development lifecycle - local development, unit tests, integration tests, staging environments, all the way up to production.
 
 ## Quick Start:
 
 If you're new to Dagster, we recommend reading about its [core concepts](https://docs.dagster.io/concepts) or learning with the hands-on [tutorial](https://docs.dagster.io/tutorial).
 
-Dagster is available on PyPI and officially supports Python 3.8, Python 3.9, Python 3.10, and Python 3.11.
+Dagster is available on PyPI and officially supports Python 3.8 through Python 3.12.
 
 ```bash
 pip install dagster dagster-webserver
 ```
 
 This installs two packages:
 
 - `dagster`: The core programming model.
 - `dagster-webserver`: The server that hosts Dagster's web UI for developing and operating Dagster jobs and assets.
 
-Running on Using a Mac with an M1 or M2 chip? Check the [install details here](https://docs.dagster.io/getting-started/install#installing-dagster-into-an-existing-python-environment).
+Running on Using a Mac with an Apple silicon chip? Check the [install details here](https://docs.dagster.io/getting-started/install#installing-dagster-into-an-existing-python-environment).
 
 ## Documentation
 
 You can find the full Dagster documentation [here](https://docs.dagster.io), including the ['getting started' guide](https://docs.dagster.io/getting-started).
 
 <hr/>
```

### Comparing `dagster-1.6.9/dagster.egg-info/SOURCES.txt` & `dagster-1.7.0/dagster.egg-info/SOURCES.txt`

 * *Files 0% similar despite different names*

```diff
@@ -84,64 +84,66 @@
 dagster/_core/op_concurrency_limits_counter.py
 dagster/_core/origin.py
 dagster/_core/telemetry.py
 dagster/_core/telemetry_upload.py
 dagster/_core/test_utils.py
 dagster/_core/utility_ops.py
 dagster/_core/utils.py
+dagster/_core/asset_graph_view/__init__.py
+dagster/_core/asset_graph_view/asset_graph_view.py
 dagster/_core/container_context/__init__.py
 dagster/_core/container_context/config.py
 dagster/_core/definitions/__init__.py
 dagster/_core/definitions/asset_check_evaluation.py
 dagster/_core/definitions/asset_check_result.py
 dagster/_core/definitions/asset_check_spec.py
 dagster/_core/definitions/asset_checks.py
 dagster/_core/definitions/asset_daemon_context.py
 dagster/_core/definitions/asset_daemon_cursor.py
 dagster/_core/definitions/asset_dep.py
 dagster/_core/definitions/asset_graph.py
 dagster/_core/definitions/asset_graph_differ.py
 dagster/_core/definitions/asset_graph_subset.py
 dagster/_core/definitions/asset_in.py
+dagster/_core/definitions/asset_job.py
+dagster/_core/definitions/asset_key.py
 dagster/_core/definitions/asset_layer.py
 dagster/_core/definitions/asset_out.py
 dagster/_core/definitions/asset_selection.py
 dagster/_core/definitions/asset_sensor_definition.py
 dagster/_core/definitions/asset_spec.py
 dagster/_core/definitions/asset_subset.py
 dagster/_core/definitions/assets.py
-dagster/_core/definitions/assets_job.py
 dagster/_core/definitions/auto_materialize_policy.py
 dagster/_core/definitions/auto_materialize_rule.py
 dagster/_core/definitions/auto_materialize_rule_evaluation.py
 dagster/_core/definitions/auto_materialize_sensor_definition.py
 dagster/_core/definitions/backfill_policy.py
+dagster/_core/definitions/base_asset_graph.py
 dagster/_core/definitions/cacheable_assets.py
 dagster/_core/definitions/composition.py
 dagster/_core/definitions/config.py
 dagster/_core/definitions/configurable.py
 dagster/_core/definitions/data_time.py
 dagster/_core/definitions/data_version.py
 dagster/_core/definitions/definition_config_schema.py
 dagster/_core/definitions/definitions_class.py
 dagster/_core/definitions/dependency.py
 dagster/_core/definitions/events.py
 dagster/_core/definitions/executor_definition.py
 dagster/_core/definitions/external_asset.py
-dagster/_core/definitions/external_asset_graph.py
 dagster/_core/definitions/freshness_based_auto_materialize.py
 dagster/_core/definitions/freshness_policy.py
 dagster/_core/definitions/freshness_policy_sensor_definition.py
 dagster/_core/definitions/graph_definition.py
 dagster/_core/definitions/hook_definition.py
 dagster/_core/definitions/hook_invocation.py
 dagster/_core/definitions/inference.py
 dagster/_core/definitions/input.py
 dagster/_core/definitions/instigation_logger.py
-dagster/_core/definitions/internal_asset_graph.py
 dagster/_core/definitions/job_base.py
 dagster/_core/definitions/job_definition.py
 dagster/_core/definitions/load_asset_checks_from_modules.py
 dagster/_core/definitions/load_assets_from_modules.py
 dagster/_core/definitions/logger_definition.py
 dagster/_core/definitions/logger_invocation.py
 dagster/_core/definitions/materialize.py
@@ -157,25 +159,27 @@
 dagster/_core/definitions/output.py
 dagster/_core/definitions/partition.py
 dagster/_core/definitions/partition_key_range.py
 dagster/_core/definitions/partition_mapping.py
 dagster/_core/definitions/partitioned_schedule.py
 dagster/_core/definitions/policy.py
 dagster/_core/definitions/reconstruct.py
+dagster/_core/definitions/remote_asset_graph.py
 dagster/_core/definitions/resolved_asset_deps.py
 dagster/_core/definitions/resource_annotation.py
 dagster/_core/definitions/resource_definition.py
 dagster/_core/definitions/resource_invocation.py
 dagster/_core/definitions/resource_requirement.py
 dagster/_core/definitions/result.py
 dagster/_core/definitions/run_config.py
 dagster/_core/definitions/run_config_schema.py
 dagster/_core/definitions/run_request.py
 dagster/_core/definitions/run_status_sensor_definition.py
 dagster/_core/definitions/schedule_definition.py
+dagster/_core/definitions/schema_change_checks.py
 dagster/_core/definitions/scoped_resources_builder.py
 dagster/_core/definitions/selector.py
 dagster/_core/definitions/sensor_definition.py
 dagster/_core/definitions/source_asset.py
 dagster/_core/definitions/step_launcher.py
 dagster/_core/definitions/target.py
 dagster/_core/definitions/time_window_partition_mapping.py
@@ -194,14 +198,19 @@
 dagster/_core/definitions/decorators/hook_decorator.py
 dagster/_core/definitions/decorators/job_decorator.py
 dagster/_core/definitions/decorators/op_decorator.py
 dagster/_core/definitions/decorators/repository_decorator.py
 dagster/_core/definitions/decorators/schedule_decorator.py
 dagster/_core/definitions/decorators/sensor_decorator.py
 dagster/_core/definitions/decorators/source_asset_decorator.py
+dagster/_core/definitions/freshness_checks/__init__.py
+dagster/_core/definitions/freshness_checks/last_update.py
+dagster/_core/definitions/freshness_checks/sensor.py
+dagster/_core/definitions/freshness_checks/time_partition.py
+dagster/_core/definitions/freshness_checks/utils.py
 dagster/_core/definitions/metadata/__init__.py
 dagster/_core/definitions/metadata/table.py
 dagster/_core/definitions/repository_definition/__init__.py
 dagster/_core/definitions/repository_definition/caching_index.py
 dagster/_core/definitions/repository_definition/repository_data.py
 dagster/_core/definitions/repository_definition/repository_data_builder.py
 dagster/_core/definitions/repository_definition/repository_definition.py
@@ -268,38 +277,38 @@
 dagster/_core/executor/in_process.py
 dagster/_core/executor/init.py
 dagster/_core/executor/multiprocess.py
 dagster/_core/executor/step_delegating/__init__.py
 dagster/_core/executor/step_delegating/step_delegating_executor.py
 dagster/_core/executor/step_delegating/step_handler/__init__.py
 dagster/_core/executor/step_delegating/step_handler/base.py
-dagster/_core/host_representation/__init__.py
-dagster/_core/host_representation/code_location.py
-dagster/_core/host_representation/external.py
-dagster/_core/host_representation/external_data.py
-dagster/_core/host_representation/feature_flags.py
-dagster/_core/host_representation/grpc_server_registry.py
-dagster/_core/host_representation/grpc_server_state_subscriber.py
-dagster/_core/host_representation/handle.py
-dagster/_core/host_representation/historical.py
-dagster/_core/host_representation/job_index.py
-dagster/_core/host_representation/origin.py
-dagster/_core/host_representation/represented.py
 dagster/_core/instance/__init__.py
 dagster/_core/instance/config.py
 dagster/_core/instance/ref.py
 dagster/_core/launcher/__init__.py
 dagster/_core/launcher/base.py
 dagster/_core/launcher/default_run_launcher.py
 dagster/_core/launcher/sync_in_memory_run_launcher.py
 dagster/_core/pipes/__init__.py
 dagster/_core/pipes/client.py
 dagster/_core/pipes/context.py
 dagster/_core/pipes/subprocess.py
 dagster/_core/pipes/utils.py
+dagster/_core/remote_representation/__init__.py
+dagster/_core/remote_representation/code_location.py
+dagster/_core/remote_representation/external.py
+dagster/_core/remote_representation/external_data.py
+dagster/_core/remote_representation/feature_flags.py
+dagster/_core/remote_representation/grpc_server_registry.py
+dagster/_core/remote_representation/grpc_server_state_subscriber.py
+dagster/_core/remote_representation/handle.py
+dagster/_core/remote_representation/historical.py
+dagster/_core/remote_representation/job_index.py
+dagster/_core/remote_representation/origin.py
+dagster/_core/remote_representation/represented.py
 dagster/_core/run_coordinator/__init__.py
 dagster/_core/run_coordinator/base.py
 dagster/_core/run_coordinator/default_run_coordinator.py
 dagster/_core/run_coordinator/queued_run_coordinator.py
 dagster/_core/scheduler/__init__.py
 dagster/_core/scheduler/execution.py
 dagster/_core/scheduler/instigation.py
@@ -492,14 +501,15 @@
 dagster/_daemon/__main__.py
 dagster/_daemon/asset_daemon.py
 dagster/_daemon/backfill.py
 dagster/_daemon/controller.py
 dagster/_daemon/daemon.py
 dagster/_daemon/sensor.py
 dagster/_daemon/types.py
+dagster/_daemon/utils.py
 dagster/_daemon/workspace.py
 dagster/_daemon/auto_run_reexecution/__init__.py
 dagster/_daemon/auto_run_reexecution/auto_run_reexecution.py
 dagster/_daemon/auto_run_reexecution/event_log_consumer.py
 dagster/_daemon/cli/__init__.py
 dagster/_daemon/monitoring/__init__.py
 dagster/_daemon/monitoring/concurrency.py
@@ -539,14 +549,15 @@
 dagster/_grpc/__generated__/__init__.py
 dagster/_grpc/__generated__/api_pb2.py
 dagster/_grpc/__generated__/api_pb2.pyi
 dagster/_grpc/__generated__/api_pb2_grpc.py
 dagster/_grpc/protos/api.proto
 dagster/_legacy/__init__.py
 dagster/_loggers/__init__.py
+dagster/_model/__init__.py
 dagster/_scheduler/__init__.py
 dagster/_scheduler/scheduler.py
 dagster/_scheduler/stale.py
 dagster/_serdes/__init__.py
 dagster/_serdes/config_class.py
 dagster/_serdes/errors.py
 dagster/_serdes/ipc.py
```

### Comparing `dagster-1.6.9/dagster.egg-info/requires.txt` & `dagster-1.7.0/dagster.egg-info/requires.txt`

 * *Files 4% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 structlog
 sqlalchemy<3,>=1.0
 toposort>=1.0
 watchdog>=0.8.3
 docstring-parser
 pydantic!=1.10.7,<3,>1.10.0
 rich
-dagster-pipes==1.6.9
+dagster-pipes==1.7.0
 
 [:platform_system == "Windows"]
 psutil>=1.0
 pywin32!=226
 
 [:python_version < "3.11"]
 protobuf<5,>=3.20.0
@@ -51,15 +51,15 @@
 [docker]
 docker
 
 [mypy]
 mypy==1.8.0
 
 [pyright]
-pyright==1.1.349
+pyright==1.1.356
 pandas-stubs
 types-backports
 types-certifi
 types-chardet
 types-croniter
 types-cryptography
 types-mock
@@ -74,30 +74,26 @@
 types-six
 types-sqlalchemy==1.4.53.34
 types-tabulate
 types-tzlocal
 types-toml
 
 [ruff]
-ruff==0.3.0
+ruff==0.3.4
 
 [test]
+buildkite-test-collector
 docker
 grpcio-tools>=1.44.0
 mock==3.0.5
 mypy-protobuf
 objgraph
 pytest-cov==2.10.1
-pytest-dependency==0.5.1
 pytest-mock==3.3.1
 pytest-rerunfailures==10.0
-pytest-runner==5.2
-pytest-xdist==3.3.1
+pytest-xdist==3.5.0
 pytest>=7.0.1
 responses<=0.23.1
 syrupy>=4.0.0
 tox==3.25.0
-rapidfuzz
-
-[test:python_version >= "3.8"]
-buildkite-test-collector
 morefs[asynclocal]
+rapidfuzz
```

### Comparing `dagster-1.6.9/setup.py` & `dagster-1.7.0/setup.py`

 * *Files 4% similar despite different names*

```diff
@@ -111,41 +111,39 @@
         'pywin32!=226; platform_system=="Windows"',
         "docstring-parser",
         "universal_pathlib; python_version<'3.12'",
         "universal_pathlib>=0.2.0; python_version>='3.12'",
         # https://github.com/pydantic/pydantic/issues/5821
         "pydantic>1.10.0,!= 1.10.7,<3",
         "rich",
-        "dagster-pipes==1.6.9",
+        "dagster-pipes==1.7.0",
     ],
     extras_require={
         "docker": ["docker"],
         "test": [
-            "buildkite-test-collector ; python_version>='3.8'",
+            "buildkite-test-collector",
             "docker",
             f"grpcio-tools>={GRPC_VERSION_FLOOR}",
             "mock==3.0.5",
             "mypy-protobuf",
             "objgraph",
             "pytest-cov==2.10.1",
-            "pytest-dependency==0.5.1",
             "pytest-mock==3.3.1",
             "pytest-rerunfailures==10.0",
-            "pytest-runner==5.2",
-            "pytest-xdist==3.3.1",
+            "pytest-xdist==3.5.0",
             "pytest>=7.0.1",
             "responses<=0.23.1",  # https://github.com/getsentry/responses/issues/654
             "syrupy>=4.0.0",
             "tox==3.25.0",
-            "morefs[asynclocal]; python_version>='3.8'",
+            "morefs[asynclocal]",
             "rapidfuzz",
         ],
         "mypy": ["mypy==1.8.0"],
         "pyright": [
-            "pyright==1.1.349",
+            "pyright==1.1.356",
             ### Stub packages
             "pandas-stubs",  # version will be resolved against pandas
             "types-backports",  # version will be resolved against backports
             "types-certifi",  # version will be resolved against certifi
             "types-chardet",  # chardet is a 2+-order dependency of some Dagster libs
             "types-croniter",  # version will be resolved against croniter
             "types-cryptography",  # version will be resolved against cryptography
@@ -161,15 +159,15 @@
             "types-six",  # needed but not specified by grpcio
             "types-sqlalchemy==1.4.53.34",  # later versions introduce odd errors
             "types-tabulate",  # version will be resolved against tabulate
             "types-tzlocal",  # version will be resolved against tzlocal
             "types-toml",  # version will be resolved against toml
         ],
         "ruff": [
-            "ruff==0.3.0",
+            "ruff==0.3.4",
         ],
     },
     entry_points={
         "console_scripts": [
             "dagster = dagster.cli:main",
             "dagster-daemon = dagster.daemon.cli:main",
         ]
```

