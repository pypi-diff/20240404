# Comparing `tmp/f2-0.0.1.4.tar.gz` & `tmp/f2-0.0.1.5.tar.gz`

## Comparing `f2-0.0.1.4.tar` & `f2-0.0.1.5.tar`

### file list

```diff
@@ -1,69 +1,65 @@
--rw-r--r--   0        0        0      453 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/__init__.py
--rw-r--r--   0        0        0       48 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/__main__.py
--rw-r--r--   0        0        0     4721 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/helps.py
--rw-r--r--   0        0        0      528 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/__apps__.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/__init__.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/__init__.py
--rw-r--r--   0        0        0     3739 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/api.py
--rw-r--r--   0        0        0    16726 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/cli.py
--rw-r--r--   0        0        0     7137 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/crawler.py
--rw-r--r--   0        0        0    10693 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/db.py
--rw-r--r--   0        0        0    12861 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/dl.py
--rw-r--r--   0        0        0    37332 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/filter.py
--rw-r--r--   0        0        0    35108 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/handler.py
--rw-r--r--   0        0        0     4751 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/help.py
--rw-r--r--   0        0        0     5235 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/model.py
--rw-r--r--   0        0        0    24408 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/utils.py
--rw-r--r--   0        0        0      551 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/test/test_apps_model.py
--rw-r--r--   0        0        0     1258 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/test/test_aweme_id.py
--rw-r--r--   0        0        0      952 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/test/test_crawler.py
--rw-r--r--   0        0        0      720 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/test/test_handler.py
--rw-r--r--   0        0        0      655 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/test/test_room_id.py
--rw-r--r--   0        0        0     1065 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/test/test_sec_user_id.py
--rw-r--r--   0        0        0      140 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/test/test_sso_login.py
--rw-r--r--   0        0        0     1737 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/douyin/test/test_webcast_id.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/__init__.py
--rw-r--r--   0        0        0     1532 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/api.py
--rw-r--r--   0        0        0    15483 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/cli.py
--rw-r--r--   0        0        0     4042 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/crawler.py
--rw-r--r--   0        0        0     5655 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/db.py
--rw-r--r--   0        0        0    11325 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/dl.py
--rw-r--r--   0        0        0    19343 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/filter.py
--rw-r--r--   0        0        0    25067 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/handler.py
--rw-r--r--   0        0        0     4613 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/help.py
--rw-r--r--   0        0        0     2373 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/model.py
--rw-r--r--   0        0        0    23775 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/tiktok/utils.py
--rw-r--r--   0        0        0       78 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/twitter/__init__.py
--rw-r--r--   0        0        0     2907 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/apps/twitter/help.py
--rw-r--r--   0        0        0      197 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/cli/__init__.py
--rw-r--r--   0        0        0     3684 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/cli/cli_commands.py
--rw-r--r--   0        0        0     6039 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/cli/cli_console.py
--rw-r--r--   0        0        0      354 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/conf/app.yaml
--rw-r--r--   0        0        0     7199 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/conf/conf.yaml
--rw-r--r--   0        0        0      442 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/conf/defaults.yaml
--rw-r--r--   0        0        0    11368 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/crawlers/base_crawler.py
--rw-r--r--   0        0        0     3078 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/db/base_db.py
--rw-r--r--   0        0        0    19266 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/dl/base_downloader.py
--rw-r--r--   0        0        0     1161 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/exceptions/__init__.py
--rw-r--r--   0        0        0     2196 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/exceptions/api_exceptions.py
--rw-r--r--   0        0        0     1610 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/exceptions/db_exceptions.py
--rw-r--r--   0        0        0     1736 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/exceptions/file_exceptions.py
--rw-r--r--   0        0        0     1255 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/i18n/translator.py
--rw-r--r--   0        0        0    29107 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/languages/en_US/LC_MESSAGES/en_US.mo
--rw-r--r--   0        0        0    27692 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/languages/zh_CN/LC_MESSAGES/zh_CN.mo
--rw-r--r--   0        0        0     3348 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/log/logger.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/__init__.py
--rw-r--r--   0        0        0      894 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/__version__.py
--rw-r--r--   0        0        0     6378 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/_dl.py
--rw-r--r--   0        0        0     1586 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/_signal.py
--rw-r--r--   0        0        0     1257 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/_singleton.py
--rw-r--r--   0        0        0     5295 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/conf_manager.py
--rw-r--r--   0        0        0     1226 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/json_filter.py
--rw-r--r--   0        0        0      186 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/mode_handler.py
--rw-r--r--   0        0        0     8047 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/utils.py
--rw-r--r--   0        0        0     6913 2020-02-02 00:00:00.000000 f2-0.0.1.4/f2/utils/xbogus.py
--rw-r--r--   0        0        0     2071 2020-02-02 00:00:00.000000 f2-0.0.1.4/.gitignore
--rw-r--r--   0        0        0    11558 2020-02-02 00:00:00.000000 f2-0.0.1.4/LICENSE
--rw-r--r--   0        0        0      793 2020-02-02 00:00:00.000000 f2-0.0.1.4/README.md
--rw-r--r--   0        0        0     1632 2020-02-02 00:00:00.000000 f2-0.0.1.4/pyproject.toml
--rw-r--r--   0        0        0     2226 2020-02-02 00:00:00.000000 f2-0.0.1.4/PKG-INFO
+-rw-r--r--   0        0        0      835 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/__init__.py
+-rw-r--r--   0        0        0       48 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/__main__.py
+-rw-r--r--   0        0        0     4139 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/helps.py
+-rw-r--r--   0        0        0      528 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/__apps__.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/__init__.py
+-rw-r--r--   0        0        0     4340 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/api.py
+-rw-r--r--   0        0        0    13947 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/cli.py
+-rw-r--r--   0        0        0    10358 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/crawler.py
+-rw-r--r--   0        0        0    10880 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/db.py
+-rw-r--r--   0        0        0    15295 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/dl.py
+-rw-r--r--   0        0        0    50773 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/filter.py
+-rw-r--r--   0        0        0    57839 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/handler.py
+-rw-r--r--   0        0        0     4692 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/help.py
+-rw-r--r--   0        0        0     6408 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/model.py
+-rw-r--r--   0        0        0    28213 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/utils.py
+-rw-r--r--   0        0        0      551 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/test/test_apps_model.py
+-rw-r--r--   0        0        0     1258 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/test/test_aweme_id.py
+-rw-r--r--   0        0        0      952 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/test/test_crawler.py
+-rw-r--r--   0        0        0      720 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/test/test_handler.py
+-rw-r--r--   0        0        0     5420 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/test/test_lrc.py
+-rw-r--r--   0        0        0      655 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/test/test_room_id.py
+-rw-r--r--   0        0        0     1065 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/test/test_sec_user_id.py
+-rw-r--r--   0        0        0      140 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/test/test_sso_login.py
+-rw-r--r--   0        0        0     1737 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/douyin/test/test_webcast_id.py
+-rw-r--r--   0        0        0     1532 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/api.py
+-rw-r--r--   0        0        0    12655 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/cli.py
+-rw-r--r--   0        0        0     4651 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/crawler.py
+-rw-r--r--   0        0        0     5706 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/db.py
+-rw-r--r--   0        0        0    11320 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/dl.py
+-rw-r--r--   0        0        0    21009 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/filter.py
+-rw-r--r--   0        0        0    25947 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/handler.py
+-rw-r--r--   0        0        0     4567 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/help.py
+-rw-r--r--   0        0        0     2373 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/model.py
+-rw-r--r--   0        0        0    26297 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/apps/tiktok/utils.py
+-rw-r--r--   0        0        0      197 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/cli/__init__.py
+-rw-r--r--   0        0        0     3641 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/cli/cli_commands.py
+-rw-r--r--   0        0        0     6039 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/cli/cli_console.py
+-rw-r--r--   0        0        0      368 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/conf/app.yaml
+-rw-r--r--   0        0        0     7199 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/conf/conf.yaml
+-rw-r--r--   0        0        0      452 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/conf/defaults.yaml
+-rw-r--r--   0        0        0    11369 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/crawlers/base_crawler.py
+-rw-r--r--   0        0        0     3078 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/db/base_db.py
+-rw-r--r--   0        0        0    21907 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/dl/base_downloader.py
+-rw-r--r--   0        0        0     1161 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/exceptions/__init__.py
+-rw-r--r--   0        0        0     2380 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/exceptions/api_exceptions.py
+-rw-r--r--   0        0        0     1706 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/exceptions/db_exceptions.py
+-rw-r--r--   0        0        0     1402 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/exceptions/file_exceptions.py
+-rw-r--r--   0        0        0     1255 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/i18n/translator.py
+-rw-r--r--   0        0        0    34741 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/languages/en_US/LC_MESSAGES/en_US.mo
+-rw-r--r--   0        0        0    32992 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/languages/zh_CN/LC_MESSAGES/zh_CN.mo
+-rw-r--r--   0        0        0     3388 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/log/logger.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/utils/__init__.py
+-rw-r--r--   0        0        0     6947 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/utils/_dl.py
+-rw-r--r--   0        0        0     1586 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/utils/_signal.py
+-rw-r--r--   0        0        0     1257 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/utils/_singleton.py
+-rw-r--r--   0        0        0     5080 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/utils/conf_manager.py
+-rw-r--r--   0        0        0     1226 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/utils/json_filter.py
+-rw-r--r--   0        0        0      186 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/utils/mode_handler.py
+-rw-r--r--   0        0        0    12213 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/utils/utils.py
+-rw-r--r--   0        0        0     8947 2020-02-02 00:00:00.000000 f2-0.0.1.5/f2/utils/xbogus.py
+-rw-r--r--   0        0        0     2071 2020-02-02 00:00:00.000000 f2-0.0.1.5/.gitignore
+-rw-r--r--   0        0        0    11558 2020-02-02 00:00:00.000000 f2-0.0.1.5/LICENSE
+-rw-r--r--   0        0        0      793 2020-02-02 00:00:00.000000 f2-0.0.1.5/README.md
+-rw-r--r--   0        0        0     1632 2020-02-02 00:00:00.000000 f2-0.0.1.5/pyproject.toml
+-rw-r--r--   0        0        0     2226 2020-02-02 00:00:00.000000 f2-0.0.1.5/PKG-INFO
```

### Comparing `f2-0.0.1.4/f2/helps.py` & `f2-0.0.1.5/f2/helps.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,113 +1,109 @@
 #!/usr/bin/env python
 # -*- encoding: utf-8 -*-
 """
 @Description:helps.py
 @Date       :2023/02/06 17:36:41
 @Author     :JohnserfSeed
-@version    :0.0.1.4
+@version    :0.0.1.5
 @License    :Apache License 2.0
 @Github     :https://github.com/johnserf-seed
 @Mail       :johnserf-seed@foxmail.com
 -------------------------------------------------
 Change Log  :
 2023/02/06 17:36:41 - create output help
+2024/03/11 18:23:30 - change get_help @ importlib path
 -------------------------------------------------
 """
 
+import f2
 import importlib
 
 from rich.console import Console
 from rich.panel import Panel
 from rich.table import Table
 from f2.i18n.translator import _
-from f2.utils import __version__
 
 
 def get_help(app_name: str) -> None:
     try:
-        module = importlib.import_module(f"f2.apps.{app_name}")
+        module = importlib.import_module(f"f2.apps.{app_name}.help")
         if hasattr(module, "help"):
             module.help()
         else:
             print(_("åœ¨ {0} åº”ç”¨é‡Œæ²¡æœ‰æ‰¾åˆ°å¸®åŠ©æ–‡ä»¶").format(app_name))
     except ImportError:
         print(_("æ²¡æœ‰æ‰¾åˆ° {0} åº”ç”¨").format(app_name))
 
 
-def f2() -> None:
+def main() -> None:
     # çœŸå½©
     console = Console(color_system="truecolor")
-    console.print(
-        f"\n:rocket: [bold]f2 {__version__._version} :rocket:", justify="center"
-    )
-    console.print(f"\n[i]{__version__._description_cn}", justify="center")
-    console.print(f"[i]{__version__._description_en}", justify="center")
-    console.print(f"[i]GitHub {__version__._repourl}\n", justify="center")
-
-    table = Table.grid(padding=1, pad_edge=True, expand=True)
-    table.add_column("Website", no_wrap=True, justify="left", style="bold")
-    table.add_column("Description", no_wrap=True, justify="left", style="bold")
-
-    # åˆ†å‰²
-    # console.rule("[b]å·²é€‚é…[/b]", align="center")
-    # table.add_row(
-    #     _("æŠ–éŸ³"), _("  å•ä¸ªä½œå“ï¼Œä¸»é¡µä½œå“ï¼Œç‚¹èµä½œå“ï¼Œæ”¶è—ä½œå“ï¼Œåˆè¾‘ä½œå“ï¼Œå›¾æ–‡ï¼ŒåŸå£°ã€‚åç»­æ›´æ–°ï¼šæ¨èä½œå“ï¼Œæœ‹å‹ä½œå“ï¼Œå¥½å‹ä½œå“ï¼Œæœç´¢ä½œå“")
-    # )
-    # table.add_row(
-    #     _("TikTok"), _("  å•ä¸ªä½œå“ï¼Œä¸»é¡µä½œå“ï¼Œç‚¹èµä½œå“ï¼Œæ”¶è—ä½œå“ï¼Œæ’­æ”¾åˆ—è¡¨ï¼ˆåˆè¾‘ï¼‰ä½œå“ï¼ŒåŸå£°ã€‚åç»­æ›´æ–°ï¼šæ¨èä½œå“ï¼Œæœ‹å‹ä½œå“ï¼Œå¥½å‹ä½œå“ï¼Œæœç´¢ä½œå“")
-    # )
-    # # å¾…é€‚é…
-    # console.print(table)
-    # åˆ†å‰²
-    # console.rule()
+    console.print(f"\n:rocket: [bold]f2 {f2.__version__} :rocket:", justify="center")
+    console.print(f"\n[i]{f2.__description_cn__}", justify="center")
+    console.print(f"[i]{f2.__description_en__}", justify="center")
+    console.print(f"[i]GitHub {f2.__repourl__}\n", justify="center")
 
     # ä½¿ç”¨æ–¹æ³•
     table = Table.grid(padding=1, pad_edge=True)
     table.add_column("Usage", no_wrap=True, justify="left", style="bold")
     table.add_row("[b]f2[/b] [magenta]<apps> [/magenta][cyan][COMMAND]")
-    table.add_row(_("ä¾‹ï¼š f2 dy -h æ¥è·å–douyinçš„å‘½ä»¤å¸®åŠ©"))
+    table.add_row(_("ä¾‹ï¼šf2 dy -h/--help è·å–douyinçš„å‘½ä»¤å¸®åŠ©"))
+    table.add_row(
+        "[b]f2[/b] [magenta][Option] [/magenta][cyan][Args][/cyan] [magenta]<apps> [/magenta][cyan][COMMAND]"
+    )
+    table.add_row(_("ä¾‹ï¼šf2 -d DEBUG dy æ—¥å¿—çº§åˆ«ä¸ºè°ƒè¯•è¿è¡Œ"))
     console.print(
         Panel(table, border_style="bold", title="ä½¿ç”¨æ–¹æ³• | Usage", title_align="left")
     )
 
-    table = Table.grid(padding=1, pad_edge=True, expand=True)
+    # åº”ç”¨åˆ—è¡¨
     table = Table(show_header=True, header_style="bold magenta")
-    table.add_column("Parameter", no_wrap=True, justify="left", style="bold")
-    table.add_column("Description", no_wrap=True, style="bold")
-    table.add_column("Status", no_wrap=True, justify="left", style="bold")
+    table.add_column(_("å‚æ•°"), no_wrap=True, justify="left", style="bold")
+    table.add_column(_("æè¿°"), no_wrap=True, style="bold")
+    table.add_column(_("çŠ¶æ€"), no_wrap=True, justify="left", style="bold")
 
     table.add_row(_("weibo æˆ– wb"), _("- è·å–å¾®åš"))
     table.add_row(
-        _("douyin æˆ– dy"), _("- å•ä¸ªä½œå“ï¼Œä¸»é¡µä½œå“ï¼Œç‚¹èµä½œå“ï¼Œæ”¶è—ä½œå“ï¼Œåˆè¾‘ä½œå“ï¼Œå›¾æ–‡ï¼Œæ–‡æ¡ˆï¼Œå°é¢ï¼Œç›´æ’­ï¼ŒåŸå£°ã€‚"), _("âœ”")
+        _("douyin æˆ– dy"),
+        _(
+            "- å•ä¸ªä½œå“ï¼Œä¸»é¡µä½œå“ï¼Œç‚¹èµä½œå“ï¼Œæ”¶è—ä½œå“ï¼Œåˆè¾‘ä½œå“ï¼Œå›¾æ–‡ï¼Œæ–‡æ¡ˆï¼Œå°é¢ï¼Œç›´æ’­ï¼ŒåŸå£°ã€‚"
+        ),
+        _("âœ”"),
     )
     table.add_row(
-        _("tiktok æˆ– tk"), _("- å•ä¸ªä½œå“ï¼Œä¸»é¡µä½œå“ï¼Œç‚¹èµä½œå“ï¼Œæ”¶è—ä½œå“ï¼Œæ’­æ”¾åˆ—è¡¨ï¼ˆåˆè¾‘ï¼‰ä½œå“ï¼Œæ–‡æ¡ˆï¼Œå°é¢ï¼ŒåŸå£°ã€‚"), _("âœ”")
+        _("tiktok æˆ– tk"),
+        _(
+            "- å•ä¸ªä½œå“ï¼Œä¸»é¡µä½œå“ï¼Œç‚¹èµä½œå“ï¼Œæ”¶è—ä½œå“ï¼Œæ’­æ”¾åˆ—è¡¨ï¼ˆåˆè¾‘ï¼‰ä½œå“ï¼Œæ–‡æ¡ˆï¼Œå°é¢ï¼ŒåŸå£°ã€‚"
+        ),
+        _("âœ”"),
     )
     table.add_row(_("instagram æˆ– ig"), _("- è·å–igçš„ä½œå“"), _("â³"))
     table.add_row(_("twitch æˆ– tv"), _("- è·å–Twitchç›´æ’­"))
     table.add_row(_("twitter æˆ– x"), _("- è·å–Twitterä½œå“"), _("â³"))
     table.add_row(_("youtube æˆ– ytb"), _("- è·å–YouTubeçš„ä½œå“"))
     table.add_row(_("bilibili æˆ– bili"), _("- è·å–BiliBiliçš„ä½œå“"))
     table.add_row(_("neteasy_music æˆ– nem"), _("- è·å–ç½‘æ˜“äº‘éŸ³ä¹ä½œå“"))
     table.add_row(_("little_red_book æˆ– lrb"), _("- è·å–å°çº¢ä¹¦çš„ä½œå“"))
     table.add_row("\n")
     table.add_row(
-        "f2 -d [magenta]<apps> [/magenta][cyan][COMMAND]",
-        _("- è®°å½•appçš„debugåˆ°/logsä¸‹ï¼Œå¦‚é‡BUGæäº¤Issueæ—¶è¯·é™„å¸¦è¯¥æ–‡ä»¶å¹¶[red]åˆ é™¤ä¸ªäººæ•æ„Ÿä¿¡æ¯[/red]"),
+        "f2 -d DEBUG",
+        _(
+            "- è®°å½•appçš„è°ƒè¯•æ—¥å¿—åˆ°/logsä¸‹ï¼Œå¦‚é‡BUGæäº¤Issueæ—¶è¯·é™„å¸¦è¯¥æ–‡ä»¶å¹¶[red]åˆ é™¤ä¸ªäººæ•æ„Ÿä¿¡æ¯[/red]"
+        ),
         _("âš "),
     )
     table.add_row(
         "Issuesâ“", "[link=https://github.com/Johnserf-Seed/f2/issues]Click Here[/]"
     ),
     table.add_row(
         "DocumentğŸ“•", "[link=https://johnserf-seed.github.io/f2/]Click Here[/]"
     )
     console.print(
         Panel(
             table,
             border_style="bold",
-            title="<apps>",
+            title="åº”ç”¨ | apps",
             title_align="left",
             subtitle=_("æ¬¢è¿æäº¤PRé€‚é…æ›´å¤šç½‘ç«™"),
         )
     )
```

### Comparing `f2-0.0.1.4/f2/apps/__apps__.py` & `f2-0.0.1.5/f2/apps/__apps__.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/douyin/api.py` & `f2-0.0.1.5/f2/apps/douyin/api.py`

 * *Files 18% similar despite different names*

```diff
@@ -50,23 +50,38 @@
 
     # ç”¨æˆ·å–œæ¬¢A (User Like A)
     USER_FAVORITE_A = f"{DOUYIN_DOMAIN}/aweme/v1/web/aweme/favorite/"
 
     # ç”¨æˆ·å–œæ¬¢B (User Like B)
     USER_FAVORITE_B = f"{IESDOUYIN_DOMAIN}/web/api/v2/aweme/like/"
 
+    # å…³æ³¨ç”¨æˆ·(User Following)
+    USER_FOLLOWING = f"{DOUYIN_DOMAIN}/aweme/v1/web/user/following/list/"
+
+    # ç²‰ä¸ç”¨æˆ· (User Follower)
+    USER_FOLLOWER = f"{DOUYIN_DOMAIN}/aweme/v1/web/user/follower/list/"
+
     # åˆé›†ä½œå“
     MIX_AWEME = f"{DOUYIN_DOMAIN}/aweme/v1/web/mix/aweme/"
 
     # ç”¨æˆ·å†å² (User History)
     USER_HISTORY = f"{DOUYIN_DOMAIN}/aweme/v1/web/history/read/"
 
     # ç”¨æˆ·æ”¶è— (User Collection)
     USER_COLLECTION = f"{DOUYIN_DOMAIN}/aweme/v1/web/aweme/listcollection/"
 
+    # ç”¨æˆ·æ”¶è—å¤¹ (User Collects)
+    USER_COLLECTS = f"{DOUYIN_DOMAIN}/aweme/v1/web/collects/list/"
+
+    # ç”¨æˆ·æ”¶è—å¤¹ä½œå“ (User Collects Posts)
+    USER_COLLECTS_VIDEO = f"{DOUYIN_DOMAIN}/aweme/v1/web/collects/video/list/"
+
+    # ç”¨æˆ·éŸ³ä¹æ”¶è— (User Music Collection)
+    USER_MUSIC_COLLECTION = f"{DOUYIN_DOMAIN}/aweme/v1/web/music/listcollection/"
+
     # é¦–é¡µæœ‹å‹ä½œå“ (Friend Feed)
     FRIEND_FEED = f"{DOUYIN_DOMAIN}/aweme/v1/web/familiar/feed/"
 
     # å…³æ³¨ç”¨æˆ·ä½œå“ (Follow Feed)
     FOLLOW_FEED = f"{DOUYIN_DOMAIN}/aweme/v1/web/follow/feed/"
 
     # ç›¸å…³æ¨è (Related Feed)
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/cli.py` & `f2-0.0.1.5/f2/apps/douyin/cli.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,27 +1,32 @@
 # path: f2/apps/douyin/cli.py
 
 import f2
 import click
 import typing
 import asyncio
-import browser_cookie3
 
 from pathlib import Path
 
 from f2 import helps
 from f2.cli.cli_commands import set_cli_config
 from f2.log.logger import logger
-from f2.utils.utils import split_dict_cookie, get_resource_path
+from f2.utils.utils import (
+    split_dict_cookie,
+    get_resource_path,
+    get_cookie_from_browser,
+    check_invalid_naming,
+    merge_config,
+)
 from f2.utils.conf_manager import ConfigManager
 from f2.i18n.translator import TranslationManager, _
 from f2.apps.douyin.handler import handle_sso_login
 
 
-def handle_help(
+def handler_help(
     ctx: click.Context,
     param: typing.Union[click.Option, click.Parameter],
     value: typing.Any,
 ) -> None:
     """
     å¤„ç†å¸®åŠ©ä¿¡æ¯ (Handle help messages)
 
@@ -49,78 +54,53 @@
     ç”¨äºè‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookie (Used to automatically get cookies from the browser)
 
     Args:
         ctx: clickçš„ä¸Šä¸‹æ–‡å¯¹è±¡ (Click's context object)
         param: æä¾›çš„å‚æ•°æˆ–é€‰é¡¹ (The provided parameter or option)
         value: å‚æ•°æˆ–é€‰é¡¹çš„å€¼ (The value of the parameter or option)
     """
-    if not value or ctx.resilient_parsing:
-        return
-
-    # å¦‚æœç”¨æˆ·æ˜ç¡®è®¾ç½®äº† --cookieï¼Œé‚£ä¹ˆè·³è¿‡è‡ªåŠ¨è·å–è¿‡ç¨‹
-    if ctx.params.get("cookie"):
+    # å¦‚æœæ²¡æœ‰æä¾›å€¼æˆ–è€…ç”¨æˆ·å·²ç»è®¾ç½®äº† resilient_parsing æˆ–è€…æä¾›äº† --cookie å‚æ•°åˆ™è·³è¿‡
+    if not value or ctx.resilient_parsing or ctx.params.get("cookie"):
         return
 
     # æ ¹æ®æµè§ˆå™¨é€‰æ‹©è·å–cookie
-    if value in ["chrome", "firefox", "edge", "opera"]:
-        try:
-            cookie_value = split_dict_cookie(get_cookie_from_browser(value))
-            manager = ConfigManager(ctx.params.get("config", "conf/app.yaml"))
-            manager.update_config_with_args("douyin", cookie=cookie_value)
-        except PermissionError:
-            message = _("è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•, å¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ !")
-            logger.error(message)
-            click.echo(message)
-            ctx.abort()
-        except Exception as e:
-            message = _("è‡ªåŠ¨è·å–Cookieå¤±è´¥: {0}".format(str(e)))
-            logger.error(message)
-            click.echo(message)
-            ctx.abort()
+    try:
+        cookie_value = split_dict_cookie(get_cookie_from_browser(value, "douyin.com"))
 
+        if not cookie_value:
+            raise ValueError(_("æ— æ³•ä» {0} æµè§ˆå™¨ä¸­è·å–cookie").format(value))
 
-def get_cookie_from_browser(browser_choice: str):
-    """
-    æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æµè§ˆå™¨è·å–douyin.comçš„cookieã€‚
-
-    Args:
-        browser_choice (str): ç”¨æˆ·é€‰æ‹©çš„æµè§ˆå™¨åç§°
-
-    Returns:
-        str: *.douyin.comçš„cookieå€¼
-    """
-
-    BROWSER_FUNCTIONS = {
-        "chrome": browser_cookie3.chrome,
-        "firefox": browser_cookie3.firefox,
-        "edge": browser_cookie3.edge,
-        "opera": browser_cookie3.opera,
-    }
-    cj_function = BROWSER_FUNCTIONS.get(browser_choice)
-    if not cj_function:
-        raise ValueError(_("ä¸æ”¯æŒçš„æµè§ˆå™¨é€‰é¡¹, è¾“å…¥f2 dy --helpæŸ¥çœ‹æ›´å¤šå¸®åŠ©!"))
-
-    cj = cj_function(domain_name="douyin.com")
-
-    # cookie_value = next((c.value for c in cj if c.name == 'ttwid'), None)
-    cookie_value = {c.name: c.value for c in cj if c.domain.endswith("douyin.com")}
-
-    if not cookie_value:
-        raise ValueError(_("æ— æ³•ä» {0} æµè§ˆå™¨ä¸­è·å–cookie").format(browser_choice))
-
-    return cookie_value
+        # å¦‚æœæ²¡æœ‰æä¾›é…ç½®æ–‡ä»¶ï¼Œé‚£ä¹ˆä½¿ç”¨é«˜é¢‘é…ç½®æ–‡ä»¶
+        manager = ConfigManager(
+            ctx.params.get("config", get_resource_path(f2.APP_CONFIG_FILE_PATH))
+        )
+        manager.update_config_with_args("douyin", cookie=cookie_value)
+    except PermissionError:
+        logger.error(_("è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•ï¼Œå¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ï¼"))
+        ctx.abort()
+    except Exception as e:
+        logger.error(_("è‡ªåŠ¨è·å–Cookieå¤±è´¥ï¼š{0}").format(str(e)))
+        ctx.abort()
 
 
 def handler_language(
     ctx: click.Context,
     param: typing.Union[click.Option, click.Parameter],
     value: typing.Any,
 ) -> typing.Any:
-    """ç”¨äºè®¾ç½®è¯­è¨€ (For setting the language)"""
+    """ç”¨äºè®¾ç½®è¯­è¨€ (For setting the language)
 
+    Args:
+        ctx: clickçš„ä¸Šä¸‹æ–‡å¯¹è±¡ (Click's context object)
+        param: æä¾›çš„å‚æ•°æˆ–é€‰é¡¹ (The provided parameter or option)
+        value: å‚æ•°æˆ–é€‰é¡¹çš„å€¼ (The value of the parameter or option)
+    """
+
+    if not value or ctx.resilient_parsing:
+        return
     TranslationManager.get_instance().set_language(value)
     global _
     _ = TranslationManager.get_instance().gettext
     return value
 
 
 def handler_naming(
@@ -138,50 +118,28 @@
     Raises:
         click.BadParameter: å¦‚æœå‘½åæ¨¡å¼æ— æ•ˆ (If the naming pattern is invalid)
 
     Returns:
         value: å‘½åæ¨¡å¼æ¨¡æ¿ (Naming pattern template)
     """
     # é¿å…å’Œé…ç½®æ–‡ä»¶å‚æ•°å†²çª
-    if value is None:
+    if not value or ctx.resilient_parsing:
         return
 
     # å…è®¸çš„æ¨¡å¼å’Œåˆ†éš”ç¬¦
-    ALLOWED_PATTERNS = ["{nickname}", "{create}", "{aid}", "{desc}"]
+    ALLOWED_PATTERNS = ["{nickname}", "{create}", "{aweme_id}", "{desc}", "{uid}"]
     ALLOWED_SEPARATORS = ["-", "_"]
 
-    temp_naming = value
-    invalid_patterns = []
-
-    # æ£€æŸ¥æä¾›çš„æ¨¡å¼æ˜¯å¦æœ‰æ•ˆ
-    for pattern in ALLOWED_PATTERNS:
-        if pattern in temp_naming:
-            temp_naming = temp_naming.replace(pattern, "")
-
-    # æ­¤æ—¶ï¼Œtemp_namingåº”åªåŒ…å«åˆ†éš”ç¬¦
-    for char in temp_naming:
-        if char not in ALLOWED_SEPARATORS:
-            invalid_patterns.append(char)
-
-    # æ£€æŸ¥è¿ç»­çš„æ— æ•ˆæ¨¡å¼æˆ–åˆ†éš”ç¬¦
-    for pattern in ALLOWED_PATTERNS:
-        # æ£€æŸ¥åƒ"{aid}{aid}"è¿™æ ·çš„æ¨¡å¼
-        if pattern + pattern in value:
-            invalid_patterns.append(pattern + pattern)
-        for sep in ALLOWED_SEPARATORS:
-            # æ£€æŸ¥åƒ"{aid}-{aid}"è¿™æ ·çš„æ¨¡å¼
-            if pattern + sep + pattern in value:
-                invalid_patterns.append(pattern + sep + pattern)
+    # æ£€æŸ¥å‘½åæ˜¯å¦ç¬¦åˆå‘½åè§„èŒƒ
+    invalid_patterns = check_invalid_naming(value, ALLOWED_PATTERNS, ALLOWED_SEPARATORS)
 
     if invalid_patterns:
         raise click.BadParameter(
-            _(
-                "`{0}` ä¸­çš„ `{1}` ä¸ç¬¦åˆå‘½åæ¨¡å¼".format(
-                    value, "".join(invalid_patterns)
-                )
+            _("`{0}` ä¸­çš„ `{1}` ä¸ç¬¦åˆå‘½åæ¨¡å¼").format(
+                value, "".join(invalid_patterns)
             )
         )
 
     return value
 
 
 def handler_sso_login(
@@ -215,43 +173,14 @@
             ctx.params.get("config", get_resource_path(f2.APP_CONFIG_FILE_PATH))
         )
         manager.update_config_with_args("douyin", cookie=login_cookie)
     else:
         raise click.UsageError(_("SSOç™»å½•å¤±è´¥ï¼Œè¯·é‡è¯•ï¼"))
 
 
-def merge_config(main_conf, custom_conf, **kwargs):
-    """
-    åˆå¹¶é…ç½®å‚æ•°ï¼Œä½¿ CLI å‚æ•°ä¼˜å…ˆçº§é«˜äºè‡ªå®šä¹‰é…ç½®ï¼Œè‡ªå®šä¹‰é…ç½®ä¼˜å…ˆçº§é«˜äºä¸»é…ç½®ï¼Œæœ€ç»ˆç”Ÿæˆå®Œæ•´é…ç½®å‚æ•°å­—å…¸ã€‚
-    Args:
-        main_conf (dict): ä¸»é…ç½®å‚æ•°å­—å…¸
-        custom_conf (dict): è‡ªå®šä¹‰é…ç½®å‚æ•°å­—å…¸
-        **kwargs: CLI å‚æ•°å’Œå…¶ä»–é¢å¤–çš„é…ç½®å‚æ•°
-
-    Returns:
-        dict: åˆå¹¶åçš„é…ç½®å‚æ•°å­—å…¸
-    """
-    # åˆå¹¶ä¸»é…ç½®å’Œè‡ªå®šä¹‰é…ç½®
-    merged_conf = {}
-    for key, value in main_conf.items():
-        merged_conf[key] = value  # å°†ä¸»é…ç½®å¤åˆ¶åˆ°åˆå¹¶åçš„é…ç½®ä¸­
-    for key, value in custom_conf.items():
-        if value is not None and value != "":  # åªæœ‰å€¼ä¸ä¸º None å’Œ ç©ºå€¼ï¼Œæ‰è¿›è¡Œåˆå¹¶
-            merged_conf[key] = value  # è‡ªå®šä¹‰é…ç½®å‚æ•°ä¼šè¦†ç›–ä¸»é…ç½®ä¸­çš„åŒåå‚æ•°
-
-    # åˆå¹¶ CLI å‚æ•°ä¸åˆå¹¶åçš„é…ç½®ï¼Œç¡®ä¿ CLI å‚æ•°çš„ä¼˜å…ˆçº§æœ€é«˜
-    for key, value in kwargs.items():
-        if key not in merged_conf:  # å¦‚æœåˆå¹¶åçš„é…ç½®ä¸­æ²¡æœ‰è¿™ä¸ªé”®ï¼Œåˆ™ç›´æ¥æ·»åŠ 
-            merged_conf[key] = value
-        elif value is not None and value != "":  # å¦‚æœå€¼ä¸ä¸º None å’Œ ç©ºå€¼ï¼Œåˆ™è¿›è¡Œåˆå¹¶
-            merged_conf[key] = value  # CLI å‚æ•°ä¼šè¦†ç›–è‡ªå®šä¹‰é…ç½®å’Œä¸»é…ç½®ä¸­çš„åŒåå‚æ•°
-
-    return merged_conf
-
-
 @click.command(name="douyin", help=_("æŠ–éŸ³æ— æ°´å°è§£æ"))
 @click.option(
     "--config",
     "-c",
     type=click.Path(file_okay=True, dir_okay=False, readable=True),  # exists=True
     help=_("é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œæœ€ä½ä¼˜å…ˆ"),
 )
@@ -265,52 +194,52 @@
     ),
 )
 @click.option(
     "--music",
     "-m",
     type=bool,
     # default="yes",
-    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°ã€‚å¯é€‰ï¼š'yes'ã€'no'"),
+    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°"),
 )
 @click.option(
     "--cover",
     "-v",
     type=bool,
     # default="yes",
-    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢ã€‚å¯é€‰ï¼š'yes'ã€'no'"),
+    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢"),
 )
 @click.option(
     "--desc",
     "-d",
     type=bool,
     # default="yes",
-    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆã€‚å¯é€‰ï¼š'yes'ã€'no'"),
+    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆ"),
 )
 @click.option(
     "--path",
     "-p",
     type=str,
     # default="Download",
-    help=_("ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„ã€‚"),
+    help=_("ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„"),
 )
 @click.option(
     "--folderize",
     "-f",
     type=bool,
     # default="yes",
-    help=_("æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ã€‚å¯é€‰ï¼š'yes'ã€'no'"),
+    help=_("æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹"),
 )
 @click.option(
     "--mode",
     "-M",
-    type=click.Choice(["one", "post", "like", "collect", "mix", "live"]),
+    type=click.Choice(f2.DOUYIN_MODE_LIST),
     # default="post",
     # required=True,
     help=_(
-        "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“(collect)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
+        "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“(collection)ï¼Œæ”¶è—å¤¹ä½œå“(collects)ï¼Œæ”¶è—éŸ³ä¹(music)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
     ),
 )
 @click.option(
     "--naming",
     "-n",
     type=str,
     # default="{create}_{desc}",
@@ -332,102 +261,107 @@
     help=_("ä¸‹è½½æ—¥æœŸåŒºé—´å‘å¸ƒçš„ä½œå“ï¼Œæ ¼å¼ï¼š2022-01-01|2023-01-01ï¼Œ'all' ä¸ºä¸‹è½½æ‰€æœ‰ä½œå“"),
 )
 @click.option(
     "--timeout",
     "-e",
     type=int,
     # default=10,
-    help=_("ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ã€‚"),
+    help=_("ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´"),
 )
 @click.option(
     "--max_retries",
     "-r",
     type=int,
     # default=5,
-    help=_("ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°ã€‚"),
+    help=_("ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°"),
 )
 @click.option(
     "--max-connections",
     "-x",
     type=int,
     # default=5,
-    help=_("ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°ã€‚"),
+    help=_("ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°"),
 )
 @click.option(
     "--max-tasks",
     "-t",
     type=int,
     # default=10,
-    help=_("å¼‚æ­¥çš„ä»»åŠ¡æ•°ã€‚"),
+    help=_("å¼‚æ­¥çš„ä»»åŠ¡æ•°"),
 )
 @click.option(
     "--max-counts",
     "-o",
     type=int,
     # default=0,
     help=_("æœ€å¤§ä½œå“ä¸‹è½½æ•°ã€‚0 è¡¨ç¤ºæ— é™åˆ¶"),
 )
 @click.option(
     "--page-counts",
     "-s",
     type=int,
     # default=20,
-    help=_("ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20ã€‚"),
+    help=_("ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20"),
 )
 @click.option(
     "--languages",
     "-l",
     type=click.Choice(["zh_CN", "en_US"]),
     default="zh_CN",
-    help=_("æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ã€‚å¯é€‰ï¼š'zh_CN'ã€'en_US'ã€‚ä¸æ”¯æŒé…ç½®æ–‡ä»¶ä¿®æ”¹ã€‚"),
+    help=_("æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ï¼Œå¯é€‰ï¼š'zh_CN'ã€'en_US'ï¼Œä¸æ”¯æŒé…ç½®æ–‡ä»¶ä¿®æ”¹"),
     callback=handler_language,
 )
 @click.option(
     "--proxies",
     "-P",
     type=str,
     nargs=2,
     help=_(
         "ä»£ç†æœåŠ¡å™¨ï¼Œæœ€å¤š 2 ä¸ªå‚æ•°ï¼Œhttpä¸httpsã€‚ç©ºæ ¼åŒºåˆ† 2 ä¸ªå‚æ•° http://x.x.x.x https://x.x.x.x"
     ),
 )
+@click.option("--lyric", "-L", type=bool, help=_("æ˜¯å¦ä¿å­˜åŸå£°æ­Œè¯"))
 @click.option(
     "--update-config",
     type=bool,
     is_flag=True,
     help=_("ä½¿ç”¨å‘½ä»¤è¡Œé€‰é¡¹æ›´æ–°é…ç½®æ–‡ä»¶ã€‚éœ€è¦å…ˆä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªé…ç½®æ–‡ä»¶è·¯å¾„"),
 )
 @click.option(
     "--init-config", type=str, help=_("åˆå§‹åŒ–é…ç½®æ–‡ä»¶ã€‚ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶")
 )
 @click.option(
     "--auto-cookie",
-    type=click.Choice(["none", "chrome", "firefox", "edge", "opera"]),
+    type=click.Choice(f2.BROWSER_LIST),
     # default="none",
-    help=_(
-        "è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
-    ),
+    help=_("è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"),
     callback=handler_auto_cookie,
 )
 @click.option(
     "--sso-login",
     is_flag=True,
-    help=_("ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–[yellow]cookie[/yellow]ï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"),
+    help=_("ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–cookieï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"),
     callback=handler_sso_login,
 )
 @click.option(
     "-h",
     is_flag=True,
     is_eager=True,
     expose_value=False,
     help=_("æ˜¾ç¤ºå¯Œæ–‡æœ¬å¸®åŠ©"),
-    callback=handle_help,
+    callback=handler_help,
 )
 @click.pass_context
-def douyin(ctx, config, init_config, update_config, **kwargs):
+def douyin(
+    ctx: click.Context,
+    config: str,
+    init_config: str,
+    update_config: bool,
+    **kwargs,
+):
     ##################
     # f2 å­˜åœ¨2ä¸ªä¸»é…ç½®æ–‡ä»¶ï¼Œåˆ†åˆ«æ˜¯appä½é¢‘é…ç½®(app.yaml)å’Œf2ä½é¢‘é…ç½®(conf.yaml)
     # appä½é¢‘é…ç½®å­˜æ”¾appç›¸å…³çš„å‚æ•°
     # f2ä½é¢‘é…ç½®å­˜æ”¾è®¡ç®—å€¼æ‰€éœ€çš„å‚æ•°
 
     # å…¶ä¸­cliå‚æ•°å…·æœ‰æœ€é«˜ä¼˜å…ˆï¼Œcli >= è‡ªå®šä¹‰ >= ä½é¢‘
     # åœ¨f2ä½é¢‘é…ç½®ä¸­è®¾ç½®ä»£ç†å‚æ•°
@@ -463,15 +397,15 @@
         main_manager.generate_config("douyin", init_config)
         # return
     elif init_config:
         raise click.UsageError(_("ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶"))
     # å¦‚æœæ²¡æœ‰åˆå§‹åŒ–é…ç½®æ–‡ä»¶ï¼Œä½†æ˜¯æ›´æ–°é…ç½®æ–‡ä»¶ï¼Œåˆ™éœ€è¦æä¾›é…ç½®æ–‡ä»¶è·¯å¾„
     elif update_config and not config:
         raise click.UsageError(
-            _("è¦æ›´æ–°é…ç½®, é¦–å…ˆéœ€è¦ä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªè‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„")
+            _("è¦æ›´æ–°é…ç½®ï¼Œé¦–å…ˆéœ€è¦ä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªè‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„")
         )
 
     # è¯»å–è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
     if config:
         custom_manager = ConfigManager(config)
     else:
         custom_manager = main_manager
@@ -489,21 +423,21 @@
             "http": kwargs["proxies"][0],
             "https": kwargs["proxies"][1],
         }
 
     # ä»ä½é¢‘é…ç½®å¼€å§‹åˆ°é«˜é¢‘é…ç½®å†åˆ°cliå‚æ•°ï¼Œé€çº§è¦†ç›–ï¼Œå¦‚æœé”®å€¼ä¸å­˜åœ¨ä½¿ç”¨çˆ¶çº§çš„é”®å€¼
     kwargs = merge_config(main_conf, custom_conf, **kwargs)
 
-    logger.info(_("ä¸»é…ç½®è·¯å¾„ï¼š {0}".format(main_conf_path)))
-    logger.info(_("è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š {0}".format(Path.cwd() / config)))
-    logger.debug(_("ä¸»é…ç½®å‚æ•°ï¼š{0}".format(main_conf)))
-    logger.debug(_("è‡ªå®šä¹‰é…ç½®å‚æ•°ï¼š{0}".format(custom_conf)))
-    logger.debug(_("CLIå‚æ•°ï¼š{0}".format(kwargs)))
+    logger.info(_("ä¸»é…ç½®è·¯å¾„ï¼š{0}").format(main_conf_path))
+    logger.info(_("è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š{0}").format(Path.cwd() / config))
+    logger.debug(_("ä¸»é…ç½®å‚æ•°ï¼š{0}").format(main_conf))
+    logger.debug(_("è‡ªå®šä¹‰é…ç½®å‚æ•°ï¼š{0}").format(custom_conf))
+    logger.debug(_("CLIå‚æ•°ï¼š{0}").format(kwargs))
 
     # å°è¯•ä»å‘½ä»¤è¡Œå‚æ•°æˆ–kwargsä¸­è·å–URL
     if not kwargs.get("url"):
         logger.error("ç¼ºä¹URLå‚æ•°ï¼Œè¯¦æƒ…çœ‹å‘½ä»¤å¸®åŠ©")
-        handle_help(ctx, None, True)
+        handler_help(ctx, None, True)
 
     # æ·»åŠ app_nameåˆ°kwargs
     kwargs["app_name"] = "douyin"
     ctx.invoke(set_cli_config, **kwargs)
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/crawler.py` & `f2-0.0.1.5/f2/apps/tiktok/crawler.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,36 +1,36 @@
-# path: f2/apps/douyin/crawler.py
+# path: f2/apps/tiktok/crawler.py
 
 import f2
 
 from f2.log.logger import logger
 from f2.i18n.translator import _
 from f2.utils.conf_manager import ConfigManager
 from f2.crawlers.base_crawler import BaseCrawler
-from f2.apps.douyin.api import DouyinAPIEndpoints as dyendpoint
-from f2.apps.douyin.model import (
+from f2.apps.tiktok.api import TiktokAPIEndpoints as tkendpoint
+from f2.apps.tiktok.model import (
     UserProfile,
     UserPost,
     UserLike,
+    UserMix,
     UserCollect,
     PostDetail,
-    UserMix,
-    UserLive,
-    UserLive2,
-    FollowUserLive,
-    LoginGetQr,
-    LoginCheckQr,
+    UserPlayList,
+    PostComment,
 )
-from f2.apps.douyin.utils import XBogusManager
+from f2.apps.tiktok.utils import XBogusManager
 
 
-class DouyinCrawler(BaseCrawler):
-    def __init__(self, kwargs: dict = {}):
+class TiktokCrawler(BaseCrawler):
+    def __init__(
+        self,
+        kwargs: dict = ...,
+    ):
         f2_manager = ConfigManager(f2.F2_CONFIG_FILE_PATH)
-        f2_conf = f2_manager.get_config("f2").get("douyin")
+        f2_conf = f2_manager.get_config("f2").get("tiktok")
         proxies_conf = kwargs.get("proxies", {"http": None, "https": None})
         proxies = {
             "http://": proxies_conf.get("http", None),
             "https://": proxies_conf.get("https", None),
         }
 
         self.headers = {
@@ -39,142 +39,91 @@
             "Cookie": kwargs["cookie"],
         }
 
         super().__init__(proxies=proxies, crawler_headers=self.headers)
 
     async def fetch_user_profile(self, params: UserProfile):
         endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.USER_DETAIL, params.dict()
-        )  # fmt: off
-        logger.debug(_("ç”¨æˆ·ä¿¡æ¯æ¥å£åœ°å€:" + endpoint))
+            self.headers.get("User-Agent"),
+            tkendpoint.USER_DETAIL,
+            params.dict(),
+        )
+        logger.debug(_("ç”¨æˆ·ä¿¡æ¯æ¥å£åœ°å€ï¼š{0}").format(endpoint))
         return await self._fetch_get_json(endpoint)
 
     async def fetch_user_post(self, params: UserPost):
         endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.USER_POST, params.dict()
-        )  # fmt: off
-        logger.debug(_("ä¸»é¡µä½œå“æ¥å£åœ°å€:" + endpoint))
+            self.headers.get("User-Agent"),
+            tkendpoint.USER_POST,
+            params.dict(),
+        )
+        logger.debug(_("ä¸»é¡µä½œå“æ¥å£åœ°å€ï¼š{0}").format(endpoint))
         return await self._fetch_get_json(endpoint)
 
     async def fetch_user_like(self, params: UserLike):
         endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.USER_FAVORITE_A, params.dict()
+            self.headers.get("User-Agent"),
+            tkendpoint.USER_LIKE,
+            params.dict(),
         )
-        logger.debug(_("å–œæ¬¢ä½œå“æ¥å£åœ°å€:" + endpoint))
+        logger.debug(_("å–œæ¬¢ä½œå“æ¥å£åœ°å€ï¼š{0}").format(endpoint))
         return await self._fetch_get_json(endpoint)
 
     async def fetch_user_collect(self, params: UserCollect):
         endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.USER_COLLECTION, params.dict()
+            self.headers.get("User-Agent"),
+            tkendpoint.USER_COLLECT,
+            params.dict(),
         )
-        logger.debug(_("æ”¶è—ä½œå“æ¥å£åœ°å€:" + endpoint))
-        return await self._fetch_post_json(endpoint, params.dict())
-
-    async def fetch_user_mix(self, params: UserMix):
-        endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.MIX_AWEME, params.dict()
-        )  # fmt: off
-        logger.debug(_("åˆé›†ä½œå“æ¥å£åœ°å€:" + endpoint))
-        return await self._fetch_get_json(endpoint)
-
-    async def fetch_post_detail(self, params: PostDetail):
-        endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.POST_DETAIL, params.dict()
-        )  # fmt: off
-        logger.debug(_("ä½œå“è¯¦æƒ…æ¥å£åœ°å€:" + endpoint))
+        logger.debug(_("æ”¶è—ä½œå“æ¥å£åœ°å€ï¼š{0}").format(endpoint))
         return await self._fetch_get_json(endpoint)
 
-    async def fetch_post_comment(self, params: PostDetail):
+    async def fetch_user_play_list(self, params: UserPlayList):
         endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.POST_COMMENT, params.dict()
+            self.headers.get("User-Agent"),
+            tkendpoint.USER_PLAY_LIST,
+            params.dict(),
         )
-        logger.debug(_("ä½œå“è¯„è®ºæ¥å£åœ°å€:" + endpoint))
-        return await self._fetch_get_json(endpoint)
-
-    async def fetch_post_feed(self, params: PostDetail):
-        endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.TAB_FEED, params.dict()
-        )  # fmt: off
-        logger.debug(_("é¦–é¡µæ¨èä½œå“æ¥å£åœ°å€:" + endpoint))
-        return await self._fetch_get_json(endpoint)
-
-    async def fetch_follow_feed(self, params: PostDetail):
-        endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.FOLLOW_FEED, params.dict()
-        )  # fmt: off
-        logger.debug(_("å…³æ³¨ä½œå“æ¥å£åœ°å€:" + endpoint))
-        return await self._fetch_get_json(endpoint)
-
-    async def fetch_friend_feed(self, params: PostDetail):
-        endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.FRIEND_FEED, params.dict()
-        )  # fmt: off
-        logger.debug(_("æœ‹å‹ä½œå“æ¥å£åœ°å€:" + endpoint))
+        logger.debug(_("åˆè¾‘åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}").format(endpoint))
         return await self._fetch_get_json(endpoint)
 
-    async def fetch_post_related(self, params: PostDetail):
+    async def fetch_user_mix(self, params: UserMix):
         endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.POST_RELATED, params.dict()
+            self.headers.get("User-Agent"),
+            tkendpoint.USER_MIX,
+            params.dict(),
         )
-        logger.debug(_("ç›¸å…³æ¨èä½œå“æ¥å£åœ°å€:" + endpoint))
-        return await self._fetch_get_json(endpoint)
-
-    async def fetch_live(self, params: UserLive):
-        endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.LIVE_INFO, params.dict()
-        )  # fmt: off
-        logger.debug(_("ç›´æ’­æ¥å£åœ°å€:" + endpoint))
+        logger.debug(_("åˆè¾‘ä½œå“æ¥å£åœ°å€ï¼š{0}").format(endpoint))
         return await self._fetch_get_json(endpoint)
 
-    async def fetch_live_room_id(self, params: UserLive2):
-        original_headers = self.aclient.headers.copy()
-        try:
-            # é¿å…invalid session
-            self.aclient.headers.update({"Cookie": ""})
-            endpoint = XBogusManager.model_2_endpoint(
-                dyendpoint.LIVE_INFO_ROOM_ID, params.dict()
-            )
-            logger.debug(_("ç›´æ’­æ¥å£åœ°å€ï¼ˆroom_idï¼‰:" + endpoint))
-            return await self._fetch_get_json(endpoint)
-        finally:
-            self.aclient.headers = original_headers
-
-    async def fetch_follow_live(self, params: FollowUserLive):
+    async def fetch_post_detail(self, params: PostDetail):
         endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.FOLLOW_USER_LIVE, params.dict()
+            self.headers.get("User-Agent"),
+            tkendpoint.AWEME_DETAIL,
+            params.dict(),
         )
-        logger.debug(_("å…³æ³¨ç”¨æˆ·ç›´æ’­æ¥å£åœ°å€:" + endpoint))
-        return await self._fetch_get_json(endpoint)
-
-    async def fetch_locate_post(self, params: UserPost):
-        endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.LOCATE_POST, params.dict()
-        )  # fmt: off
-        logger.debug(_("å®šä½ä¸Šä¸€æ¬¡ä½œå“æ¥å£åœ°å€:" + endpoint))
+        logger.debug(_("ä½œå“è¯¦æƒ…æ¥å£åœ°å€ï¼š{0}").format(endpoint))
         return await self._fetch_get_json(endpoint)
 
-    async def fetch_login_qrcode(self, parms: LoginGetQr):
+    async def fetch_post_comment(self, params: PostComment):
         endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.SSO_LOGIN_GET_QR, parms.dict()
+            self.headers.get("User-Agent"),
+            tkendpoint.POST_COMMENT,
+            params.dict(),
         )
-        logger.debug(_("SSOè·å–äºŒç»´ç æ¥å£åœ°å€:" + endpoint))
+        logger.debug(_("ä½œå“è¯„è®ºæ¥å£åœ°å€ï¼š{0}").format(endpoint))
         return await self._fetch_get_json(endpoint)
 
-    async def fetch_check_qrcode(self, parms: LoginCheckQr):
-        endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.SSO_LOGIN_CHECK_QR, parms.dict()
-        )
-        logger.debug(_("SSOæ£€æŸ¥æ‰«ç çŠ¶æ€æ¥å£åœ°å€:" + endpoint))
-        return await self._fetch_response(endpoint)
-
-    async def fetch_check_login(self, parms: LoginCheckQr):
+    async def fetch_post_recommend(self, params: PostDetail):
         endpoint = XBogusManager.model_2_endpoint(
-            dyendpoint.SSO_LOGIN_CHECK_LOGIN, parms.dict()
+            self.headers.get("User-Agent"),
+            tkendpoint.HOME_RECOMMEND,
+            params.dict(),
         )
-        logger.debug(_("SSOæ£€æŸ¥ç™»å½•çŠ¶æ€æ¥å£åœ°å€:" + endpoint))
+        logger.debug(_("é¦–é¡µæ¨èæ¥å£åœ°å€ï¼š{0}").format(endpoint))
         return await self._fetch_get_json(endpoint)
 
     async def __aenter__(self):
         return self
 
     async def __aexit__(self, exc_type, exc_val, exc_tb):
         await self.close()
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/db.py` & `f2-0.0.1.5/f2/apps/douyin/db.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 # path: f2/apps/douyin/db.py
 
-import aiosqlite
 from f2.db.base_db import BaseDB
 
 
 class AsyncUserDB(BaseDB):
     TABLE_NAME = "user_info_web"
 
     async def _create_table(self) -> None:
@@ -28,18 +27,20 @@
             "is_block BOOLEAN",
             "is_blocked BOOLEAN",
             "is_star BOOLEAN",
             "live_status INTEGER",
             "mix_count INTEGER",
             "mplatform_followers_count INTEGER",
             "nickname TEXT",
+            "nickname_raw TEXT",
             "room_id TEXT",
             "school_name TEXT",
             "short_id TEXT",
             "signature TEXT",
+            "signature_raw TEXT",
             "total_favorited INTEGER",
             "uid TEXT",
             "unique_id TEXT",
             "user_age INTEGER",
             "last_aweme_id TEXT",
         ]
 
@@ -73,15 +74,15 @@
         await self.execute(
             f"INSERT OR REPLACE INTO {self.TABLE_NAME} ({keys}) VALUES ({placeholders})",
             values,
         )
         # VALUES (?, {placeholders})', (kwargs.get('sec_user_id'), *values))
         await self.commit()
 
-    async def update_user_info(self, sec_user_id, **kwargs) -> None:
+    async def update_user_info(self, sec_user_id: str, **kwargs) -> None:
         """
         æ›´æ–°ç”¨æˆ·ä¿¡æ¯
 
         Args:
             sec_user_id (str): ç”¨æˆ·å”¯ä¸€æ ‡è¯†
             **kwargs: ç”¨æˆ·çš„å…¶ä»–å­—æ®µé”®å€¼å¯¹
         """
@@ -143,25 +144,27 @@
         """
         await super()._create_table()
         fields = [
             "api_status_code TEXT",
             "aweme_id TEXT PRIMARY KEY",
             "aweme_type TEXT",
             "nickname TEXT",
+            "nickname_raw TEXT",
             "sec_user_id TEXT",
             "short_id TEXT",
             "uid TEXT",
             "unique_id TEXT",
             "can_comment TEXT",
             "can_forward TEXT",
             "can_share TEXT",
             "can_show_comment TEXT",
             "comment_gid TEXT",
             "create_time TEXT",
             "desc TEXT",
+            "desc_raw TEXT",
             "duration TEXT",
             "is_ads TEXT",
             "is_story TEXT",
             "is_top TEXT",
             "video_bit_rate JSON",
             "video_play_addr TEXT",
             "images JSON",
@@ -170,37 +173,43 @@
             "part_see TEXT",
             "private_status TEXT",
             "is_delete TEXT",
             "is_prohibited TEXT",
             "is_long_video TEXT",
             "media_type TEXT",
             "mix_desc TEXT",
+            "mix_desc_raw TEXT",
             "mix_create_time TEXT",
             "mix_id TEXT",
             "mix_name TEXT",
             "mix_pic_type TEXT",
             "mix_type TEXT",
             "mix_share_url TEXT",
             "mix_update_time TEXT",
             "is_commerce_music TEXT",
             "is_original TEXT",
             "is_original_sound TEXT",
             "is_pgc TEXT",
             "music_author TEXT",
+            "music_author_raw TEXT",
             "music_author_deleted TEXT",
             "music_duration TEXT",
             "music_id TEXT",
             "music_mid TEXT",
             "pgc_author TEXT",
+            "pgc_author_raw TEXT",
             "pgc_author_title TEXT",
+            "pgc_author_title_raw TEXT",
             "pgc_music_type TEXT",
             "music_status TEXT",
             "music_owner_handle TEXT",
+            "music_owner_handle_raw TEXT",
             "music_owner_id TEXT",
             "music_owner_nickname TEXT",
+            "music_owner_nickname_raw TEXT",
             "music_play_url TEXT",
             "position TEXT",
             "region TEXT",
             "seo_ocr_content TEXT",
             "allow_douplus TEXT",
             "download_setting TEXT",
             "allow_share TEXT",
@@ -251,37 +260,34 @@
         """
         æ‰¹é‡æ·»åŠ è§†é¢‘ä¿¡æ¯
 
         Args:
             video_data_list (list): è§†é¢‘ä¿¡æ¯åˆ—è¡¨
             ignore_fields (list): è¦å¿½ç•¥çš„å­—æ®µåˆ—è¡¨ï¼Œä¾‹å¦‚ ["field1", "field2"]
         """
-        try:
-            # å¦‚æœ ignore_fields æœªæä¾›æˆ–è€…ä¸º Noneï¼Œå°†å…¶è®¾ç½®ä¸ºç©ºåˆ—è¡¨
-            ignore_fields = ignore_fields or []
-
-            # åˆ é™¤è¦å¿½ç•¥çš„å­—æ®µ
-            for field in ignore_fields:
-                for video_data in video_data_list:
-                    if field in video_data:
-                        del video_data[field]
+        # å¦‚æœ ignore_fields æœªæä¾›æˆ–è€…ä¸º Noneï¼Œå°†å…¶è®¾ç½®ä¸ºç©ºåˆ—è¡¨
+        ignore_fields = ignore_fields or []
 
-            keys = ", ".join(video_data_list[0].keys())
-            placeholders = ", ".join(["?" for _ in range(len(video_data_list[0]))])
+        # åˆ é™¤è¦å¿½ç•¥çš„å­—æ®µ
+        for field in ignore_fields:
+            for video_data in video_data_list:
+                if field in video_data:
+                    del video_data[field]
 
-            # æ„å»ºæ’å…¥æ•°æ®çš„å…ƒç»„åˆ—è¡¨
-            values = [tuple(video_data.values()) for video_data in video_data_list]
+        keys = ", ".join(video_data_list[0].keys())
+        placeholders = ", ".join(["?" for _ in range(len(video_data_list[0]))])
 
-            await self.execute(
-                f"INSERT OR REPLACE INTO {self.TABLE_NAME} ({keys}) VALUES ({placeholders})",
-                values,
-            )
-            await self.commit()
-        except aiosqlite.Error as e:
-            print(f"Error batch inserting videos: {e}")
+        # æ„å»ºæ’å…¥æ•°æ®çš„å…ƒç»„åˆ—è¡¨
+        values = [tuple(video_data.values()) for video_data in video_data_list]
+
+        await self.execute(
+            f"INSERT OR REPLACE INTO {self.TABLE_NAME} ({keys}) VALUES ({placeholders})",
+            values,
+        )
+        await self.commit()
 
     async def get_video_info(self, aweme_id: str) -> dict:
         """
         è·å–ç‰¹å®šè§†é¢‘çš„ä¿¡æ¯
 
         Args:
             aweme_id (str): è§†é¢‘ID
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/dl.py` & `f2-0.0.1.5/f2/apps/tiktok/dl.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,44 +1,43 @@
-# path: f2/apps/douyin/dl.py
+# path: f2/apps/tiktok/dl.py
 
 import sys
 from datetime import datetime
 from typing import Any, Union
 
 from f2.i18n.translator import _
 from f2.log.logger import logger
 from f2.dl.base_downloader import BaseDownloader
 from f2.utils.utils import get_timestamp, timestamp_2_str
-from f2.apps.douyin.db import AsyncUserDB
-from f2.apps.douyin.utils import format_file_name
+from f2.apps.tiktok.db import AsyncUserDB
+from f2.apps.tiktok.utils import format_file_name
 
 
-class DouyinDownloader(BaseDownloader):
+class TiktokDownloader(BaseDownloader):
     def __init__(self, kwargs: dict = {}):
         if kwargs["cookie"] is None:
             raise ValueError(
                 _(
-                    "cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å– f2 -d dy --helpï¼Œå¦‚æ‰«ç ç™»å½•è¯·ä¿ç•™åŒå¼•å·cookie: "
-                    "ï¼Œå†ä½¿ç”¨--sso-loginå‘½ä»¤ã€‚"
+                    "cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å–ã€‚å¦‚ `--auto-cookie edge`"
                 )
             )
 
         super().__init__(kwargs)
 
-    async def save_last_aweme_id(self, sec_user_id: str, aweme_id: int) -> None:
+    async def save_last_aweme_id(self, secUid: str, aweme_id: str) -> None:
         """
         ä¿å­˜æœ€åä¸€ä¸ªè¯·æ±‚çš„aweme_id
         (Save the last requested aweme_id)
 
         Args:
-            aweme_id (int): ä½œå“id (aweme_id)
+            aweme_id (str): ä½œå“id (aweme_id)
         """
 
-        async with AsyncUserDB("douyin_users.db") as db:
-            await db.update_user_info(sec_user_id=sec_user_id, last_aweme_id=aweme_id)
+        async with AsyncUserDB("tiktok_users.db") as db:
+            await db.update_user_info(secUid=secUid, last_aweme_id=aweme_id)
 
     async def filter_aweme_datas_by_interval(
         self, aweme_datas: Union[list, dict], interval: str
     ) -> Union[list[dict], dict, None]:
         """
         ç­›é€‰æŒ‡å®šæ—¥æœŸåŒºé—´å†…çš„ä½œå“
 
@@ -59,16 +58,18 @@
             start_date = datetime.strptime(start_str + " 00-00-00", "%Y-%m-%d %H-%M-%S")
             end_date = datetime.strptime(end_str + " 23-59-59", "%Y-%m-%d %H-%M-%S")
             logger.info(_("ç­›é€‰æ—¥æœŸåŒºé—´ï¼š{0} è‡³ {1}").format(start_date, end_date))
         except ValueError:
             logger.error(_("æ—¥æœŸåŒºé—´å‚æ•°æ ¼å¼é”™è¯¯ï¼Œè¯·æŸ¥é˜…æ–‡æ¡£åé‡è¯•"))
             return None
 
+        logger.info(aweme_datas)
+
         if isinstance(aweme_datas, dict):
-            aweme_date_str = aweme_datas.get("create_time")
+            aweme_date_str = aweme_datas.get("createTime")
             try:
                 aweme_date = datetime.strptime(aweme_date_str, "%Y-%m-%d %H-%M-%S")
             except ValueError:
                 logger.warning(_("æ— æ³•è§£æä½œå“å‘å¸ƒæ—¶é—´ï¼š{0}").format(aweme_date_str))
                 return None
 
             # æ£€æŸ¥ä½œå“å‘å¸ƒæ—¶é—´æ˜¯å¦åœ¨æŒ‡å®šåŒºé—´å†…
@@ -144,78 +145,84 @@
         self, kwargs: dict, aweme_data_dict: dict, user_path: Any
     ) -> None:
         """
         å¤„ç†ä¸‹è½½ä»»åŠ¡
 
         Args:
             kwargs (dict): å‘½ä»¤è¡Œå‚æ•°
-            aweme_data_dict (dict): ä½œå“æ•°æ®å­—å…¸
-            user_path (Any): ç”¨æˆ·ç›®å½•è·¯å¾„
         """
 
         # æ„å»ºæ–‡ä»¶å¤¹è·¯å¾„
         base_path = (
             user_path
             / format_file_name(kwargs.get("naming", "{create}_{desc}"), aweme_data_dict)
             if kwargs.get("folderize")
             else user_path
         )
 
-        sec_user_id = str(aweme_data_dict.get("sec_user_id"))  # ç”¨æˆ·ID
-        aweme_prohibited = aweme_data_dict.get("is_prohibited")  # ä½œå“çŠ¶æ€ 0æ­£å¸¸, 1å±è”½
-        aweme_part_see = aweme_data_dict.get(
-            "part_see"
-        )  # éƒ¨åˆ†å¯è§ part_see 1, private_status 1
-        aweme_status = aweme_data_dict.get(
-            "private_status"
-        )  # è§†é¢‘æƒé™ 0å…¬å¼€æˆ–ä¸ç»™è°çœ‹, 1ç§å¯†, 2äº’å…³æœ‹å‹
-        aweme_type = aweme_data_dict.get(
-            "aweme_type"
-        )  # è§†é¢‘ç±»å‹ 0è§†é¢‘, 55åŠ¨å›¾æˆ–å…³é—­ä¸‹è½½, 61æŒ‘æˆ˜ï¼Œ 109æ—¥å¸¸, 68å›¾é›†
+        secUid = str(aweme_data_dict.get("secUid"))  # ç”¨æˆ·ID
+        aweme_privateItem = aweme_data_dict.get(
+            "privateItem"
+        )  # ä½œå“æƒé™ falseå…¬å¼€, trueç§å¯†
+        aweme_secret = aweme_data_dict.get("secret")  # ä½œå“æƒé™ falseå…¬å¼€, trueç§å¯†
         aweme_id = str(aweme_data_dict.get("aweme_id"))  # è§†é¢‘ID
 
         logger.debug(f"========{aweme_id}========")
         logger.debug(aweme_data_dict)
-        logger.debug("================")
+        logger.debug("===================================")
 
         # æ£€æŸ¥ä½œå“æ˜¯å¦è¢«å±è”½
-        if aweme_prohibited:
-            logger.warning(_("{0} è¯¥ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id))
+        if aweme_privateItem:
+            logger.warning(_("è¯¥ {0} ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id))
             return
 
         # æ£€æŸ¥ä½œå“æ˜¯å¦å¯è§
-        if aweme_status in [0, 1, 2]:
+        if not aweme_secret:
+            video_name = (
+                format_file_name(
+                    kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
+                )
+                + "_video"
+            )
+
+            video_url = aweme_data_dict.get("video_playAddr")
+            if video_url != None:
+                await self.initiate_download(
+                    _("è§†é¢‘"), video_url, base_path, video_name, ".mp4"
+                )
+            else:
+                logger.warning(_("{0} è¯¥ä½œå“æ²¡æœ‰è§†é¢‘é“¾æ¥ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id))
+
             # å¤„ç†éŸ³ä¹ä¸‹è½½ä»»åŠ¡
             if kwargs.get("music"):
-                if aweme_data_dict.get("music_status") == 1:  # åŸå£°çŠ¶æ€ 1 æ­£å¸¸ 0 å¤±æ•ˆ
-                    music_name = (
-                        format_file_name(
-                            kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
-                        )
-                        + "_music"
+                music_name = (
+                    format_file_name(
+                        kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
                     )
+                    + "_music"
+                )
 
-                    music_url = aweme_data_dict.get("music_play_url")
-                    if music_url != None:
-                        await self.initiate_download(
-                            _("åŸå£°"), music_url, base_path, music_name, ".mp3"
-                        )
+                music_url = aweme_data_dict.get("music_playUrl")
+                if music_url != None:
+                    await self.initiate_download(
+                        _("åŸå£°"), music_url, base_path, music_name, ".mp3"
+                    )
                 else:
                     logger.warning(_("{0} è¯¥åŸå£°å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id))
 
             # å¤„ç†å°é¢ä¸‹è½½ä»»åŠ¡
             if kwargs.get("cover"):
                 cover_name = (
                     format_file_name(
                         kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
                     )
                     + "_cover"
                 )
-                animated_cover_url = aweme_data_dict.get("animated_cover")
-                cover_url = aweme_data_dict.get("cover")
+                animated_cover_url = aweme_data_dict.get("video_dynamicCover")
+                cover_url = aweme_data_dict.get("video_cover")
                 if animated_cover_url != None:
                     await self.initiate_download(
                         _("å°é¢"), animated_cover_url, base_path, cover_name, ".webp"
                     )
                 elif cover_url != None:
                     logger.warning(_("{0} è¯¥ä½œå“æ²¡æœ‰åŠ¨æ€å°é¢").format(aweme_id))
                     await self.initiate_download(
@@ -233,58 +240,27 @@
                     + "_desc"
                 )
                 desc_content = aweme_data_dict.get("desc")
                 await self.initiate_static_download(
                     _("æ–‡æ¡ˆ"), desc_content, base_path, desc_name, ".txt"
                 )
 
-            # å¤„ç†ä¸åŒç±»å‹çš„ä½œå“ä¸‹è½½ä»»åŠ¡
-            if aweme_type in [0, 55, 61, 109]:
-                video_name = (
-                    format_file_name(
-                        kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
-                    )
-                    + "_video"
-                )
-
-                video_url = aweme_data_dict.get("video_play_addr")
-                if video_url != None:
-                    await self.initiate_download(
-                        _("è§†é¢‘"), video_url, base_path, video_name, ".mp4"
-                    )
-                else:
-                    logger.warning(
-                        _("{0} è¯¥ä½œå“æ²¡æœ‰è§†é¢‘é“¾æ¥ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id)
-                    )
-
-            elif aweme_type in [68]:
-                for i, image_url in enumerate(aweme_data_dict.get("images", None)):
-                    image_name = f"{format_file_name(kwargs.get('naming'), aweme_data_dict)}_image_{i + 1}"
-                    if image_url != None:
-                        await self.initiate_download(
-                            _("å›¾é›†"), image_url, base_path, image_name, ".jpg"
-                        )
-                    else:
-                        logger.warning(
-                            _("{0} è¯¥å›¾é›†æ²¡æœ‰å›¾ç‰‡é“¾æ¥ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id)
-                        )
-
         # ä¿å­˜æœ€åä¸€ä¸ªaweme_id
-        await self.save_last_aweme_id(sec_user_id, aweme_id)
+        await self.save_last_aweme_id(secUid, aweme_id)
 
     async def create_stream_tasks(
         self, kwargs: dict, webcast_datas: Union[list, dict], user_path: Any
     ) -> None:
         """
         åˆ›å»ºè§†é¢‘æµä¸‹è½½ä»»åŠ¡
 
         Args:
             kwargs (dict): å‘½ä»¤è¡Œå‚æ•°
             aweme_datas (list, dict): ä½œå“æ•°æ®åˆ—è¡¨æˆ–å­—å…¸
-            user_path (Any): ç”¨æˆ·ç›®å½•è·¯å¾„
+            user_path (str): ç”¨æˆ·ç›®å½•è·¯å¾„
         """
 
         if (
             not kwargs
             or not webcast_datas
             or not isinstance(webcast_datas, (list, dict))
             or not user_path
@@ -304,16 +280,14 @@
         self, kwargs: dict, webcast_data_dict: dict, user_path: Any
     ) -> None:
         """
         å¤„ç†è§†é¢‘æµä¸‹è½½ä»»åŠ¡
 
         Args:
             kwargs (dict): å‘½ä»¤è¡Œå‚æ•°
-            aweme_data_dict (dict): ç›´æ’­æ•°æ®å­—å…¸
-            user_path (Any): ç”¨æˆ·ç›®å½•è·¯å¾„
         """
         custom_fields = {
             "create": timestamp_2_str(timestamp=get_timestamp(unit="sec")),
             "nickname": webcast_data_dict.get("nickname", ""),
             "aweme_id": webcast_data_dict.get("room_id", ""),
             "desc": webcast_data_dict.get("live_title", ""),
             "uid": webcast_data_dict.get("user_id", ""),
@@ -324,13 +298,13 @@
             / format_file_name(
                 kwargs.get("naming", "{create}_{desc}"), custom_fields=custom_fields
             )
             if kwargs.get("folderize")
             else user_path
         )
 
-        webcast_name = f"{format_file_name(kwargs.get('naming'), custom_fields=custom_fields)}_live"
-        webcast_url = webcast_data_dict.get("m3u8_pull_url").get("FULL_HD1")
+        webcast_name = f"{format_file_name(kwargs.get('naming', '{create}_{desc}'), custom_fields=custom_fields)}_live"
+        webcast_url = webcast_data_dict.get("m3u8_pull_url", None).get("FULL_HD1")
 
         await self.initiate_m3u8_download(
             _("ç›´æ’­"), webcast_url, base_path, webcast_name, ".mp4"
         )
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/filter.py` & `f2-0.0.1.5/f2/apps/douyin/filter.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+# path: f2/apps/douyin/filter.py
+
 from f2.utils.json_filter import JSONModel
 from f2.utils.utils import _get_first_item_from_list, timestamp_2_str, replaceT
 
 # Filter
 
 
 class UserProfileFilter(JSONModel):
@@ -70,14 +72,18 @@
         return self._get_attr_value("$.user.mplatform_followers_count")
 
     @property
     def nickname(self):
         return replaceT(self._get_attr_value("$.user.nickname"))
 
     @property
+    def nickname_raw(self):
+        return self._get_attr_value("$.user.nickname")
+
+    @property
     def room_id(self):
         return self._get_attr_value("$.user.room_id")
 
     @property
     def school_name(self):
         return self._get_attr_value("$.user.school_name")
 
@@ -90,14 +96,18 @@
         return self._get_attr_value("$.user.short_id")
 
     @property
     def signature(self):
         return replaceT(self._get_attr_value("$.user.signature"))
 
     @property
+    def signature_raw(self):
+        return self._get_attr_value("$.user.signature")
+
+    @property
     def total_favorited(self):
         return self._get_attr_value("$.user.total_favorited")
 
     @property
     def uid(self):
         return self._get_attr_value("$.user.uid")
 
@@ -105,14 +115,17 @@
     def unique_id(self):
         return self._get_attr_value("$.user.unique_id")
 
     @property
     def user_age(self):
         return self._get_attr_value("$.user.user_age")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
 
@@ -137,69 +150,81 @@
     def aweme_type(self):
         return self._get_list_attr_value("$.aweme_list[*].aweme_type")
 
     @property
     def create_time(self):
         create_times = self._get_list_attr_value("$.aweme_list[*].create_time")
         return (
-            [timestamp_2_str(ct) for ct in create_times]
+            [timestamp_2_str(str(ct)) for ct in create_times]
             if isinstance(create_times, list)
-            else timestamp_2_str(create_times)
+            else timestamp_2_str(str(create_times))
         )
 
     @property
     def desc(self):
         return replaceT(self._get_list_attr_value("$.aweme_list[*].desc"))
 
     @property
+    def desc_raw(self):
+        return self._get_list_attr_value("$.aweme_list[*].desc")
+
+    @property
     def uid(self):
         return self._get_list_attr_value("$.aweme_list[*].author.uid")
 
     @property
     def sec_user_id(self):
         return self._get_list_attr_value("$.aweme_list[*].author.sec_uid")
 
     @property
     def nickname(self):
         return replaceT(self._get_list_attr_value("$.aweme_list[*].author.nickname"))
 
     @property
+    def nickname_raw(self):
+        return self._get_list_attr_value("$.aweme_list[*].author.nickname")
+
+    @property
     def author_avatar_thumb(self):
         return self._get_list_attr_value(
             "$.aweme_list[*].author.avatar_thumb.url_list[0]"
         )
 
     @property
     def images(self):
         images_list = self._get_list_attr_value("$.aweme_list[*].images")
 
         return [
-            [
-                img["url_list"][0]
-                for img in images
-                if isinstance(img, dict) and "url_list" in img and img["url_list"]
-            ]
-            if images
-            else None
+            (
+                [
+                    img["url_list"][0]
+                    for img in images
+                    if isinstance(img, dict) and "url_list" in img and img["url_list"]
+                ]
+                if images
+                else None
+            )
             for images in images_list
         ]
 
     @property
     def animated_cover(self):
         # ä¸´æ—¶åŠæ³•
         # https://github.com/h2non/jsonpath-ng/issues/82
 
         # è·å–æ‰€æœ‰è§†é¢‘
         videos = self._get_list_attr_value("$.aweme_list[*].video")
 
         # é€ä¸ªè§†é¢‘åˆ¤æ–­æ˜¯å¦å­˜åœ¨animated_cover
         animated_covers = [
-            video.get("animated_cover", {}).get("url_list", [None])[0]
-            if video.get("animated_cover")
-            else None
+            (
+                video.get("animated_cover", {}).get("url_list", [None])[0]
+                if video.get("animated_cover")
+                else None
+            )
             for video in videos
         ]
 
         return animated_covers
 
     @property
     def cover(self):
@@ -212,19 +237,23 @@
         return self._get_list_attr_value("$.aweme_list[*].video.play_addr.url_list[0]")
 
     @property
     def video_bit_rate(self):
         bit_rate_data = self._get_list_attr_value("$.aweme_list[*].video.bit_rate")
 
         return [
-            [aweme["bit_rate"]]
-            if isinstance(aweme, dict)
-            else [aweme[0]["bit_rate"]]
-            if len(aweme) == 1
-            else [item["bit_rate"] for item in aweme]
+            (
+                [aweme["bit_rate"]]
+                if isinstance(aweme, dict)
+                else (
+                    [aweme[0]["bit_rate"]]
+                    if len(aweme) == 1
+                    else [item["bit_rate"] for item in aweme]
+                )
+            )
             for aweme in bit_rate_data
         ]
 
     @property
     def video_duration(self):
         return self._get_list_attr_value("$.aweme_list[*].video.duration")
 
@@ -252,14 +281,18 @@
         return self._get_list_attr_value("$.aweme_list[*].music.status")
 
     @property
     def music_title(self):
         return replaceT(self._get_list_attr_value("$.aweme_list[*].music.title"))
 
     @property
+    def music_title_raw(self):
+        return self._get_list_attr_value("$.aweme_list[*].music.title")
+
+    @property
     def music_play_url(self):
         url_list = self._get_list_attr_value("$.aweme_list[*].music.play_url.url_list")
         return _get_first_item_from_list(url_list)
 
     @property
     def has_more(self) -> bool:
         return bool(self._get_attr_value("$.has_more"))
@@ -268,14 +301,17 @@
     def max_cursor(self):
         return self._get_attr_value("$.max_cursor")
 
     @property
     def min_cursor(self):
         return self._get_attr_value("$.min_cursor")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
 
@@ -309,123 +345,715 @@
                 attr_values = getattr(self, key)
                 index = aweme_entries.index(entry)
                 d[key] = attr_values[index] if index < len(attr_values) else None
             list_dicts.append(d)
         return list_dicts
 
 
-class UserCollectFilter(UserPostFilter):
+class UserCollectionFilter(UserPostFilter):
     def __init__(self, data):
         super().__init__(data)
 
     @property
     def max_cursor(self):
         return self._get_attr_value("$.cursor")
 
 
+class UserCollectsFilter(JSONModel):
+
+    @property
+    def max_cursor(self):
+        return self._get_attr_value("$.cursor")
+
+    @property
+    def status_code(self):
+        return self._get_attr_value("$.status_code")
+
+    @property
+    def total_number(self):
+        return self._get_attr_value("$.total_number")
+
+    @property
+    def has_more(self):
+        return bool(self._get_attr_value("$.has_more"))
+
+    @property
+    def app_id(self):
+        return self._get_list_attr_value("$.collects_list[*].app_id")
+
+    @property
+    def collects_cover(self):
+        return self._get_list_attr_value(
+            "$.collects_list[*].collects_cover.url_list[0]"
+        )
+
+    @property
+    def collects_id(self):
+        return self._get_list_attr_value("$.collects_list[*].collects_id")
+
+    @property
+    def collects_name(self):
+        return replaceT(self._get_list_attr_value("$.collects_list[*].collects_name"))
+
+    @property
+    def collects_name_raw(self):
+        return self._get_list_attr_value("$.collects_list[*].collects_name")
+
+    @property
+    def create_time(self):
+        create_times = self._get_list_attr_value("$.collects_list[*].create_time")
+        return (
+            [timestamp_2_str(str(ct)) for ct in create_times]
+            if isinstance(create_times, list)
+            else timestamp_2_str(str(create_times))
+        )
+
+    @property
+    def follow_status(self):
+        return self._get_list_attr_value("$.collects_list[*].follow_status")
+
+    @property
+    def followed_count(self):
+        return self._get_list_attr_value("$.collects_list[*].followed_count")
+
+    @property
+    def is_normal_status(self):
+        return self._get_list_attr_value("$.collects_list[*].is_normal_status")
+
+    @property
+    def item_type(self):
+        return self._get_list_attr_value("$.collects_list[*].item_type")
+
+    @property
+    def last_collect_time(self):
+        create_times = self._get_list_attr_value("$.collects_list[*].last_collect_time")
+        return (
+            [timestamp_2_str(str(ct)) for ct in create_times]
+            if isinstance(create_times, list)
+            else timestamp_2_str(str(create_times))
+        )
+
+    @property
+    def play_count(self):
+        return self._get_list_attr_value("$.collects_list[*].play_count")
+
+    @property
+    def states(self):
+        return self._get_list_attr_value("$.collects_list[*].states")
+
+    @property
+    def status(self):
+        return self._get_list_attr_value("$.collects_list[*].status")
+
+    @property
+    def system_type(self):
+        return self._get_list_attr_value("$.collects_list[*].system_type")
+
+    @property
+    def total_number(self):
+        return self._get_list_attr_value("$.collects_list[*].total_number")
+
+    @property
+    def user_id(self):
+        return self._get_list_attr_value("$.collects_list[*].user_id")
+
+    # user_info
+    @property
+    def nickname(self):
+        return replaceT(
+            self._get_list_attr_value("$.collects_list[*].user_info.nickname")
+        )
+
+    @property
+    def nickname_raw(self):
+        return self._get_list_attr_value("$.collects_list[*].user_info.nickname")
+
+    @property
+    def uid(self):
+        return self._get_list_attr_value("$.collects_list[*].user_info.uid")
+
+    def _to_raw(self) -> dict:
+        return self._data
+
+    def _to_dict(self) -> dict:
+        return {
+            prop_name: getattr(self, prop_name)
+            for prop_name in dir(self)
+            if not prop_name.startswith("__") and not prop_name.startswith("_")
+        }
+
+
+class UserMusicCollectionFilter(JSONModel):
+
+    @property
+    def max_cursor(self):
+        return self._get_attr_value("$.cursor")
+
+    @property
+    def has_more(self):
+        return self._get_attr_value("$.has_more")
+
+    @property
+    def status_code(self):
+        return self._get_attr_value("$.status_code")
+
+    @property
+    def msg(self):
+        return self._get_attr_value("$.msg")
+
+    @property
+    def album(self):
+        return self._get_list_attr_value("$.mc_list[*].album")
+
+    @property
+    def audition_duration(self):
+        return self._get_list_attr_value("$.mc_list[*].audition_duration")
+
+    @property
+    def duration(self):
+        return self._get_list_attr_value("$.mc_list[*].duration")
+
+    @property
+    def author(self):
+        return replaceT(self._get_list_attr_value("$.mc_list[*].author"))
+
+    @property
+    def author_raw(self):
+        return self._get_list_attr_value("$.mc_list[*].author")
+
+    @property
+    def collect_status(self):
+        return self._get_list_attr_value("$.mc_list[*].collect_stat")
+
+    @property
+    def music_status(self):
+        return self._get_list_attr_value("$.mc_list[*].music_status")
+
+    @property
+    def cover_hd(self):
+        return self._get_list_attr_value("$.mc_list[*].cover_hd.url_list[0]")
+
+    @property
+    def music_id(self):
+        return self._get_list_attr_value("$.mc_list[*].id")
+
+    @property
+    def mid(self):
+        return self._get_list_attr_value("$.mc_list[*].mid")
+
+    @property
+    def is_commerce_music(self):
+        return self._get_list_attr_value("$.mc_list[*].is_commerce_music")
+
+    @property
+    def is_original(self):
+        return self._get_list_attr_value("$.mc_list[*].is_original")
+
+    @property
+    def is_original_sound(self):
+        return self._get_list_attr_value("$.mc_list[*].is_original_sound")
+
+    @property
+    def lyric_type(self):
+        return self._get_list_attr_value("$.mc_list[*].lyric_type")
+
+    @property
+    def lyric_url(self):
+        # ä¸æ˜¯æ¯ä¸ªä½œå“éƒ½æœ‰ lyric_urlï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸º None
+        lyric_urls = []
+        for item in self._data.get("mc_list"):
+            lyric_urls.append(item.get("lyric_url", None))
+
+        return lyric_urls
+
+    @property
+    def play_url(self):
+        return self._get_list_attr_value("$.mc_list[*].play_url.url_list[0]")
+
+    @property
+    def title(self):
+        return replaceT(self._get_list_attr_value("$.mc_list[*].title"))
+
+    @property
+    def title_raw(self):
+        return self._get_list_attr_value("$.mc_list[*].title")
+
+    @property
+    def strong_beat_url(self):
+        return self._get_list_attr_value("$.mc_list[*].strong_beat_url.url_list[0]")
+
+    @property
+    def owner_nickname(self):
+        return replaceT(self._get_list_attr_value("$.mc_list[*].owner_nickname"))
+
+    @property
+    def owner_nickname_raw(self):
+        return self._get_list_attr_value("$.mc_list[*].owner_nickname")
+
+    @property
+    def owner_id(self):
+        return self._get_list_attr_value("$.mc_list[*].owner_id")
+
+    @property
+    def sec_uid(self):
+        return self._get_list_attr_value("$.mc_list[*].sec_uid")
+
+    def _to_raw(self) -> dict:
+        return self._data
+
+    def _to_dict(self) -> dict:
+        return {
+            prop_name: getattr(self, prop_name)
+            for prop_name in dir(self)
+            if not prop_name.startswith("__") and not prop_name.startswith("_")
+        }
+
+    def _to_list(self):
+        exclude_list = ["has_more", "max_cursor", "status_code", "msg"]
+
+        keys = [
+            prop_name
+            for prop_name in dir(self)
+            if not prop_name.startswith("__")
+            and not prop_name.startswith("_")
+            and prop_name not in exclude_list
+        ]
+
+        aweme_entries = self._get_attr_value("$.mc_list") or []
+
+        list_dicts = []
+        for entry in aweme_entries:
+            d = {
+                "has_more": self.has_more,
+                "max_cursor": self.max_cursor,
+                "status_code": self.status_code,
+                "msg": self.msg,
+            }
+            for key in keys:
+                attr_values = getattr(self, key)
+                index = aweme_entries.index(entry)
+                d[key] = attr_values[index] if index < len(attr_values) else None
+            list_dicts.append(d)
+        return list_dicts
+
+
 class UserMixFilter(UserPostFilter):
     def __init__(self, data):
         super().__init__(data)
 
     @property
     def max_cursor(self):
         return self._get_attr_value("$.cursor")
 
 
 class UserLikeFilter(UserPostFilter):
     def __init__(self, data):
         super().__init__(data)
 
 
-class PostDetailFilter(JSONModel):
-    # api_status_code = property(lambda self: self._get_attr_value("$.status_code"))
-    # # author
-    # nickname = property(lambda self: replaceT(self._get_attr_value("$.aweme_detail.author.nickname")))
-    # sec_user_id = property(lambda self: self._get_attr_value("$.aweme_detail.author.sec_uid"))
-    # short_id = property(lambda self: self._get_attr_value("$.aweme_detail.author.short_id"))
-    # uid = property(lambda self: self._get_attr_value("$.aweme_detail.author.uid"))
-    # unique_id = property(lambda self: self._get_attr_value("$.aweme_detail.author.unique_id"))
-
-    # can_comment = property(lambda self: self._get_attr_value("$.aweme_detail.aweme_control.can_comment"))
-    # can_forward = property(lambda self: self._get_attr_value("$.aweme_detail.aweme_control.can_forward"))
-    # can_share = property(lambda self: self._get_attr_value("$.aweme_detail.aweme_control.can_share"))
-    # can_show_comment = property(lambda self: self._get_attr_value("$.aweme_detail.aweme_control.can_show_comment"))
-    # aweme_type = property(lambda self: self._get_attr_value("$.aweme_detail.aweme_control.aweme_type"))
-    # aweme_id = property(lambda self: self._get_attr_value("$.aweme_detail.aweme_id"))
-    # comment_gid = property(lambda self: self._get_attr_value("$.aweme_detail.comment_gid"))
-    # create_time = property(lambda self: timestamp_2_str(self._get_attr_value("$.aweme_detail.create_time")))
-    # desc = property(lambda self: replaceT(self._get_attr_value("$.aweme_detail.desc")))
-    # duration = property(lambda self: self._get_attr_value("$.aweme_detail.duration"))
-    # is_ads = property(lambda self: self._get_attr_value("$.aweme_detail.is_ads"))
-    # is_story = property(lambda self: self._get_attr_value("$.aweme_detail.is_story"))
-    # is_top = property(lambda self: self._get_attr_value("$.aweme_detail.is_top"))
-    # video_bit_rate = property(lambda self: [
-    #     [aweme['bit_rate']] if isinstance(aweme, dict)
-    #     else [aweme[0]['bit_rate']] if len(aweme) == 1
-    #     else [item['bit_rate'] for item in aweme]
-    #     for aweme in self._get_list_attr_value("$.aweme_detail.video.bit_rate")
-    # ])
-    # video_play_addr = property(lambda self: self._get_attr_value("$.aweme_detail.video.play_addr.url_list[0]"))
-    # images = property(lambda self: [
-    #     [img['url_list'][0] for img in images if isinstance(img, dict) and 'url_list' in img and img['url_list']]
-    #     if images else None
-    #     for images in self._get_list_attr_value("$.aweme_detail.images")
-    # ])
-
-    # # aweme status
-    # is_delete = property(lambda self: self._get_attr_value("$.aweme_detail.status.is_delete"))
-    # is_prohibited = property(lambda self: self._get_attr_value("$.aweme_detail.status.is_prohibited"))
-
-    # is_long_video = property(lambda self: self._get_attr_value("$.aweme_detail.long_video"))
-    # media_type = property(lambda self: self._get_attr_value("$.aweme_detail.media_type"))
-    # # mix
-    # mix_desc = property(lambda self: replaceT(self._get_attr_value("$.aweme_detail.mix_info.mix_desc")))
-    # mix_create_time = property(lambda self: timestamp_2_str(self._get_attr_value("$.aweme_detail.mix_info.mix_create_time")))
-    # mix_id = property(lambda self: self._get_attr_value("$.aweme_detail.mix_info.mix_id"))
-    # mix_name = property(lambda self: self._get_attr_value("$.aweme_detail.mix_info.mix_name"))
-    # mix_pic_type = property(lambda self: self._get_attr_value("$.aweme_detail.mix_info.mix_pic_type"))
-    # mix_type = property(lambda self: self._get_attr_value("$.aweme_detail.mix_info.mix_type"))
-    # mix_share_url = property(lambda self: self._get_attr_value("$.aweme_detail.mix_info.mix_share_url"))
-    # mix_update_time = property(lambda self: timestamp_2_str(self._get_attr_value("$.aweme_detail.mix_info.mix_update_time")))
-    # # music
-    # is_commerce_music = property(lambda self: self._get_attr_value("$.aweme_detail.music.is_commerce_music"))
-    # is_original = property(lambda self: self._get_attr_value("$.aweme_detail.music.is_original"))
-    # is_original_sound = property(lambda self: self._get_attr_value("$.aweme_detail.music.is_original_sound"))
-    # is_pgc = property(lambda self: self._get_attr_value("$.aweme_detail.music.is_pgc"))
-    # music_author = property(lambda self: replaceT(self._get_attr_value("$.aweme_detail.music.author")))
-    # music_author_deleted = property(lambda self: self._get_attr_value("$.aweme_detail.music.author_deleted"))
-    # music_duration = property(lambda self: self._get_attr_value("$.aweme_detail.music.duration"))
-    # music_id = property(lambda self: self._get_attr_value("$.aweme_detail.music.id"))
-    # music_id_str = property(lambda self: self._get_attr_value("$.aweme_detail.music.id_str"))
-    # music_mid = property(lambda self: self._get_attr_value("$.aweme_detail.music.mid"))
-    # pgc_author = property(lambda self: replaceT(self._get_attr_value("$.aweme_detail.music.matched_pgc_sound.pgc_author")))
-    # pgc_author_title = property(lambda self: replaceT(self._get_attr_value("$.aweme_detail.music.matched_pgc_sound.pgc_author_title")))
-    # pgc_music_type = property(lambda self: self._get_attr_value("$.aweme_detail.music.matched_pgc_sound.pgc_music_type"))
-    # music_status = property(lambda self: self._get_attr_value("$.aweme_detail.music.status"))
-    # music_owner_handle = property(lambda self: replaceT(self._get_attr_value("$.aweme_detail.music.owner_handle")))
-    # music_owner_id = property(lambda self: self._get_attr_value("$.aweme_detail.music.owner_id"))
-    # music_owner_nickname = property(lambda self: replaceT(self._get_attr_value("$.aweme_detail.music.owner_nickname")))
-    # music_play_url = property(lambda self: self._get_attr_value("$.aweme_detail.music.play_url.url_list[0]"))
-
-    # # position
-    # position = property(lambda self: self._get_attr_value("$.aweme_detail.position"))
-    # # region = property(lambda self: self._get_attr_value("$.aweme_detail.region"))
-
-    # # seo_ocr_content
-    # seo_ocr_content = property(lambda self: self._get_attr_value("$.aweme_detail.seo_info.seo_ocr_content"))
-
-    # admire_count = property(lambda self: self._get_attr_value("$.aweme_detail.statistics.admire_count"))
-    # collect_count = property(lambda self: self._get_attr_value("$.aweme_detail.statistics.collect_count"))
-    # comment_count = property(lambda self: self._get_attr_value("$.aweme_detail.statistics.comment_count"))
-    # digg_count = property(lambda self: self._get_attr_value("$.aweme_detail.statistics.digg_count"))
-    # # play_count = property(lambda self: self._get_attr_value("$.aweme_detail.statistics.play_count"))
-    # share_count = property(lambda self: self._get_attr_value("$.aweme_detail.statistics.share_count"))
+class UserFollowingFilter(JSONModel):
+
+    @property
+    def status_code(self):  # 1 æ­£å¸¸ï¼Œ2096 ç”¨æˆ·éšç§è®¾ç½®ä¸å…è®¸æŸ¥çœ‹
+        return self._get_attr_value("$.status_code")
+
+    @property
+    def status_msg(self):
+        return self._get_attr_value("$.status_msg")
+
+    @property
+    def has_more(self):
+        return self._get_attr_value("$.has_more")
+
+    @property
+    def total(self):
+        return self._get_attr_value("$.total")
+
+    @property
+    def mix_count(self):
+        return self._get_attr_value("$.mix_count")
+
+    @property
+    def offset(self):
+        return self._get_attr_value("$.offset")
+
+    @property
+    def myself_user_id(self):
+        return self._get_attr_value("$.myself_user_id")
+
+    @property
+    def max_time(self):
+        return self._get_attr_value("$.max_time")
+
+    @property
+    def min_time(self):
+        return self._get_attr_value("$.min_time")
+
+    # following_list
+    @property
+    def avatar_larger(self):
+        return self._get_list_attr_value("$.followings[*].avatar_larger.url_list[0]")
+
+    @property
+    def can_comment(self):
+        return self._get_list_attr_value("$.followings[*].aweme_control.can_comment")
+
+    @property
+    def can_forward(self):
+        return self._get_list_attr_value("$.followings[*].aweme_control.can_forward")
+
+    @property
+    def can_share(self):
+        return self._get_list_attr_value("$.followings[*].aweme_control.can_share")
+
+    @property
+    def can_show_comment(self):
+        return self._get_list_attr_value(
+            "$.followings[*].aweme_control.can_show_comment"
+        )
+
+    @property
+    def aweme_count(self):
+        return self._get_list_attr_value("$.followings[*].aweme_count")
+
+    @property
+    def back_cover(self):
+        return self._get_list_attr_value("$.followings[*].cover_url[0].url_list[0]")
+
+    @property
+    def register_time(self):
+        return self._get_list_attr_value("$.followings[*].create_time")
+
+    @property
+    def secondary_priority(self):
+        # secondary_priority 6 ä»£è¡¨æœªçœ‹è¿‡çš„ä½œå“æ•°é‡ 1 ä»£è¡¨æ­£åœ¨ç›´æ’­ 7 ä»£è¡¨ç®€ä»‹å†…å®¹
+        return self._get_list_attr_value(
+            "$.followings[*].following_list_secondary_information_struct.secondary_information_priority"
+        )
+
+    @property
+    def secondary_text(self):
+        return replaceT(
+            self._get_list_attr_value(
+                "$.followings[*].following_list_secondary_information_struct.secondary_information_text"
+            )
+        )
+
+    @property
+    def secondary_text_raw(self):
+        return self._get_list_attr_value(
+            "$.followings[*].following_list_secondary_information_struct.secondary_information_text"
+        )
+
+    @property
+    def is_block(self):
+        return self._get_list_attr_value("$.followings[*].is_block")
+
+    @property
+    def is_blocked(self):
+        return self._get_list_attr_value("$.followings[*].is_blocked")
+
+    @property
+    def is_gov_media_vip(self):
+        return self._get_list_attr_value("$.followings[*].is_gov_media_vip")
 
-    # hashtag_ids = property(lambda self: self._get_list_attr_value("$.aweme_detail.text_extra[*].hashtag_id"))
-    # hashtag_names = property(lambda self: self._get_list_attr_value("$.aweme_detail.text_extra[*].hashtag_name"))
+    @property
+    def is_mix_user(self):
+        return self._get_list_attr_value("$.followings[*].is_mix_user")
+
+    @property
+    def is_phone_binded(self):
+        return self._get_list_attr_value("$.followings[*].is_phone_binded")
+
+    @property
+    def is_star(self):
+        return self._get_list_attr_value("$.followings[*].is_star")
+
+    @property
+    def is_top(self):
+        # è¶…ç²‰?
+        return self._get_list_attr_value("$.followings[*].is_top")
+
+    @property
+    def is_verified(self):
+        # å®å?
+        return self._get_list_attr_value("$.followings[*].is_verified")
+
+    @property
+    def language(self):
+        return self._get_list_attr_value("$.followings[*].language")
+
+    @property
+    def nickname(self):
+        return replaceT(self._get_list_attr_value("$.followings[*].nickname"))
+
+    @property
+    def nickname_raw(self):
+        return self._get_list_attr_value("$.followings[*].nickname")
+
+    @property
+    def relation_label(self):
+        return self._get_list_attr_value("$.followings[*].relation_label")
+
+    @property
+    def room_id(self):
+        return self._get_list_attr_value("$.followings[*].room_id")
+
+    @property
+    def sec_uid(self):
+        return self._get_list_attr_value("$.followings[*].sec_uid")
+
+    @property
+    def secret(self):
+        # ç§å¯†?
+        return self._get_list_attr_value("$.followings[*].secret")
+
+    @property
+    def short_id(self):
+        return self._get_list_attr_value("$.followings[*].short_id")
+
+    @property
+    def signature(self):
+        return replaceT(self._get_list_attr_value("$.followings[*].signature"))
+
+    @property
+    def signature_raw(self):
+        return self._get_list_attr_value("$.followings[*].signature")
+
+    @property
+    def uid(self):
+        return self._get_list_attr_value("$.followings[*].uid")
+
+    @property
+    def unique_id(self):
+        return self._get_list_attr_value("$.followings[*].unique_id")
+
+    def _to_raw(self) -> dict:
+        return self._data
+
+    def _to_dict(self) -> dict:
+        return {
+            prop_name: getattr(self, prop_name)
+            for prop_name in dir(self)
+            if not prop_name.startswith("__") and not prop_name.startswith("_")
+        }
+
+    def _to_list(self):
+        exclude_list = [
+            "status_code",
+            "status_msg",
+            "has_more",
+            "total",
+            "mix_count",
+            "offset",
+            "myself_user_id",
+            "max_time",
+            "min_time",
+        ]
+
+        keys = [
+            prop_name
+            for prop_name in dir(self)
+            if not prop_name.startswith("__")
+            and not prop_name.startswith("_")
+            and prop_name not in exclude_list
+        ]
+
+        following_entries = self._get_attr_value("$.followings") or []
+
+        list_dicts = []
+        for entry in following_entries:
+            d = {
+                "has_more": self.has_more,
+                "total": self.total,
+                "mix_count": self.mix_count,
+                "offset": self.offset,
+                "myself_user_id": self.myself_user_id,
+                "max_time": self.max_time,
+                "min_time": self.min_time,
+            }
+            for key in keys:
+                attr_values = getattr(self, key)
+                index = following_entries.index(entry)
+                d[key] = attr_values[index] if index < len(attr_values) else None
+            list_dicts.append(d)
+        return list_dicts
+
+
+class UserFollowerFilter(UserFollowingFilter):
+    def __init__(self, data):
+        super().__init__(data)
+
+    @property
+    def total(self):
+        return self._get_attr_value("$.total")
+
+    # followers
+    @property
+    def avatar_larger(self):
+        return self._get_list_attr_value("$.followers[*].avatar_larger.url_list[0]")
+
+    @property
+    def can_comment(self):
+        return self._get_list_attr_value("$.followers[*].aweme_control.can_comment")
+
+    @property
+    def can_forward(self):
+        return self._get_list_attr_value("$.followers[*].aweme_control.can_forward")
+
+    @property
+    def can_share(self):
+        return self._get_list_attr_value(
+            "$.followersfollowers[*].aweme_control.can_share"
+        )
+
+    @property
+    def can_show_comment(self):
+        return self._get_list_attr_value(
+            "$.followers[*].aweme_control.can_show_comment"
+        )
+
+    @property
+    def aweme_count(self):
+        return self._get_list_attr_value("$.followers[*].aweme_count")
+
+    @property
+    def back_cover(self):
+        return self._get_list_attr_value("$.followers[*].cover_url[0].url_list[0]")
+
+    @property
+    def register_time(self):
+        return self._get_list_attr_value("$.followers[*].create_time")
+
+    @property
+    def is_block(self):
+        return self._get_list_attr_value("$.followers[*].is_block")
+
+    @property
+    def is_blocked(self):
+        return self._get_list_attr_value("$.followers[*].is_blocked")
+
+    @property
+    def is_gov_media_vip(self):
+        return self._get_list_attr_value("$.followers[*].is_gov_media_vip")
+
+    @property
+    def is_mix_user(self):
+        return self._get_list_attr_value("$.followers[*].is_mix_user")
+
+    @property
+    def is_phone_binded(self):
+        return self._get_list_attr_value("$.followers[*].is_phone_binded")
+
+    @property
+    def is_star(self):
+        return self._get_list_attr_value("$.followers[*].is_star")
+
+    @property
+    def is_top(self):
+        # è¶…ç²‰?
+        return self._get_list_attr_value("$.followers[*].is_top")
+
+    @property
+    def is_verified(self):
+        # å®å?
+        return self._get_list_attr_value("$.followers[*].is_verified")
+
+    @property
+    def language(self):
+        return self._get_list_attr_value("$.followers[*].language")
+
+    @property
+    def nickname(self):
+        return replaceT(self._get_list_attr_value("$.followers[*].nickname"))
+
+    @property
+    def nickname_raw(self):
+        return self._get_list_attr_value("$.followers[*].nickname")
+
+    @property
+    def relation_label(self):
+        return self._get_list_attr_value("$.followers[*].relation_label")
+
+    @property
+    def room_id(self):
+        return self._get_list_attr_value("$.followers[*].room_id")
+
+    @property
+    def sec_uid(self):
+        return self._get_list_attr_value("$.followers[*].sec_uid")
+
+    @property
+    def secret(self):
+        # ç§å¯†?
+        return self._get_list_attr_value("$.followers[*].secret")
+
+    @property
+    def short_id(self):
+        return self._get_list_attr_value("$.followers[*].short_id")
+
+    @property
+    def signature(self):
+        return replaceT(self._get_list_attr_value("$.followers[*].signature"))
+
+    @property
+    def signature_raw(self):
+        return self._get_list_attr_value("$.followers[*].signature")
+
+    @property
+    def uid(self):
+        return self._get_list_attr_value("$.followers[*].uid")
+
+    @property
+    def unique_id(self):
+        return self._get_list_attr_value("$.followers[*].unique_id")
+
+    def _to_list(self):
+        exclude_list = [
+            "status_code",
+            "status_msg",
+            "has_more",
+            "total",
+            "mix_count",
+            "offset",
+            "myself_user_id",
+            "max_time",
+            "min_time",
+        ]
+
+        keys = [
+            prop_name
+            for prop_name in dir(self)
+            if not prop_name.startswith("__")
+            and not prop_name.startswith("_")
+            and prop_name not in exclude_list
+        ]
+
+        following_entries = self._get_attr_value("$.followers") or []
+
+        list_dicts = []
+        for entry in following_entries:
+            d = {
+                "has_more": self.has_more,
+                "total": self.total,
+                "mix_count": self.mix_count,
+                "offset": self.offset,
+                "myself_user_id": self.myself_user_id,
+                "max_time": self.max_time,
+                "min_time": self.min_time,
+            }
+            for key in keys:
+                attr_values = getattr(self, key)
+                index = following_entries.index(entry)
+                d[key] = attr_values[index] if index < len(attr_values) else None
+            list_dicts.append(d)
+        return list_dicts
+
+
+class PostDetailFilter(JSONModel):
 
     @property
     def api_status_code(self):
         return self._get_attr_value("$.status_code")
 
     @property
     def aweme_type(self):
@@ -437,14 +1065,18 @@
 
     # author
     @property
     def nickname(self):
         return replaceT(self._get_attr_value("$.aweme_detail.author.nickname"))
 
     @property
+    def nickname_raw(self):
+        return self._get_attr_value("$.aweme_detail.author.nickname")
+
+    @property
     def sec_user_id(self):
         return self._get_attr_value("$.aweme_detail.author.sec_uid")
 
     @property
     def short_id(self):
         return self._get_attr_value("$.aweme_detail.author.short_id")
 
@@ -483,14 +1115,18 @@
         return timestamp_2_str(str(self._get_attr_value("$.aweme_detail.create_time")))
 
     @property
     def desc(self):
         return replaceT(self._get_attr_value("$.aweme_detail.desc"))
 
     @property
+    def desc_raw(self):
+        return self._get_attr_value("$.aweme_detail.desc")
+
+    @property
     def duration(self):
         return self._get_attr_value("$.aweme_detail.duration")
 
     @property
     def is_ads(self):
         return self._get_attr_value("$.aweme_detail.is_ads")
 
@@ -530,14 +1166,18 @@
 
     # mix
     @property
     def mix_desc(self):
         return replaceT(self._get_attr_value("$.aweme_detail.mix_info.mix_desc"))
 
     @property
+    def mix_desc_raw(self):
+        return self._get_attr_value("$.aweme_detail.mix_info.mix_desc")
+
+    @property
     def mix_create_time(self):
         return timestamp_2_str(
             str(self._get_attr_value("$.aweme_detail.mix_info.mix_create_time"))
         )
 
     @property
     def mix_id(self):
@@ -583,14 +1223,18 @@
         return self._get_attr_value("$.aweme_detail.music.is_pgc")
 
     @property
     def music_author(self):
         return replaceT(self._get_attr_value("$.aweme_detail.music.author"))
 
     @property
+    def music_author_raw(self):
+        return self._get_attr_value("$.aweme_detail.music.author")
+
+    @property
     def music_author_deleted(self):
         return self._get_attr_value("$.aweme_detail.music.author_deleted")
 
     @property
     def music_duration(self):
         return self._get_attr_value("$.aweme_detail.music.duration")
 
@@ -605,44 +1249,62 @@
     @property
     def pgc_author(self):
         return replaceT(
             self._get_attr_value("$.aweme_detail.music.matched_pgc_sound.pgc_author")
         )
 
     @property
+    def pgc_author_raw(self):
+        return self._get_attr_value("$.aweme_detail.music.matched_pgc_sound.pgc_author")
+
+    @property
     def pgc_author_title(self):
         return replaceT(
             self._get_attr_value(
                 "$.aweme_detail.music.matched_pgc_sound.pgc_author_title"
             )
         )
 
     @property
+    def pgc_author_title_raw(self):
+        return self._get_attr_value(
+            "$.aweme_detail.music.matched_pgc_sound.pgc_author_title"
+        )
+
+    @property
     def pgc_music_type(self):
         return self._get_attr_value(
             "$.aweme_detail.music.matched_pgc_sound.pgc_music_type"
         )
 
     @property
     def music_status(self):
         return self._get_attr_value("$.aweme_detail.music.status")
 
     @property
     def music_owner_handle(self):
         return replaceT(self._get_attr_value("$.aweme_detail.music.owner_handle"))
 
     @property
+    def music_owner_handle_raw(self):
+        return self._get_attr_value("$.aweme_detail.music.owner_handle")
+
+    @property
     def music_owner_id(self):
         return self._get_attr_value("$.aweme_detail.music.owner_id")
 
     @property
     def music_owner_nickname(self):
         return replaceT(self._get_attr_value("$.aweme_detail.music.owner_nickname"))
 
     @property
+    def music_owner_nickname_raw(self):
+        return self._get_attr_value("$.aweme_detail.music.owner_nickname")
+
+    @property
     def music_play_url(self):
         return self._get_attr_value("$.aweme_detail.music.play_url.url_list[0]")
 
     # position
     @property
     def position(self):
         return self._get_attr_value("$.aweme_detail.position")
@@ -720,67 +1382,45 @@
     @property
     def video_bit_rate(self):
         bit_rate_data = self._get_list_attr_value(
             "$.aweme_detail.video.bit_rate",
         )
 
         return [
-            [aweme["bit_rate"]]
-            if isinstance(aweme, dict)
-            else [aweme[0]["bit_rate"]]
-            if len(aweme) == 1
-            else [item["bit_rate"] for item in aweme]
+            (
+                [aweme["bit_rate"]]
+                if isinstance(aweme, dict)
+                else (
+                    [aweme[0]["bit_rate"]]
+                    if len(aweme) == 1
+                    else [item["bit_rate"] for item in aweme]
+                )
+            )
             for aweme in bit_rate_data
         ]
 
     @property
     def video_play_addr(self):
-        return self._get_attr_value("$.aweme_detail.video.play_addr.url_list[0]")
+        return self._get_attr_value("$.aweme_detail.video.play_addr.url_list")
 
     # images
     @property
     def images(self):
         return self._get_list_attr_value("$.aweme_detail.images[*].url_list[0]")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
 
-    def _to_list(self):
-        # ä¸éœ€è¦çš„å±æ€§åˆ—è¡¨
-        exclude_list = ["has_more", "max_cursor", "min_cursor"]
-        # ç”Ÿæˆå±æ€§åç§°åˆ—è¡¨ï¼Œç„¶åè¿‡æ»¤æ‰ä¸éœ€è¦çš„å±æ€§
-        keys = [
-            prop_name
-            for prop_name in dir(self)
-            if not prop_name.startswith("__")
-            and not prop_name.startswith("_")
-            and prop_name not in exclude_list
-        ]
-
-        aweme_entries = self._get_attr_value("$.aweme_detail") or []
-
-        list_dicts = []
-        # éå†æ¯ä¸ªæ¡ç›®å¹¶åˆ›å»ºä¸€ä¸ªå­—å…¸
-        # (Iterate through each entry and create a dict)
-        for entry in aweme_entries:
-            d = {}
-            for key in keys:
-                attr_values = getattr(self, key)
-                # å½“å‰aweme_entryåœ¨å±æ€§åˆ—è¡¨ä¸­çš„ç´¢å¼•
-                index = aweme_entries.index(entry)
-                # å¦‚æœå±æ€§å€¼çš„é•¿åº¦è¶³å¤Ÿåˆ™èµ‹å€¼ï¼Œå¦åˆ™èµ‹None
-                # (Assign value if the length of the attribute value is sufficient, otherwise assign None)
-                d[key] = attr_values[index] if index < len(attr_values) else None
-            list_dicts.append(d)
-        return list_dicts
-
 
 class UserLiveFilter(JSONModel):
     # live
     @property
     def api_status_code(self):
         return self._get_attr_value("$.status_code")
 
@@ -793,14 +1433,18 @@
         return self._get_attr_value("$.data.data[0].status")
 
     @property
     def live_title(self):
         return replaceT(self._get_attr_value("$.data.data[0].title"))
 
     @property
+    def live_title_raw(self):
+        return self._get_attr_value("$.data.data[0].title")
+
+    @property
     def cover(self):
         return self._get_attr_value("$.data.data[0].cover.url_list[0]")
 
     @property
     def user_count(self):
         return self._get_attr_value("$.data.data[0].stats.user_count_str")
 
@@ -830,14 +1474,18 @@
         return self._get_attr_value("$.data.data[0].owner.sec_uid")
 
     @property
     def nickname(self):
         return replaceT(self._get_attr_value("$.data.data[0].owner.nickname"))
 
     @property
+    def nickname_raw(self):
+        return self._get_attr_value("$.data.data[0].owner.nickname")
+
+    @property
     def avatar_thumb(self):
         return self._get_attr_value("$.data.data[0].owner.avatar_thumb.url_list[0]")
 
     @property
     def follow_status(self):
         return self._get_attr_value("$.data.data[0].owner.follow_info.follow_status")
 
@@ -877,50 +1525,24 @@
     def DiggAuth(self):
         return self._get_attr_value("$.data.data[0].room_auth.Digg")
 
     @property
     def ShareAuth(self):
         return self._get_attr_value("$.data.data[0].room_auth.Share")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
 
-    def _to_list(self):
-        # ä¸éœ€è¦çš„å±æ€§åˆ—è¡¨
-        exclude_list = []
-        # ç”Ÿæˆå±æ€§åç§°åˆ—è¡¨ï¼Œç„¶åè¿‡æ»¤æ‰ä¸éœ€è¦çš„å±æ€§
-        keys = [
-            prop_name
-            for prop_name in dir(self)
-            if not prop_name.startswith("__")
-            and not prop_name.startswith("_")
-            and prop_name not in exclude_list
-        ]
-
-        aweme_entries = self._get_attr_value("$.aweme_list") or []
-
-        list_dicts = []
-        # éå†æ¯ä¸ªæ¡ç›®å¹¶åˆ›å»ºä¸€ä¸ªå­—å…¸
-        # (Iterate through each entry and create a dict)
-        for entry in aweme_entries:
-            d = {}
-            for key in keys:
-                attr_values = getattr(self, key)
-                # å½“å‰aweme_entryåœ¨å±æ€§åˆ—è¡¨ä¸­çš„ç´¢å¼•
-                index = aweme_entries.index(entry)
-                # å¦‚æœå±æ€§å€¼çš„é•¿åº¦è¶³å¤Ÿåˆ™èµ‹å€¼ï¼Œå¦åˆ™èµ‹None
-                # (Assign value if the length of the attribute value is sufficient, otherwise assign None)
-                d[key] = attr_values[index] if index < len(attr_values) else None
-            list_dicts.append(d)
-        return list_dicts
-
 
 class UserLive2Filter(JSONModel):
     # live
     @property
     def api_status_code(self):
         return self._get_attr_value("$.status_code")
 
@@ -937,24 +1559,28 @@
         return self._get_attr_value("$.data.room.status")
 
     @property
     def live_title(self):
         return replaceT(self._get_attr_value("$.data.room.title"))
 
     @property
+    def live_title_raw(self):
+        return self._get_attr_value("$.data.room.title")
+
+    @property
     def user_count(self):
         return self._get_attr_value("$.data.room.user_count")
 
     @property
     def create_time(self):
-        return timestamp_2_str(self._get_attr_value("$.data.room.create_time"))
+        return timestamp_2_str(str(self._get_attr_value("$.data.room.create_time")))
 
     @property
     def finish_time(self):
-        return timestamp_2_str(self._get_attr_value("$.data.room.finish_time"))
+        return timestamp_2_str(str(self._get_attr_value("$.data.room.finish_time")))
 
     @property
     def cover(self):
         return self._get_attr_value("$.data.room.cover.url_list[0]")
 
     @property
     def stream_id(self):
@@ -974,22 +1600,34 @@
 
     # user
     @property
     def nickname(self):
         return replaceT(self._get_attr_value("$.data.room.owner.nickname"))
 
     @property
+    def nickname_raw(self):
+        return self._get_attr_value("$.data.room.owner.nickname")
+
+    @property
     def gender(self):
         return replaceT(self._get_attr_value("$.data.room.owner.gender"))
 
     @property
+    def gender_raw(self):
+        return self._get_attr_value("$.data.room.owner.gender")
+
+    @property
     def signature(self):
         return replaceT(self._get_attr_value("$.data.room.owner.signature"))
 
     @property
+    def signature_raw(self):
+        return self._get_attr_value("$.data.room.owner.signature")
+
+    @property
     def avatar_large(self):
         return self._get_attr_value("$.data.room.owner.avatar_large.url_list[0]")
 
     @property
     def verified(self):
         return self._get_attr_value("$.data.room.owner.verified")
 
@@ -1005,14 +1643,17 @@
     def follower_count(self):
         return self._get_attr_value("$.data.room.owner.follow_info.follower_count")
 
     @property
     def sec_uid(self):
         return self._get_attr_value("$.data.room.owner.sec_uid")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
 
@@ -1070,14 +1711,17 @@
     def error_code(self):
         return self._get_attr_value("$.error_code")
 
     @property
     def message(self):
         return self._get_attr_value("$.message")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
 
@@ -1107,13 +1751,16 @@
     def message(self):
         return self._get_attr_value("$.message")
 
     @property
     def verify_ticket(self):
         return self._get_attr_value("$.verify_ticket")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/handler.py` & `f2-0.0.1.5/f2/apps/tiktok/handler.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,925 +1,695 @@
-# path: f2/apps/douyin/handler.py
+# path: f2/apps/tiktok/handler.py
 
-import asyncio
-from typing import AsyncGenerator, Dict, Any, List
+import sys
+
+from pathlib import Path
+from typing import AsyncGenerator, Union, List, Any
 
-from f2.log.logger import logger
 from f2.i18n.translator import _
+from f2.log.logger import logger
 from f2.utils.mode_handler import mode_handler, mode_function_map
-from f2.utils.utils import split_set_cookie
-from f2.apps.douyin.db import AsyncUserDB, AsyncVideoDB
-from f2.apps.douyin.crawler import DouyinCrawler
-from f2.apps.douyin.dl import DouyinDownloader
-from f2.apps.douyin.model import (
-    UserPost,
+from f2.apps.tiktok.db import AsyncUserDB, AsyncVideoDB
+from f2.apps.tiktok.crawler import TiktokCrawler
+from f2.apps.tiktok.dl import TiktokDownloader
+from f2.apps.tiktok.model import (
     UserProfile,
+    UserPost,
     UserLike,
     UserCollect,
     UserMix,
+    UserPlayList,
     PostDetail,
-    UserLive,
-    UserLive2,
-    LoginGetQr,
-    LoginCheckQr,
 )
-from f2.apps.douyin.filter import (
-    UserPostFilter,
+from f2.apps.tiktok.filter import (
     UserProfileFilter,
-    UserCollectFilter,
-    UserMixFilter,
+    UserPostFilter,
     PostDetailFilter,
-    UserLiveFilter,
-    UserLive2Filter,
-    GetQrcodeFilter,
-    CheckQrcodeFilter,
+    UserMixFilter,
+    UserPlayListFilter,
 )
-from f2.apps.douyin.utils import (
+from f2.apps.tiktok.utils import (
     SecUserIdFetcher,
     AwemeIdFetcher,
-    WebCastIdFetcher,
-    VerifyFpManager,
     create_or_rename_user_folder,
-    show_qrcode,
 )
 from f2.cli.cli_console import RichConsoleManager
+from f2.exceptions.api_exceptions import APIResponseError
 
 rich_console = RichConsoleManager().rich_console
 rich_prompt = RichConsoleManager().rich_prompt
 
 
-class DouyinHandler:
+class TiktokHandler:
 
     # éœ€è¦å¿½ç•¥çš„å­—æ®µï¼ˆéœ€è¿‡æ»¤æ‰æœ‰æ—¶æ•ˆæ€§çš„å­—æ®µï¼‰
     ignore_fields = ["video_play_addr", "images", "video_bit_rate", "cover"]
 
-    def __init__(self, kwargs) -> None:
+    def __init__(self, kwargs: dict = ...) -> None:
         self.kwargs = kwargs
-        self.downloader = DouyinDownloader(kwargs)
+        self.downloader = TiktokDownloader(kwargs)
 
-    async def handler_user_profile(self, sec_user_id: str) -> UserProfileFilter:
+    async def handler_user_profile(
+        self,
+        secUid: str = "",
+        uniqueId: str = "",
+    ) -> UserProfileFilter:
         """
         ç”¨äºè·å–æŒ‡å®šç”¨æˆ·çš„ä¸ªäººä¿¡æ¯
         (Used to get personal info of specified users)
 
         Args:
-            sec_user_id: str: ç”¨æˆ·ID (User ID)
+            secUid: str: ç”¨æˆ·ID (User ID)
+            uniqueId: str: ç”¨æˆ·å”¯ä¸€ID (User unique ID)
 
         Return:
             user: UserProfileFilter: ç”¨æˆ·ä¿¡æ¯è¿‡æ»¤å™¨ (User info filter)
         """
 
-        async with DouyinCrawler(self.kwargs) as crawler:
-            params = UserProfile(sec_user_id=sec_user_id)
+        if not secUid and not uniqueId:
+            raise ValueError(_("è‡³å°‘æä¾› secUid æˆ– uniqueId ä¸­çš„ä¸€ä¸ªå‚æ•°"))
+
+        async with TiktokCrawler(self.kwargs) as crawler:
+            params = UserProfile(secUid=secUid, uniqueId=uniqueId)
             response = await crawler.fetch_user_profile(params)
+            user = UserProfileFilter(response)
+            if user.nickname is None:
+                raise APIResponseError(_("APIå†…å®¹è¯·æ±‚å¤±è´¥ï¼Œè¯·æ›´æ¢æ–°cookieåå†è¯•"))
             return UserProfileFilter(response)
 
-    async def get_user_nickname(self, sec_user_id: str, db: AsyncUserDB) -> str:
+    async def get_user_nickname(
+        self,
+        secUid: str,
+        db: AsyncUserDB,
+    ) -> str:
         """
-        è·å–æŒ‡å®šç”¨æˆ·çš„æ˜µç§°ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œåˆ™ä»æœåŠ¡å™¨è·å–å¹¶å­˜å‚¨åˆ°æ•°æ®åº“ä¸­
-        (Used to get personal info of specified users)
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·çš„æ˜µç§°
+        (Used to get nickname of specified users)
 
         Args:
-            sec_user_id (str): ç”¨æˆ·ID (User ID)
-            db (AsyncUserDB): ç”¨æˆ·æ•°æ®åº“ (User database)
+            secUid: str: ç”¨æˆ·ID (User ID)
+            db: AsyncUserDB: ç”¨æˆ·æ•°æ®åº“ (User database)
 
-        Returns:
-            user_nickname: (str): ç”¨æˆ·æ˜µç§° (User nickname)
+        Return:
+            nick_name: str: ç”¨æˆ·æ˜µç§° (User nickname)
         """
 
-        user_dict = await db.get_user_info(sec_user_id)
+        user_dict = await db.get_user_info(secUid)
         if not user_dict:
-            user_dict = await self.handler_user_profile(sec_user_id)
+            user_dict = await self.handler_user_profile(secUid)
             await db.add_user_info(**user_dict._to_dict())
-        return user_dict.get("nickname")
+        return user_dict.get("nickname", "")
 
     async def get_or_add_user_data(
-        self, kwargs: dict, sec_user_id: str, db: AsyncUserDB
-    ) -> Any:
+        self,
+        secUid: str,
+        db: AsyncUserDB,
+    ) -> Path:
         """
         è·å–æˆ–åˆ›å»ºç”¨æˆ·æ•°æ®åŒæ—¶åˆ›å»ºç”¨æˆ·ç›®å½•
         (Get or create user data and create user directory)
 
         Args:
             kwargs (dict): é…ç½®å‚æ•° (Conf parameters)
-            sec_user_id (str): ç”¨æˆ·ID (User ID)
+            secUid (str): ç”¨æˆ·ID (User ID)
             db (AsyncUserDB): ç”¨æˆ·æ•°æ®åº“ (User database)
 
         Returns:
             user_path (Path): ç”¨æˆ·ç›®å½•è·¯å¾„ (User directory path)
         """
 
         # å°è¯•ä»æ•°æ®åº“ä¸­è·å–ç”¨æˆ·æ•°æ®
-        local_user_data = await db.get_user_info(sec_user_id)
+        local_user_data = await db.get_user_info(secUid)
 
         # ä»æœåŠ¡å™¨è·å–å½“å‰ç”¨æˆ·æœ€æ–°æ•°æ®
-        current_user_data = await self.handler_user_profile(sec_user_id)
+        current_user_data = await self.handler_user_profile(secUid)
 
         # è·å–å½“å‰ç”¨æˆ·æœ€æ–°æ˜µç§°
         current_nickname = current_user_data._to_dict().get("nickname")
 
         # è®¾ç½®ç”¨æˆ·ç›®å½•
         user_path = create_or_rename_user_folder(
-            kwargs, local_user_data, current_nickname
+            self.kwargs, local_user_data, current_nickname
         )
 
         # å¦‚æœç”¨æˆ·ä¸åœ¨æ•°æ®åº“ä¸­ï¼Œå°†å…¶æ·»åŠ åˆ°æ•°æ®åº“
         if not local_user_data:
             await db.add_user_info(**current_user_data._to_dict())
 
         return user_path
 
     @classmethod
     async def get_or_add_video_data(
-        cls, aweme_data: dict, db: AsyncVideoDB, ignore_fields: list = None
+        cls,
+        aweme_data: dict,
+        db: AsyncVideoDB,
+        ignore_fields: list = None,
     ):
         """
-        è·å–æˆ–åˆ›å»ºä½œå“æ•°æ®åº“æ•°æ®
+        è·å–æˆ–åˆ›å»ºä½œå“æ•°æ®åŒæ—¶åˆ›å»ºç”¨æˆ·ç›®å½•
         (Get or create user data and create user directory)
 
         Args:
             aweme_data (dict): ä½œå“æ•°æ® (User data)
             db (AsyncVideoDB): ä½œå“æ•°æ®åº“ (User database)
             ignore_fields (list): å‰”é™¤çš„å­—æ®µ
         """
 
         # å°è¯•ä»æ•°æ®åº“ä¸­è·å–ä½œå“æ•°æ®
-        local_video_data = await db.get_video_info(aweme_data.get("aweme_id"))
+        local_video_data = await db.get_video_info(aweme_data.get("aweme_id", None))
 
         # å¦‚æœä½œå“ä¸åœ¨æ•°æ®åº“ä¸­ï¼Œå°†å…¶æ·»åŠ åˆ°æ•°æ®åº“
         if not local_video_data:
             # ä»æœåŠ¡å™¨è·å–å½“å‰ä½œå“æœ€æ–°æ•°æ®
             # current_video_data = await fetch_one_video(aweme_data.get("aweme_id"))
             await db.add_video_info(ignore_fields=ignore_fields, **aweme_data)
 
+    async def fetch_play_list(
+        self,
+        secUid: str,
+        cursor: int,
+        page_counts: int,
+    ) -> UserPlayListFilter:
+        """
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·çš„ä½œå“åˆé›†åˆ—è¡¨
+        (Used to get video mix list of specified user)
+
+        Args:
+            secUid: str: ç”¨æˆ·ID (User ID)
+            cursor: int: åˆ†é¡µæ¸¸æ ‡ (Page cursor)
+            page_counts: int: åˆ†é¡µæ•°é‡ (Page counts)
+
+        Return:
+            playlist: UserPlayListFilter: ä½œå“åˆé›†åˆ—è¡¨ (Video mix list)
+        """
+
+        logger.debug(_("å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„ä½œå“åˆé›†åˆ—è¡¨").format(secUid))
+
+        async with TiktokCrawler(self.kwargs) as crawler:
+            params = UserPlayList(secUid=secUid, cursor=cursor, count=page_counts)
+            response = await crawler.fetch_user_play_list(params)
+            playlist = UserPlayListFilter(response)
+
+        if not playlist.hasPlayList:
+            logger.info(_("ç”¨æˆ·ï¼š{0} æ²¡æœ‰ä½œå“åˆé›†").format(secUid))
+            return {}
+
+        logger.debug(_("å½“å‰è¯·æ±‚çš„cursorï¼š{0}").format(cursor))
+        logger.debug(
+            _("ä½œå“åˆé›†IDï¼š{0} ä½œå“åˆé›†æ ‡é¢˜ï¼š{1}").format(
+                playlist.mixId, playlist.mixName
+            )
+        )
+        logger.debug("===================================")
+        return playlist
+
+    async def select_playlist(
+        self, playlists: Union[dict, UserPlayListFilter]
+    ) -> Union[str, List[str]]:
+        """
+        ç”¨äºé€‰æ‹©è¦ä¸‹è½½çš„ä½œå“åˆè¾‘
+        (Used to select the video mix to download)
+
+        Args:
+            playlists: Union[dict, UserPlayListFilter]: ä½œå“åˆè¾‘åˆ—è¡¨ (Video mix list)
+
+        Return:
+            selected_index: Union[str, List[str]]: é€‰æ‹©çš„ä½œå“åˆè¾‘åºå· (Selected video mix index)
+        """
+
+        if playlists == {}:
+            sys.exit(_("ç”¨æˆ·æ²¡æœ‰ä½œå“åˆè¾‘"))
+
+        rich_console.print("[bold]è¯·é€‰æ‹©è¦ä¸‹è½½çš„åˆè¾‘ï¼š[/bold]")
+        rich_console.print("0: [bold]å…¨éƒ¨ä¸‹è½½[/bold]")
+
+        for i in range(len(playlists.mixId)):
+            rich_console.print(
+                _("{0}: {1} (åŒ…å« {2} ä¸ªä½œå“ï¼Œæ”¶è—å¤¹ID {3})").format(
+                    i + 1,
+                    playlists.mixName[i],
+                    playlists.videoCount[i],
+                    playlists.mixId[i],
+                )
+            )
+
+        # rich_prompt ä¼šæœ‰å­—ç¬¦åˆ·æ–°é—®é¢˜ï¼Œæš‚æ—¶ä½¿ç”¨rich_print
+        rich_console.print(_("[bold yellow]è¯·è¾“å…¥å¸Œæœ›ä¸‹è½½çš„åˆè¾‘åºå·ï¼š[/bold yellow]"))
+        selected_index = int(
+            rich_prompt.ask(
+                # _("[bold yellow]è¯·è¾“å…¥å¸Œæœ›ä¸‹è½½çš„åˆè¾‘åºå·:[/bold yellow]"),
+                choices=[str(i) for i in range(len(playlists) + 1)],
+            )
+        )
+
+        if selected_index == 0:
+            return playlists.mixId
+        else:
+            return playlists.mixId[selected_index - 1]
+
     @mode_handler("one")
-    async def handle_one_video(self):
+    async def handler_one_video(self):
         """
-        ç”¨äºå¤„ç†å•ä¸ªè§†é¢‘ã€‚
-        (Used to process a single video.)
+        ç”¨äºè·å–æŒ‡å®šä½œå“çš„ä¿¡æ¯
+        (Used to get video info of specified video)
 
         Args:
             kwargs: dict: å‚æ•°å­—å…¸ (Parameter dictionary)
         """
 
         aweme_id = await AwemeIdFetcher.get_aweme_id(self.kwargs.get("url"))
 
         aweme_data = await self.fetch_one_video(aweme_id)
 
-        async with AsyncUserDB("douyin_users.db") as db:
-            user_path = await self.get_or_add_user_data(
-                self.kwargs, aweme_data.get("sec_user_id"), db
+        async with AsyncUserDB("tiktok_users.db") as udb:
+            user_path = await self.get_or_add_user_data(aweme_data.secUid, udb)
+
+        async with AsyncVideoDB("tiktok_videos.db") as vdb:
+            await self.get_or_add_video_data(
+                aweme_data._to_dict(), vdb, self.ignore_fields
             )
 
-        async with AsyncVideoDB("douyin_videos.db") as db:
-            await self.get_or_add_video_data(aweme_data, db, self.ignore_fields)
+        logger.debug(_("å•ä¸ªä½œå“æ•°æ®ï¼š{0}").format(aweme_data._to_dict()))
 
-        logger.debug(_("å•ä¸ªè§†é¢‘æ•°æ®: {0}".format(aweme_data)))
-        await self.downloader.create_download_tasks(self.kwargs, aweme_data, user_path)
+        # åˆ›å»ºä¸‹è½½ä»»åŠ¡
+        await self.downloader.create_download_tasks(
+            self.kwargs, aweme_data._to_dict(), user_path
+        )
 
-    async def fetch_one_video(self, aweme_id: str) -> dict:
+    async def fetch_one_video(self, itemId: str) -> PostDetailFilter:
         """
-        ç”¨äºè·å–å•ä¸ªè§†é¢‘ã€‚
+        ç”¨äºè·å–æŒ‡å®šä½œå“çš„è¯¦ç»†ä¿¡æ¯
+        (Used to get detailed information of specified video)
 
         Args:
-            aweme_id: str: è§†é¢‘ID
+            itemId: str: ä½œå“ID (Video ID)
 
         Return:
-            video_data: dict: è§†é¢‘æ•°æ®å­—å…¸ï¼ŒåŒ…å«è§†é¢‘IDã€è§†é¢‘æ–‡æ¡ˆã€ä½œè€…æ˜µç§°
+            video: PostDetailFilter: ä½œå“ä¿¡æ¯è¿‡æ»¤å™¨ (Video info filter)
         """
 
-        logger.debug(_("å¼€å§‹çˆ¬å–è§†é¢‘: {0}").format(aweme_id))
-        async with DouyinCrawler(self.kwargs) as crawler:
-            params = PostDetail(aweme_id=aweme_id)
+        logger.debug(_("å¼€å§‹çˆ¬å–ä½œå“ï¼š{0}").format(itemId))
+        async with TiktokCrawler(self.kwargs) as crawler:
+            params = PostDetail(itemId=itemId)
             response = await crawler.fetch_post_detail(params)
             video = PostDetailFilter(response)
 
         logger.debug(
-            _("è§†é¢‘ID: {0} è§†é¢‘æ–‡æ¡ˆ: {1} ä½œè€…: {2}").format(
+            _("ä½œå“IDï¼š{0} ä½œå“æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}").format(
                 video.aweme_id, video.desc, video.nickname
             )
         )
 
-        return video._to_dict()
+        return video
 
     @mode_handler("post")
-    async def handle_user_post(self):
+    async def handler_user_post(self):
         """
-        ç”¨äºå¤„ç†ç”¨æˆ·å‘å¸ƒçš„è§†é¢‘ã€‚
-        (Used to process videos published by users.)
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·çš„ä½œå“ä¿¡æ¯
+        (Used to get video info of specified user)
 
         Args:
             kwargs: dict: å‚æ•°å­—å…¸ (Parameter dictionary)
         """
 
-        max_cursor = self.kwargs.get("max_cursor", 0)
-        page_counts = self.kwargs.get("page_counts", 20)
+        cursor = self.kwargs.get("cursor", 0)
+        page_counts = self.kwargs.get("page_counts", 35)
         max_counts = self.kwargs.get("max_counts")
 
-        # è·å–ç”¨æˆ·æ•°æ®å¹¶è¿”å›åˆ›å»ºç”¨æˆ·ç›®å½•
-        sec_user_id = await SecUserIdFetcher.get_sec_user_id(self.kwargs.get("url"))
-        async with AsyncUserDB("douyin_users.db") as udb:
-            user_path = await self.get_or_add_user_data(self.kwargs, sec_user_id, udb)
+        secUid = await SecUserIdFetcher.get_secuid(self.kwargs.get("url"))
+
+        async with AsyncUserDB("tiktok_users.db") as udb:
+            user_path = await self.get_or_add_user_data(secUid, udb)
 
         async for aweme_data_list in self.fetch_user_post_videos(
-            sec_user_id, max_cursor, page_counts, max_counts
+            secUid, cursor, page_counts, max_counts
         ):
             # åˆ›å»ºä¸‹è½½ä»»åŠ¡
             await self.downloader.create_download_tasks(
-                self.kwargs, aweme_data_list, user_path
+                self.kwargs, aweme_data_list._to_list(), user_path
             )
 
-            # # ä¸€æ¬¡æ€§æ‰¹é‡æ’å…¥è§†é¢‘æ•°æ®åˆ°æ•°æ®åº“
-            # async with AsyncVideoDB("douyin_videos.db") as db:
-            #     await db.batch_insert_videos(aweme_data_list, ignore_fields)
-
     async def fetch_user_post_videos(
-        self,
-        sec_user_id: str,
-        max_cursor: int = 0,
-        page_counts: int = 20,
-        max_counts: int = None,
-    ):
+        self, secUid: str, cursor: int, page_counts: int, max_counts: float
+    ) -> AsyncGenerator[UserPostFilter, Any]:
         """
-        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·å‘å¸ƒçš„è§†é¢‘åˆ—è¡¨ã€‚
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·å‘å¸ƒçš„ä½œå“åˆ—è¡¨
+        (Used to get video list of specified user)
 
         Args:
-            sec_user_id: str: ç”¨æˆ·ID
-            max_cursor: int: èµ·å§‹é¡µ
-            page_counts: int: æ¯é¡µè§†é¢‘æ•°
-            max_counts: int: æœ€å¤§è§†é¢‘æ•°
+            secUid: str: ç”¨æˆ·ID (User ID)
+            cursor: int: åˆ†é¡µæ¸¸æ ‡ (Page cursor)
+            page_counts: int: åˆ†é¡µæ•°é‡ (Page counts)
+            max_counts: float: æœ€å¤§æ•°é‡ (Max counts)
 
         Return:
-            aweme_data: dict: è§†é¢‘æ•°æ®å­—å…¸ï¼ŒåŒ…å«è§†é¢‘IDåˆ—è¡¨ã€è§†é¢‘æ–‡æ¡ˆã€ä½œè€…æ˜µç§°ã€èµ·å§‹é¡µ
+            video: AsyncGenerator[UserPostFilter, Any]: ç”¨æˆ·å‘å¸ƒä½œå“ä¿¡æ¯è¿‡æ»¤å™¨ (Video info filter)
         """
 
         max_counts = max_counts or float("inf")
         videos_collected = 0
 
-        logger.debug(_("å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} å‘å¸ƒçš„è§†é¢‘").format(sec_user_id))
+        logger.debug(_("å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} å‘å¸ƒçš„ä½œå“").format(secUid))
 
         while videos_collected < max_counts:
             current_request_size = min(page_counts, max_counts - videos_collected)
 
-            logger.debug("=====================================")
+            logger.debug("===================================")
             logger.debug(
                 _("æœ€å¤§æ•°é‡: {0} æ¯æ¬¡è¯·æ±‚æ•°é‡: {1}").format(
                     max_counts, current_request_size
                 )
             )
-            logger.debug(_("å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ").format(max_cursor))
+            logger.debug(_("å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ").format(cursor))
 
-            async with DouyinCrawler(self.kwargs) as crawler:
-                params = UserPost(
-                    max_cursor=max_cursor,
-                    count=current_request_size,
-                    sec_user_id=sec_user_id,
-                )
+            async with TiktokCrawler(self.kwargs) as crawler:
+                params = UserPost(secUid=secUid, cursor=cursor, count=page_counts)
                 response = await crawler.fetch_user_post(params)
                 video = UserPostFilter(response)
 
             if not video.has_aweme:
-                logger.debug(_("{0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“".format(max_cursor)))
-                if not video.has_more:
-                    logger.debug(_("ç”¨æˆ·: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•".format(sec_user_id)))
+                logger.debug(_("ç¬¬ {0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“").format(cursor))
+                if not video.hasMore and str(video.api_status_code) == "0":
+                    logger.debug(_("ç”¨æˆ·ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•").format(secUid))
                     break
+                else:
+                    cursor = video.cursor
+                    continue
 
-                max_cursor = video.max_cursor
-                continue
-
-            logger.debug(_("å½“å‰è¯·æ±‚çš„max_cursor: {0}").format(max_cursor))
+            logger.debug(_("å½“å‰è¯·æ±‚çš„cursorï¼š{0}").format(cursor))
             logger.debug(
-                _("è§†é¢‘ID: {0} è§†é¢‘æ–‡æ¡ˆ: {1} ä½œè€…: {2}").format(
+                _("ä½œå“IDï¼š{0} ä½œå“æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}").format(
                     video.aweme_id, video.desc, video.nickname
                 )
             )
-            logger.debug("=====================================")
+            logger.debug("===================================")
 
-            aweme_data_list = video._to_list()
-            yield aweme_data_list
+            yield video
 
-            # æ›´æ–°å·²ç»å¤„ç†çš„è§†é¢‘æ•°é‡ (Update the number of videos processed)
+            # æ›´æ–°å·²ç»å¤„ç†çš„ä½œå“æ•°é‡ (Update the number of videos processed)
             videos_collected += len(video.aweme_id)
-            max_cursor = video.max_cursor
+            cursor = video.cursor
 
-        logger.debug(_("çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å–{0}ä¸ªè§†é¢‘").format(videos_collected))
+        logger.debug(_("çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªä½œå“").format(videos_collected))
 
     @mode_handler("like")
-    async def handle_user_like(self):
+    async def handler_user_like(self):
         """
-        ç”¨äºå¤„ç†ç”¨æˆ·å–œæ¬¢çš„è§†é¢‘ (Used to process videos liked by users)
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·çš„ç‚¹èµä½œå“ä¿¡æ¯
+        (Used to get liked video info of specified user)
 
         Args:
             kwargs: dict: å‚æ•°å­—å…¸ (Parameter dictionary)
         """
 
-        max_cursor = self.kwargs.get("max_cursor", 0)
-        page_counts = self.kwargs.get("page_counts", 20)
+        cursor = self.kwargs.get("cursor", 0)
+        page_counts = self.kwargs.get("page_counts", 30)
         max_counts = self.kwargs.get("max_counts")
 
-        # è·å–ç”¨æˆ·æ•°æ®å¹¶è¿”å›åˆ›å»ºç”¨æˆ·ç›®å½•
-        sec_user_id = await SecUserIdFetcher.get_sec_user_id(self.kwargs.get("url"))
-        async with AsyncUserDB("douyin_users.db") as db:
-            user_path = await self.get_or_add_user_data(self.kwargs, sec_user_id, db)
+        secUid = await SecUserIdFetcher.get_secuid(self.kwargs.get("url"))
+
+        async with AsyncUserDB("tiktok_users.db") as udb:
+            user_path = await self.get_or_add_user_data(secUid, udb)
 
         async for aweme_data_list in self.fetch_user_like_videos(
-            sec_user_id, max_cursor, page_counts, max_counts
+            secUid, cursor, page_counts, max_counts
         ):
             # åˆ›å»ºä¸‹è½½ä»»åŠ¡
             await self.downloader.create_download_tasks(
-                self.kwargs, aweme_data_list, user_path
+                self.kwargs, aweme_data_list._to_list(), user_path
             )
 
-            # async with AsyncVideoDB("douyin_videos.db") as db:
-            #     for aweme_data in aweme_data_list:
-            #         await get_or_add_video_data(aweme_data, db, ignore_fields)
-
-            # # ä¸€æ¬¡æ€§æ‰¹é‡æ’å…¥è§†é¢‘æ•°æ®åˆ°æ•°æ®åº“
-            # async with AsyncVideoDB("douyin_videos.db") as db:
-            #     await db.batch_insert_videos(aweme_data_list, ignore_fields)
-
     async def fetch_user_like_videos(
-        self,
-        sec_user_id: str,
-        max_cursor: int = 0,
-        page_counts: int = 20,
-        max_counts: int = None,
-    ) -> AsyncGenerator[List[Dict[str, Any]], None]:
-        """
-        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·å–œæ¬¢çš„è§†é¢‘åˆ—è¡¨ã€‚
+        self, secUid: str, cursor: int, page_counts: int, max_counts: float
+    ) -> AsyncGenerator[UserPostFilter, Any]:
+        """
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·ç‚¹èµçš„ä½œå“åˆ—è¡¨
+        (Used to get liked video list of specified user)
 
         Args:
-            sec_user_id: str: ç”¨æˆ·ID
-            max_cursor: int: èµ·å§‹é¡µ
-            page_counts: int: æ¯é¡µè§†é¢‘æ•°
-            max_counts: int: æœ€å¤§è§†é¢‘æ•°
+            secUid: str: ç”¨æˆ·ID (User ID)
+            cursor: int: åˆ†é¡µæ¸¸æ ‡ (Page cursor)
+            page_counts: int: åˆ†é¡µæ•°é‡ (Page counts)
+            max_counts: float: æœ€å¤§æ•°é‡ (Max counts)
 
         Return:
-            aweme_data: dict: è§†é¢‘æ•°æ®å­—å…¸ï¼ŒåŒ…å«è§†é¢‘IDåˆ—è¡¨ã€è§†é¢‘æ–‡æ¡ˆã€ä½œè€…æ˜µç§°ã€èµ·å§‹é¡µ
+            like: AsyncGenerator[UserPostFilter, Any]: ç”¨æˆ·ç‚¹èµä½œå“ä¿¡æ¯è¿‡æ»¤å™¨ (Video info filter)
         """
 
         max_counts = max_counts or float("inf")
         videos_collected = 0
 
-        logger.debug(_("å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} å–œæ¬¢çš„è§†é¢‘").format(sec_user_id))
+        logger.debug(_("å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} ç‚¹èµçš„ä½œå“").format(secUid))
 
         while videos_collected < max_counts:
             current_request_size = min(page_counts, max_counts - videos_collected)
 
-            logger.debug("=====================================")
+            logger.debug("===================================")
             logger.debug(
-                _("æœ€å¤§æ•°é‡: {0} æ¯æ¬¡è¯·æ±‚æ•°é‡: {1}").format(
+                _("æœ€å¤§æ•°é‡ï¼š{0} æ¯æ¬¡è¯·æ±‚æ•°é‡ï¼š{1}").format(
                     max_counts, current_request_size
                 )
             )
-            logger.debug(_("å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ").format(max_cursor))
+            logger.debug(_("å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ").format(cursor))
 
-            async with DouyinCrawler(self.kwargs) as crawler:
-                params = UserLike(
-                    max_cursor=max_cursor,
-                    count=current_request_size,
-                    sec_user_id=sec_user_id,
-                )
+            async with TiktokCrawler(self.kwargs) as crawler:
+                params = UserLike(secUid=secUid, cursor=cursor, count=page_counts)
                 response = await crawler.fetch_user_like(params)
-                video = UserPostFilter(response)
+                like = UserPostFilter(response)
 
-            if not video.has_aweme:
-                logger.debug(_("{0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“".format(max_cursor)))
-                if not video.has_more:
-                    logger.debug(_("ç”¨æˆ·: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•".format(sec_user_id)))
-                    break
+            if like.has_aweme:
+                logger.debug(_("å½“å‰è¯·æ±‚çš„cursorï¼š{0}").format(cursor))
+                logger.debug(
+                    _("ä½œå“IDï¼š{0} ä½œå“æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}").format(
+                        like.aweme_id, like.desc, like.nickname
+                    )
+                )
+                logger.debug("===================================")
 
-                max_cursor = video.max_cursor
-                continue
+                yield like
 
-            logger.debug(_("å½“å‰è¯·æ±‚çš„max_cursor: {0}").format(max_cursor))
-            logger.debug(
-                _("è§†é¢‘ID: {0} è§†é¢‘æ–‡æ¡ˆ: {1} ä½œè€…: {2}").format(
-                    video.aweme_id, video.desc, video.nickname
-                )
-            )
-            logger.debug("=====================================")
+                # æ›´æ–°å·²ç»å¤„ç†çš„ä½œå“æ•°é‡ (Update the number of videos processed)
+                videos_collected += len(like.aweme_id)
 
-            aweme_data_list = video._to_list()
-            yield aweme_data_list
+                if not like.hasMore and str(like.api_status_code) == "0":
+                    logger.debug(_("ç”¨æˆ·ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•").format(secUid))
+                    break
 
-            # æ›´æ–°å·²ç»å¤„ç†çš„è§†é¢‘æ•°é‡ (Update the number of videos processed)
-            videos_collected += len(aweme_data_list)
-            max_cursor = video.max_cursor
+            else:
+                logger.debug(_("ç¬¬ {0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“").format(cursor))
 
-        logger.debug(_("çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å–{0}ä¸ªè§†é¢‘").format(videos_collected))
+                if not like.hasMore and str(like.api_status_code) == "0":
+                    logger.debug(_("ç”¨æˆ·ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•").format(secUid))
+                    break
+
+            # æ›´æ–°å·²ç»å¤„ç†çš„ä½œå“æ•°é‡ (Update the number of videos processed)
+            videos_collected += len(like.aweme_id)
+            cursor = like.cursor
+
+        logger.debug(_("çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªä½œå“").format(videos_collected))
 
     @mode_handler("collect")
-    async def handle_user_collect(self):
+    async def handler_user_collect(self):
         """
-        ç”¨äºå¤„ç†ç”¨æˆ·æ”¶è—çš„è§†é¢‘ (Used to process videos collected by users)
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·çš„æ”¶è—ä½œå“ä¿¡æ¯
+        (Used to get collected video info of specified user)
 
         Args:
             kwargs: dict: å‚æ•°å­—å…¸ (Parameter dictionary)
         """
 
-        max_cursor = self.kwargs.get("max_cursor", 0)
-        page_counts = self.kwargs.get("page_counts", 20)
+        cursor = self.kwargs.get("cursor", 0)
+        page_counts = self.kwargs.get("page_counts", 30)
         max_counts = self.kwargs.get("max_counts")
 
-        sec_user_id = await SecUserIdFetcher.get_sec_user_id(self.kwargs.get("url"))
+        secUid = await SecUserIdFetcher.get_secuid(self.kwargs.get("url"))
 
-        async with AsyncUserDB("douyin_users.db") as db:
-            user_path = await self.get_or_add_user_data(self.kwargs, sec_user_id, db)
+        async with AsyncUserDB("tiktok_users.db") as udb:
+            user_path = await self.get_or_add_user_data(secUid, udb)
 
         async for aweme_data_list in self.fetch_user_collect_videos(
-            max_cursor, page_counts, max_counts
+            secUid, cursor, page_counts, max_counts
         ):
+            # åˆ›å»ºä¸‹è½½ä»»åŠ¡
             await self.downloader.create_download_tasks(
-                self.kwargs, aweme_data_list, user_path
+                self.kwargs, aweme_data_list._to_list(), user_path
             )
 
     async def fetch_user_collect_videos(
-        self, max_cursor: int = 0, page_counts: int = 20, max_counts: int = None
-    ) -> AsyncGenerator[List[Dict[str, Any]], None]:
+        self, secUid: str, cursor: int, page_counts: int, max_counts: float
+    ) -> AsyncGenerator[UserPostFilter, Any]:
         """
-        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·æ”¶è—çš„è§†é¢‘åˆ—è¡¨ã€‚
-        (Used to get the list of videos collected by the specified user.)
-        è¯¥æ¥å£éœ€è¦ç”¨POSTä¸”åªé cookieæ¥è·å–æ•°æ®ã€‚
-        (This interface needs to be POST and only relies on cookies to get data.)
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·æ”¶è—çš„ä½œå“åˆ—è¡¨
+        (Used to get collected video list of specified user)
 
         Args:
-            max_cursor: int: èµ·å§‹é¡µ (Start page)
-            page_counts: int: æ¯é¡µè§†é¢‘æ•° (Number of videos per page)
-            max_counts: int: æœ€å¤§è§†é¢‘æ•° (Maximum number of videos)
+            secUid: str: ç”¨æˆ·ID (User ID)
+            cursor: int: åˆ†é¡µæ¸¸æ ‡ (Page cursor)
+            page_counts: int: åˆ†é¡µæ•°é‡ (Page counts)
+            max_counts: float: æœ€å¤§æ•°é‡ (Max counts)
 
         Return:
-            aweme_data: dict: è§†é¢‘æ•°æ®å­—å…¸, åŒ…å«è§†é¢‘IDåˆ—è¡¨ã€è§†é¢‘æ–‡æ¡ˆã€ä½œè€…æ˜µç§°ã€èµ·å§‹é¡µ
-            (Video data dictionary, including video ID list, video description,
-            author nickname, start page)
+            collect: AsyncGenerator[UserPostFilter, Any]: æ”¶è—ä½œå“ä¿¡æ¯è¿‡æ»¤å™¨ (Video info filter)
         """
 
         max_counts = max_counts or float("inf")
         videos_collected = 0
 
-        logger.debug(_("å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„è§†é¢‘"))
+        logger.debug(_("å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} æ”¶è—çš„ä½œå“").format(secUid))
 
         while videos_collected < max_counts:
             current_request_size = min(page_counts, max_counts - videos_collected)
 
-            logger.debug("=====================================")
+            logger.debug("===================================")
             logger.debug(
-                _("æœ€å¤§æ•°é‡: {0} æ¯æ¬¡è¯·æ±‚æ•°é‡: {1}").format(
+                _("æœ€å¤§æ•°é‡ï¼š{0} æ¯æ¬¡è¯·æ±‚æ•°é‡ï¼š{1}").format(
                     max_counts, current_request_size
                 )
             )
-            logger.debug(_("å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ").format(max_cursor))
+            logger.debug(_("å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ").format(cursor))
 
-            async with DouyinCrawler(self.kwargs) as crawler:
-                params = UserCollect(cursor=max_cursor, count=current_request_size)
+            async with TiktokCrawler(self.kwargs) as crawler:
+                params = UserCollect(secUid=secUid, cursor=cursor, count=page_counts)
                 response = await crawler.fetch_user_collect(params)
-                video = UserCollectFilter(response)
-
-            logger.debug(_("å½“å‰è¯·æ±‚çš„max_cursor: {0}").format(max_cursor))
-            logger.debug(
-                _("è§†é¢‘ID: {0} è§†é¢‘æ–‡æ¡ˆ: {1} ä½œè€…: {2}").format(
-                    video.aweme_id, video.desc, video.nickname
-                )
-            )
-            logger.debug("=====================================")
-
-            aweme_data_list = video._to_list()
-            yield aweme_data_list
-
-            if not video.has_more:
-                logger.debug(_("ç”¨æˆ·æ”¶è—çš„è§†é¢‘é‡‡é›†å®Œæ¯•"))
-                break
-
-            # æ›´æ–°å·²ç»å¤„ç†çš„è§†é¢‘æ•°é‡ (Update the number of videos processed)
-            videos_collected += len(aweme_data_list)
-            max_cursor = video.max_cursor
-
-    @mode_handler("mix")
-    async def handle_user_mix(self):
-        """
-        ç”¨äºå¤„ç†ç”¨æˆ·åˆé›†çš„è§†é¢‘ (Used to process videos of users' collections)
-
-        Args:
-            kwargs: dict: å‚æ•°å­—å…¸ (Parameter dictionary)
-        """
-
-        max_cursor = self.kwargs.get("max_cursor", 0)
-        page_counts = self.kwargs.get("page_counts", 20)
-        max_counts = self.kwargs.get("max_counts")
-
-        aweme_id = await AwemeIdFetcher.get_aweme_id(self.kwargs.get("url"))
-        mix_data = await self.fetch_one_video(aweme_id)
-        sec_user_id = mix_data.get("sec_user_id")
-        mix_id = mix_data.get("mix_id")
-
-        async with AsyncUserDB("douyin_users.db") as db:
-            user_path = await self.get_or_add_user_data(self.kwargs, sec_user_id, db)
-
-        async for aweme_data_list in self.fetch_user_mix_videos(
-            mix_id, max_cursor, page_counts, max_counts
-        ):
-            # åˆ›å»ºä¸‹è½½ä»»åŠ¡
-            await self.downloader.create_download_tasks(
-                self.kwargs, aweme_data_list, user_path
-            )
-
-        # async with AsyncVideoDB("douyin_videos.db") as db:
-        #     for aweme_data in aweme_data_list:
-        #         await get_or_add_video_data(aweme_data, db, ignore_fields)
-
-    async def fetch_user_mix_videos(
-        self,
-        mix_id: str,
-        max_cursor: int = 0,
-        page_counts: int = 20,
-        max_counts: int = None,
-    ) -> AsyncGenerator[List[Dict[str, Any]], None]:
-        """
-        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·åˆé›†çš„è§†é¢‘åˆ—è¡¨ã€‚
-
-        Args:
-            mix_id: str: åˆé›†ID
-            max_cursor: int: èµ·å§‹é¡µ
-            page_counts: int: æ¯é¡µè§†é¢‘æ•°
-            max_counts: int: æœ€å¤§è§†é¢‘æ•°
-
-        Return:
-            aweme_data: dict: è§†é¢‘æ•°æ®å­—å…¸ï¼ŒåŒ…å«è§†é¢‘IDåˆ—è¡¨ã€è§†é¢‘æ–‡æ¡ˆã€ä½œè€…æ˜µç§°ã€èµ·å§‹é¡µ
-        """
-
-        max_counts = max_counts or float("inf")
-        videos_collected = 0
-
-        logger.debug(_("å¼€å§‹çˆ¬å–åˆé›†: {0} çš„è§†é¢‘").format(mix_id))
-
-        while videos_collected < max_counts:
-            current_request_size = min(page_counts, max_counts - videos_collected)
-
-            logger.debug("=====================================")
-            logger.debug(
-                _("æœ€å¤§æ•°é‡: {0} æ¯æ¬¡è¯·æ±‚æ•°é‡: {1}").format(
-                    max_counts, current_request_size
-                )
-            )
-            logger.debug(_("å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ").format(max_cursor))
-
-            async with DouyinCrawler(self.kwargs) as crawler:
-                params = UserMix(
-                    cursor=max_cursor, count=current_request_size, mix_id=mix_id
-                )
-                response = await crawler.fetch_user_mix(params)
-                video = UserMixFilter(response)
+                collect = UserPostFilter(response)
 
-            logger.debug(_("å½“å‰è¯·æ±‚çš„max_cursor: {0}").format(max_cursor))
-            logger.debug(
-                _("è§†é¢‘ID: {0} è§†é¢‘æ–‡æ¡ˆ: {1} ä½œè€…: {2}").format(
-                    video.aweme_id, video.desc, video.nickname
+            if collect.has_aweme:
+                logger.debug(_("å½“å‰è¯·æ±‚çš„cursorï¼š{0}").format(cursor))
+                logger.debug(
+                    _("ä½œå“IDï¼š{0} ä½œå“æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}").format(
+                        collect.aweme_id, collect.desc, collect.nickname
+                    )
                 )
-            )
-            logger.debug("=====================================")
-
-            aweme_data_list = video._to_list()
-            yield aweme_data_list
-
-            # æ›´æ–°å·²ç»å¤„ç†çš„è§†é¢‘æ•°é‡ (Update the number of videos processed)
-            videos_collected += len(aweme_data_list)
-            max_cursor = video.max_cursor
-
-            if not video.has_more:
-                logger.debug(_("åˆé›†: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•").format(mix_id))
-                break
-
-        logger.debug(_("çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å–{0}ä¸ªè§†é¢‘").format(videos_collected))
-
-    @mode_handler("live")
-    async def handle_user_live(self):
-        """
-        ç”¨äºå¤„ç†ç”¨æˆ·ç›´æ’­ (Used to process user live)
-
-        Args:
-            kwargs: dict: å‚æ•°å­—å…¸ (Parameter dictionary)
-        """
+                logger.debug("===================================")
 
-        # è·å–ç›´æ’­ç›¸å…³ä¿¡æ¯ä¸ä¸»æ’­ä¿¡æ¯
-        webcast_id = await WebCastIdFetcher.get_webcast_id(self.kwargs.get("url"))
+                yield collect
 
-        # ç„¶åä¸‹è½½ç›´æ’­æ¨æµ
-        webcast_data = await self.fetch_user_live_videos(webcast_id)
-        live_status = webcast_data.get("live_status")
-        # æ˜¯å¦æ­£åœ¨ç›´æ’­
-        if live_status != 2:
-            logger.debug(_("ç›´æ’­å·²ç»“æŸ"))
-            return
-        sec_user_id = webcast_data.get("sec_user_id")
+                # æ›´æ–°å·²ç»å¤„ç†çš„ä½œå“æ•°é‡ (Update the number of videos processed)
+                videos_collected += len(collect.aweme_id)
 
-        async with AsyncUserDB("douyin_users.db") as db:
-            user_path = await self.get_or_add_user_data(self.kwargs, sec_user_id, db)
-        await self.downloader.create_stream_tasks(self.kwargs, webcast_data, user_path)
-
-    async def fetch_user_live_videos(self, webcast_id: str):
-        """
-        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·ç›´æ’­åˆ—è¡¨ã€‚
-        (Used to get the list of videos collected by the specified user.)
-
-        Args:
-            webcast_id: str: ç›´æ’­ID (Live ID)
-
-        Return:
-            webcast_data: dict: ç›´æ’­æ•°æ®å­—å…¸ï¼ŒåŒ…å«ç›´æ’­IDã€ç›´æ’­æ ‡é¢˜ã€ç›´æ’­çŠ¶æ€ã€è§‚çœ‹äººæ•°ã€å­åˆ†åŒºã€ä¸»æ’­æ˜µç§°
-            (Live data dict, including live ID, live title, live status, number of viewers,
-            sub-partition, anchor nickname)
-        """
-
-        logger.debug(_("å¼€å§‹çˆ¬å–ç›´æ’­: {0} çš„æ•°æ®").format(webcast_id))
-        logger.debug("=====================================")
-
-        async with DouyinCrawler(self.kwargs) as crawler:
-            params = UserLive(web_rid=webcast_id, room_id_str="")
-            response = await crawler.fetch_live(params)
-            live = UserLiveFilter(response)
-
-        logger.debug(
-            _("ç›´æ’­ID: {0} ç›´æ’­æ ‡é¢˜: {1} ç›´æ’­çŠ¶æ€: {2} è§‚çœ‹äººæ•°: {3}").format(
-                live.room_id, live.live_title, live.live_status, live.user_count
-            )
-        )
-        logger.debug(
-            _("å­åˆ†åŒº: {0} ä¸»æ’­æ˜µç§°: {1}").format(
-                live.sub_partition_title, live.nickname
-            )
-        )
-        logger.debug("=====================================")
-        logger.debug(_("ç›´æ’­ä¿¡æ¯çˆ¬å–ç»“æŸ"))
-
-        webcast_data = live._to_dict()
-        return webcast_data
-
-    async def fetch_user_live_videos_by_room_id(self, room_id: str):
-        """
-        ä½¿ç”¨room_idè·å–æŒ‡å®šç”¨æˆ·ç›´æ’­åˆ—è¡¨ã€‚
-        (Used to get the list of videos collected by the specified user)
-
-        Args:
-            room_id: str: ç›´æ’­ID (Live ID)
+                if not collect.hasMore and str(collect.api_status_code) == "0":
+                    logger.debug(_("ç”¨æˆ·ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•").format(secUid))
+                    break
 
-        Return:
-            webcast_data: dict: ç›´æ’­æ•°æ®å­—å…¸ï¼ŒåŒ…å«ç›´æ’­IDã€ç›´æ’­æ ‡é¢˜ã€ç›´æ’­çŠ¶æ€ã€è§‚çœ‹äººæ•°ã€ä¸»æ’­æ˜µç§°
-            (Live data dict, including live ID, live title, live status, number of viewers,
-            anchor nickname)
-        """
+            else:
+                logger.debug(_("ç¬¬ {0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“").format(cursor))
 
-        logger.debug(_("å¼€å§‹çˆ¬å–æˆ¿é—´å·: {0} çš„æ•°æ®").format(room_id))
-        logger.debug("=====================================")
-
-        async with DouyinCrawler(self.kwargs) as crawler:
-            params = UserLive2(room_id=room_id)
-            response = await crawler.fetch_live_room_id(params)
-            live = UserLive2Filter(response)
+                if not collect.hasMore and str(collect.api_status_code) == "0":
+                    logger.debug(_("ç”¨æˆ·ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•").format(secUid))
+                    break
 
-        logger.debug(
-            _("ç›´æ’­ID: {0} ç›´æ’­æ ‡é¢˜: {1} ç›´æ’­çŠ¶æ€: {2} è§‚çœ‹äººæ•°: {3}").format(
-                live.web_rid, live.live_title, live.live_status, live.user_count
-            )
-        )
-        logger.debug(
-            _("ä¸»æ’­æ˜µç§°: {0} å¼€æ’­æ—¶é—´: {1} ç›´æ’­æµæ¸…æ™°åº¦: {2}").format(
-                live.nickname,
-                live.create_time,
-                "ã€".join(
-                    [f"{key}: {value}" for key, value in live.resolution_name.items()]
-                ),
-            )
-        )
-        logger.debug("=====================================")
-        logger.debug(_("ç›´æ’­ä¿¡æ¯çˆ¬å–ç»“æŸ"))
+            # æ›´æ–°å·²ç»å¤„ç†çš„ä½œå“æ•°é‡ (Update the number of videos processed)
+            videos_collected += len(collect.aweme_id)
+            cursor = collect.cursor
 
-        webcast_data = live._to_dict()
-        return webcast_data
+        logger.debug(_("çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªä½œå“").format(videos_collected))
 
-    @mode_handler("feed")
-    async def handle_user_feed(self):
+    @mode_handler("mix")
+    async def handler_user_mix(self):
         """
-        ç”¨äºå¤„ç†ç”¨æˆ·feed (Used to process user feed)
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·çš„åˆé›†ä½œå“ä¿¡æ¯
+        (Used to get mix video info of specified user)
 
         Args:
             kwargs: dict: å‚æ•°å­—å…¸ (Parameter dictionary)
         """
 
-        max_cursor = self.kwargs.get("max_cursor", 0)
-        page_counts = self.kwargs.get("page_counts", 20)
+        cursor = self.kwargs.get("cursor", 0)
+        page_counts = self.kwargs.get("page_counts", 30)
         max_counts = self.kwargs.get("max_counts")
 
-        sec_user_id = await SecUserIdFetcher.get_sec_user_id(self.kwargs.get("url"))
-
-        async with AsyncUserDB("douyin_users.db") as db:
-            user_path = await self.get_or_add_user_data(self.kwargs, sec_user_id, db)
-
-        async for aweme_data_list in self.fetch_user_feed_videos(
-            sec_user_id, max_cursor, page_counts, max_counts
-        ):
-            # åˆ›å»ºä¸‹è½½ä»»åŠ¡
-            await self.downloader.create_download_tasks(
-                self.kwargs, aweme_data_list, user_path
-            )
+        secUid = await SecUserIdFetcher.get_secuid(self.kwargs.get("url"))
+        playlist = await self.fetch_play_list(secUid, cursor, page_counts)
+        mixId = await self.select_playlist(playlist)
+
+        async with AsyncUserDB("tiktok_users.db") as audb:
+            user_path = await self.get_or_add_user_data(secUid, audb)
+
+        if isinstance(mixId, str):
+            mixId = [mixId]
+
+        for mixId in playlist.get("mixId", []):
+            async for aweme_data_list in self.fetch_user_mix_videos(
+                mixId, cursor, page_counts, max_counts
+            ):
+                # åˆ›å»ºä¸‹è½½ä»»åŠ¡
+                await self.downloader.create_download_tasks(
+                    self.kwargs, aweme_data_list._to_list(), user_path
+                )
 
-    async def fetch_user_feed_videos(
-        self,
-        sec_user_id: str,
-        max_cursor: int = 0,
-        page_counts: int = 20,
-        max_counts: int = None,
-    ) -> AsyncGenerator[List[Dict[str, Any]], None]:
-        """
-        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·feedçš„è§†é¢‘åˆ—è¡¨ã€‚
+    async def fetch_user_mix_videos(
+        self, mixId: str, cursor: int, page_counts: int, max_counts: float
+    ) -> AsyncGenerator[UserMixFilter, Any]:
+        """
+        ç”¨äºè·å–æŒ‡å®šç”¨æˆ·åˆé›†çš„ä½œå“åˆ—è¡¨
+        (Used to get mix video list of specified user)
 
         Args:
-            sec_user_id: str: ç”¨æˆ·ID
-            max_cursor: int: èµ·å§‹é¡µ
-            page_counts: int: æ¯é¡µè§†é¢‘æ•°
-            max_counts: int: æœ€å¤§è§†é¢‘æ•°
+            mixId: str: åˆé›†ID (Mix ID)
+            cursor: int: åˆ†é¡µæ¸¸æ ‡ (Page cursor)
+            page_counts: int: åˆ†é¡µæ•°é‡ (Page counts)
+            max_counts: float: æœ€å¤§æ•°é‡ (Max counts)
 
         Return:
-            aweme_data: dict: è§†é¢‘æ•°æ®å­—å…¸ï¼ŒåŒ…å«è§†é¢‘IDåˆ—è¡¨ã€è§†é¢‘æ–‡æ¡ˆã€ä½œè€…æ˜µç§°ã€èµ·å§‹é¡µ
+            mix: AsyncGenerator[UserMixFilter, Any]: åˆé›†ä½œå“ä¿¡æ¯è¿‡æ»¤å™¨ (Video info filter)
         """
 
         max_counts = max_counts or float("inf")
         videos_collected = 0
 
-        logger.debug(_("å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} feedçš„è§†é¢‘").format(sec_user_id))
+        logger.debug(_("å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} åˆé›†çš„ä½œå“").format(mixId))
 
         while videos_collected < max_counts:
             current_request_size = min(page_counts, max_counts - videos_collected)
 
-            logger.debug("=====================================")
+            logger.debug("===================================")
             logger.debug(
                 _("æœ€å¤§æ•°é‡: {0} æ¯æ¬¡è¯·æ±‚æ•°é‡: {1}").format(
                     max_counts, current_request_size
                 )
             )
-            logger.debug(_("å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ").format(max_cursor))
+            logger.debug(_("å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ").format(cursor))
 
-            async with DouyinCrawler(self.kwargs) as crawler:
-                params = UserPost(
-                    max_cursor=max_cursor,
-                    count=current_request_size,
-                    sec_user_id=sec_user_id,
-                )
-                response = await crawler.fetch_user_post(params)
-                video = UserPostFilter(response)
-
-            if not video.has_aweme:
-                logger.debug(_("{0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“".format(max_cursor)))
-                if not video.has_more:
-                    logger.debug(_("ç”¨æˆ·: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•".format(sec_user_id)))
-                    break
-
-                max_cursor = video.max_cursor
-                continue
+            async with TiktokCrawler(self.kwargs) as crawler:
+                params = UserMix(mixId=mixId, cursor=cursor, count=page_counts)
+                response = await crawler.fetch_user_mix(params)
+                mix = UserMixFilter(response)
 
-            logger.debug(_("å½“å‰è¯·æ±‚çš„max_cursor: {0}").format(max_cursor))
-            logger.debug(
-                _("è§†é¢‘ID: {0} è§†é¢‘æ–‡æ¡ˆ: {1} ä½œè€…: {2}").format(
-                    video.aweme_id, video.desc, video.nickname
+            if mix.has_aweme:
+                logger.debug(_("å½“å‰è¯·æ±‚çš„cursor: {0}").format(cursor))
+                logger.debug(
+                    _("ä½œå“ID: {0} ä½œå“æ–‡æ¡ˆ: {1} ä½œè€…: {2}").format(
+                        mix.aweme_id, mix.desc, mix.nickname
+                    )
                 )
-            )
-            logger.debug("=====================================")
-
-            aweme_data_list = video._to_list()
-            yield aweme_data_list
-
-            # æ›´æ–°å·²ç»å¤„ç†çš„è§†é¢‘æ•°é‡ (Update the number of videos processed)
-            videos_collected += len(video.aweme_id)
-            max_cursor = video.max_cursor
+                logger.debug("===================================")
 
-        logger.debug(_("çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å–{0}ä¸ªè§†é¢‘").format(videos_collected))
+                yield mix
 
+                # æ›´æ–°å·²ç»å¤„ç†çš„ä½œå“æ•°é‡ (Update the number of videos processed)
+                videos_collected += len(mix.aweme_id)
 
-async def handle_sso_login():
-    """
-    ç”¨äºå¤„ç†ç”¨æˆ·ç™»å½• (Used to process user login)
-    """
-
-    kwargs = {
-        "proxies": {"http": None, "https": None},
-        "cookie": "",
-        "headers": {
-            "Referer": "https://www.douyin.com/",
-            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML,like Gecko) Chrome/104.0.0.0 Safari/537.36",
-        },
-    }
-
-    async def get_qrcode() -> str:
-        params = LoginGetQr(verifyFp=verify_fp, fp=verify_fp)
-        async with DouyinCrawler(kwargs) as crawler:
-            response = await crawler.fetch_login_qrcode(params)
-            sso = GetQrcodeFilter(response)
-            show_qrcode(sso.qrcode_index_url)
-            return await check_qrcode(sso.token, crawler)
-
-    async def check_qrcode(token: str, crawler) -> bool:
-        """
-        æ£€æŸ¥äºŒç»´ç çŠ¶æ€
-
-        Args:
-            token (str): äºŒç»´ç token
-
-        Returns:
-            bool: æ˜¯å¦æˆåŠŸç™»å½•
-        """
-        logger.debug(f"check_qrcode token:{token}")
-
-        status_mapping = {
-            "1": {"message": _("[  ç™»å½•  ]:ç­‰å¾…äºŒç»´ç æ‰«æï¼"), "log": logger.info},
-            "2": {"message": _("[  ç™»å½•  ]:æ‰«æäºŒç»´ç æˆåŠŸï¼"), "log": logger.info},
-            "3": {"message": _("[  ç™»å½•  ]:ç¡®è®¤äºŒç»´ç ç™»å½•ï¼"), "log": logger.info},
-            "4": {
-                "message": _("[  ç™»å½•  ]:è®¿é—®é¢‘ç¹ï¼Œè¯·æ£€æŸ¥å‚æ•°ï¼"),
-                "log": logger.warning,
-            },
-            "5": {
-                "message": _("[  ç™»å½•  ]:äºŒç»´ç è¿‡æœŸï¼Œé‡æ–°è·å–ï¼"),
-                "log": logger.warning,
-            },
-            "2046": {
-                "messages": _("[  ç™»å½•  ]:æ‰«ç ç¯å¢ƒå¼‚å¸¸ï¼Œè¯·å‰å¾€appéªŒè¯ï¼"),
-                "log": logger.warning,
-            },
-        }
-
-        while True:
-            params = LoginCheckQr(token=token, verifyFp=verify_fp, fp=verify_fp)
-            check_response = await crawler.fetch_check_qrcode(params)
-            check = CheckQrcodeFilter(check_response.json())
-            check_status = check.status
-            check_status = "2046" if check_status is None else check_status
-
-            status_info = status_mapping.get(check_status, {})
-            message = status_info.get("message", "")
-            log_func = status_info.get("log", logger.info)
-            logger.info(message)
-            log_func(message)
-
-            if check_status == "3":
-                login_cookies = split_set_cookie(
-                    check_response.headers.get("set-cookie", "")
-                )
-                is_login, login_cookie = await login_redirect(
-                    check.redirect_url, login_cookies, crawler
-                )
-                return is_login, login_cookie
-            elif check_status == "5":
-                get_qrcode()
-                break
-            elif check_status is None:
-                break
-
-            await asyncio.sleep(5)
-
-    async def login_redirect(redirect_url: str, login_cookies: str, crawler):
-        """
-        ç™»å½•é‡å®šå‘ï¼Œè·å–ç™»å½•åCookie
+                if not mix.hasMore and str(mix.api_status_code) == "0":
+                    logger.debug(_("åˆè¾‘: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•").format(mixId))
+                    break
 
-        Args:
-            redirect_url (str): é‡å®šå‘url
-            login_cookies (str): ç™»å½•cookie
+            else:
+                logger.debug(_("ç¬¬ {0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“").format(cursor))
 
-        Returns:
-            is_login (bool): æ˜¯å¦æˆåŠŸç™»å½•
-            login_cookie (str): ç™»å½•cookie
-        """
-        crawler.headers["Cookie"] = login_cookies
-        redirect_response = await crawler.get_fetch_data(redirect_url)
+                if not mix.hasMore and str(mix.api_status_code) == "0":
+                    logger.debug(_("åˆè¾‘: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•").format(mixId))
+                    break
 
-        if redirect_response.history and len(redirect_response.history) > 1:
-            logger.debug(f"login_redirect headers:{redirect_response.headers}")
-            logger.debug(f"login_redirect history:{redirect_response.history}")
-            logger.debug(
-                f"login_redirect history[0] headers:{redirect_response.history[0].headers}"
-            )
-            logger.debug(
-                f"login_redirect history[1] headers:{redirect_response.history[1].headers}"
-            )
-            # è·å–é‡æœ€åä¸€ä¸ªé‡å®šå‘é‡Œçš„Cookie
-            login_cookie = split_set_cookie(
-                redirect_response.history[1].headers.get("set-cookie", "")
-            )
-            logger.debug(f"login_cookie:{login_cookie}")
-            return True, login_cookie
-        else:
-            logger.warning("[  ç™»å½•  ]:è‡ªåŠ¨é‡å®šå‘ç™»å½•å¤±è´¥")
-            if redirect_response:
-                error_message = f"ç½‘ç»œå¼‚å¸¸: è‡ªåŠ¨é‡å®šå‘ç™»å½•å¤±è´¥ã€‚ çŠ¶æ€ç : {redirect_response.status_code}, å“åº”ä½“: {redirect_response.text}"
-            else:
-                error_message = f"ç½‘ç»œå¼‚å¸¸: è‡ªåŠ¨é‡å®šå‘ç™»å½•å¤±è´¥ã€‚ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ã€‚"
-            logger.warning(error_message)
-            return False, ""
+            # æ›´æ–°å·²ç»å¤„ç†çš„ä½œå“æ•°é‡ (Update the number of videos processed)
+            videos_collected += len(mix.aweme_id)
+            cursor = mix.cursor
 
-    verify_fp = VerifyFpManager.gen_verify_fp()
-    return await get_qrcode()
+        logger.debug(_("çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªä½œå“").format(videos_collected))
 
 
 async def main(kwargs):
     mode = kwargs.get("mode")
     if mode in mode_function_map:
-        await mode_function_map[mode](DouyinHandler(kwargs))
+        await mode_function_map[mode](TiktokHandler(kwargs))
     else:
         logger.error(_("ä¸å­˜åœ¨è¯¥æ¨¡å¼: {0}").format(mode))
+        rich_console.print(_("ä¸å­˜åœ¨è¯¥æ¨¡å¼: {0}").format(mode))
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/help.py` & `f2-0.0.1.5/f2/apps/tiktok/help.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# path: f2/apps/douyin/help.py
+# path: f2/apps/tiktok/help.py
 
 from rich.console import Console
 from rich.panel import Panel
 from rich.table import Table
 
 from f2.i18n.translator import _
 
@@ -33,15 +33,15 @@
             "[dark_cyan]Choice",
             _("æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ã€‚å¯é€‰ï¼š'yes'ã€'no'"),
         ),
         (
             "-M --mode",
             "[dark_cyan]Choice",
             _(
-                "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“(collect)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
+                "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post), ç‚¹èµä½œå“(like), æ”¶è—ä½œå“(collect), åˆè¾‘æ’­æ”¾åˆ—è¡¨(mix)"
             ),
         ),
         (
             "-n --naming",
             "[dark_cyan]str",
             _("å…¨å±€ä½œå“æ–‡ä»¶å‘½åæ–¹å¼ï¼Œå‰å¾€æ–‡æ¡£æŸ¥çœ‹æ›´å¤šå¸®åŠ©"),
         ),
@@ -59,15 +59,19 @@
                 "ä¸‹è½½æ—¥æœŸåŒºé—´å‘å¸ƒçš„ä½œå“ï¼Œæ ¼å¼ï¼š2022-01-01|2023-01-01ï¼Œ'all' ä¸ºä¸‹è½½æ‰€æœ‰ä½œå“"
             ),
         ),
         ("-e --timeout", "[dark_cyan]int", _("ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ã€‚")),
         ("-r --max-retries", "[dark_cyan]int", _("ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°ã€‚")),
         ("-x --max-connections", "[dark_cyan]int", _("ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°ã€‚")),
         ("-t --max-tasks", "[dark_cyan]int", _("å¼‚æ­¥çš„ä»»åŠ¡æ•°ã€‚")),
-        ("-o --max-counts", "[dark_cyan]int", _("æœ€å¤§ä½œå“ä¸‹è½½æ•°ã€‚0 è¡¨ç¤ºæ— é™åˆ¶")),
+        (
+            "-o --max-counts",
+            "[dark_cyan]int",
+            _("æœ€å¤§ä½œå“ä¸‹è½½æ•°ã€‚0 è¡¨ç¤ºæ— é™åˆ¶"),
+        ),
         (
             "-s --page-counts",
             "[dark_cyan]int",
             _("ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20ã€‚"),
         ),
         (
             "-l --languages",
@@ -91,31 +95,26 @@
             "[dark_cyan]Flag",
             _("åˆå§‹åŒ–é…ç½®æ–‡ä»¶ã€‚ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶"),
         ),
         (
             "--auto-cookie",
             "[dark_cyan]Choice",
             _(
-                "è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
+                "è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
             ),
         ),
-        (
-            "--sso-login",
-            "[dark_cyan]Flag",
-            _("ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–[yellow]cookie[/yellow]ï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"),
-        ),
         ("--help", "[dark_cyan]Flag", _("æ˜¾ç¤ºç»å…¸å¸®åŠ©ä¿¡æ¯")),
         (
             "",
             "",
             _(
                 "æ›´åŠ è¯¦ç»†çš„å‚æ•°è¯´æ˜è¯·ç‚¹å‡»[link=https://johnserf-seed.github.io/f2/site-config.html][dark_violet]å‰å¾€æ–‡æ¡£[/dark_violet][/]æŸ¥çœ‹"
             ),
         ),
     ]
 
     for option in options:
         table.add_row(*option)
 
     console.print(
-        Panel(table, border_style="bold", title="[DouYin]", title_align="left")
+        Panel(table, border_style="bold", title="[TikTok]", title_align="left")
     )
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/model.py` & `f2-0.0.1.5/f2/apps/douyin/model.py`

 * *Files 18% similar despite different names*

```diff
@@ -8,26 +8,26 @@
 
 # Base Model
 class BaseRequestModel(BaseModel):
     device_platform: str = "webapp"
     aid: str = "6383"
     channel: str = "channel_pc_web"
     pc_client_type: int = 1
-    version_code: str = "170400"
-    version_name: str = "17.4.0"
+    version_code: str = "190500"
+    version_name: str = "19.5.0"
     cookie_enabled: str = "true"
     screen_width: int = 1920
     screen_height: int = 1080
     browser_language: str = "zh-CN"
     browser_platform: str = "Win32"
     browser_name: str = "Edge"
-    browser_version: str = "117.0.2045.47"
+    browser_version: str = "122.0.0.0"
     browser_online: str = "true"
     engine_name: str = "Blink"
-    engine_version: str = "117.0.0.0"
+    engine_version: str = "122.0.0.0"
     os_name: str = "Windows"
     os_version: str = "10"
     cpu_core_num: int = 12
     device_memory: int = 8
     platform: str = "PC"
     downlink: int = 10
     effective_type: str = "4g"
@@ -59,14 +59,15 @@
     type_id: str = "0"
     live_id: str = "1"
     sec_user_id: str = ""
     version_code: str = "99.99.99"
     app_id: str = "1128"
     msToken: str = TokenManager.gen_real_msToken()
 
+
 class BaseLoginModel(BaseModel):
     service: str = "https://www.douyin.com"
     need_logo: str = "false"
     need_short_url: str = "true"
     device_platform: str = "web_app"
     aid: str = "6383"
     account_sdk_source: str = "sso"
@@ -87,20 +88,39 @@
 
 class UserLike(BaseRequestModel):
     max_cursor: int
     count: int
     sec_user_id: str
 
 
-class UserCollect(BaseRequestModel):
+class UserCollection(BaseRequestModel):
     # POST
     cursor: int
     count: int
 
 
+class UserCollects(BaseRequestModel):
+    # GET
+    cursor: int
+    count: int
+
+
+class UserCollectsVideo(BaseRequestModel):
+    # GET
+    cursor: int
+    count: int
+    collects_id: str
+
+
+class UserMusicCollection(BaseRequestModel):
+    # GET
+    cursor: int
+    count: int
+
+
 class UserMix(BaseRequestModel):
     cursor: int
     count: int
     mix_id: str
 
 
 class FriendFeed(BaseRequestModel):
@@ -171,14 +191,15 @@
     publish_video_strategy_type: int = 2
 
 
 class UserLive(BaseLiveModel):
     web_rid: str
     room_id_str: str
 
+
 class UserLive2(BaseLiveModel2):
     room_id: str
 
 
 class FollowUserLive(BaseRequestModel):
     scene: str = "aweme_pc_follow_top"
 
@@ -206,12 +227,41 @@
 
 
 class LoginGetQr(BaseLoginModel):
     verifyFp: str = ""
     fp: str = ""
     # msToken: str = TokenManager.gen_real_msToken()
 
+
 class LoginCheckQr(BaseLoginModel):
     token: str = ""
     verifyFp: str = ""
     fp: str = ""
-    # msToken: str = TokenManager.gen_real_msToken()
+    # msToken: str = TokenManager.gen_real_msToken()
+
+
+class UserFollowing(BaseRequestModel):
+    user_id: str = ""
+    sec_user_id: str = ""
+    offset: int = 0  # ç›¸å½“äºcursor
+    min_time: int = 0
+    max_time: int = 0
+    count: int = 20
+    # source_type = 1: æœ€è¿‘å…³æ³¨ éœ€è¦æŒ‡å®šmax_time(s) 3: æœ€æ—©å…³æ³¨ éœ€è¦æŒ‡å®šmin_time(s) 4: ç»¼åˆæ’åº
+    source_type: int = 4
+    gps_access: int = 0
+    address_book_access: int = 0
+    is_top: int = 1
+
+
+class UserFollower(BaseRequestModel):
+    user_id: str
+    sec_user_id: str
+    offset: int = 0  # ç›¸å½“äºcursor ä½†åªå¯¹source_type: = 2 æœ‰æ•ˆï¼Œå…¶ä»–æƒ…å†µä¸º 0 å³å¯
+    min_time: int = 0
+    max_time: int = 0
+    count: int = 20
+    # source_type = 1: æœ€è¿‘å…³æ³¨ éœ€è¦æŒ‡å®šmax_time(s) 2: ç»¼åˆå…³æ³¨(æ„ä¹‰ä¸æ˜)
+    source_type: int = 1
+    gps_access: int = 0
+    address_book_access: int = 0
+    is_top: int = 1
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/utils.py` & `f2-0.0.1.5/f2/apps/tiktok/utils.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,16 +1,13 @@
-# path: f2/apps/douyin/utils.py
+# path: f2/apps/tiktok/utils.py
 
 import f2
 import re
 import json
-import time
 import httpx
-import qrcode
-import random
 import asyncio
 
 from typing import Union
 from pathlib import Path
 
 from f2.i18n.translator import _
 from f2.log.logger import logger
@@ -22,24 +19,24 @@
     extract_valid_urls,
     split_filename,
 )
 from f2.exceptions.api_exceptions import (
     APIError,
     APIConnectionError,
     APIResponseError,
-    APIUnavailableError,
     APIUnauthorizedError,
     APINotFoundError,
 )
 
 
 class TokenManager:
-    f2_manager = ConfigManager(f2.F2_CONFIG_FILE_PATH).get_config("f2").get("douyin")
+    f2_manager = ConfigManager(f2.F2_CONFIG_FILE_PATH).get_config("f2").get("tiktok")
     token_conf = f2_manager.get("msToken", None)
     ttwid_conf = f2_manager.get("ttwid", None)
+    odin_tt_conf = f2_manager.get("odin_tt", None)
     proxies_conf = f2_manager.get("proxies", None)
     proxies = {
         "http://": proxies_conf.get("http", None),
         "https://": proxies_conf.get("https", None),
     }
 
     @classmethod
@@ -54,467 +51,506 @@
                 "magic": cls.token_conf["magic"],
                 "version": cls.token_conf["version"],
                 "dataType": cls.token_conf["dataType"],
                 "strData": cls.token_conf["strData"],
                 "tspFromClient": get_timestamp(),
             }
         )
+
         headers = {
             "User-Agent": cls.token_conf["User-Agent"],
             "Content-Type": "application/json",
         }
 
         transport = httpx.HTTPTransport(retries=5)
         with httpx.Client(transport=transport, proxies=cls.proxies) as client:
             try:
                 response = client.post(
                     cls.token_conf["url"], headers=headers, content=payload
                 )
-
-                if response.status_code == 401:
-                    raise APIUnauthorizedError(_("ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–msToken"))
-                elif response.status_code == 404:
-                    raise APINotFoundError(_("æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"))
+                response.raise_for_status()
 
                 msToken = str(httpx.Cookies(response.cookies).get("msToken"))
 
-                if len(msToken) not in [120, 128]:
-                    raise APIResponseError(
-                        _(
-                            "msToken: è¯·æ£€æŸ¥å¹¶æ›´æ–° f2 ä¸­ conf.yaml é…ç½®æ–‡ä»¶ä¸­çš„ msTokenï¼Œä»¥åŒ¹é… douyin æ–°è§„åˆ™ã€‚"
-                        )
-                    )
+                if len(msToken) not in [148]:
+                    raise APIResponseError(_("{0} å†…å®¹ä¸ç¬¦åˆè¦æ±‚").format("msToken"))
 
                 return msToken
 
-            except httpx.RequestError:
+            except httpx.RequestError as exc:
                 # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
                 raise APIConnectionError(
                     _(
-                        "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
-                    ).format(cls.token_conf["url"], cls.proxies, cls.__name__)
+                        "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                    ).format(cls.token_conf["url"], cls.proxies, cls.__name__, exc)
                 )
 
             except httpx.HTTPStatusError as e:
                 # æ•è· httpx çš„çŠ¶æ€ä»£ç é”™è¯¯ (captures specific status code errors from httpx)
-                raise APIResponseError(
-                    f"HTTP Status Code {e.response.status_code}: {e.response.text}"
-                )
+                if response.status_code == 401:
+                    raise APIUnauthorizedError(
+                        _(
+                            "å‚æ•°éªŒè¯å¤±è´¥ï¼Œè¯·æ›´æ–° F2 é…ç½®æ–‡ä»¶ä¸­çš„ {0}ï¼Œä»¥åŒ¹é… {1} æ–°è§„åˆ™"
+                        ).format("msToken", "tiktok")
+                    )
+
+                elif response.status_code == 404:
+                    raise APINotFoundError(_("{0} æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹").format("msToken"))
+                else:
+                    raise APIResponseError(
+                        _("é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} ").format(
+                            e.response.url, e.response.status_code, e.response.text
+                        )
+                    )
 
             except APIError as e:
+                # è¿”å›è™šå‡çš„msToken (Return a fake msToken)
+                logger.error(_("msToken APIé”™è¯¯ï¼š{0}").format(e))
                 logger.info(_("ç”Ÿæˆè™šå‡çš„msToken"))
                 return cls.gen_false_msToken()
 
     @classmethod
     def gen_false_msToken(cls) -> str:
         """ç”ŸæˆéšæœºmsToken (Generate random msToken)"""
-        return gen_random_str(126) + "=="
+        return gen_random_str(146) + "=="
 
     @classmethod
     def gen_ttwid(cls) -> str:
         """
-        ç”Ÿæˆè¯·æ±‚å¿…å¸¦çš„ttwid
-        (Generate the essential ttwid for requests)
+        ç”Ÿæˆè¯·æ±‚å¿…å¸¦çš„ttwid (Generate the essential ttwid for requests)
         """
-
         transport = httpx.HTTPTransport(retries=5)
-        with httpx.Client(transport=transport) as client:
+        with httpx.Client(transport=transport, proxies=cls.proxies) as client:
             try:
                 response = client.post(
-                    cls.ttwid_conf["url"], content=cls.ttwid_conf["data"]
+                    cls.ttwid_conf["url"],
+                    content=cls.ttwid_conf["data"],
+                    headers={
+                        "Cookie": cls.ttwid_conf.get("cookie"),
+                        "Content-Type": "text/plain",
+                    },
                 )
+                response.raise_for_status()
 
-                if response.status_code == 401:
-                    raise APIUnauthorizedError(_("ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–ttwid"))
-                elif response.status_code == 404:
-                    raise APINotFoundError(_("æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"))
+                ttwid = httpx.Cookies(response.cookies).get("ttwid")
+
+                if ttwid is None:
+                    raise APIResponseError(
+                        _("ttwid: æ£€æŸ¥æ²¡æœ‰é€šè¿‡, è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„ttwid")
+                    )
 
-                ttwid = str(httpx.Cookies(response.cookies).get("ttwid"))
                 return ttwid
 
-            except httpx.RequestError:
+            except httpx.RequestError as exc:
                 # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
                 raise APIConnectionError(
                     _(
-                        "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
-                    ).format(cls.ttwid_conf["url"], cls.proxies, cls.__name__)
+                        "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                    ).format(cls.ttwid_conf["url"], cls.proxies, cls.__name__, exc)
                 )
 
             except httpx.HTTPStatusError as e:
                 # æ•è· httpx çš„çŠ¶æ€ä»£ç é”™è¯¯ (captures specific status code errors from httpx)
-                raise APIResponseError(
-                    f"HTTP Status Code {e.response.status_code}: {e.response.text}"
-                )
+                if response.status_code == 401:
+                    raise APIUnauthorizedError(
+                        _(
+                            "å‚æ•°éªŒè¯å¤±è´¥ï¼Œè¯·æ›´æ–° F2 é…ç½®æ–‡ä»¶ä¸­çš„ {0}ï¼Œä»¥åŒ¹é… {1} æ–°è§„åˆ™"
+                        ).format("ttwid", "tiktok")
+                    )
 
+                elif response.status_code == 404:
+                    raise APINotFoundError(_("{0} æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹").format("ttwid"))
+                else:
+                    raise APIResponseError(
+                        _("é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} ").format(
+                            e.response.url, e.response.status_code, e.response.text
+                        )
+                    )
 
-class VerifyFpManager:
     @classmethod
-    def gen_verify_fp(cls) -> str:
+    def gen_odin_tt(cls):
         """
-        ç”ŸæˆverifyFp ä¸ s_v_web_id (Generate verifyFp)
+        ç”Ÿæˆè¯·æ±‚å¿…å¸¦çš„odin_tt (Generate the essential odin_tt for requests)
         """
-        base_str = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
-        t = len(base_str)
-        milliseconds = int(round(time.time() * 1000))
-        base36 = ""
-        while milliseconds > 0:
-            remainder = milliseconds % 36
-            if remainder < 10:
-                base36 = str(remainder) + base36
-            else:
-                base36 = chr(ord("a") + remainder - 10) + base36
-            milliseconds = int(milliseconds / 36)
-        r = base36
-        o = [""] * 36
-        o[8] = o[13] = o[18] = o[23] = "_"
-        o[14] = "4"
+        transport = httpx.HTTPTransport(retries=5)
+        with httpx.Client(transport=transport, proxies=cls.proxies) as client:
+            try:
+                response = client.get(cls.odin_tt_conf["url"])
+                response.raise_for_status()
 
-        for i in range(36):
-            if not o[i]:
-                n = 0 or int(random.random() * t)
-                if i == 19:
-                    n = 3 & n | 8
-                o[i] = base_str[n]
+                odin_tt = httpx.Cookies(response.cookies).get("odin_tt")
 
-        return "verify_" + r + "_" + "".join(o)
+                if odin_tt is None:
+                    raise APIResponseError(_("{0} å†…å®¹ä¸ç¬¦åˆè¦æ±‚").format("odin_tt"))
 
-    @classmethod
-    def gen_s_v_web_id(cls) -> str:
-        return cls.gen_verify_fp()
+                return odin_tt
+
+            except httpx.RequestError as exc:
+                # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
+                raise APIConnectionError(
+                    _(
+                        "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                    ).format(cls.odin_tt_conf["url"], cls.proxies, cls.__name__, exc)
+                )
+
+            except httpx.HTTPStatusError as e:
+                # æ•è· httpx çš„çŠ¶æ€ä»£ç é”™è¯¯ (captures specific status code errors from httpx)
+                if response.status_code == 401:
+                    raise APIUnauthorizedError(
+                        _(
+                            "å‚æ•°éªŒè¯å¤±è´¥ï¼Œè¯·æ›´æ–° F2 é…ç½®æ–‡ä»¶ä¸­çš„ {0}ï¼Œä»¥åŒ¹é… {1} æ–°è§„åˆ™"
+                        ).format("odin_tt", "tiktok")
+                    )
+
+                elif response.status_code == 404:
+                    raise APINotFoundError(_("{0} æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹").format("odin_tt"))
+                else:
+                    raise APIResponseError(
+                        _("é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} ").format(
+                            e.response.url, e.response.status_code, e.response.text
+                        )
+                    )
 
 
 class XBogusManager:
     @classmethod
-    def str_2_endpoint(cls, endpoint: str) -> str:
+    def str_2_endpoint(
+        cls,
+        user_agent: str,
+        endpoint: str,
+    ) -> str:
         try:
-            final_endpoint = XB().getXBogus(endpoint)
+            final_endpoint = XB(user_agent).getXBogus(endpoint)
         except Exception as e:
             raise RuntimeError(_("ç”ŸæˆX-Boguså¤±è´¥: {0})").format(e))
 
         return final_endpoint[0]
 
     @classmethod
-    def model_2_endpoint(cls, base_endpoint: str, params: dict) -> str:
+    def model_2_endpoint(
+        cls,
+        user_agent: str,
+        base_endpoint: str,
+        params: dict,
+    ) -> str:
+        # æ£€æŸ¥paramsæ˜¯å¦æ˜¯ä¸€ä¸ªå­—å…¸ (Check if params is a dict)
         if not isinstance(params, dict):
             raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯å­—å…¸ç±»å‹"))
 
         param_str = "&".join([f"{k}={v}" for k, v in params.items()])
 
         try:
-            xb_value = XB().getXBogus(param_str)
+            xb_value = XB(user_agent).getXBogus(param_str)
         except Exception as e:
             raise RuntimeError(_("ç”ŸæˆX-Boguså¤±è´¥: {0})").format(e))
 
         # æ£€æŸ¥base_endpointæ˜¯å¦å·²æœ‰æŸ¥è¯¢å‚æ•° (Check if base_endpoint already has query parameters)
         separator = "&" if "?" in base_endpoint else "?"
 
         final_endpoint = f"{base_endpoint}{separator}{param_str}&X-Bogus={xb_value[1]}"
 
         return final_endpoint
 
 
 class SecUserIdFetcher:
     # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
-    _DOUYIN_URL_PATTERN = re.compile(r"user/([^/?]*)")
-    _REDIRECT_URL_PATTERN = re.compile(r"sec_uid=([^&]*)")
+    _TIKTOK_SECUID_PARREN = re.compile(
+        r"<script id=\"__UNIVERSAL_DATA_FOR_REHYDRATION__\" type=\"application/json\">(.*?)</script>"
+    )
+    _TIKTOK_UNIQUEID_PARREN = re.compile(r"/@([^/?]*)")
+    _TIKTOK_NOTFOUND_PARREN = re.compile(r"notfound")
 
     @classmethod
-    async def get_sec_user_id(cls, url: str) -> str:
+    async def get_secuid(cls, url: str) -> str:
         """
-        ä»å•ä¸ªurlä¸­è·å–sec_user_id (Get sec_user_id from a single url)
-
+        è·å–TikTokç”¨æˆ·sec_uid
         Args:
-            url (str): è¾“å…¥çš„url (Input url)
-
-        Returns:
-            str: åŒ¹é…åˆ°çš„sec_user_id (Matched sec_user_id)ã€‚
+            url: ç”¨æˆ·ä¸»é¡µé“¾æ¥
+        Return:
+            sec_uid: ç”¨æˆ·å”¯ä¸€æ ‡è¯†
         """
 
+        # è¿›è¡Œå‚æ•°æ£€æŸ¥
         if not isinstance(url, str):
-            raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"))
+            raise TypeError("è¾“å…¥å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
 
         # æå–æœ‰æ•ˆURL
         url = extract_valid_urls(url)
 
         if url is None:
             raise (
-                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__)))
+                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__))
             )
 
-        pattern = (
-            cls._REDIRECT_URL_PATTERN
-            if "v.douyin.com" in url
-            else cls._DOUYIN_URL_PATTERN
-        )
-
-        try:
-            transport = httpx.AsyncHTTPTransport(retries=5)
-            async with httpx.AsyncClient(
-                transport=transport, proxies=TokenManager.proxies, timeout=10
-            ) as client:
+        transport = httpx.AsyncHTTPTransport(retries=5)
+        async with httpx.AsyncClient(
+            transport=transport, proxies=TokenManager.proxies, timeout=10
+        ) as client:
+            try:
                 response = await client.get(url, follow_redirects=True)
-
+                # 444ä¸€èˆ¬ä¸ºNginxæ‹¦æˆªï¼Œä¸è¿”å›çŠ¶æ€ (444 is generally intercepted by Nginx and does not return status)
                 if response.status_code in {200, 444}:
-                    match = pattern.search(str(response.url))
-                    if match:
-                        return match.group(1)
-                    else:
+                    if cls._TIKTOK_NOTFOUND_PARREN.search(str(response.url)):
+                        raise APINotFoundError(
+                            _(
+                                "é¡µé¢ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯ç”±äºåŒºåŸŸé™åˆ¶ï¼ˆä»£ç†ï¼‰é€ æˆçš„ã€‚ç±»å: {0}"
+                            ).format(cls.__name__)
+                        )
+
+                    match = cls._TIKTOK_SECUID_PARREN.search(str(response.text))
+                    if not match:
                         raise APIResponseError(
                             _(
-                                "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_user_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»å: {0}".format(
-                                    cls.__name__
-                                )
-                            )
+                                "æœªåœ¨å“åº”ä¸­æ‰¾åˆ° {0}ï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µã€‚ç±»å: {1}"
+                            ).format("sec_uid", cls.__name__)
                         )
 
-                elif response.status_code == 401:
-                    raise APIUnauthorizedError(
-                        _("æœªæˆæƒçš„è¯·æ±‚ã€‚ç±»å: {0}".format(cls.__name__))
-                    )
-                elif response.status_code == 404:
-                    raise APINotFoundError(
-                        _("æœªæ‰¾åˆ°APIç«¯ç‚¹ã€‚ç±»å: {0}".format(cls.__name__))
-                    )
-                elif response.status_code == 503:
-                    raise APIUnavailableError(
-                        _("APIæœåŠ¡ä¸å¯ç”¨ã€‚ç±»å: {0}".format(cls.__name__))
-                    )
-                else:
-                    raise APIError(
-                        _("APIé”™è¯¯ç ï¼š{0}ã€‚ç±»å: {1}").format(
-                            response.status_code, cls.__name__
+                    # æå–SIGI_STATEå¯¹è±¡ä¸­çš„sec_uid
+                    data = json.loads(match.group(1))
+                    default_scope = data.get("__DEFAULT_SCOPE__", {})
+                    user_detail = default_scope.get("webapp.user-detail", {})
+                    user_info = user_detail.get("userInfo", {}).get("user", {})
+                    sec_uid = user_info.get("secUid")
+
+                    if sec_uid is None:
+                        raise RuntimeError(
+                            _("è·å– {0} å¤±è´¥ï¼Œ{1}").format(sec_uid, user_info)
                         )
-                    )
 
-        except httpx.RequestError:
-            raise APIConnectionError(
-                _(
-                    "è¿æ¥åˆ°APIæ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥URLæˆ–ç½‘ç»œæƒ…å†µã€‚ç±»å: {0}".format(
-                        cls.__name__
-                    )
-                ),
-                url,
-            )
+                    return sec_uid
+                else:
+                    raise ConnectionError(_("æ¥å£çŠ¶æ€ç å¼‚å¸¸, è¯·æ£€æŸ¥é‡è¯•"))
+
+            except httpx.RequestError as exc:
+                # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
+                raise APIConnectionError(
+                    _(
+                        "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                    ).format(url, TokenManager.proxies, cls.__name__, exc)
+                )
 
     @classmethod
-    async def get_all_sec_user_id(cls, urls: list) -> list:
+    async def get_all_secuid(cls, urls: list) -> list:
         """
-        è·å–åˆ—è¡¨sec_user_idåˆ—è¡¨ (Get list sec_user_id list)
+        è·å–åˆ—è¡¨secuidåˆ—è¡¨ (Get list sec_user_id list)
 
         Args:
             urls: list: ç”¨æˆ·urlåˆ—è¡¨ (User url list)
 
         Return:
-            sec_user_ids: list: ç”¨æˆ·sec_user_idåˆ—è¡¨ (User sec_user_id list)
+            secuids: list: ç”¨æˆ·secuidåˆ—è¡¨ (User secuid list)
         """
 
         if not isinstance(urls, list):
             raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹"))
 
         # æå–æœ‰æ•ˆURL
         urls = extract_valid_urls(urls)
 
         if urls == []:
             raise (
                 APINotFoundError(
-                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__))
+                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__)
                 )
             )
 
-        sec_user_ids = [cls.get_sec_user_id(url) for url in urls]
-        return await asyncio.gather(*sec_user_ids)
-
-
-class AwemeIdFetcher:
-    # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
-    _DOUYIN_VIDEO_URL_PATTERN = re.compile(r"video/([^/?]*)")
-    _DOUYIN_NOTE_URL_PATTERN = re.compile(r"note/([^/?]*)")
+        secuids = [cls.get_secuid(url) for url in urls]
+        return await asyncio.gather(*secuids)
 
     @classmethod
-    async def get_aweme_id(cls, url: str) -> str:
+    async def get_uniqueid(cls, url: str) -> str:
         """
-        ä»å•ä¸ªurlä¸­è·å–aweme_id (Get aweme_id from a single url)
-
+        è·å–TikTokç”¨æˆ·unique_id
         Args:
-            url (str): è¾“å…¥çš„url (Input url)
-
-        Returns:
-            str: åŒ¹é…åˆ°çš„aweme_id (Matched aweme_id)ã€‚
+            url: ç”¨æˆ·ä¸»é¡µé“¾æ¥
+        Return:
+            unique_id: ç”¨æˆ·å”¯ä¸€id
         """
 
+        # è¿›è¡Œå‚æ•°æ£€æŸ¥
         if not isinstance(url, str):
-            raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"))
+            raise TypeError("è¾“å…¥å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
 
         # æå–æœ‰æ•ˆURL
         url = extract_valid_urls(url)
 
         if url is None:
             raise (
-                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__)))
+                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__))
             )
 
-        # é‡å®šå‘åˆ°å®Œæ•´é“¾æ¥
         transport = httpx.AsyncHTTPTransport(retries=5)
         async with httpx.AsyncClient(
             transport=transport, proxies=TokenManager.proxies, timeout=10
         ) as client:
             try:
                 response = await client.get(url, follow_redirects=True)
 
-                video_pattern = cls._DOUYIN_VIDEO_URL_PATTERN
-                note_pattern = cls._DOUYIN_NOTE_URL_PATTERN
+                if response.status_code in {200, 444}:
+                    if cls._TIKTOK_NOTFOUND_PARREN.search(str(response.url)):
+                        raise APINotFoundError(
+                            _(
+                                "é¡µé¢ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯ç”±äºåŒºåŸŸé™åˆ¶ï¼ˆä»£ç†ï¼‰é€ æˆçš„ã€‚ç±»å: {0}"
+                            ).format(cls.__name__)
+                        )
 
-                match = video_pattern.search(str(response.url))
-                if match:
-                    aweme_id = match.group(1)
-                else:
-                    match = note_pattern.search(str(response.url))
-                    if match:
-                        aweme_id = match.group(1)
-                    else:
+                    match = cls._TIKTOK_UNIQUEID_PARREN.search(str(response.url))
+                    if not match:
                         raise APIResponseError(
-                            _("æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°aweme_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºä½œå“é¡µ")
+                            _("æœªåœ¨å“åº”ä¸­æ‰¾åˆ° {0}").format("unique_id")
                         )
-                return aweme_id
+
+                    unique_id = match.group(1)
+
+                    if unique_id is None:
+                        raise RuntimeError(
+                            _("è·å– {0} å¤±è´¥ï¼Œ{1}").format("unique_id", response.url)
+                        )
+
+                    return unique_id
+                else:
+                    raise ConnectionError(
+                        _("æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}, è¯·æ£€æŸ¥é‡è¯•").format(response.status_code)
+                    )
 
             except httpx.RequestError:
                 raise APIConnectionError(
                     _(
                         "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
-                    ).format(
-                        url,
-                        TokenManager.proxies,
-                        cls.__name__,
-                    )
+                    ).format(url, TokenManager.proxies, cls.__name__),
                 )
 
     @classmethod
-    async def get_all_aweme_id(cls, urls: list) -> list:
+    async def get_all_uniqueid(cls, urls: list) -> list:
         """
-        è·å–è§†é¢‘aweme_id,ä¼ å…¥åˆ—è¡¨urléƒ½å¯ä»¥è§£æå‡ºaweme_id (Get video aweme_id, pass in the list url can parse out aweme_id)
+        è·å–åˆ—è¡¨unique_idåˆ—è¡¨ (Get list sec_user_id list)
 
         Args:
-            urls: list: åˆ—è¡¨url (list url)
+            urls: list: ç”¨æˆ·urlåˆ—è¡¨ (User url list)
 
         Return:
-            aweme_ids: list: è§†é¢‘çš„å”¯ä¸€æ ‡è¯†ï¼Œè¿”å›åˆ—è¡¨ (The unique identifier of the video, return list)
+            unique_ids: list: ç”¨æˆ·unique_idåˆ—è¡¨ (User unique_id list)
         """
 
         if not isinstance(urls, list):
             raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹"))
 
         # æå–æœ‰æ•ˆURL
         urls = extract_valid_urls(urls)
 
         if urls == []:
             raise (
                 APINotFoundError(
-                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__))
+                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__)
                 )
             )
 
-        aweme_ids = [cls.get_aweme_id(url) for url in urls]
-        return await asyncio.gather(*aweme_ids)
-
+        unique_ids = [cls.get_uniqueid(url) for url in urls]
+        return await asyncio.gather(*unique_ids)
 
-class MixIdFetcher:
-    @classmethod
-    async def get_mix_id(cls, url: str) -> str:
-        return
 
+class AwemeIdFetcher:
+    # https://www.tiktok.com/@scarlettjonesuk/video/7255716763118226715
+    # https://www.tiktok.com/@scarlettjonesuk/video/7255716763118226715?is_from_webapp=1&sender_device=pc&web_id=7306060721837852167
 
-class WebCastIdFetcher:
     # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
-    _DOUYIN_LIVE_URL_PATTERN = re.compile(r"live/([^/?]*)")
-    # https://live.douyin.com/766545142636?cover_type=0&enter_from_merge=web_live&enter_method=web_card&game_name=&is_recommend=1&live_type=game&more_detail=&request_id=20231110224012D47CD00C18B4AE4BFF9B&room_id=7299828646049827596&stream_type=vertical&title_type=1&web_live_page=hot_live&web_live_tab=all
-    # https://live.douyin.com/766545142636
-    _DOUYIN_LIVE_URL_PATTERN2 = re.compile(r"https://live.douyin.com/(\d+)")
-    # https://webcast.amemv.com/douyin/webcast/reflow/7318296342189919011?u_code=l1j9bkbd&did=MS4wLjABAAAAEs86TBQPNwAo-RGrcxWyCdwKhI66AK3Pqf3ieo6HaxI&iid=MS4wLjABAAAA0ptpM-zzoliLEeyvWOCUt-_dQza4uSjlIvbtIazXnCY&with_sec_did=1&use_link_command=1&ecom_share_track_params=&extra_params={"from_request_id":"20231230162057EC005772A8EAA0199906","im_channel_invite_id":"0"}&user_id=3644207898042206&liveId=7318296342189919011&from=share&style=share&enter_method=click_share&roomId=7318296342189919011&activity_info={}
-    _DOUYIN_LIVE_URL_PATTERN3 = re.compile(r"reflow/([^/?]*)")
+    _TIKTOK_AWEMEID_PARREN = re.compile(r"video/(\d*)")
+    _TIKTOK_NOTFOUND_PARREN = re.compile(r"notfound")
 
     @classmethod
-    async def get_webcast_id(cls, url: str) -> str:
+    async def get_aweme_id(cls, url: str) -> str:
         """
-        ä»å•ä¸ªurlä¸­è·å–webcast_id (Get webcast_id from a single url)
-
+        è·å–TikTokä½œå“aweme_id
         Args:
-            url (str): è¾“å…¥çš„url (Input url)
-
-        Returns:
-            str: åŒ¹é…åˆ°çš„webcast_id (Matched webcast_id)ã€‚
+            url: ä½œå“é“¾æ¥
+        Return:
+            aweme_id: ä½œå“å”¯ä¸€æ ‡è¯†
         """
 
+        # è¿›è¡Œå‚æ•°æ£€æŸ¥
         if not isinstance(url, str):
-            raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"))
+            raise TypeError("è¾“å…¥å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
 
         # æå–æœ‰æ•ˆURL
         url = extract_valid_urls(url)
 
         if url is None:
             raise (
-                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__)))
+                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__))
             )
 
-        # é‡å®šå‘åˆ°å®Œæ•´é“¾æ¥
         transport = httpx.AsyncHTTPTransport(retries=5)
         async with httpx.AsyncClient(
             transport=transport, proxies=TokenManager.proxies, timeout=10
         ) as client:
-            response = await client.get(url, follow_redirects=True)
-            url = str(response.url)
+            try:
+                response = await client.get(url, follow_redirects=True)
 
-        live_pattern = cls._DOUYIN_LIVE_URL_PATTERN
-        live_pattern2 = cls._DOUYIN_LIVE_URL_PATTERN2
-        live_pattern3 = cls._DOUYIN_LIVE_URL_PATTERN3
-
-        if live_pattern.search(url):
-            match = live_pattern.search(url)
-        elif live_pattern2.search(url):
-            match = live_pattern2.search(url)
-        elif live_pattern3.search(url):
-            match = live_pattern3.search(url)
-            logger.debug(
-                _(
-                    "è¯¥é“¾æ¥è¿”å›çš„æ˜¯room_idï¼Œè¯·ä½¿ç”¨`fetch_user_live_videos_by_room_id`æ¥å£"
-                )
-            )
-        else:
-            raise APIResponseError(
-                _("æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°webcast_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç›´æ’­é¡µ")
-            )
+                if response.status_code in {200, 444}:
+                    if cls._TIKTOK_NOTFOUND_PARREN.search(str(response.url)):
+                        raise APINotFoundError(
+                            _(
+                                "é¡µé¢ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯ç”±äºåŒºåŸŸé™åˆ¶ï¼ˆä»£ç†ï¼‰é€ æˆçš„ã€‚ç±»å: {0}"
+                            ).format(cls.__name__)
+                        )
+
+                    match = cls._TIKTOK_AWEMEID_PARREN.search(str(response.url))
+                    if not match:
+                        raise APIResponseError(
+                            _("æœªåœ¨å“åº”ä¸­æ‰¾åˆ° {0}").format("aweme_id")
+                        )
+
+                    aweme_id = match.group(1)
 
-        return match.group(1)
+                    if aweme_id is None:
+                        raise RuntimeError(
+                            _("è·å– {0} å¤±è´¥ï¼Œ{1}").format("aweme_id", response.url)
+                        )
+
+                    return aweme_id
+                else:
+                    raise ConnectionError(
+                        _("æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}ï¼Œè¯·æ£€æŸ¥é‡è¯•").format(response.status_code)
+                    )
+
+            except httpx.RequestError as exc:
+                # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
+                raise APIConnectionError(
+                    _(
+                        "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                    ).format(url, TokenManager.proxies, cls.__name__, exc)
+                )
 
     @classmethod
-    async def get_all_webcast_id(cls, urls: list) -> list:
+    async def get_all_aweme_id(cls, urls: list) -> list:
         """
-        è·å–ç›´æ’­webcast_id,ä¼ å…¥åˆ—è¡¨urléƒ½å¯ä»¥è§£æå‡ºwebcast_id (Get live webcast_id, pass in the list url can parse out webcast_id)
+        è·å–è§†é¢‘aweme_id,ä¼ å…¥åˆ—è¡¨urléƒ½å¯ä»¥è§£æå‡ºaweme_id (Get video aweme_id, pass in the list url can parse out aweme_id)
 
         Args:
             urls: list: åˆ—è¡¨url (list url)
 
         Return:
-            webcast_ids: list: ç›´æ’­çš„å”¯ä¸€æ ‡è¯†ï¼Œè¿”å›åˆ—è¡¨ (The unique identifier of the live, return list)
+            aweme_ids: list: è§†é¢‘çš„å”¯ä¸€æ ‡è¯†ï¼Œè¿”å›åˆ—è¡¨ (The unique identifier of the video, return list)
         """
 
         if not isinstance(urls, list):
             raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹"))
 
         # æå–æœ‰æ•ˆURL
         urls = extract_valid_urls(urls)
 
         if urls == []:
             raise (
                 APINotFoundError(
-                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__))
+                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__)
                 )
             )
 
-        webcast_ids = [cls.get_webcast_id(url) for url in urls]
-        return await asyncio.gather(*webcast_ids)
+        aweme_ids = [cls.get_aweme_id(url) for url in urls]
+        return await asyncio.gather(*aweme_ids)
 
 
 def format_file_name(
     naming_template: str,
     aweme_data: dict = {},
     custom_fields: dict = {},
 ) -> str:
@@ -546,45 +582,45 @@
         "win32": 200,
         "cygwin": 60,
         "darwin": 60,
         "linux": 60,
     }
 
     fields = {
-        "create": aweme_data.get("create_time", ""),  # é•¿åº¦å›ºå®š19
+        "create": aweme_data.get("createTime", ""),  # é•¿åº¦å›ºå®š19
         "nickname": aweme_data.get("nickname", ""),  # æœ€é•¿30
         "aweme_id": aweme_data.get("aweme_id", ""),  # é•¿åº¦å›ºå®š19
         "desc": split_filename(aweme_data.get("desc", ""), os_limit),
         "uid": aweme_data.get("uid", ""),  # å›ºå®š11
     }
 
     if custom_fields:
         # æ›´æ–°è‡ªå®šä¹‰å­—æ®µ
         fields.update(custom_fields)
 
     try:
         return naming_template.format(**fields)
     except KeyError as e:
-        raise KeyError(_("æ–‡ä»¶åæ¨¡æ¿å­—æ®µ {0} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥".format(e)))
+        raise KeyError(_("æ–‡ä»¶åæ¨¡æ¿å­—æ®µ {0} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥").format(e))
 
 
 def create_user_folder(kwargs: dict, nickname: Union[str, int]) -> Path:
     """
     æ ¹æ®æä¾›çš„é…ç½®æ–‡ä»¶å’Œæ˜µç§°ï¼Œåˆ›å»ºå¯¹åº”çš„ä¿å­˜ç›®å½•ã€‚
     (Create the corresponding save directory according to the provided conf file and nickname.)
 
     Args:
         kwargs (dict): é…ç½®æ–‡ä»¶ï¼Œå­—å…¸æ ¼å¼ã€‚(Conf file, dict format)
         nickname (Union[str, int]): ç”¨æˆ·çš„æ˜µç§°ï¼Œå…è®¸å­—ç¬¦ä¸²æˆ–æ•´æ•°ã€‚  (User nickname, allow strings or integers)
 
     Note:
         å¦‚æœæœªåœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šè·¯å¾„ï¼Œåˆ™é»˜è®¤ä¸º "Download"ã€‚
         (If the path is not specified in the conf file, it defaults to "Download".)
-        æ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„ã€‚
-        (Support absolute and relative paths)
+        ä»…æ”¯æŒç›¸å¯¹è·¯å¾„ã€‚
+        (Only relative paths are supported.)
 
     Raises:
         TypeError: å¦‚æœ kwargs ä¸æ˜¯å­—å…¸æ ¼å¼ï¼Œå°†å¼•å‘ TypeErrorã€‚
         (If kwargs is not in dict format, TypeError will be raised.)
     """
 
     # ç¡®å®šå‡½æ•°å‚æ•°æ˜¯å¦æ­£ç¡®
@@ -592,15 +628,15 @@
         raise TypeError("kwargs å‚æ•°å¿…é¡»æ˜¯å­—å…¸")
 
     # åˆ›å»ºåŸºç¡€è·¯å¾„
     base_path = Path(kwargs.get("path", "Download"))
 
     # æ·»åŠ ä¸‹è½½æ¨¡å¼å’Œç”¨æˆ·å
     user_path = (
-        base_path / "douyin" / kwargs.get("mode", "PLEASE_SETUP_MODE") / str(nickname)
+        base_path / "tiktok" / kwargs.get("mode", "PLEASE_SETUP_MODE") / str(nickname)
     )
 
     # è·å–ç»å¯¹è·¯å¾„å¹¶ç¡®ä¿å®ƒå­˜åœ¨
     resolve_user_path = user_path.resolve()
 
     # åˆ›å»ºç›®å½•
     resolve_user_path.mkdir(parents=True, exist_ok=True)
@@ -648,28 +684,7 @@
         return user_path
 
     if local_user_data.get("nickname") != current_nickname:
         # æ˜µç§°ä¸ä¸€è‡´ï¼Œè§¦å‘ç›®å½•æ›´æ–°æ“ä½œ
         user_path = rename_user_folder(user_path, current_nickname)
 
     return user_path
-
-
-def show_qrcode(qrcode_url: str, show_image: bool = False) -> None:
-    """
-    æ˜¾ç¤ºäºŒç»´ç 
-
-    Args:
-        qrcode_url (str): ç™»å½•äºŒç»´ç é“¾æ¥
-        show_image (bool): æ˜¯å¦æ˜¾ç¤ºå›¾åƒï¼ŒTrue è¡¨ç¤ºæ˜¾ç¤ºï¼ŒFalse è¡¨ç¤ºåœ¨æ§åˆ¶å°æ˜¾ç¤º
-    """
-    if show_image:
-        # åˆ›å»ºå¹¶æ˜¾ç¤ºQRç å›¾åƒ
-        qr_code_img = qrcode.make(qrcode_url)
-        qr_code_img.show()
-    else:
-        # åœ¨æ§åˆ¶å°ä»¥ ASCII å½¢å¼æ‰“å°äºŒç»´ç 
-        qr = qrcode.QRCode()
-        qr.add_data(qrcode_url)
-        qr.make(fit=True)
-        # åœ¨æ§åˆ¶å°ä»¥ ASCII å½¢å¼æ‰“å°äºŒç»´ç 
-        qr.print_ascii(invert=True)
```

### Comparing `f2-0.0.1.4/f2/apps/douyin/test/test_apps_model.py` & `f2-0.0.1.5/f2/apps/douyin/test/test_apps_model.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/douyin/test/test_aweme_id.py` & `f2-0.0.1.5/f2/apps/douyin/test/test_aweme_id.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/douyin/test/test_crawler.py` & `f2-0.0.1.5/f2/apps/douyin/test/test_crawler.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/douyin/test/test_handler.py` & `f2-0.0.1.5/f2/apps/douyin/test/test_handler.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/douyin/test/test_room_id.py` & `f2-0.0.1.5/f2/apps/douyin/test/test_room_id.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/douyin/test/test_sec_user_id.py` & `f2-0.0.1.5/f2/apps/douyin/test/test_sec_user_id.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/douyin/test/test_webcast_id.py` & `f2-0.0.1.5/f2/apps/douyin/test/test_webcast_id.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/tiktok/api.py` & `f2-0.0.1.5/f2/apps/tiktok/api.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/tiktok/cli.py` & `f2-0.0.1.5/f2/apps/tiktok/cli.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,25 +1,30 @@
 # path: f2/apps/tiktok/cli.py
 
 import f2
 import click
 import typing
-import browser_cookie3
 
 from pathlib import Path
 
 from f2 import helps
 from f2.cli.cli_commands import set_cli_config
 from f2.log.logger import logger
-from f2.utils.utils import split_dict_cookie, get_resource_path
+from f2.utils.utils import (
+    split_dict_cookie,
+    get_resource_path,
+    get_cookie_from_browser,
+    check_invalid_naming,
+    merge_config,
+)
 from f2.utils.conf_manager import ConfigManager
 from f2.i18n.translator import TranslationManager, _
 
 
-def handle_help(
+def handler_help(
     ctx: click.Context,
     param: typing.Union[click.Option, click.Parameter],
     value: typing.Any,
 ) -> None:
     """
     å¤„ç†å¸®åŠ©ä¿¡æ¯ (Handle help messages)
 
@@ -46,78 +51,53 @@
     ç”¨äºè‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookie (Used to automatically get cookies from the browser)
 
     Args:
         ctx: clickçš„ä¸Šä¸‹æ–‡å¯¹è±¡ (Click's context object)
         param: æä¾›çš„å‚æ•°æˆ–é€‰é¡¹ (The provided parameter or option)
         value: å‚æ•°æˆ–é€‰é¡¹çš„å€¼ (The value of the parameter or option)
     """
-    if not value or ctx.resilient_parsing:
-        return
-
-    # å¦‚æœç”¨æˆ·æ˜ç¡®è®¾ç½®äº† --cookieï¼Œé‚£ä¹ˆè·³è¿‡è‡ªåŠ¨è·å–è¿‡ç¨‹
-    if ctx.params.get("cookie"):
+    # å¦‚æœç”¨æˆ·æ²¡æœ‰æä¾›å€¼æˆ–è€…è®¾ç½®äº† resilient_parsing æˆ–è€…è®¾ç½®äº† --cookieï¼Œé‚£ä¹ˆè·³è¿‡è‡ªåŠ¨è·å–è¿‡ç¨‹
+    if not value or ctx.resilient_parsing or ctx.params.get("cookie"):
         return
 
     # æ ¹æ®æµè§ˆå™¨é€‰æ‹©è·å–cookie
-    if value in ["chrome", "firefox", "edge", "opera"]:
-        try:
-            cookie_value = split_dict_cookie(get_cookie_from_browser(value))
-            manager = ConfigManager(ctx.params.get("config", "conf/app.yaml"))
-            manager.update_config_with_args("tiktok", cookie=cookie_value)
-        except PermissionError:
-            message = _("è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•, å¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ !")
-            logger.error(message)
-            click.echo(message)
-            ctx.abort()
-        except Exception as e:
-            message = _("è‡ªåŠ¨è·å–Cookieå¤±è´¥: {0}".format(str(e)))
-            logger.error(message)
-            click.echo(message)
-            ctx.abort()
-
-
-def get_cookie_from_browser(browser_choice: str):
-    """
-    æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æµè§ˆå™¨è·å–tiktok.comçš„cookieã€‚
-
-    Args:
-        browser_choice (str): ç”¨æˆ·é€‰æ‹©çš„æµè§ˆå™¨åç§°
-
-    Returns:
-        str: *.tiktok.comçš„cookieå€¼
-    """
-
-    BROWSER_FUNCTIONS = {
-        "chrome": browser_cookie3.chrome,
-        "firefox": browser_cookie3.firefox,
-        "edge": browser_cookie3.edge,
-        "opera": browser_cookie3.opera,
-    }
-    cj_function = BROWSER_FUNCTIONS.get(browser_choice)
-    if not cj_function:
-        raise ValueError(_("ä¸æ”¯æŒçš„æµè§ˆå™¨é€‰é¡¹, è¾“å…¥f2 dy --helpæŸ¥çœ‹æ›´å¤šå¸®åŠ©!"))
-
-    cj = cj_function(domain_name="tiktok.com")
+    try:
+        cookie_value = split_dict_cookie(get_cookie_from_browser(value, "tiktok.com"))
 
-    # cookie_value = next((c.value for c in cj if c.name == 'ttwid'), None)
-    cookie_value = {c.name: c.value for c in cj if c.domain.endswith("tiktok.com")}
+        if not cookie_value:
+            raise ValueError(_("æ— æ³•ä» {0} æµè§ˆå™¨ä¸­è·å–cookie").format(value))
 
-    if not cookie_value:
-        raise ValueError(_("æ— æ³•ä»{0}æµè§ˆå™¨ä¸­è·å–cookie").format(browser_choice))
-
-    return cookie_value
+        # å¦‚æœæ²¡æœ‰æä¾›é…ç½®æ–‡ä»¶ï¼Œé‚£ä¹ˆä½¿ç”¨é«˜é¢‘é…ç½®æ–‡ä»¶
+        manager = ConfigManager(
+            ctx.params.get("config", get_resource_path(f2.APP_CONFIG_FILE_PATH))
+        )
+        manager.update_config_with_args("tiktok", cookie=cookie_value)
+    except PermissionError:
+        logger.error(_("è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•ï¼Œå¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ï¼"))
+        ctx.abort()
+    except Exception as e:
+        logger.error(_("è‡ªåŠ¨è·å–Cookieå¤±è´¥ï¼š{0}").format(str(e)))
+        ctx.abort()
 
 
 def handler_language(
     ctx: click.Context,
     param: typing.Union[click.Option, click.Parameter],
     value: typing.Any,
 ) -> typing.Any:
-    """ç”¨äºè®¾ç½®è¯­è¨€ (For setting the language)"""
+    """ç”¨äºè®¾ç½®è¯­è¨€ (For setting the language)
 
+    Args:
+        ctx: clickçš„ä¸Šä¸‹æ–‡å¯¹è±¡ (Click's context object)
+        param: æä¾›çš„å‚æ•°æˆ–é€‰é¡¹ (The provided parameter or option)
+        value: å‚æ•°æˆ–é€‰é¡¹çš„å€¼ (The value of the parameter or option)
+    """
+
+    if not value or ctx.resilient_parsing:
+        return
     TranslationManager.get_instance().set_language(value)
     global _
     _ = TranslationManager.get_instance().gettext
     return value
 
 
 def handler_naming(
@@ -135,85 +115,34 @@
     Raises:
         click.BadParameter: å¦‚æœå‘½åæ¨¡å¼æ— æ•ˆ (If the naming pattern is invalid)
 
     Returns:
         value: å‘½åæ¨¡å¼æ¨¡æ¿ (Naming pattern template)
     """
     # é¿å…å’Œé…ç½®æ–‡ä»¶å‚æ•°å†²çª
-    if value is None:
+    if not value or ctx.resilient_parsing:
         return
 
     # å…è®¸çš„æ¨¡å¼å’Œåˆ†éš”ç¬¦
-    ALLOWED_PATTERNS = ["{nickname}", "{create}", "{aid}", "{desc}"]
+    ALLOWED_PATTERNS = ["{nickname}", "{create}", "{aweme_id}", "{desc}", "{uid}"]
     ALLOWED_SEPARATORS = ["-", "_"]
 
-    temp_naming = value
-    invalid_patterns = []
-
-    # æ£€æŸ¥æä¾›çš„æ¨¡å¼æ˜¯å¦æœ‰æ•ˆ
-    for pattern in ALLOWED_PATTERNS:
-        if pattern in temp_naming:
-            temp_naming = temp_naming.replace(pattern, "")
-
-    # æ­¤æ—¶ï¼Œtemp_namingåº”åªåŒ…å«åˆ†éš”ç¬¦
-    for char in temp_naming:
-        if char not in ALLOWED_SEPARATORS:
-            invalid_patterns.append(char)
-
-    # æ£€æŸ¥è¿ç»­çš„æ— æ•ˆæ¨¡å¼æˆ–åˆ†éš”ç¬¦
-    for pattern in ALLOWED_PATTERNS:
-        # æ£€æŸ¥åƒ"{aid}{aid}"è¿™æ ·çš„æ¨¡å¼
-        if pattern + pattern in value:
-            invalid_patterns.append(pattern + pattern)
-        for sep in ALLOWED_SEPARATORS:
-            # æ£€æŸ¥åƒ"{aid}-{aid}"è¿™æ ·çš„æ¨¡å¼
-            if pattern + sep + pattern in value:
-                invalid_patterns.append(pattern + sep + pattern)
+    # æ£€æŸ¥å‘½åæ˜¯å¦ç¬¦åˆå‘½åè§„èŒƒ
+    invalid_patterns = check_invalid_naming(value, ALLOWED_PATTERNS, ALLOWED_SEPARATORS)
 
     if invalid_patterns:
         raise click.BadParameter(
-            _(
-                "`{0}` ä¸­çš„ `{1}` ä¸ç¬¦åˆå‘½åæ¨¡å¼".format(
-                    value, "".join(invalid_patterns)
-                )
+            _("`{0}` ä¸­çš„ `{1}` ä¸ç¬¦åˆå‘½åæ¨¡å¼").format(
+                value, "".join(invalid_patterns)
             )
         )
 
     return value
 
 
-def merge_config(main_conf, custom_conf, **kwargs):
-    """
-    åˆå¹¶é…ç½®å‚æ•°ï¼Œä½¿ CLI å‚æ•°ä¼˜å…ˆçº§é«˜äºè‡ªå®šä¹‰é…ç½®ï¼Œè‡ªå®šä¹‰é…ç½®ä¼˜å…ˆçº§é«˜äºä¸»é…ç½®ï¼Œæœ€ç»ˆç”Ÿæˆå®Œæ•´é…ç½®å‚æ•°å­—å…¸ã€‚
-    Args:
-        main_conf (dict): ä¸»é…ç½®å‚æ•°å­—å…¸
-        custom_conf (dict): è‡ªå®šä¹‰é…ç½®å‚æ•°å­—å…¸
-        **kwargs: CLI å‚æ•°å’Œå…¶ä»–é¢å¤–çš„é…ç½®å‚æ•°
-
-    Returns:
-        dict: åˆå¹¶åçš„é…ç½®å‚æ•°å­—å…¸
-    """
-    # åˆå¹¶ä¸»é…ç½®å’Œè‡ªå®šä¹‰é…ç½®
-    merged_conf = {}
-    for key, value in main_conf.items():
-        merged_conf[key] = value  # å°†ä¸»é…ç½®å¤åˆ¶åˆ°åˆå¹¶åçš„é…ç½®ä¸­
-    for key, value in custom_conf.items():
-        if value is not None and value != "":  # åªæœ‰å€¼ä¸ä¸º None å’Œ ç©ºå€¼ï¼Œæ‰è¿›è¡Œåˆå¹¶
-            merged_conf[key] = value  # è‡ªå®šä¹‰é…ç½®å‚æ•°ä¼šè¦†ç›–ä¸»é…ç½®ä¸­çš„åŒåå‚æ•°
-
-    # åˆå¹¶ CLI å‚æ•°ä¸åˆå¹¶åçš„é…ç½®ï¼Œç¡®ä¿ CLI å‚æ•°çš„ä¼˜å…ˆçº§æœ€é«˜
-    for key, value in kwargs.items():
-        if key not in merged_conf:  # å¦‚æœåˆå¹¶åçš„é…ç½®ä¸­æ²¡æœ‰è¿™ä¸ªé”®ï¼Œåˆ™ç›´æ¥æ·»åŠ 
-            merged_conf[key] = value
-        elif value is not None and value != "":  # å¦‚æœå€¼ä¸ä¸º None å’Œ ç©ºå€¼ï¼Œåˆ™è¿›è¡Œåˆå¹¶
-            merged_conf[key] = value  # CLI å‚æ•°ä¼šè¦†ç›–è‡ªå®šä¹‰é…ç½®å’Œä¸»é…ç½®ä¸­çš„åŒåå‚æ•°
-
-    return merged_conf
-
-
 @click.command(name="tiktok", help=_("TikTokæ— æ°´å°è§£æ"))
 @click.option(
     "--config",
     "-c",
     type=click.Path(file_okay=True, dir_okay=False, readable=True),  # exists=True
     help=_("é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œæœ€ä½ä¼˜å…ˆ"),
 )
@@ -227,48 +156,48 @@
     ),
 )
 @click.option(
     "--music",
     "-m",
     type=bool,
     # default="yes",
-    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°ã€‚å¯é€‰ï¼š'yes'ã€'no'"),
+    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°"),
 )
 @click.option(
     "--cover",
     "-v",
     type=bool,
     # default="yes",
-    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢ã€‚å¯é€‰ï¼š'yes'ã€'no'"),
+    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢"),
 )
 @click.option(
     "--desc",
     "-d",
     type=bool,
     # default="yes",
-    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆã€‚å¯é€‰ï¼š'yes'ã€'no'"),
+    help=_("æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆ"),
 )
 @click.option(
     "--path",
     "-p",
     type=str,
     # default="Download",
-    help=_("ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„ã€‚"),
+    help=_("ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„"),
 )
 @click.option(
     "--folderize",
     "-f",
     type=bool,
     # default="yes",
-    help=_("æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ã€‚å¯é€‰ï¼š'yes'ã€'no'"),
+    help=_("æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹"),
 )
 @click.option(
     "--mode",
     "-M",
-    type=click.Choice(["one", "post", "like", "collect", "mix"]),
+    type=click.Choice(f2.TIKTOK_MODE_LIST),
     # default="post",
     # required=True,
     help=_(
         "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post), ç‚¹èµä½œå“(like), æ”¶è—ä½œå“(collect), åˆè¾‘æ’­æ”¾åˆ—è¡¨(mix)"
     ),
 )
 @click.option(
@@ -363,31 +292,35 @@
 )
 @click.option(
     "--init-config", type=str, help=_("åˆå§‹åŒ–é…ç½®æ–‡ä»¶ã€‚ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶")
 )
 # @click.confirmation_option(prompt='æ˜¯å¦è¦ä½¿ç”¨å‘½ä»¤è¡Œçš„å‚æ•°æ›´æ–°é…ç½®æ–‡ä»¶?')
 @click.option(
     "--auto-cookie",
-    type=click.Choice(["none", "chrome", "firefox", "edge", "opera"]),
+    type=click.Choice(f2.BROWSER_LIST),
     # default="none",
-    help=_(
-        "è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
-    ),
+    help=_("è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"),
     callback=handler_auto_cookie,
 )
 @click.option(
     "-h",
     is_flag=True,
     is_eager=True,
     expose_value=False,
-    help="æ˜¾ç¤ºå¯Œæ–‡æœ¬å¸®åŠ©",
-    callback=handle_help,
+    help=_("æ˜¾ç¤ºå¯Œæ–‡æœ¬å¸®åŠ©"),
+    callback=handler_help,
 )
 @click.pass_context
-def tiktok(ctx, config, init_config, update_config, **kwargs):
+def tiktok(
+    ctx: click.Context,
+    config: str,
+    init_config: str,
+    update_config: bool,
+    **kwargs,
+) -> None:
     ##################
     # f2 å­˜åœ¨2ä¸ªä¸»é…ç½®æ–‡ä»¶ï¼Œåˆ†åˆ«æ˜¯appä½é¢‘é…ç½®(app.yaml)å’Œf2ä½é¢‘é…ç½®(conf.yaml)
     # appä½é¢‘é…ç½®å­˜æ”¾appç›¸å…³çš„å‚æ•°
     # f2ä½é¢‘é…ç½®å­˜æ”¾è®¡ç®—å€¼æ‰€éœ€çš„å‚æ•°
 
     # å…¶ä¸­cliå‚æ•°å…·æœ‰æœ€é«˜ä¼˜å…ˆï¼Œcli >= è‡ªå®šä¹‰ >= ä½é¢‘
     # åœ¨f2ä½é¢‘é…ç½®ä¸­è®¾ç½®ä»£ç†å‚æ•°
@@ -449,21 +382,21 @@
             "http": kwargs["proxies"][0],
             "https": kwargs["proxies"][1],
         }
 
     # ä»ä½é¢‘é…ç½®å¼€å§‹åˆ°é«˜é¢‘é…ç½®å†åˆ°cliå‚æ•°ï¼Œé€çº§è¦†ç›–ï¼Œå¦‚æœé”®å€¼ä¸å­˜åœ¨ä½¿ç”¨çˆ¶çº§çš„é”®å€¼
     kwargs = merge_config(main_conf, custom_conf, **kwargs)
 
-    logger.info(_("ä¸»é…ç½®è·¯å¾„ï¼š {0}".format(main_conf_path)))
-    logger.info(_("è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š {0}".format(Path.cwd() / config)))
-    logger.debug(_("ä¸»é…ç½®å‚æ•°ï¼š{0}".format(main_conf)))
-    logger.debug(_("è‡ªå®šä¹‰é…ç½®å‚æ•°ï¼š{0}".format(custom_conf)))
-    logger.debug(_("CLIå‚æ•°ï¼š{0}".format(kwargs)))
+    logger.info(_("ä¸»é…ç½®è·¯å¾„ï¼š{0}").format(main_conf_path))
+    logger.info(_("è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š{0}").format(Path.cwd() / config))
+    logger.debug(_("ä¸»é…ç½®å‚æ•°ï¼š{0}").format(main_conf))
+    logger.debug(_("è‡ªå®šä¹‰é…ç½®å‚æ•°ï¼š{0}").format(custom_conf))
+    logger.debug(_("CLIå‚æ•°ï¼š{0}").format(kwargs))
 
     # å°è¯•ä»å‘½ä»¤è¡Œå‚æ•°æˆ–kwargsä¸­è·å–URL
     if not kwargs.get("url"):
         logger.error("ç¼ºä¹URLå‚æ•°ï¼Œè¯¦æƒ…çœ‹å‘½ä»¤å¸®åŠ©")
-        handle_help(ctx, None, True)
+        handler_help(ctx, None, True)
 
     # æ·»åŠ app_nameåˆ°kwargs
     kwargs["app_name"] = "tiktok"
     ctx.invoke(set_cli_config, **kwargs)
```

### Comparing `f2-0.0.1.4/f2/apps/tiktok/db.py` & `f2-0.0.1.5/f2/apps/tiktok/db.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 # path: f2/apps/tiktok/db.py
 
-import aiosqlite
 from f2.db.base_db import BaseDB
 
 
 class AsyncUserDB(BaseDB):
     TABLE_NAME = "user_info_web"
 
     async def _create_table(self) -> None:
@@ -20,22 +19,24 @@
             "followerCount INTEGER",
             "followingCount INTEGER",
             "friendCount INTEGER",
             "heartCount INTEGER",
             "videoCount INTEGER",
             "uid TEXT",
             "nickname TEXT",
+            "nickname_raw TEXT",
             "uniqueId TEXT",
             "commentSetting BOOLEAN",
             "followingVisibility BOOLEAN",
             "openFavorite BOOLEAN",
             "privateAccount BOOLEAN",
             "showPlayListTab BOOLEAN",
             "relation BOOLEAN",
             "signature TEXT",
+            "signature_raw TEXT",
             "ttSeller BOOLEAN",
             "verified BOOLEAN",
             "last_aweme_id TEXT",
             "api_status_code TEXT",
         ]
 
         fields_sql = ", ".join(fields)
```

### Comparing `f2-0.0.1.4/f2/apps/tiktok/dl.py` & `f2-0.0.1.5/f2/apps/douyin/dl.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,44 +1,43 @@
-# path: f2/apps/tiktok/dl.py
+# path: f2/apps/douyin/dl.py
 
 import sys
 from datetime import datetime
 from typing import Any, Union
 
 from f2.i18n.translator import _
 from f2.log.logger import logger
 from f2.dl.base_downloader import BaseDownloader
 from f2.utils.utils import get_timestamp, timestamp_2_str
-from f2.apps.tiktok.db import AsyncUserDB
-from f2.apps.tiktok.utils import format_file_name
+from f2.apps.douyin.db import AsyncUserDB
+from f2.apps.douyin.utils import format_file_name, json_2_lrc
 
 
-class TiktokDownloader(BaseDownloader):
+class DouyinDownloader(BaseDownloader):
     def __init__(self, kwargs: dict = {}):
         if kwargs["cookie"] is None:
             raise ValueError(
                 _(
-                    "cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å– f2 -d dy --helpï¼Œå¦‚æ‰«ç ç™»å½•è¯·ä¿ç•™åŒå¼•å·cookie: "
-                    "ï¼Œå†ä½¿ç”¨--sso-loginå‘½ä»¤ã€‚"
+                    "cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å–ã€‚å¦‚ `--auto-cookie edge`"
                 )
             )
 
         super().__init__(kwargs)
 
-    async def save_last_aweme_id(self, secUid: str, aweme_id: str) -> None:
+    async def save_last_aweme_id(self, sec_user_id: str, aweme_id: int) -> None:
         """
         ä¿å­˜æœ€åä¸€ä¸ªè¯·æ±‚çš„aweme_id
         (Save the last requested aweme_id)
 
         Args:
-            aweme_id (str): ä½œå“id (aweme_id)
+            aweme_id (int): ä½œå“id (aweme_id)
         """
 
-        async with AsyncUserDB("tiktok_users.db") as db:
-            await db.update_user_info(secUid=secUid, last_aweme_id=aweme_id)
+        async with AsyncUserDB("douyin_users.db") as db:
+            await db.update_user_info(sec_user_id=sec_user_id, last_aweme_id=aweme_id)
 
     async def filter_aweme_datas_by_interval(
         self, aweme_datas: Union[list, dict], interval: str
     ) -> Union[list[dict], dict, None]:
         """
         ç­›é€‰æŒ‡å®šæ—¥æœŸåŒºé—´å†…çš„ä½œå“
 
@@ -59,18 +58,16 @@
             start_date = datetime.strptime(start_str + " 00-00-00", "%Y-%m-%d %H-%M-%S")
             end_date = datetime.strptime(end_str + " 23-59-59", "%Y-%m-%d %H-%M-%S")
             logger.info(_("ç­›é€‰æ—¥æœŸåŒºé—´ï¼š{0} è‡³ {1}").format(start_date, end_date))
         except ValueError:
             logger.error(_("æ—¥æœŸåŒºé—´å‚æ•°æ ¼å¼é”™è¯¯ï¼Œè¯·æŸ¥é˜…æ–‡æ¡£åé‡è¯•"))
             return None
 
-        logger.info(aweme_datas)
-
         if isinstance(aweme_datas, dict):
-            aweme_date_str = aweme_datas.get("createTime")
+            aweme_date_str = aweme_datas.get("create_time")
             try:
                 aweme_date = datetime.strptime(aweme_date_str, "%Y-%m-%d %H-%M-%S")
             except ValueError:
                 logger.warning(_("æ— æ³•è§£æä½œå“å‘å¸ƒæ—¶é—´ï¼š{0}").format(aweme_date_str))
                 return None
 
             # æ£€æŸ¥ä½œå“å‘å¸ƒæ—¶é—´æ˜¯å¦åœ¨æŒ‡å®šåŒºé—´å†…
@@ -78,15 +75,17 @@
                 logger.info(
                     _("ä½œå“å‘å¸ƒæ—¶é—´åœ¨æŒ‡å®šåŒºé—´å†…ï¼šä½œå“id {0} å‘å¸ƒæ—¶é—´ {1}").format(
                         aweme_datas.get("aweme_id"), aweme_date_str
                     )
                 )
                 return aweme_datas
             else:
-                logger.warning(_("ä½œå“å‘å¸ƒæ—¶é—´ä¸åœ¨æŒ‡å®šåŒºé—´å†…ï¼š{0}").format(aweme_date_str))
+                logger.warning(
+                    _("ä½œå“å‘å¸ƒæ—¶é—´ä¸åœ¨æŒ‡å®šåŒºé—´å†…ï¼š{0}").format(aweme_date_str)
+                )
                 return None
 
         elif isinstance(aweme_datas, list):
             # éå†åˆ—è¡¨ä¸­çš„æ¯ä¸ªå­—å…¸
             filtered_list = []
             for aweme_data in aweme_datas:
                 filtered_data = await self.filter_aweme_datas_by_interval(
@@ -144,82 +143,78 @@
         self, kwargs: dict, aweme_data_dict: dict, user_path: Any
     ) -> None:
         """
         å¤„ç†ä¸‹è½½ä»»åŠ¡
 
         Args:
             kwargs (dict): å‘½ä»¤è¡Œå‚æ•°
+            aweme_data_dict (dict): ä½œå“æ•°æ®å­—å…¸
+            user_path (Any): ç”¨æˆ·ç›®å½•è·¯å¾„
         """
 
         # æ„å»ºæ–‡ä»¶å¤¹è·¯å¾„
         base_path = (
             user_path
             / format_file_name(kwargs.get("naming", "{create}_{desc}"), aweme_data_dict)
             if kwargs.get("folderize")
             else user_path
         )
 
-        secUid = str(aweme_data_dict.get("secUid"))  # ç”¨æˆ·ID
-        aweme_privateItem = aweme_data_dict.get("privateItem")  # ä½œå“æƒé™ falseå…¬å¼€, trueç§å¯†
-        aweme_secret = aweme_data_dict.get("secret")  # ä½œå“æƒé™ falseå…¬å¼€, trueç§å¯†
+        sec_user_id = str(aweme_data_dict.get("sec_user_id"))  # ç”¨æˆ·ID
+        aweme_prohibited = aweme_data_dict.get("is_prohibited")  # ä½œå“çŠ¶æ€ 0æ­£å¸¸, 1å±è”½
+        aweme_part_see = aweme_data_dict.get(
+            "part_see"
+        )  # éƒ¨åˆ†å¯è§ part_see 1, private_status 1
+        aweme_status = aweme_data_dict.get(
+            "private_status"
+        )  # è§†é¢‘æƒé™ 0å…¬å¼€æˆ–ä¸ç»™è°çœ‹, 1ç§å¯†, 2äº’å…³æœ‹å‹
+        aweme_type = aweme_data_dict.get(
+            "aweme_type"
+        )  # è§†é¢‘ç±»å‹ 0è§†é¢‘, 55åŠ¨å›¾æˆ–å…³é—­ä¸‹è½½, 61æŒ‘æˆ˜ï¼Œ 109æ—¥å¸¸, 68å›¾é›†
         aweme_id = str(aweme_data_dict.get("aweme_id"))  # è§†é¢‘ID
 
         logger.debug(f"========{aweme_id}========")
         logger.debug(aweme_data_dict)
-        logger.debug("================")
+        logger.debug("===================================")
 
         # æ£€æŸ¥ä½œå“æ˜¯å¦è¢«å±è”½
-        if aweme_privateItem:
-            logger.warning(_("{0} è¯¥ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id))
+        if aweme_prohibited:
+            logger.warning(_("è¯¥ {0} ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id))
             return
 
         # æ£€æŸ¥ä½œå“æ˜¯å¦å¯è§
-        if not aweme_secret:
-            video_name = (
-                format_file_name(
-                    kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
-                )
-                + "_video"
-            )
-
-            video_url = aweme_data_dict.get("video_playAddr")
-            if video_url != None:
-                await self.initiate_download(
-                    _("è§†é¢‘"), video_url, base_path, video_name, ".mp4"
-                )
-            else:
-                logger.warning(_("{0} è¯¥ä½œå“æ²¡æœ‰è§†é¢‘é“¾æ¥ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id))
-
+        if aweme_status in [0, 1, 2]:
             # å¤„ç†éŸ³ä¹ä¸‹è½½ä»»åŠ¡
             if kwargs.get("music"):
-                music_name = (
-                    format_file_name(
-                        kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
+                if aweme_data_dict.get("music_status") == 1:  # åŸå£°çŠ¶æ€ 1 æ­£å¸¸ 0 å¤±æ•ˆ
+                    music_name = (
+                        format_file_name(
+                            kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
+                        )
+                        + "_music"
                     )
-                    + "_music"
-                )
 
-                music_url = aweme_data_dict.get("music_playUrl")
-                if music_url != None:
-                    await self.initiate_download(
-                        _("åŸå£°"), music_url, base_path, music_name, ".mp3"
-                    )
+                    music_url = aweme_data_dict.get("music_play_url")
+                    if music_url != None:
+                        await self.initiate_download(
+                            _("åŸå£°"), music_url, base_path, music_name, ".mp3"
+                        )
                 else:
                     logger.warning(_("{0} è¯¥åŸå£°å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id))
 
             # å¤„ç†å°é¢ä¸‹è½½ä»»åŠ¡
             if kwargs.get("cover"):
                 cover_name = (
                     format_file_name(
                         kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
                     )
                     + "_cover"
                 )
-                animated_cover_url = aweme_data_dict.get("video_dynamicCover")
-                cover_url = aweme_data_dict.get("video_cover")
+                animated_cover_url = aweme_data_dict.get("animated_cover")
+                cover_url = aweme_data_dict.get("cover")
                 if animated_cover_url != None:
                     await self.initiate_download(
                         _("å°é¢"), animated_cover_url, base_path, cover_name, ".webp"
                     )
                 elif cover_url != None:
                     logger.warning(_("{0} è¯¥ä½œå“æ²¡æœ‰åŠ¨æ€å°é¢").format(aweme_id))
                     await self.initiate_download(
@@ -237,27 +232,131 @@
                     + "_desc"
                 )
                 desc_content = aweme_data_dict.get("desc")
                 await self.initiate_static_download(
                     _("æ–‡æ¡ˆ"), desc_content, base_path, desc_name, ".txt"
                 )
 
+            # å¤„ç†ä¸åŒç±»å‹çš„ä½œå“ä¸‹è½½ä»»åŠ¡
+            if aweme_type in [0, 55, 61, 109]:
+                video_name = (
+                    format_file_name(
+                        kwargs.get("naming", "{create}_{desc}"), aweme_data_dict
+                    )
+                    + "_video"
+                )
+                # video_play_addr ç°åœ¨ä¸ºä¸€ä¸ªlistï¼Œç¬¬ä¸€ä¸ªé“¾æ¥ä¸‹è½½å¤±è´¥ï¼Œåˆ™ä¸‹è½½ç¬¬äºŒä¸ªé“¾æ¥
+                video_url = aweme_data_dict.get("video_play_addr")
+                if video_url != None:
+                    await self.initiate_download(
+                        _("è§†é¢‘"), video_url, base_path, video_name, ".mp4"
+                    )
+                else:
+                    logger.warning(
+                        _("{0} è¯¥ä½œå“æ²¡æœ‰è§†é¢‘é“¾æ¥ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id)
+                    )
+
+            elif aweme_type in [68]:
+                for i, image_url in enumerate(aweme_data_dict.get("images", None)):
+                    image_name = f"{format_file_name(kwargs.get('naming'), aweme_data_dict)}_image_{i + 1}"
+                    if image_url != None:
+                        await self.initiate_download(
+                            _("å›¾é›†"), image_url, base_path, image_name, ".jpg"
+                        )
+                    else:
+                        logger.warning(
+                            _("{0} è¯¥å›¾é›†æ²¡æœ‰å›¾ç‰‡é“¾æ¥ï¼Œæ— æ³•ä¸‹è½½").format(aweme_id)
+                        )
+
         # ä¿å­˜æœ€åä¸€ä¸ªaweme_id
-        await self.save_last_aweme_id(secUid, aweme_id)
+        await self.save_last_aweme_id(sec_user_id, aweme_id)
+
+    async def create_music_download_tasks(
+        self, kwargs: dict, music_datas: Union[list, dict], user_path: Any
+    ) -> None:
+        """
+        åˆ›å»ºéŸ³ä¹ä¸‹è½½ä»»åŠ¡
+
+        Args:
+            kwargs (dict): å‘½ä»¤è¡Œå‚æ•°
+            music_datas (list, dict): éŸ³ä¹æ•°æ®åˆ—è¡¨æˆ–å­—å…¸
+            user_path (Any): ç”¨æˆ·ç›®å½•è·¯å¾„
+        """
+
+        if (
+            not kwargs
+            or not music_datas
+            or not isinstance(music_datas, (list, dict))
+            or not user_path
+        ):
+            return
+
+        if isinstance(music_datas, dict):
+            await self.handler_music_download(kwargs, music_datas, user_path)
+        else:
+            for music_data in music_datas:
+                await self.handler_music_download(kwargs, music_data, user_path)
+
+        # æ‰§è¡Œä¸‹è½½ä»»åŠ¡
+        await self.execute_tasks()
+
+    async def handler_music_download(
+        self, kwargs: dict, music_data_dict: dict, user_path: Any
+    ) -> None:
+        """
+        å¤„ç†éŸ³ä¹ä¸‹è½½ä»»åŠ¡
+
+        Args:
+            kwargs (dict): å‘½ä»¤è¡Œå‚æ•°
+            music_data_dict (dict): éŸ³ä¹æ•°æ®å­—å…¸
+            user_path (Any): ç”¨æˆ·ç›®å½•è·¯å¾„
+        """
+
+        # æ„å»ºæ–‡ä»¶å¤¹è·¯å¾„
+        base_path = (
+            user_path / music_data_dict.get("title")
+            if kwargs.get("folderize")
+            else user_path
+        )
+        music_name = music_data_dict.get("title") + "_music"
+        music_url = music_data_dict.get("play_url")
+        lyric_name = music_data_dict.get("title") + "_lyric"
+        lyric_url = music_data_dict.get("lyric_url")
+
+        if music_url != None:
+            await self.initiate_download(
+                _("éŸ³ä¹"), music_url, base_path, music_name, ".mp3"
+            )
+
+        if kwargs.get("lyric"):
+            if lyric_url is None:
+                return
+
+            # ä¸‹è½½stræ ¼å¼çš„jsonæ­Œè¯æ–‡ä»¶
+            lyric = await self.get_fetch_data(lyric_url)
+
+            # å¦‚æœjsonæ­Œè¯æ–‡ä»¶ä¸‹è½½æˆåŠŸï¼Œåˆ™è¯»å–å¹¶å¤„ç†æˆlrcæ ¼å¼
+            if lyric.status_code != 200:
+                return
+
+            lrc_content = json_2_lrc(lyric.json())
+            await self.initiate_static_download(
+                _("æ­Œè¯"), lrc_content, base_path, lyric_name, ".lrc"
+            )
 
     async def create_stream_tasks(
         self, kwargs: dict, webcast_datas: Union[list, dict], user_path: Any
     ) -> None:
         """
         åˆ›å»ºè§†é¢‘æµä¸‹è½½ä»»åŠ¡
 
         Args:
             kwargs (dict): å‘½ä»¤è¡Œå‚æ•°
             aweme_datas (list, dict): ä½œå“æ•°æ®åˆ—è¡¨æˆ–å­—å…¸
-            user_path (str): ç”¨æˆ·ç›®å½•è·¯å¾„
+            user_path (Any): ç”¨æˆ·ç›®å½•è·¯å¾„
         """
 
         if (
             not kwargs
             or not webcast_datas
             or not isinstance(webcast_datas, (list, dict))
             or not user_path
@@ -277,14 +376,16 @@
         self, kwargs: dict, webcast_data_dict: dict, user_path: Any
     ) -> None:
         """
         å¤„ç†è§†é¢‘æµä¸‹è½½ä»»åŠ¡
 
         Args:
             kwargs (dict): å‘½ä»¤è¡Œå‚æ•°
+            aweme_data_dict (dict): ç›´æ’­æ•°æ®å­—å…¸
+            user_path (Any): ç”¨æˆ·ç›®å½•è·¯å¾„
         """
         custom_fields = {
             "create": timestamp_2_str(timestamp=get_timestamp(unit="sec")),
             "nickname": webcast_data_dict.get("nickname", ""),
             "aweme_id": webcast_data_dict.get("room_id", ""),
             "desc": webcast_data_dict.get("live_title", ""),
             "uid": webcast_data_dict.get("user_id", ""),
@@ -295,13 +396,13 @@
             / format_file_name(
                 kwargs.get("naming", "{create}_{desc}"), custom_fields=custom_fields
             )
             if kwargs.get("folderize")
             else user_path
         )
 
-        webcast_name = f"{format_file_name(kwargs.get('naming', '{create}_{desc}'), custom_fields=custom_fields)}_live"
-        webcast_url = webcast_data_dict.get("m3u8_pull_url", None).get("FULL_HD1")
+        webcast_name = f"{format_file_name(kwargs.get('naming'), custom_fields=custom_fields)}_live"
+        webcast_url = webcast_data_dict.get("m3u8_pull_url").get("FULL_HD1")
 
         await self.initiate_m3u8_download(
             _("ç›´æ’­"), webcast_url, base_path, webcast_name, ".mp4"
         )
```

### Comparing `f2-0.0.1.4/f2/apps/tiktok/filter.py` & `f2-0.0.1.5/f2/apps/tiktok/filter.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,9 @@
 # path: f2/apps/tiktok/filter.py
 
-from typing import List, Union
-
 from f2.utils.json_filter import JSONModel
 from f2.utils.utils import _get_first_item_from_list, timestamp_2_str, replaceT
 
 
 class UserProfileFilter(JSONModel):
     @property
     def api_status_code(self):
@@ -42,14 +40,18 @@
         return self._get_attr_value("$.userInfo.user.id")
 
     @property
     def nickname(self):
         return replaceT(self._get_attr_value("$.userInfo.user.nickname"))
 
     @property
+    def nickname_raw(self):
+        return self._get_attr_value("$.userInfo.user.nickname")
+
+    @property
     def secUid(self):
         return self._get_attr_value("$.userInfo.user.secUid")
 
     @property
     def uniqueId(self):
         return self._get_attr_value("$.userInfo.user.uniqueId")
 
@@ -78,21 +80,28 @@
         return bool(self._get_attr_value("$.userInfo.user.relation"))
 
     @property
     def signature(self):
         return replaceT(self._get_attr_value("$.userInfo.user.signature"))
 
     @property
+    def signature_raw(self):
+        return self._get_attr_value("$.userInfo.user.signature")
+
+    @property
     def ttSeller(self) -> bool:
         return bool(self._get_attr_value("$.userInfo.user.ttSeller"))
 
     @property
     def verified(self) -> bool:
         return bool(self._get_attr_value("$.userInfo.user.verified"))
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
 
@@ -129,24 +138,32 @@
         )
 
     @property
     def desc(self):
         return replaceT(self._get_list_attr_value("$.itemList[*].desc"))
 
     @property
+    def desc_raw(self):
+        return self._get_list_attr_value("$.itemList[*].desc")
+
+    @property
     def textExtra(self):
         return self._get_list_attr_value("$.itemList[*].textExtra")
 
     # author
 
     @property
     def nickname(self):
         return replaceT(self._get_list_attr_value("$.itemList[*].author.nickname"))
 
     @property
+    def nickname_raw(self):
+        return self._get_list_attr_value("$.itemList[*].author.nickname")
+
+    @property
     def uid(self):
         return self._get_list_attr_value("$.itemList[*].author.id")
 
     @property
     def secUid(self):
         return self._get_list_attr_value("$.itemList[*].author.secUid")
 
@@ -218,14 +235,18 @@
         return self._get_list_attr_value("$.itemList[*].music.album")
 
     @property
     def music_authorName(self):
         return replaceT(self._get_list_attr_value("$.itemList[*].music.authorName"))
 
     @property
+    def music_authorName_raw(self):
+        return self._get_list_attr_value("$.itemList[*].music.authorName")
+
+    @property
     def music_coverLarge(self):
         return self._get_list_attr_value("$.itemList[*].music.coverLarge")
 
     @property
     def music_duration(self):
         return self._get_list_attr_value("$.itemList[*].music.duration")
 
@@ -241,14 +262,18 @@
     def music_playUrl(self):
         return self._get_list_attr_value("$.itemList[*].music.playUrl")
 
     @property
     def music_title(self):
         return replaceT(self._get_list_attr_value("$.itemList[*].music.title"))
 
+    @property
+    def music_title_raw(self):
+        return self._get_list_attr_value("$.itemList[*].music.title")
+
     # video
     @property
     def video_bitrate(self):
         return self._get_list_attr_value("$.itemList[*].video.bitrate")
 
     # @property
     # def video_bitrateInfo(self):
@@ -262,19 +287,25 @@
     #         for aweme in bit_rate_data
     #     ]
 
     @property
     def video_bitrateInfo(self):
         bit_rate_data = self._get_list_attr_value("$.itemList[*].video.bitrateInfo")
         return [
-            [aweme.get("Bitrate", "")]  # ä½¿ç”¨ get æ–¹æ³•ä»¥å¤„ç†å­—å…¸ä¸­æ²¡æœ‰ "Bitrate" é”®çš„æƒ…å†µ
-            if isinstance(aweme, dict)
-            else [aweme[0].get("Bitrate", "")]
-            if len(aweme) == 1
-            else [item.get("Bitrate", "") for item in aweme]
+            (
+                [
+                    aweme.get("Bitrate", "")
+                ]  # ä½¿ç”¨ get æ–¹æ³•ä»¥å¤„ç†å­—å…¸ä¸­æ²¡æœ‰ "Bitrate" é”®çš„æƒ…å†µ
+                if isinstance(aweme, dict)
+                else (
+                    [aweme[0].get("Bitrate", "")]
+                    if len(aweme) == 1
+                    else [item.get("Bitrate", "") for item in aweme]
+                )
+            )
             for aweme in bit_rate_data
         ]
 
     @property
     def video_codecType(self):
         return self._get_list_attr_value("$.itemList[*].video.codecType")
 
@@ -302,14 +333,17 @@
     def video_height(self):
         return self._get_list_attr_value("$.itemList[*].video.height")
 
     @property
     def video_width(self):
         return self._get_list_attr_value("$.itemList[*].video.width")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
 
@@ -379,14 +413,17 @@
     def mixName(self):
         return self._get_attr_value("$.playList[*].mixName")
 
     @property
     def videoCount(self):
         return self._get_attr_value("$.playList[*].videoCount")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
 
@@ -414,26 +451,34 @@
         return self._get_attr_value("$.itemInfo.itemStruct.author.id")
 
     @property
     def nickname(self):
         return replaceT(self._get_attr_value("$.itemInfo.itemStruct.author.nickname"))
 
     @property
+    def nickname_raw(self):
+        return self._get_attr_value("$.itemInfo.itemStruct.author.nickname")
+
+    @property
     def secUid(self):
         return self._get_attr_value("$.itemInfo.itemStruct.author.secUid")
 
     @property
     def uniqueId(self):
         return self._get_attr_value("$.itemInfo.itemStruct.author.uniqueId")
 
     @property
     def signature(self):
         return replaceT(self._get_attr_value("$.itemInfo.itemStruct.author.signature"))
 
     @property
+    def signature_raw(self):
+        return self._get_attr_value("$.itemInfo.itemStruct.author.signature")
+
+    @property
     def openFavorite(self):
         return self._get_attr_value("$.itemInfo.itemStruct.author.openFavorite")
 
     @property
     def privateAccount(self):
         return self._get_attr_value("$.itemInfo.itemStruct.author.privateAccount")
 
@@ -458,14 +503,18 @@
         )
 
     @property
     def desc(self):
         return replaceT(self._get_attr_value("$.itemInfo.itemStruct.desc"))
 
     @property
+    def desc_raw(self):
+        return self._get_attr_value("$.itemInfo.itemStruct.desc")
+
+    @property
     def textExtra(self):
         return self._get_attr_value("$.itemInfo.itemStruct.textExtra")
 
     @property
     def aweme_id(self):
         return self._get_attr_value("$.itemInfo.itemStruct.id")
 
@@ -528,14 +577,18 @@
 
     # music
     @property
     def music_authorName(self):
         return replaceT(self._get_attr_value("$.itemInfo.itemStruct.music.authorName"))
 
     @property
+    def music_authorName_raw(self):
+        return self._get_attr_value("$.itemInfo.itemStruct.music.authorName")
+
+    @property
     def music_coverLarge(self):
         return self._get_attr_value("$.itemInfo.itemStruct.music.coverLarge")
 
     @property
     def music_duration(self):
         return self._get_attr_value("$.itemInfo.itemStruct.music.duration")
 
@@ -551,14 +604,18 @@
     def music_playUrl(self):
         return self._get_attr_value("$.itemInfo.itemStruct.music.playUrl")
 
     @property
     def music_title(self):
         return replaceT(self._get_attr_value("$.itemInfo.itemStruct.music.title"))
 
+    @property
+    def music_title_raw(self):
+        return self._get_attr_value("$.itemInfo.itemStruct.music.title")
+
     # video
     @property
     def video_bitrate(self):
         return self._get_attr_value("$.itemInfo.itemStruct.video.bitrate")
 
     @property
     def video_bitrateInfo(self):
@@ -595,14 +652,17 @@
     def video_height(self):
         return self._get_attr_value("$.itemInfo.itemStruct.video.height")
 
     @property
     def video_width(self):
         return self._get_attr_value("$.itemInfo.itemStruct.video.width")
 
+    def _to_raw(self) -> dict:
+        return self._data
+
     def _to_dict(self) -> dict:
         return {
             prop_name: getattr(self, prop_name)
             for prop_name in dir(self)
             if not prop_name.startswith("__") and not prop_name.startswith("_")
         }
```

### Comparing `f2-0.0.1.4/f2/apps/tiktok/help.py` & `f2-0.0.1.5/f2/apps/douyin/help.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# path: f2/apps/tiktok/help.py
+# path: f2/apps/douyin/help.py
 
 from rich.console import Console
 from rich.panel import Panel
 from rich.table import Table
 
 from f2.i18n.translator import _
 
@@ -20,28 +20,28 @@
         (
             "-u --url",
             "[dark_cyan]str",
             _(
                 "æ ¹æ®æ¨¡å¼æä¾›ç›¸åº”çš„é“¾æ¥ã€‚ä¾‹å¦‚ï¼šä¸»é¡µã€ç‚¹èµã€æ”¶è—ä½œå“å¡«å…¥ä¸»é¡µé“¾æ¥ï¼Œå•ä½œå“å¡«å…¥ä½œå“é“¾æ¥ï¼Œåˆè¾‘ä¸ç›´æ’­åŒä¸Š"
             ),
         ),
-        ("-m --music", "[dark_cyan]Choice", _("æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°ã€‚å¯é€‰ï¼š'yes'ã€'no'")),
-        ("-v --cover", "[dark_cyan]Choice", _("æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢ã€‚å¯é€‰ï¼š'yes'ã€'no'")),
-        ("-d --desc", "[dark_cyan]Choice", _("æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆã€‚å¯é€‰ï¼š'yes'ã€'no'")),
+        ("-m --music", "[dark_cyan]Bool", _("æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°")),
+        ("-v --cover", "[dark_cyan]Bool", _("æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢")),
+        ("-d --desc", "[dark_cyan]Bool", _("æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆ")),
         ("-p --path", "[dark_cyan]str", _("ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„ã€‚")),
         (
             "-f --folderize",
-            "[dark_cyan]Choice",
-            _("æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ã€‚å¯é€‰ï¼š'yes'ã€'no'"),
+            "[dark_cyan]Bool",
+            _("æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹"),
         ),
         (
             "-M --mode",
             "[dark_cyan]Choice",
             _(
-                "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post), ç‚¹èµä½œå“(like), æ”¶è—ä½œå“(collect), åˆè¾‘æ’­æ”¾åˆ—è¡¨(mix)"
+                "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“(collection)ï¼Œæ”¶è—å¤¹ä½œå“(collects)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
             ),
         ),
         (
             "-n --naming",
             "[dark_cyan]str",
             _("å…¨å±€ä½œå“æ–‡ä»¶å‘½åæ–¹å¼ï¼Œå‰å¾€æ–‡æ¡£æŸ¥çœ‹æ›´å¤šå¸®åŠ©"),
         ),
@@ -55,66 +55,68 @@
         (
             "-i --interval",
             "[dark_cyan]str",
             _(
                 "ä¸‹è½½æ—¥æœŸåŒºé—´å‘å¸ƒçš„ä½œå“ï¼Œæ ¼å¼ï¼š2022-01-01|2023-01-01ï¼Œ'all' ä¸ºä¸‹è½½æ‰€æœ‰ä½œå“"
             ),
         ),
-        ("-e --timeout", "[dark_cyan]int", _("ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ã€‚")),
-        ("-r --max-retries", "[dark_cyan]int", _("ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°ã€‚")),
-        ("-x --max-connections", "[dark_cyan]int", _("ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°ã€‚")),
-        ("-t --max-tasks", "[dark_cyan]int", _("å¼‚æ­¥çš„ä»»åŠ¡æ•°ã€‚")),
-        (
-            "-o --max-counts",
-            "[dark_cyan]int",
-            _("æœ€å¤§ä½œå“ä¸‹è½½æ•°ã€‚0 è¡¨ç¤ºæ— é™åˆ¶"),
-        ),
+        ("-e --timeout", "[dark_cyan]int", _("ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´")),
+        ("-r --max-retries", "[dark_cyan]int", _("ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°")),
+        ("-x --max-connections", "[dark_cyan]int", _("ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°")),
+        ("-t --max-tasks", "[dark_cyan]int", _("å¼‚æ­¥çš„ä»»åŠ¡æ•°")),
+        ("-o --max-counts", "[dark_cyan]int", _("æœ€å¤§ä½œå“ä¸‹è½½æ•°ã€‚0 è¡¨ç¤ºæ— é™åˆ¶")),
         (
             "-s --page-counts",
             "[dark_cyan]int",
-            _("ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20ã€‚"),
+            _("ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20"),
         ),
         (
             "-l --languages",
             "[dark_cyan]Choice",
             _("æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ã€‚å¯é€‰ï¼š'zh_CN'ã€'en_US'"),
         ),
         (
             "-P --proxies",
             "[dark_cyan]str",
             _(
                 "ä»£ç†æœåŠ¡å™¨ï¼Œæœ€å¤š 2 ä¸ªå‚æ•°ï¼Œhttpä¸httpsã€‚ç©ºæ ¼åŒºåˆ† 2 ä¸ªå‚æ•° http://x.x.x.x https://x.x.x.x"
             ),
         ),
+        ("-L --lyric", "[dark_cyan]Bool", _("æ˜¯å¦ä¿å­˜è§†é¢‘æ­Œè¯")),
         (
             "--update-config",
             "[dark_cyan]Flag",
             _("ä½¿ç”¨å‘½ä»¤è¡Œé€‰é¡¹æ›´æ–°é…ç½®æ–‡ä»¶ã€‚éœ€è¦å…ˆä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªé…ç½®æ–‡ä»¶è·¯å¾„"),
         ),
         (
             "--init-config",
             "[dark_cyan]Flag",
             _("åˆå§‹åŒ–é…ç½®æ–‡ä»¶ã€‚ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶"),
         ),
         (
             "--auto-cookie",
             "[dark_cyan]Choice",
             _(
-                "è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
+                "è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
             ),
         ),
+        (
+            "--sso-login",
+            "[dark_cyan]Flag",
+            _("ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–[yellow]cookie[/yellow]ï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"),
+        ),
         ("--help", "[dark_cyan]Flag", _("æ˜¾ç¤ºç»å…¸å¸®åŠ©ä¿¡æ¯")),
         (
             "",
             "",
             _(
                 "æ›´åŠ è¯¦ç»†çš„å‚æ•°è¯´æ˜è¯·ç‚¹å‡»[link=https://johnserf-seed.github.io/f2/site-config.html][dark_violet]å‰å¾€æ–‡æ¡£[/dark_violet][/]æŸ¥çœ‹"
             ),
         ),
     ]
 
     for option in options:
         table.add_row(*option)
 
     console.print(
-        Panel(table, border_style="bold", title="[TikTok]", title_align="left")
+        Panel(table, border_style="bold", title="[DouYin]", title_align="left")
     )
```

### Comparing `f2-0.0.1.4/f2/apps/tiktok/model.py` & `f2-0.0.1.5/f2/apps/tiktok/model.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/apps/tiktok/utils.py` & `f2-0.0.1.5/f2/apps/douyin/utils.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,13 +1,16 @@
-# path: f2/apps/tiktok/utils.py
+# path: f2/apps/douyin/utils.py
 
 import f2
 import re
 import json
+import time
 import httpx
+import qrcode
+import random
 import asyncio
 
 from typing import Union
 from pathlib import Path
 
 from f2.i18n.translator import _
 from f2.log.logger import logger
@@ -19,24 +22,24 @@
     extract_valid_urls,
     split_filename,
 )
 from f2.exceptions.api_exceptions import (
     APIError,
     APIConnectionError,
     APIResponseError,
+    APIUnavailableError,
     APIUnauthorizedError,
     APINotFoundError,
 )
 
 
 class TokenManager:
-    f2_manager = ConfigManager(f2.F2_CONFIG_FILE_PATH).get_config("f2").get("tiktok")
+    f2_manager = ConfigManager(f2.F2_CONFIG_FILE_PATH).get_config("f2").get("douyin")
     token_conf = f2_manager.get("msToken", None)
     ttwid_conf = f2_manager.get("ttwid", None)
-    odin_tt_conf = f2_manager.get("odin_tt", None)
     proxies_conf = f2_manager.get("proxies", None)
     proxies = {
         "http://": proxies_conf.get("http", None),
         "https://": proxies_conf.get("https", None),
     }
 
     @classmethod
@@ -51,461 +54,506 @@
                 "magic": cls.token_conf["magic"],
                 "version": cls.token_conf["version"],
                 "dataType": cls.token_conf["dataType"],
                 "strData": cls.token_conf["strData"],
                 "tspFromClient": get_timestamp(),
             }
         )
-
         headers = {
             "User-Agent": cls.token_conf["User-Agent"],
             "Content-Type": "application/json",
         }
 
         transport = httpx.HTTPTransport(retries=5)
         with httpx.Client(transport=transport, proxies=cls.proxies) as client:
             try:
                 response = client.post(
-                    cls.token_conf["url"], headers=headers, content=payload
+                    cls.token_conf["url"], content=payload, headers=headers
                 )
-
-                if response.status_code == 401:
-                    raise APIUnauthorizedError(_("ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–msToken"))
-                elif response.status_code == 404:
-                    raise APINotFoundError(_("æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"))
+                response.raise_for_status()
 
                 msToken = str(httpx.Cookies(response.cookies).get("msToken"))
-
-                if len(msToken) not in [148]:
-                    raise APIResponseError(
-                        _(
-                            "msToken: è¯·æ£€æŸ¥å¹¶æ›´æ–° f2 ä¸­ conf.yaml é…ç½®æ–‡ä»¶ä¸­çš„ msTokenï¼Œä»¥åŒ¹é… tiktok æ–°è§„åˆ™ã€‚"
-                        )
-                    )
+                if len(msToken) not in [120, 128]:
+                    raise APIResponseError(_("{0} å†…å®¹ä¸ç¬¦åˆè¦æ±‚").format("msToken"))
 
                 return msToken
 
-            except httpx.RequestError:
+            except httpx.RequestError as exc:
                 # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
                 raise APIConnectionError(
                     _(
-                        "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
-                    ).format(cls.token_conf["url"], cls.proxies, cls.__name__)
+                        "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                    ).format(cls.token_conf["url"], cls.proxies, cls.__name__, exc)
                 )
 
             except httpx.HTTPStatusError as e:
                 # æ•è· httpx çš„çŠ¶æ€ä»£ç é”™è¯¯ (captures specific status code errors from httpx)
-                raise APIResponseError(
-                    f"HTTP Status Code {e.response.status_code}: {e.response.text}"
-                )
+                if e.response.status_code == 401:
+                    raise APIUnauthorizedError(
+                        _(
+                            "å‚æ•°éªŒè¯å¤±è´¥ï¼Œè¯·æ›´æ–° F2 é…ç½®æ–‡ä»¶ä¸­çš„ {0}ï¼Œä»¥åŒ¹é… {1} æ–°è§„åˆ™"
+                        ).format("msToken", "douyin")
+                    )
+
+                elif e.response.status_code == 404:
+                    raise APINotFoundError(_("{0} æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹").format("msToken"))
+                else:
+                    raise APIResponseError(
+                        _("é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} ").format(
+                            e.response.url, e.response.status_code, e.response.text
+                        )
+                    )
 
             except APIError as e:
                 # è¿”å›è™šå‡çš„msToken (Return a fake msToken)
+                logger.error(_("msToken APIé”™è¯¯ï¼š{0}").format(e))
                 logger.info(_("ç”Ÿæˆè™šå‡çš„msToken"))
                 return cls.gen_false_msToken()
 
     @classmethod
     def gen_false_msToken(cls) -> str:
         """ç”ŸæˆéšæœºmsToken (Generate random msToken)"""
-        return gen_random_str(146) + "=="
+        return gen_random_str(126) + "=="
 
     @classmethod
     def gen_ttwid(cls) -> str:
         """
-        ç”Ÿæˆè¯·æ±‚å¿…å¸¦çš„ttwid (Generate the essential ttwid for requests)
+        ç”Ÿæˆè¯·æ±‚å¿…å¸¦çš„ttwid
+        (Generate the essential ttwid for requests)
         """
+
         transport = httpx.HTTPTransport(retries=5)
-        with httpx.Client(transport=transport, proxies=cls.proxies) as client:
+        with httpx.Client(transport=transport) as client:
             try:
                 response = client.post(
-                    cls.ttwid_conf["url"],
-                    headers={
-                        "Cookie": cls.ttwid_conf.get("cookie"),
-                        "Content-Type": "text/plain",
-                    },
-                    content=cls.ttwid_conf["data"],
+                    cls.ttwid_conf["url"], content=cls.ttwid_conf["data"]
                 )
+                response.raise_for_status()
 
-                if response.status_code == 401:
-                    raise APIUnauthorizedError(_("401 ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–ttwid"))
-                elif response.status_code == 404:
-                    raise APINotFoundError(_("404 æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"))
-
-                ttwid = httpx.Cookies(response.cookies).get("ttwid")
-
-                if ttwid is None:
-                    raise APIResponseError(
-                        _("ttwid: æ£€æŸ¥æ²¡æœ‰é€šè¿‡, è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„ttwid")
-                    )
-
+                ttwid = str(httpx.Cookies(response.cookies).get("ttwid"))
                 return ttwid
 
-            except httpx.RequestError:
+            except httpx.RequestError as exc:
                 # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
                 raise APIConnectionError(
                     _(
-                        "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
-                    ).format(cls.ttwid_conf["url"], cls.proxies, cls.__name__)
+                        "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                    ).format(cls.ttwid_conf["url"], cls.proxies, cls.__name__, exc)
                 )
 
             except httpx.HTTPStatusError as e:
                 # æ•è· httpx çš„çŠ¶æ€ä»£ç é”™è¯¯ (captures specific status code errors from httpx)
-                raise APIResponseError(
-                    f"HTTP Status Code {e.response.status_code}: {e.response.text}"
-                )
-
-    @classmethod
-    def gen_odin_tt(cls):
-        """
-        ç”Ÿæˆè¯·æ±‚å¿…å¸¦çš„odin_tt (Generate the essential odin_tt for requests)
-        """
-        transport = httpx.HTTPTransport(retries=5)
-        with httpx.Client(transport=transport, proxies=cls.proxies) as client:
-            try:
-                response = client.get(cls.odin_tt_conf["url"])
-
-                if response.status_code == 401:
-                    raise APIUnauthorizedError(_("401 ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–ttwid"))
-                elif response.status_code == 404:
-                    raise APINotFoundError(_("404 æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"))
-
-                odin_tt = httpx.Cookies(response.cookies).get("odin_tt")
+                if e.response.status_code == 401:
+                    raise APIUnauthorizedError(
+                        _(
+                            "å‚æ•°éªŒè¯å¤±è´¥ï¼Œè¯·æ›´æ–° F2 é…ç½®æ–‡ä»¶ä¸­çš„ {0}ï¼Œä»¥åŒ¹é… {1} æ–°è§„åˆ™"
+                        ).format("ttwid", "douyin")
+                    )
 
-                if odin_tt is None:
+                elif e.response.status_code == 404:
+                    raise APINotFoundError(_("ttwidæ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"))
+                else:
                     raise APIResponseError(
-                        _("odin_tt: æ£€æŸ¥æ²¡æœ‰é€šè¿‡, è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„odin_tt")
+                        _("é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} ").format(
+                            e.response.url, e.response.status_code, e.response.text
+                        )
                     )
 
-                return odin_tt
 
-            except httpx.RequestError:
-                # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
-                raise APIConnectionError(
-                    _(
-                        "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
-                    ).format(cls.odin_tt_conf["url"], cls.proxies, cls.__name__)
-                )
+class VerifyFpManager:
+    @classmethod
+    def gen_verify_fp(cls) -> str:
+        """
+        ç”ŸæˆverifyFp ä¸ s_v_web_id (Generate verifyFp)
+        """
+        base_str = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
+        t = len(base_str)
+        milliseconds = int(round(time.time() * 1000))
+        base36 = ""
+        while milliseconds > 0:
+            remainder = milliseconds % 36
+            if remainder < 10:
+                base36 = str(remainder) + base36
+            else:
+                base36 = chr(ord("a") + remainder - 10) + base36
+            milliseconds = int(milliseconds / 36)
+        r = base36
+        o = [""] * 36
+        o[8] = o[13] = o[18] = o[23] = "_"
+        o[14] = "4"
+
+        for i in range(36):
+            if not o[i]:
+                n = 0 or int(random.random() * t)
+                if i == 19:
+                    n = 3 & n | 8
+                o[i] = base_str[n]
 
-            except httpx.HTTPStatusError as e:
-                # æ•è· httpx çš„çŠ¶æ€ä»£ç é”™è¯¯ (captures specific status code errors from httpx)
-                raise APIResponseError(
-                    f"HTTP Status Code {e.response.status_code}: {e.response.text}"
-                )
+        return "verify_" + r + "_" + "".join(o)
+
+    @classmethod
+    def gen_s_v_web_id(cls) -> str:
+        return cls.gen_verify_fp()
 
 
 class XBogusManager:
     @classmethod
-    def str_2_endpoint(cls, endpoint: str) -> str:
+    def str_2_endpoint(
+        cls,
+        user_agent: str,
+        endpoint: str,
+    ) -> str:
         try:
-            final_endpoint = XB().getXBogus(endpoint)
+            final_endpoint = XB(user_agent).getXBogus(endpoint)
         except Exception as e:
             raise RuntimeError(_("ç”ŸæˆX-Boguså¤±è´¥: {0})").format(e))
 
         return final_endpoint[0]
 
     @classmethod
-    def model_2_endpoint(cls, base_endpoint: str, params: dict) -> str:
-        # æ£€æŸ¥paramsæ˜¯å¦æ˜¯ä¸€ä¸ªå­—å…¸ (Check if params is a dict)
+    def model_2_endpoint(
+        cls,
+        user_agent: str,
+        base_endpoint: str,
+        params: dict,
+    ) -> str:
         if not isinstance(params, dict):
             raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯å­—å…¸ç±»å‹"))
 
         param_str = "&".join([f"{k}={v}" for k, v in params.items()])
 
         try:
-            xb_value = XB().getXBogus(param_str)
+            xb_value = XB(user_agent).getXBogus(param_str)
         except Exception as e:
             raise RuntimeError(_("ç”ŸæˆX-Boguså¤±è´¥: {0})").format(e))
 
         # æ£€æŸ¥base_endpointæ˜¯å¦å·²æœ‰æŸ¥è¯¢å‚æ•° (Check if base_endpoint already has query parameters)
         separator = "&" if "?" in base_endpoint else "?"
 
         final_endpoint = f"{base_endpoint}{separator}{param_str}&X-Bogus={xb_value[1]}"
 
         return final_endpoint
 
 
 class SecUserIdFetcher:
-    _TIKTOK_SECUID_PARREN = re.compile(
-        r"<script id=\"__UNIVERSAL_DATA_FOR_REHYDRATION__\" type=\"application/json\">(.*?)</script>"
-    )
-    _TIKTOK_UNIQUEID_PARREN = re.compile(r"/@([^/?]*)")
-    _TIKTOK_NOTFOUND_PARREN = re.compile(r"notfound")
+    # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
+    _DOUYIN_URL_PATTERN = re.compile(r"user/([^/?]*)")
+    _REDIRECT_URL_PATTERN = re.compile(r"sec_uid=([^&]*)")
 
     @classmethod
-    async def get_secuid(cls, url: str) -> str:
+    async def get_sec_user_id(cls, url: str) -> str:
         """
-        è·å–TikTokç”¨æˆ·sec_uid
+        ä»å•ä¸ªurlä¸­è·å–sec_user_id (Get sec_user_id from a single url)
+
         Args:
-            url: ç”¨æˆ·ä¸»é¡µé“¾æ¥
-        Return:
-            sec_uid: ç”¨æˆ·å”¯ä¸€æ ‡è¯†
+            url (str): è¾“å…¥çš„url (Input url)
+
+        Returns:
+            str: åŒ¹é…åˆ°çš„sec_user_id (Matched sec_user_id)ã€‚
         """
 
-        # è¿›è¡Œå‚æ•°æ£€æŸ¥
         if not isinstance(url, str):
-            raise TypeError("è¾“å…¥å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
+            raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"))
 
         # æå–æœ‰æ•ˆURL
         url = extract_valid_urls(url)
 
         if url is None:
             raise (
-                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__)))
+                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__))
             )
 
-        transport = httpx.AsyncHTTPTransport(retries=5)
-        async with httpx.AsyncClient(
-            transport=transport, proxies=TokenManager.proxies, timeout=10
-        ) as client:
-            try:
-                response = await client.get(url, follow_redirects=True)
+        pattern = (
+            cls._REDIRECT_URL_PATTERN
+            if "v.douyin.com" in url
+            else cls._DOUYIN_URL_PATTERN
+        )
 
+        try:
+            transport = httpx.AsyncHTTPTransport(retries=5)
+            async with httpx.AsyncClient(
+                transport=transport, proxies=TokenManager.proxies, timeout=10
+            ) as client:
+                response = await client.get(url, follow_redirects=True)
+                # 444ä¸€èˆ¬ä¸ºNginxæ‹¦æˆªï¼Œä¸è¿”å›çŠ¶æ€ (444 is generally intercepted by Nginx and does not return status)
                 if response.status_code in {200, 444}:
-                    if cls._TIKTOK_NOTFOUND_PARREN.search(str(response.url)):
-                        raise APINotFoundError(
-                            _(
-                                "é¡µé¢ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯ç”±äºåŒºåŸŸé™åˆ¶ï¼ˆä»£ç†ï¼‰é€ æˆçš„ã€‚ç±»å: {0}".format(
-                                    cls.__name__
-                                )
-                            )
-                        )
-                    match = cls._TIKTOK_SECUID_PARREN.search(str(response.text))
-                    if not match:
+                    match = pattern.search(str(response.url))
+                    if match:
+                        return match.group(1)
+                    else:
                         raise APIResponseError(
                             _(
-                                "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_uid, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»å: {0}".format(
-                                    cls.__name__
-                                )
-                            )
+                                "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_user_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»åï¼š{0}"
+                            ).format(cls.__name__)
                         )
 
-                    # æå–SIGI_STATEå¯¹è±¡ä¸­çš„sec_uid
-                    data = json.loads(match.group(1))
-                    default_scope = data.get("__DEFAULT_SCOPE__", {})
-                    user_detail = default_scope.get("webapp.user-detail", {})
-                    user_info = user_detail.get("userInfo", {}).get("user", {})
-                    sec_uid = user_info.get("secUid")
-
-                    if sec_uid is None:
-                        raise RuntimeError(_("è·å–sec_uidå¤±è´¥, {0}".format(user_info)))
-
-                    return sec_uid
+                elif response.status_code == 401:
+                    raise APIUnauthorizedError(
+                        _("æœªæˆæƒçš„è¯·æ±‚ã€‚ç±»åï¼š{0}").format(cls.__name__)
+                    )
+                elif response.status_code == 404:
+                    raise APINotFoundError(
+                        _("æœªæ‰¾åˆ°APIç«¯ç‚¹ã€‚ç±»åï¼š{0}").format(cls.__name__)
+                    )
+                elif response.status_code == 503:
+                    raise APIUnavailableError(
+                        _("APIæœåŠ¡ä¸å¯ç”¨ã€‚ç±»åï¼š{0}").format(cls.__name__)
+                    )
                 else:
-                    raise ConnectionError(_("æ¥å£çŠ¶æ€ç å¼‚å¸¸, è¯·æ£€æŸ¥é‡è¯•"))
+                    raise APIResponseError(
+                        _("é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} ").format(
+                            response.url, response.status_code, response.text
+                        )
+                    )
 
-            except httpx.RequestError:
-                raise APIConnectionError(
-                    _(
-                        "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
-                    ).format(url, TokenManager.proxies, cls.__name__)
-                )
+        except httpx.RequestError as exc:
+            raise APIConnectionError(
+                _(
+                    "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                ).format(url, TokenManager.proxies, cls.__name__, exc)
+            )
 
     @classmethod
-    async def get_all_secuid(cls, urls: list) -> list:
+    async def get_all_sec_user_id(cls, urls: list) -> list:
         """
-        è·å–åˆ—è¡¨secuidåˆ—è¡¨ (Get list sec_user_id list)
+        è·å–åˆ—è¡¨sec_user_idåˆ—è¡¨ (Get list sec_user_id list)
 
         Args:
             urls: list: ç”¨æˆ·urlåˆ—è¡¨ (User url list)
 
         Return:
-            secuids: list: ç”¨æˆ·secuidåˆ—è¡¨ (User secuid list)
+            sec_user_ids: list: ç”¨æˆ·sec_user_idåˆ—è¡¨ (User sec_user_id list)
         """
 
         if not isinstance(urls, list):
             raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹"))
 
         # æå–æœ‰æ•ˆURL
         urls = extract_valid_urls(urls)
 
         if urls == []:
             raise (
                 APINotFoundError(
-                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__))
+                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__)
                 )
             )
 
-        secuids = [cls.get_secuid(url) for url in urls]
-        return await asyncio.gather(*secuids)
+        sec_user_ids = [cls.get_sec_user_id(url) for url in urls]
+        return await asyncio.gather(*sec_user_ids)
+
+
+class AwemeIdFetcher:
+    # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
+    _DOUYIN_VIDEO_URL_PATTERN = re.compile(r"video/([^/?]*)")
+    _DOUYIN_NOTE_URL_PATTERN = re.compile(r"note/([^/?]*)")
 
     @classmethod
-    async def get_uniqueid(cls, url: str) -> str:
+    async def get_aweme_id(cls, url: str) -> str:
         """
-        è·å–TikTokç”¨æˆ·unique_id
+        ä»å•ä¸ªurlä¸­è·å–aweme_id (Get aweme_id from a single url)
+
         Args:
-            url: ç”¨æˆ·ä¸»é¡µé“¾æ¥
-        Return:
-            unique_id: ç”¨æˆ·å”¯ä¸€id
+            url (str): è¾“å…¥çš„url (Input url)
+
+        Returns:
+            str: åŒ¹é…åˆ°çš„aweme_id (Matched aweme_id)ã€‚
         """
 
-        # è¿›è¡Œå‚æ•°æ£€æŸ¥
         if not isinstance(url, str):
-            raise TypeError("è¾“å…¥å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
+            raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"))
 
         # æå–æœ‰æ•ˆURL
         url = extract_valid_urls(url)
 
         if url is None:
             raise (
-                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__)))
+                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__))
             )
 
+        # é‡å®šå‘åˆ°å®Œæ•´é“¾æ¥
         transport = httpx.AsyncHTTPTransport(retries=5)
         async with httpx.AsyncClient(
             transport=transport, proxies=TokenManager.proxies, timeout=10
         ) as client:
             try:
                 response = await client.get(url, follow_redirects=True)
+                response.raise_for_status()
 
-                if response.status_code in {200, 444}:
-                    match = cls._TIKTOK_UNIQUEID_PARREN.search(str(response.url))
-                    if not match:
-                        raise APIResponseError(_("æœªåœ¨å“åº”ä¸­æ‰¾åˆ°unique_id"))
-
-                    unique_id = match.group(1)
-
-                    if unique_id is None:
-                        raise RuntimeError(
-                            _("è·å–unique_idå¤±è´¥, {0}".format(response.url))
-                        )
+                video_pattern = cls._DOUYIN_VIDEO_URL_PATTERN
+                note_pattern = cls._DOUYIN_NOTE_URL_PATTERN
 
-                    return unique_id
+                match = video_pattern.search(str(response.url))
+                if match:
+                    aweme_id = match.group(1)
                 else:
-                    raise ConnectionError(
-                        _("æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}, è¯·æ£€æŸ¥é‡è¯•").format(response.status_code)
-                    )
+                    match = note_pattern.search(str(response.url))
+                    if match:
+                        aweme_id = match.group(1)
+                    else:
+                        raise APIResponseError(
+                            _("æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°aweme_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºä½œå“é¡µ")
+                        )
+                return aweme_id
 
-            except httpx.RequestError:
+            except httpx.RequestError as exc:
+                # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
                 raise APIConnectionError(
                     _(
-                        "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
-                    ).format(url, TokenManager.proxies, cls.__name__),
+                        "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                    ).format(url, TokenManager.proxies, cls.__name__, exc)
+                )
+
+            except httpx.HTTPStatusError as e:
+                raise APIResponseError(
+                    _("é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} ").format(
+                        e.response.url, e.response.status_code, e.response.text
+                    )
                 )
 
     @classmethod
-    async def get_all_uniqueid(cls, urls: list) -> list:
+    async def get_all_aweme_id(cls, urls: list) -> list:
         """
-        è·å–åˆ—è¡¨unique_idåˆ—è¡¨ (Get list sec_user_id list)
+        è·å–è§†é¢‘aweme_id,ä¼ å…¥åˆ—è¡¨urléƒ½å¯ä»¥è§£æå‡ºaweme_id (Get video aweme_id, pass in the list url can parse out aweme_id)
 
         Args:
-            urls: list: ç”¨æˆ·urlåˆ—è¡¨ (User url list)
+            urls: list: åˆ—è¡¨url (list url)
 
         Return:
-            unique_ids: list: ç”¨æˆ·unique_idåˆ—è¡¨ (User unique_id list)
+            aweme_ids: list: è§†é¢‘çš„å”¯ä¸€æ ‡è¯†ï¼Œè¿”å›åˆ—è¡¨ (The unique identifier of the video, return list)
         """
 
         if not isinstance(urls, list):
             raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹"))
 
         # æå–æœ‰æ•ˆURL
         urls = extract_valid_urls(urls)
 
         if urls == []:
             raise (
                 APINotFoundError(
-                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__))
+                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__)
                 )
             )
 
-        unique_ids = [cls.get_uniqueid(url) for url in urls]
-        return await asyncio.gather(*unique_ids)
+        aweme_ids = [cls.get_aweme_id(url) for url in urls]
+        return await asyncio.gather(*aweme_ids)
+
 
+class MixIdFetcher:
+    # è·å–æ–¹æ³•åŒAwemeIdFetcher
+    @classmethod
+    async def get_mix_id(cls, url: str) -> str:
+        return
 
-class AwemeIdFetcher:
-    # https://www.tiktok.com/@scarlettjonesuk/video/7255716763118226715
-    # https://www.tiktok.com/@scarlettjonesuk/video/7255716763118226715?is_from_webapp=1&sender_device=pc&web_id=7306060721837852167
 
+class WebCastIdFetcher:
     # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
-    _TIKTOK_AWEMEID_PARREN = re.compile(r"video/(\d*)")
+    _DOUYIN_LIVE_URL_PATTERN = re.compile(r"live/([^/?]*)")
+    # https://live.douyin.com/766545142636?cover_type=0&enter_from_merge=web_live&enter_method=web_card&game_name=&is_recommend=1&live_type=game&more_detail=&request_id=20231110224012D47CD00C18B4AE4BFF9B&room_id=7299828646049827596&stream_type=vertical&title_type=1&web_live_page=hot_live&web_live_tab=all
+    # https://live.douyin.com/766545142636
+    _DOUYIN_LIVE_URL_PATTERN2 = re.compile(r"http[s]?://live.douyin.com/(\d+)")
+    # https://webcast.amemv.com/douyin/webcast/reflow/7318296342189919011?u_code=l1j9bkbd&did=MS4wLjABAAAAEs86TBQPNwAo-RGrcxWyCdwKhI66AK3Pqf3ieo6HaxI&iid=MS4wLjABAAAA0ptpM-zzoliLEeyvWOCUt-_dQza4uSjlIvbtIazXnCY&with_sec_did=1&use_link_command=1&ecom_share_track_params=&extra_params={"from_request_id":"20231230162057EC005772A8EAA0199906","im_channel_invite_id":"0"}&user_id=3644207898042206&liveId=7318296342189919011&from=share&style=share&enter_method=click_share&roomId=7318296342189919011&activity_info={}
+    _DOUYIN_LIVE_URL_PATTERN3 = re.compile(r"reflow/([^/?]*)")
 
     @classmethod
-    async def get_aweme_id(cls, url: str) -> str:
+    async def get_webcast_id(cls, url: str) -> str:
         """
-        è·å–TikTokä½œå“aweme_id
+        ä»å•ä¸ªurlä¸­è·å–webcast_id (Get webcast_id from a single url)
+
         Args:
-            url: ä½œå“é“¾æ¥
-        Return:
-            aweme_id: ä½œå“å”¯ä¸€æ ‡è¯†
+            url (str): è¾“å…¥çš„url (Input url)
+
+        Returns:
+            str: åŒ¹é…åˆ°çš„webcast_id (Matched webcast_id)ã€‚
         """
 
-        # è¿›è¡Œå‚æ•°æ£€æŸ¥
         if not isinstance(url, str):
-            raise TypeError("è¾“å…¥å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
+            raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"))
 
         # æå–æœ‰æ•ˆURL
         url = extract_valid_urls(url)
 
         if url is None:
             raise (
-                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__)))
+                APINotFoundError(_("è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__))
             )
-
-        transport = httpx.AsyncHTTPTransport(retries=5)
-        async with httpx.AsyncClient(
-            transport=transport, proxies=TokenManager.proxies, timeout=10
-        ) as client:
-            try:
+        try:
+            # é‡å®šå‘åˆ°å®Œæ•´é“¾æ¥
+            transport = httpx.AsyncHTTPTransport(retries=5)
+            async with httpx.AsyncClient(
+                transport=transport, proxies=TokenManager.proxies, timeout=10
+            ) as client:
                 response = await client.get(url, follow_redirects=True)
+                response.raise_for_status()
+                url = str(response.url)
 
-                if response.status_code in {200, 444}:
-                    match = cls._TIKTOK_AWEMEID_PARREN.search(str(response.url))
-                    if not match:
-                        raise APIResponseError(_("æœªåœ¨å“åº”ä¸­æ‰¾åˆ°aweme_id"))
-
-                    aweme_id = match.group(1)
-
-                    if aweme_id is None:
-                        raise RuntimeError(
-                            _("è·å–aweme_idå¤±è´¥, {0}".format(response.url))
+                live_pattern = cls._DOUYIN_LIVE_URL_PATTERN
+                live_pattern2 = cls._DOUYIN_LIVE_URL_PATTERN2
+                live_pattern3 = cls._DOUYIN_LIVE_URL_PATTERN3
+
+                if live_pattern.search(url):
+                    match = live_pattern.search(url)
+                elif live_pattern2.search(url):
+                    match = live_pattern2.search(url)
+                elif live_pattern3.search(url):
+                    match = live_pattern3.search(url)
+                    logger.warning(
+                        _(
+                            "è¯¥é“¾æ¥è¿”å›çš„æ˜¯room_idï¼Œè¯·ä½¿ç”¨`fetch_user_live_videos_by_room_id`æ¥å£"
                         )
-
-                    return aweme_id
+                    )
                 else:
-                    raise ConnectionError(
-                        _("æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}, è¯·æ£€æŸ¥é‡è¯•").format(response.status_code)
+                    raise APIResponseError(
+                        _("æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°webcast_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç›´æ’­é¡µ")
                     )
 
-            except httpx.RequestError:
-                raise APIConnectionError(
-                    _(
-                        "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
-                    ).format(
-                        url,
-                        TokenManager.proxies,
-                        cls.__name__,
-                    )
+                return match.group(1)
+
+        except httpx.RequestError as exc:
+            # æ•è·æ‰€æœ‰ä¸ httpx è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸æƒ…å†µ (Captures all httpx request-related exceptions)
+            raise APIConnectionError(
+                _(
+                    "è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+                ).format(url, TokenManager.proxies, cls.__name__, exc)
+            )
+
+        except httpx.HTTPStatusError as e:
+            raise APIResponseError(
+                _("é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} ").format(
+                    e.response.url, e.response.status_code, e.response.text
                 )
+            )
 
     @classmethod
-    async def get_all_aweme_id(cls, urls: list) -> list:
+    async def get_all_webcast_id(cls, urls: list) -> list:
         """
-        è·å–è§†é¢‘aweme_id,ä¼ å…¥åˆ—è¡¨urléƒ½å¯ä»¥è§£æå‡ºaweme_id (Get video aweme_id, pass in the list url can parse out aweme_id)
+        è·å–ç›´æ’­webcast_id,ä¼ å…¥åˆ—è¡¨urléƒ½å¯ä»¥è§£æå‡ºwebcast_id (Get live webcast_id, pass in the list url can parse out webcast_id)
 
         Args:
             urls: list: åˆ—è¡¨url (list url)
 
         Return:
-            aweme_ids: list: è§†é¢‘çš„å”¯ä¸€æ ‡è¯†ï¼Œè¿”å›åˆ—è¡¨ (The unique identifier of the video, return list)
+            webcast_ids: list: ç›´æ’­çš„å”¯ä¸€æ ‡è¯†ï¼Œè¿”å›åˆ—è¡¨ (The unique identifier of the live, return list)
         """
 
         if not isinstance(urls, list):
             raise TypeError(_("å‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹"))
 
         # æå–æœ‰æ•ˆURL
         urls = extract_valid_urls(urls)
 
         if urls == []:
             raise (
                 APINotFoundError(
-                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}".format(cls.__name__))
+                    _("è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}").format(cls.__name__)
                 )
             )
 
-        aweme_ids = [cls.get_aweme_id(url) for url in urls]
-        return await asyncio.gather(*aweme_ids)
+        webcast_ids = [cls.get_webcast_id(url) for url in urls]
+        return await asyncio.gather(*webcast_ids)
 
 
 def format_file_name(
     naming_template: str,
     aweme_data: dict = {},
     custom_fields: dict = {},
 ) -> str:
@@ -537,45 +585,45 @@
         "win32": 200,
         "cygwin": 60,
         "darwin": 60,
         "linux": 60,
     }
 
     fields = {
-        "create": aweme_data.get("createTime", ""),  # é•¿åº¦å›ºå®š19
+        "create": aweme_data.get("create_time", ""),  # é•¿åº¦å›ºå®š19
         "nickname": aweme_data.get("nickname", ""),  # æœ€é•¿30
         "aweme_id": aweme_data.get("aweme_id", ""),  # é•¿åº¦å›ºå®š19
         "desc": split_filename(aweme_data.get("desc", ""), os_limit),
         "uid": aweme_data.get("uid", ""),  # å›ºå®š11
     }
 
     if custom_fields:
         # æ›´æ–°è‡ªå®šä¹‰å­—æ®µ
         fields.update(custom_fields)
 
     try:
         return naming_template.format(**fields)
     except KeyError as e:
-        raise KeyError(_("æ–‡ä»¶åæ¨¡æ¿å­—æ®µ {0} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥".format(e)))
+        raise KeyError(_("æ–‡ä»¶åæ¨¡æ¿å­—æ®µ {0} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥").format(e))
 
 
 def create_user_folder(kwargs: dict, nickname: Union[str, int]) -> Path:
     """
     æ ¹æ®æä¾›çš„é…ç½®æ–‡ä»¶å’Œæ˜µç§°ï¼Œåˆ›å»ºå¯¹åº”çš„ä¿å­˜ç›®å½•ã€‚
     (Create the corresponding save directory according to the provided conf file and nickname.)
 
     Args:
         kwargs (dict): é…ç½®æ–‡ä»¶ï¼Œå­—å…¸æ ¼å¼ã€‚(Conf file, dict format)
         nickname (Union[str, int]): ç”¨æˆ·çš„æ˜µç§°ï¼Œå…è®¸å­—ç¬¦ä¸²æˆ–æ•´æ•°ã€‚  (User nickname, allow strings or integers)
 
     Note:
         å¦‚æœæœªåœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šè·¯å¾„ï¼Œåˆ™é»˜è®¤ä¸º "Download"ã€‚
         (If the path is not specified in the conf file, it defaults to "Download".)
-        ä»…æ”¯æŒç›¸å¯¹è·¯å¾„ã€‚
-        (Only relative paths are supported.)
+        æ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„ã€‚
+        (Support absolute and relative paths)
 
     Raises:
         TypeError: å¦‚æœ kwargs ä¸æ˜¯å­—å…¸æ ¼å¼ï¼Œå°†å¼•å‘ TypeErrorã€‚
         (If kwargs is not in dict format, TypeError will be raised.)
     """
 
     # ç¡®å®šå‡½æ•°å‚æ•°æ˜¯å¦æ­£ç¡®
@@ -583,15 +631,15 @@
         raise TypeError("kwargs å‚æ•°å¿…é¡»æ˜¯å­—å…¸")
 
     # åˆ›å»ºåŸºç¡€è·¯å¾„
     base_path = Path(kwargs.get("path", "Download"))
 
     # æ·»åŠ ä¸‹è½½æ¨¡å¼å’Œç”¨æˆ·å
     user_path = (
-        base_path / "tiktok" / kwargs.get("mode", "PLEASE_SETUP_MODE") / str(nickname)
+        base_path / "douyin" / kwargs.get("mode", "PLEASE_SETUP_MODE") / str(nickname)
     )
 
     # è·å–ç»å¯¹è·¯å¾„å¹¶ç¡®ä¿å®ƒå­˜åœ¨
     resolve_user_path = user_path.resolve()
 
     # åˆ›å»ºç›®å½•
     resolve_user_path.mkdir(parents=True, exist_ok=True)
@@ -639,7 +687,59 @@
         return user_path
 
     if local_user_data.get("nickname") != current_nickname:
         # æ˜µç§°ä¸ä¸€è‡´ï¼Œè§¦å‘ç›®å½•æ›´æ–°æ“ä½œ
         user_path = rename_user_folder(user_path, current_nickname)
 
     return user_path
+
+
+def show_qrcode(qrcode_url: str, show_image: bool = False) -> None:
+    """
+    æ˜¾ç¤ºäºŒç»´ç  (Show QR code)
+
+    Args:
+        qrcode_url (str): ç™»å½•äºŒç»´ç é“¾æ¥ (Login QR code link)
+        show_image (bool): æ˜¯å¦æ˜¾ç¤ºå›¾åƒï¼ŒTrue è¡¨ç¤ºæ˜¾ç¤ºï¼ŒFalse è¡¨ç¤ºåœ¨æ§åˆ¶å°æ˜¾ç¤º
+        (Whether to display the image, True means display, False means display in the console)
+    """
+    if show_image:
+        # åˆ›å»ºå¹¶æ˜¾ç¤ºQRç å›¾åƒ
+        qr_code_img = qrcode.make(qrcode_url)
+        qr_code_img.show()
+    else:
+        # åœ¨æ§åˆ¶å°ä»¥ ASCII å½¢å¼æ‰“å°äºŒç»´ç 
+        qr = qrcode.QRCode()
+        qr.add_data(qrcode_url)
+        qr.make(fit=True)
+        # åœ¨æ§åˆ¶å°ä»¥ ASCII å½¢å¼æ‰“å°äºŒç»´ç 
+        qr.print_ascii(invert=True)
+
+
+def json_2_lrc(data: Union[str, list, dict]) -> str:
+    """
+    ä»æŠ–éŸ³åŸå£°jsonæ ¼å¼æ­Œè¯ç”Ÿæˆlrcæ ¼å¼æ­Œè¯
+    (Generate lrc lyrics format from Douyin original json lyrics format)
+
+    Args:
+        data (Union[str, list, dict]): æŠ–éŸ³åŸå£°jsonæ ¼å¼æ­Œè¯ (Douyin original json lyrics format)
+
+    Returns:
+        str: ç”Ÿæˆçš„lrcæ ¼å¼æ­Œè¯ (Generated lrc format lyrics)
+    """
+    try:
+        lrc_lines = []
+        for item in data:
+            text = item["text"]
+            time_seconds = float(item["timeId"])
+            minutes = int(time_seconds // 60)
+            seconds = int(time_seconds % 60)
+            milliseconds = int((time_seconds % 1) * 1000)
+            time_str = f"{minutes:02}:{seconds:02}.{milliseconds:03}"
+            lrc_lines.append(f"[{time_str}] {text}")
+    except KeyError as e:
+        raise KeyError(_("æ­Œè¯æ•°æ®å­—æ®µé”™è¯¯ï¼š{0}").format(e))
+    except RuntimeError as e:
+        raise RuntimeError(_("ç”Ÿæˆæ­Œè¯æ–‡ä»¶å¤±è´¥ï¼š{0}ï¼Œè¯·æ£€æŸ¥æ­Œè¯ `data` å†…å®¹").format(e))
+    except TypeError as e:
+        raise TypeError(_("æ­Œè¯æ•°æ®ç±»å‹é”™è¯¯ï¼š{0}").format(e))
+    return "\n".join(lrc_lines)
```

### Comparing `f2-0.0.1.4/f2/cli/cli_commands.py` & `f2-0.0.1.5/f2/cli/cli_commands.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # path: f2/cli/cli_command.py
 
+import f2
 import click
 import typing
 import asyncio
 import importlib
 
 from f2 import helps
 from f2.apps import __apps__ as apps_module
-from f2.utils import __version__
 from f2.exceptions import APIError
 from f2.cli.cli_console import RichConsoleManager
 from f2.utils._signal import SignalManager
 from f2.i18n.translator import _
 from f2.log.logger import logger
 
 
@@ -19,28 +19,28 @@
 def handle_help(
     ctx: click.Context,
     param: typing.Union[click.Option, click.Parameter],
     value: typing.Any,
 ) -> None:
     if not value or ctx.resilient_parsing:
         return
-    helps.f2()
+    helps.main()
     ctx.exit()
 
 
 # å¤„ç†ç‰ˆæœ¬å·
 def handle_version(
     ctx: click.Context,
     param: typing.Union[click.Option, click.Parameter],
     value: typing.Any,
 ) -> None:
     if not value or ctx.resilient_parsing:
         return
-    logger.debug(f"Version {__version__._version}")
-    print(f"Version {__version__._version}")
+
+    click.echo(f"Version {f2.__version__}")
     ctx.exit()
 
 
 # å¤„ç†debug
 def handle_debug(
     ctx: click.Context,
     param: typing.Union[click.Option, click.Parameter],
@@ -130,18 +130,19 @@
 
     SignalManager().register_shutdown_signal()
 
     with RichConsoleManager().progress:
         try:
             asyncio.run(run_app(kwargs))
         except APIError as e:
-            logger.error(e.display_error())
+            logger.error(e)
 
 
 async def run_app(kwargs):
+    logger.info(f"Version {f2.__version__}")
     app_name = kwargs["app_name"]
     app_module = importlib.import_module(f"f2.apps.{app_name}.handler")
     await app_module.main(kwargs)
 
 
 if __name__ == "__main__":
     main()
```

### Comparing `f2-0.0.1.4/f2/cli/cli_console.py` & `f2-0.0.1.5/f2/cli/cli_console.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/conf/conf.yaml` & `f2-0.0.1.5/f2/conf/conf.yaml`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/crawlers/base_crawler.py` & `f2-0.0.1.5/f2/crawlers/base_crawler.py`

 * *Files 5% similar despite different names*

```diff
@@ -146,15 +146,14 @@
             try:
                 response = await self.aclient.get(url, follow_redirects=True)
                 if not response.text.strip() or not response.content:
                     error_message = _(
                         "ç¬¬ {0} æ¬¡å“åº”å†…å®¹ä¸ºç©º, çŠ¶æ€ç : {1}, URL:{2}"
                     ).format(attempt + 1, response.status_code, response.url)
 
-                    print(error_message)
                     logger.warning(error_message)
 
                     if attempt == self._max_retries - 1:
                         raise APIRetryExhaustedError(
                             _("è·å–ç«¯ç‚¹æ•°æ®å¤±è´¥, æ¬¡æ•°è¾¾åˆ°ä¸Šé™")
                         )
 
@@ -172,15 +171,15 @@
                     ).format(url, self.proxies, self.__class__.__name__)
                 )
 
             except httpx.HTTPStatusError as http_error:
                 self.handle_http_status_error(http_error, url, attempt + 1)
 
             except APIError as e:
-                e.display_error()
+                logger.error(e)
 
     async def post_fetch_data(self, url: str, params: dict = {}):
         """
         è·å–POSTç«¯ç‚¹æ•°æ® (Get POST endpoint data)
 
         Args:
             url (str): ç«¯ç‚¹URL (Endpoint URL)
@@ -195,15 +194,14 @@
                     url, json=dict(params), follow_redirects=True
                 )
                 if not response.text.strip() or not response.content:
                     error_message = _(
                         "ç¬¬ {0} æ¬¡å“åº”å†…å®¹ä¸ºç©º, çŠ¶æ€ç : {1}, URL:{2}"
                     ).format(attempt + 1, response.status_code, response.url)
 
-                    print(error_message)
                     logger.warning(error_message)
 
                     if attempt == self._max_retries - 1:
                         raise APIRetryExhaustedError(
                             _("è·å–ç«¯ç‚¹æ•°æ®å¤±è´¥, æ¬¡æ•°è¾¾åˆ°ä¸Šé™")
                         )
 
@@ -221,15 +219,15 @@
                     ).format(url, self.proxies, self.__class__.__name__)
                 )
 
             except httpx.HTTPStatusError as http_error:
                 self.handle_http_status_error(http_error, url, attempt + 1)
 
             except APIError as e:
-                e.display_error()
+                logger.error(e)
 
     async def head_fetch_data(self, url: str):
         """
         è·å–HEADç«¯ç‚¹æ•°æ® (Get HEAD endpoint data)
 
         Args:
             url (str): ç«¯ç‚¹URL (Endpoint URL)
@@ -250,15 +248,15 @@
                 )
             )
 
         except httpx.HTTPStatusError as http_error:
             self.handle_http_status_error(http_error, url, 1)
 
         except APIError as e:
-            e.display_error()
+            logger.error(e)
 
     def handle_http_status_error(self, http_error, url: str, attempt):
         """
         å¤„ç†HTTPçŠ¶æ€é”™è¯¯ (Handle HTTP status error)
 
         Args:
             http_error: HTTPçŠ¶æ€é”™è¯¯ (HTTP status error)
@@ -275,39 +273,41 @@
             APIRetryExhaustedError: é‡è¯•æ¬¡æ•°è¾¾åˆ°ä¸Šé™ (The number of retries has reached the upper limit)
         """
         response = getattr(http_error, "response", None)
         status_code = getattr(response, "status_code", None)
 
         if response is None or status_code is None:
             logger.error(
-                _("HTTPçŠ¶æ€é”™è¯¯: {0}, URL: {1}, å°è¯•æ¬¡æ•°: {2}").format(
+                _("HTTPçŠ¶æ€é”™è¯¯ï¼š{0}, URLï¼š{1}, å°è¯•æ¬¡æ•°ï¼š{2}").format(
                     http_error, url, attempt
                 )
             )
-            raise APIResponseError(f"å¤„ç†HTTPé”™è¯¯æ—¶é‡åˆ°æ„å¤–æƒ…å†µ: {http_error}")
+            raise APIResponseError(
+                _("å¤„ç†HTTPé”™è¯¯æ—¶é‡åˆ°æ„å¤–æƒ…å†µï¼š{0}").format(http_error)
+            )
 
         if status_code == 302:
             pass
         elif status_code == 404:
-            raise APINotFoundError(f"HTTP Status Code {status_code}")
+            raise APINotFoundError(_("HTTPçŠ¶æ€ç é”™è¯¯ï¼š"), status_code)
         elif status_code == 503:
-            raise APIUnavailableError(f"HTTP Status Code {status_code}")
+            raise APIUnavailableError(_("HTTPçŠ¶æ€ç é”™è¯¯ï¼š"), status_code)
         elif status_code == 408:
-            raise APITimeoutError(f"HTTP Status Code {status_code}")
+            raise APITimeoutError(_("HTTPçŠ¶æ€ç é”™è¯¯ï¼š"), status_code)
         elif status_code == 401:
-            raise APIUnauthorizedError(f"HTTP Status Code {status_code}")
+            raise APIUnauthorizedError(_("HTTPçŠ¶æ€ç é”™è¯¯ï¼š"), status_code)
         elif status_code == 429:
-            raise APIRateLimitError(f"HTTP Status Code {status_code}")
+            raise APIRateLimitError(_("HTTPçŠ¶æ€ç é”™è¯¯ï¼š"), status_code)
         else:
             logger.error(
-                _("HTTPçŠ¶æ€é”™è¯¯: {0}, URL: {1}, å°è¯•æ¬¡æ•°: {2}").format(
-                    status_code, url, attempt
+                _("HTTPçŠ¶æ€é”™è¯¯ï¼š{0}, URLï¼š{1}, å°è¯•æ¬¡æ•°ï¼š{2}").format(
+                    http_error, url, attempt
                 )
             )
-            raise APIResponseError(f"HTTPçŠ¶æ€é”™è¯¯: {status_code}")
+            raise APIResponseError(_("HTTPçŠ¶æ€ç é”™è¯¯ï¼š"), status_code)
 
     async def close(self):
         await self.aclient.aclose()
 
     async def __aenter__(self):
         return self
```

### Comparing `f2-0.0.1.4/f2/db/base_db.py` & `f2-0.0.1.5/f2/db/base_db.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/dl/base_downloader.py` & `f2-0.0.1.5/f2/dl/base_downloader.py`

 * *Files 11% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import sys
 import httpx
 import asyncio
 import aiofiles
 import traceback
 from pathlib import Path
 from rich.progress import TaskID
-from typing import Union, Optional, Any
+from typing import Union, Optional, Any, List
 
 from f2.log.logger import logger
 from f2.i18n.translator import _
 from f2.cli.cli_console import RichConsoleManager
 from f2.crawlers.base_crawler import BaseCrawler
 from f2.utils._signal import SignalManager
 from f2.utils.utils import ensure_path
@@ -22,15 +22,15 @@
     get_segments_from_m3u8,
 )
 
 
 class BaseDownloader(BaseCrawler):
     """åŸºç¡€ä¸‹è½½å™¨ (Base Downloader Class)"""
 
-    def __init__(self, kwargs: dict = {}):
+    def __init__(self, kwargs: dict = ...):
         proxies_conf = kwargs.get("proxies", {"http": None, "https": None})
         proxies = {
             "http://": proxies_conf.get("http", None),
             "https://": proxies_conf.get("https", None),
         }
 
         self.headers = {
@@ -38,15 +38,14 @@
             "Referer": kwargs["headers"]["Referer"],
             "Cookie": kwargs["cookie"],
         }
 
         super().__init__(proxies=proxies, crawler_headers=self.headers)
         self.progress = RichConsoleManager().progress
         self.download_tasks = []
-        logger.debug(_("BaseDownloader è¯·æ±‚å¤´headers:{0}".format(self.headers)))
 
     @staticmethod
     def _ensure_path(path: Union[str, Path]) -> Path:
         return ensure_path(path)
 
     async def _download_chunks(
         self,
@@ -73,97 +72,151 @@
                 if SignalManager.is_shutdown_signaled():
                     break
                 await file.write(chunk)
                 await self.progress.update(
                     task_id, advance=len(chunk), total=int(content_length)
                 )
         except httpx.ReadTimeout as e:
-            logger.warning(_("æ–‡ä»¶åŒºå—ä¸‹è½½è¶…æ—¶: {0}".format(e)))
+            logger.warning(_("æ–‡ä»¶åŒºå—ä¸‹è½½è¶…æ—¶ï¼š{0}").format(e))
         except Exception as e:
-            logger.error(_("æ–‡ä»¶åŒºå—ä¸‹è½½å¤±è´¥: {0}".format(e)))
+            logger.error(_("æ–‡ä»¶åŒºå—ä¸‹è½½å¤±è´¥ï¼š{0}").format(e))
 
     async def download_file(
-        self, task_id: TaskID, url: str, full_path: Union[str, Path]
+        self,
+        task_id: TaskID,
+        urls: Union[str, List[str]],
+        full_path: Union[str, Path],
     ) -> None:
         """
         ä¸‹è½½æ–‡ä»¶ (Download file)
 
         Args:
             task_id (TaskID): ä»»åŠ¡ID (Task ID)
-            url (str): æ–‡ä»¶URL (File URL)
+            urls (Union[str, List[str]]): æ–‡ä»¶URL (File URL)
             full_path (Union[str, Path]): ä¿å­˜è·¯å¾„ (Save path)
+
+        Note:
+            urlä»…ä»£è¡¨ä¸€ä¸ªæ–‡ä»¶çš„é“¾æ¥ï¼Œå½“urlä¸ºåˆ—è¡¨æ—¶ï¼Œè¡¨ç¤ºè¯¥æ–‡ä»¶çš„å¤šä¸ªé“¾æ¥
+            (url represents only a link to a file, when url is a list,
+                it represents multiple links to the file)
         """
         async with self.semaphore:
+            # å¦‚æœurlsæ˜¯å•ä¸ªé“¾æ¥ï¼Œåˆ™è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿ç»Ÿä¸€å¤„ç†
+            if isinstance(urls, str):
+                urls = [urls]
+
             # ç¡®ä¿ç›®æ ‡è·¯å¾„å­˜åœ¨ (Ensure target path exists)
             full_path = self._ensure_path(full_path)
-            # è·å–æ–‡ä»¶å†…å®¹å¤§å° (Get the size of the file content)
-            content_length = await get_content_length(url, self.headers, self.proxies)
 
-            logger.debug(
-                _("{0}åœ¨æœåŠ¡å™¨ä¸Šçš„æ€»å†…å®¹é•¿åº¦ä¸ºï¼š{1} å­—èŠ‚".format(url, content_length))
-            )
+            # éå†æ‰€æœ‰é“¾æ¥ (Iterate over all links)
+            for link in urls:
+                # è·å–æ–‡ä»¶å†…å®¹å¤§å° (Get the size of the file content)
+                content_length = await get_content_length(
+                    link, self.headers, self.proxies
+                )
 
-            # å¦‚æœæ–‡ä»¶å†…å®¹å¤§å°ä¸º0, åˆ™ä¸ä¸‹è½½ (If file content size is 0, skip download)
-            if content_length == 0:
-                logger.warning(_("å†…å®¹é•¿åº¦ä¸º0ï¼Œè·³è¿‡ä¸‹è½½"))
-                await self.progress.update(
-                    task_id,
-                    description=_("[  ä¸¢å¤±  ]:"),
-                    filename=trim_filename(full_path.name, 45),
-                    state="completed",
+                logger.debug(
+                    _("{0} åœ¨æœåŠ¡å™¨ä¸Šçš„æ€»å†…å®¹é•¿åº¦ä¸ºï¼š{1} å­—èŠ‚").format(
+                        link, content_length
+                    )
                 )
-                return
 
-            # ç¡®ä¿ç›®æ ‡è·¯å¾„å­˜åœ¨ (Ensure target path exists)
-            full_path.parent.mkdir(parents=True, exist_ok=True)
-            # å¯»æ‰¾æœªä¸‹è½½å®Œçš„ä¸´æ—¶æ–‡ä»¶ (Find unfinished temporary files)
-            tmp_path = full_path.with_suffix(".tmp")
-            # è·å–ä¸´æ—¶æ–‡ä»¶çš„å¤§å° (Get the size of the temporary file)
-            start_byte = 0 if not tmp_path.exists() else tmp_path.stat().st_size
-
-            logger.debug(
-                _(
-                    "æ‰¾åˆ°äº†æœªä¸‹è½½å®Œçš„æ–‡ä»¶ {0}, å¤§å°ä¸º {1} å­—èŠ‚".format(
+                # å¦‚æœæ–‡ä»¶å†…å®¹å¤§å°ä¸º0, åˆ™å°è¯•ä¸‹ä¸€ä¸ªé“¾æ¥ (If file content size is 0, try the next link)
+                if content_length == 0:
+                    logger.warning(
+                        _("é“¾æ¥ {0} å†…å®¹é•¿åº¦ä¸º0ï¼Œå°è¯•ä¸‹ä¸€ä¸ªé“¾æ¥æ˜¯å¦å¯ç”¨").format(link)
+                    )
+                    continue
+
+                # ç¡®ä¿ç›®æ ‡è·¯å¾„å­˜åœ¨ (Ensure target path exists)
+                full_path.parent.mkdir(parents=True, exist_ok=True)
+                # å¯»æ‰¾æœªä¸‹è½½å®Œçš„ä¸´æ—¶æ–‡ä»¶ (Find unfinished temporary files)
+                tmp_path = full_path.with_suffix(".tmp")
+                # è·å–ä¸´æ—¶æ–‡ä»¶çš„å¤§å° (Get the size of the temporary file)
+                start_byte = 0 if not tmp_path.exists() else tmp_path.stat().st_size
+
+                logger.debug(
+                    _("æ‰¾åˆ°äº†æœªä¸‹è½½å®Œçš„æ–‡ä»¶ {0}, å¤§å°ä¸º {1} å­—èŠ‚").format(
                         tmp_path, start_byte
                     )
                 )
-            )
 
-            if start_byte in [0, content_length]:
-                if start_byte:
+                if start_byte in [0, content_length]:
+                    if start_byte:
+                        tmp_path.rename(full_path)
+                        logger.debug(_("ä¸´æ—¶æ–‡ä»¶å·²å®Œå…¨ä¸‹è½½"))
+                        return
+
+                # æ„å»ºrangeè¯·æ±‚å¤´ (Build range request header)
+                range_headers = (
+                    {"Range": "bytes={}-".format(start_byte)} if start_byte else {}
+                )
+                range_headers.update(self.headers)
+                range_request = self.aclient.build_request(
+                    "GET", link, headers=range_headers
+                )
+                async with aiofiles.open(
+                    tmp_path, "ab" if start_byte else "wb"
+                ) as file:
+                    await self._download_chunks(
+                        self.aclient, range_request, file, content_length, task_id
+                    )
+
+                # ä¸‹è½½å®Œæˆåé‡å‘½åæ–‡ä»¶ (Rename file after download is complete)
+                try:
                     tmp_path.rename(full_path)
-                    logger.debug(_("ä¸´æ—¶æ–‡ä»¶å·²å®Œå…¨ä¸‹è½½"))
-                    return
+                except FileExistsError:
+                    logger.warning(_("{0} å·²å­˜åœ¨ï¼Œå°†è¦†ç›–").format(full_path))
+                    tmp_path.replace(full_path)
+                except PermissionError:
+                    logger.error(
+                        _(
+                            "å¦ä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶æˆ–å—å¼‚æ­¥è°ƒåº¦å½±å“ï¼Œè¯¥ä»»åŠ¡éœ€è¦é‡æ–°ä¸‹è½½"
+                        )
+                    )
+                    # å°è¯•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ (Try to delete the temporary file)
+                    try:
+                        tmp_path.unlink()
+                        tmp_path.rename(full_path)
+                    except Exception as e:
+                        logger.error(_("å°è¯•åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ï¼š{0}").format(e))
 
-            # æ„å»ºrangeè¯·æ±‚å¤´ (Build range request header)
-            range_headers = (
-                {"Range": "bytes={}-".format(start_byte)} if start_byte else {}
-            )
-            range_headers.update(self.headers)
-            range_request = self.aclient.build_request(
-                "GET", url, headers=range_headers
-            )
-            async with aiofiles.open(tmp_path, "ab" if start_byte else "wb") as file:
-                await self._download_chunks(
-                    self.aclient, range_request, file, content_length, task_id
+                    await self.progress.update(
+                        task_id,
+                        description=_("[  å¤±è´¥  ]ï¼š"),
+                        filename=trim_filename(full_path.name, 45),
+                        state="error",
+                    )
+
+                await self.progress.update(
+                    task_id,
+                    description=_("[  å®Œæˆ  ]ï¼š"),
+                    filename=trim_filename(full_path.name, 45),
+                    state="completed",
                 )
+                logger.debug(_("ä¸‹è½½å®Œæˆ, æ–‡ä»¶å·²ä¿å­˜ä¸º {0}").format(full_path))
 
-            # ä¸‹è½½å®Œæˆåé‡å‘½åæ–‡ä»¶ (Rename file after download is complete)
-            tmp_path.rename(full_path)
+                # å¦‚æœä¸‹è½½æˆåŠŸï¼Œåˆ™è·³å‡ºå¾ªç¯ (If download is successful, break the loop)
+                break
 
-            await self.progress.update(
-                task_id,
-                description=_("[  å®Œæˆ  ]:"),
-                filename=trim_filename(full_path.name, 45),
-                state="completed",
-            )
-            logger.debug(_("ä¸‹è½½å®Œæˆ, æ–‡ä»¶å·²ä¿å­˜ä¸º {0}".format(full_path)))
+            else:
+                # å¦‚æœéå†å®Œæ‰€æœ‰é“¾æ¥ä»ç„¶æ— æ³•æˆåŠŸä¸‹è½½ï¼Œåˆ™è®°å½•è­¦å‘Š
+                logger.warning("æ‰€æœ‰é“¾æ¥éƒ½æ— æ³•ä¸‹è½½")
+                await self.progress.update(
+                    task_id,
+                    description=_("[  ä¸¢å¤±  ]ï¼šæ‰€æœ‰é“¾æ¥éƒ½æ— æ³•ä¸‹è½½"),
+                    filename=trim_filename(full_path.name, 45),
+                    state="error",
+                )
 
     async def save_file(
-        self, task_id: TaskID, content: Any, full_path: Union[str, Path]
+        self,
+        task_id: TaskID,
+        content: Any,
+        full_path: Union[str, Path],
     ):
         """
         ä¿å­˜æ–‡ä»¶ (Save file)
 
         Args:
             task_id (TaskID): ä»»åŠ¡ID (Task ID)
             content (Any): æ–‡ä»¶å†…å®¹ (File content)
@@ -184,18 +237,21 @@
 
         await self.progress.update(
             task_id,
             description=_("[  å®Œæˆ  ]:"),
             filename=trim_filename(full_path.name, 45),
             state="completed",
         )
-        logger.debug(_("ä¸‹è½½å®Œæˆ, æ–‡ä»¶å·²ä¿å­˜ä¸º {0}".format(full_path)))
+        logger.debug(_("ä¸‹è½½å®Œæˆ, æ–‡ä»¶å·²ä¿å­˜ä¸º {0}").format(full_path))
 
     async def download_m3u8_stream(
-        self, task_id: TaskID, url: str, full_path: Union[str, Path]
+        self,
+        task_id: TaskID,
+        url: str,
+        full_path: Union[str, Path],
     ) -> None:
         """
         ä¸‹è½½m3u8æµè§†é¢‘ (Download m3u8 stream video)
 
         Args:
             task_id (TaskID): ä»»åŠ¡ID (Task ID)
             url (str): m3u8æ–‡ä»¶çš„URL (m3u8 file URL)
@@ -259,17 +315,17 @@
                                     await self.progress.update(
                                         task_id,
                                         advance=len(chunk),
                                         total=total_downloaded,
                                     )
 
                             except httpx.ReadTimeout as e:
-                                logger.warning(_("TSæ–‡ä»¶ä¸‹è½½è¶…æ—¶: {0}".format(e)))
+                                logger.warning(_("TSæ–‡ä»¶ä¸‹è½½è¶…æ—¶: {0}").format(e))
                             except Exception as e:
-                                logger.error(_("TSæ–‡ä»¶ä¸‹è½½å¤±è´¥: {0}".format(e)))
+                                logger.error(_("TSæ–‡ä»¶ä¸‹è½½å¤±è´¥: {0}").format(e))
                                 logger.error(traceback.format_exc())
                             finally:
                                 await ts_response.aclose()
                     # ç­‰å¾…ä¸€æ®µæ—¶é—´åå†æ¬¡è¯·æ±‚æ›´æ–° (Request update again after waiting for a while)
                     await asyncio.sleep(5)
 
                 except httpx.HTTPStatusError as e:
@@ -279,53 +335,58 @@
                             task_id,
                             description=_("[  ä¸¢å¤±  ]:"),
                             filename=trim_filename(full_path.name, 45),
                             state="completed",
                         )
                         return
                     else:
-                        logger.error(_("HTTPé”™è¯¯: {0}".format(e)))
+                        logger.error(_("HTTPé”™è¯¯: {0}").format(e))
                         await self.progress.update(
                             task_id,
                             description=_("[  å¤±è´¥  ]:"),
                             filename=trim_filename(full_path.name, 45),
                             state="completed",
                         )
                         return
 
                 except Exception as e:
-                    logger.error(_("m3u8æ–‡ä»¶è§£æå¤±è´¥: {0}".format(e)))
+                    logger.error(_("m3u8æ–‡ä»¶è§£æå¤±è´¥: {0}").format(e))
                     logger.error(traceback.format_exc())
                     await self.progress.update(
                         task_id,
                         description=_("[  å¤±è´¥  ]:"),
                         filename=trim_filename(full_path.name, 45),
                         state="completed",
                     )
                     return
 
     async def initiate_download(
         self,
         file_type: str,
-        file_url: str,
+        file_url: Union[str, List[str]],
         base_path: Union[str, Path],
         file_name: str,
         file_suffix: Optional[str],
     ) -> None:
         """
         åˆå§‹åŒ–ä¸‹è½½ä»»åŠ¡ã€‚å¦‚æœæ–‡ä»¶å·²ç»å­˜åœ¨ï¼Œåˆ™è·³è¿‡ä¸‹è½½ã€‚å¦åˆ™ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„å¼‚æ­¥ä¸‹è½½ä»»åŠ¡ã€‚
         (Initiate a download task. If file already exists,
         skip the download. Otherwise, create a new async download task)
 
         Args:
             file_type (str): æ–‡ä»¶ç±»å‹æè¿° (File type description)
-            file_url (str): æ–‡ä»¶URL (File URL)
+            file_url (Union[str, List[str]]): æ–‡ä»¶URL (File URL)
             file_name (str): æ–‡ä»¶åç§° (File name)
             base_path (Union[str, Path]): åŸºç¡€è·¯å¾„ (Base path)
             file_suffix (Optional[str]): æ–‡ä»¶åç¼€ (File suffix)
+
+        Note:
+            file_urlä»…ä»£è¡¨ä¸€ä¸ªæ–‡ä»¶çš„é“¾æ¥ï¼Œå½“file_urlä¸ºåˆ—è¡¨æ—¶ï¼Œè¡¨ç¤ºè¯¥æ–‡ä»¶çš„å¤šä¸ªé“¾æ¥
+            (file_url represents only a link to a file, when file_url is a list,
+                it represents multiple links to the file)
         """
 
         # æ–‡ä»¶è·¯å¾„
         file_path = f"{file_name}{file_suffix}"
         # æ–‡ä»¶å…¨è·¯å¾„
         full_path = self._ensure_path(base_path) / file_path
 
@@ -336,15 +397,15 @@
                 start=True,
                 total=1,
                 completed=1,
             )
             await self.progress.update(task_id, state="completed")
         else:
             task_id = await self.progress.add_task(
-                description=_("[  {0}  ]:".format(file_type)),
+                description=_("[  {0}  ]:").format(file_type),
                 filename=trim_filename(file_path, 45),
                 start=True,
             )
             await self.progress.update(task_id, state="starting")
             download_task = asyncio.create_task(
                 self.download_file(task_id, file_url, full_path)
             )
@@ -383,15 +444,15 @@
                 start=True,
                 total=1,
                 completed=1,
             )
             await self.progress.update(task_id, state="completed")
         else:
             task_id = await self.progress.add_task(
-                description=_("[  {0}  ]:".format(file_type)),
+                description=_("[  {0}  ]:").format(file_type),
                 filename=trim_filename(file_path, 45),
                 start=True,
             )
             await self.progress.update(task_id, state="starting")
             download_task = asyncio.create_task(
                 self.save_file(task_id, content, full_path)
             )
@@ -429,28 +490,28 @@
                 start=True,
                 total=1,
                 completed=1,
             )
             await self.progress.update(task_id, state="completed")
         else:
             task_id = await self.progress.add_task(
-                description=_("[  {0}  ]:".format(file_type)),
+                description=_("[  {0}  ]:").format(file_type),
                 filename=trim_filename(file_path, 45),
                 start=True,
             )
             await self.progress.update(task_id, state="starting")
             download_task = asyncio.create_task(
                 self.download_m3u8_stream(task_id, m3u8_url, full_path)
             )
             self.download_tasks.append(download_task)
 
     async def execute_tasks(self):
         """æ‰§è¡Œæ‰€æœ‰ä¸‹è½½ä»»åŠ¡ (Execute all download tasks)"""
         logger.debug(
-            _("å¼€å§‹æ‰§è¡Œä¸‹è½½ä»»åŠ¡ï¼Œæœ¬æ¬¡å…±æœ‰ {0} ä¸ªä»»åŠ¡".format(len(self.download_tasks)))
+            _("å¼€å§‹æ‰§è¡Œä¸‹è½½ä»»åŠ¡ï¼Œæœ¬æ¬¡å…±æœ‰ {0} ä¸ªä»»åŠ¡").format(len(self.download_tasks))
         )
         await asyncio.gather(*self.download_tasks)
         self.download_tasks.clear()
 
     async def close(self) -> None:
         """å…³é—­ä¸‹è½½å™¨ (Close the downloader)"""
         await self.aclient.aclose()
```

### Comparing `f2-0.0.1.4/f2/exceptions/__init__.py` & `f2-0.0.1.5/f2/exceptions/__init__.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/exceptions/api_exceptions.py` & `f2-0.0.1.5/f2/exceptions/api_exceptions.py`

 * *Files 26% similar despite different names*

```diff
@@ -4,74 +4,75 @@
 
 exception_console = RichConsoleManager().exception_console
 
 
 class APIError(Exception):
     """åŸºæœ¬APIå¼‚å¸¸ç±»ï¼Œå…¶ä»–APIå¼‚å¸¸éƒ½ä¼šç»§æ‰¿è¿™ä¸ªç±»"""
 
-    def __init__(self, status_code=None):
-        self.status_code = status_code
+    def __init__(self, message=None, status_code=None):
         exception_console.print(
             "è¯·å‰å¾€QAæ–‡æ¡£ https://johnserf-seed.github.io/f2/question-answer/qa.html æŸ¥çœ‹ç›¸å…³å¸®åŠ©"
         )
+        self.status_code = status_code
+        super().__init__(message)
 
-    def display_error(self):
-        """æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯å’ŒçŠ¶æ€ç ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"""
-        return f"Error: {self.args[0]}." + (
-            f" Status Code: {self.status_code}." if self.status_code else ""
+    def __str__(self):
+        """è¿”å›é”™è¯¯ä¿¡æ¯å’Œæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"""
+        return f"{super().__str__()}" + (
+            f" Status Code: {self.status_code}" if self.status_code else ""
         )
 
 
 class APIConnectionError(APIError):
     """å½“ä¸APIçš„è¿æ¥å‡ºç°é—®é¢˜æ—¶æŠ›å‡º"""
 
-    def display_error(self):
-        return f"API Connection Error: {self.args[0]}."
+    def __init__(self, message=None, status_code=None):
+        super().__init__(message, status_code)
 
 
 class APIUnavailableError(APIError):
     """å½“APIæœåŠ¡ä¸å¯ç”¨æ—¶æŠ›å‡ºï¼Œä¾‹å¦‚ç»´æŠ¤æˆ–è¶…æ—¶"""
 
-    def display_error(self):
-        return f"API Unavailable Error: {self.args[0]}."
+    def __init__(self, message=None, status_code=None):
+        super().__init__(message, status_code)
 
 
 class APINotFoundError(APIError):
     """å½“APIç«¯ç‚¹ä¸å­˜åœ¨æ—¶æŠ›å‡º"""
 
-    def display_error(self):
-        return f"API Not Found Error: {self.args[0]}."
+    def __init__(self, message=None, status_code=None):
+        super().__init__(message, status_code)
 
 
 class APIResponseError(APIError):
     """å½“APIè¿”å›çš„å“åº”ä¸é¢„æœŸä¸ç¬¦æ—¶æŠ›å‡º"""
 
-    def display_error(self):
-        return f"API Response Error: {self.args[0]}."
+    def __init__(self, message=None, status_code=None):
+        super().__init__(message, status_code)
 
 
 class APIRateLimitError(APIError):
     """å½“è¾¾åˆ°APIçš„è¯·æ±‚é€Ÿç‡é™åˆ¶æ—¶æŠ›å‡º"""
 
-    def display_error(self):
-        return f"API Rate Limit Error: {self.args[0]}."
+    def __init__(self, message=None, status_code=None):
+        super().__init__(message, status_code)
 
 
 class APITimeoutError(APIError):
     """å½“APIè¯·æ±‚è¶…æ—¶æ—¶æŠ›å‡º"""
 
-    def display_error(self):
-        return f"API Timeout Error: {self.args[0]}."
+    def __init__(self, message=None, status_code=None):
+        super().__init__(message, status_code)
 
 
 class APIUnauthorizedError(APIError):
     """å½“APIè¯·æ±‚ç”±äºæˆæƒå¤±è´¥è€Œè¢«æ‹’ç»æ—¶æŠ›å‡º"""
 
-    def display_error(self):
-        return f"API Unauthorized Error: {self.args[0]}."
+    def __init__(self, message=None, status_code=None):
+        super().__init__(message, status_code)
 
 
 class APIRetryExhaustedError(APIError):
     """å½“APIè¯·æ±‚é‡è¯•æ¬¡æ•°ç”¨å°½æ—¶æŠ›å‡º"""
 
-    def display_error(self):
-        return f"API Retry Exhausted Error: {self.args[0]}."
+    def __init__(self, message=None, status_code=None):
+        super().__init__(message, status_code)
```

### Comparing `f2-0.0.1.4/f2/exceptions/file_exceptions.py` & `f2-0.0.1.5/f2/exceptions/file_exceptions.py`

 * *Files 22% similar despite different names*

```diff
@@ -4,54 +4,45 @@
 
 exception_console = RichConsoleManager().exception_console
 
 
 class FileError(Exception):
     """åŸºæœ¬çš„æ–‡ä»¶é”™è¯¯å¼‚å¸¸ç±»ï¼Œå…¶ä»–æ–‡ä»¶å¼‚å¸¸éƒ½ä¼šç»§æ‰¿è¿™ä¸ªç±»"""
 
-    def __init__(self, filepath=None):
-        self.filepath = filepath
+    def __init__(self, message, filepath=None):
         exception_console.print(
             "è¯·å‰å¾€QAæ–‡æ¡£ https://johnserf-seed.github.io/f2/question-answer/qa.html æŸ¥çœ‹ç›¸å…³å¸®åŠ©"
         )
+        self.filepath = filepath
+        super().__init__(message)
 
-    def display_error(self):
-        """æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯å’Œæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"""
-        return f"File Error: {self.args[0]}." + (
-            f" Filepath: {self.filepath}." if self.filepath else ""
-        )
+    def __str__(self):
+        """è¿”å›é”™è¯¯ä¿¡æ¯å’Œæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"""
+        return f"{super().__str__()} Filepath: {self.filepath}" if self.filepath else ""
 
 
-class FileNotFound(FileError, FileNotFoundError):
+class FileNotFound(FileError):
     """æ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯"""
 
-    def display_error(self):
-        return f"File Not Found Error: {self.args[0]}." + (
-            f" Filepath: {self.filepath}." if self.filepath else ""
-        )
+    def __init__(self, message=None, filepath=None):
+        super().__init__(message, filepath)
 
 
-class FilePermissionError(FileError, PermissionError):
+class FilePermissionError(FileError):
     """æ–‡ä»¶æƒé™é”™è¯¯"""
 
-    def display_error(self):
-        return f"File Permission Error: {self.args[0]}." + (
-            f" Filepath: {self.filepath}." if self.filepath else ""
-        )
+    def __init__(self, message, filepath=None):
+        super().__init__(message, filepath)
 
 
 class FileReadError(FileError):
     """æ–‡ä»¶è¯»å–é”™è¯¯"""
 
-    def display_error(self):
-        return f"File Read Error: {self.args[0]}." + (
-            f" Filepath: {self.filepath}." if self.filepath else ""
-        )
+    def __init__(self, message, filepath=None):
+        super().__init__(message, filepath)
 
 
 class FileWriteError(FileError):
     """æ–‡ä»¶å†™å…¥é”™è¯¯"""
 
-    def display_error(self):
-        return f"File Write Error: {self.args[0]}." + (
-            f" Filepath: {self.filepath}." if self.filepath else ""
-        )
+    def __init__(self, message, filepath=None):
+        super().__init__(message, filepath)
```

### Comparing `f2-0.0.1.4/f2/i18n/translator.py` & `f2-0.0.1.5/f2/i18n/translator.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/languages/en_US/LC_MESSAGES/en_US.mo` & `f2-0.0.1.5/f2/languages/en_US/LC_MESSAGES/en_US.mo`

 * *Files 22% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: f2-translate\n"
 "Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"
-"PO-Revision-Date: 2024-02-15 23:31+0800\n"
+"PO-Revision-Date: 2024-04-05 00:24+0800\n"
 "Last-Translator: JohnserfSeed <johnserf-seed@foxmail.com>\n"
 "Language-Team: English, United States\n"
 "Language: en_US\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -14,20 +14,14 @@
 "X-Crowdin-Project: f2-translate\n"
 "X-Crowdin-Project-ID: 631650\n"
 "X-Crowdin-Language: en-US\n"
 "X-Crowdin-File: messages.pot\n"
 "X-Crowdin-File-ID: 2\n"
 "X-Generator: Poedit 3.3.2\n"
 
-msgid "'{0}' é…ç½®æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨"
-msgstr "'{0}' Configuration file path does not exist"
-
-msgid "'{0}' é…ç½®æ–‡ä»¶è·¯å¾„æ— å†™æƒé™"
-msgstr "'{0}' Configuration file path has no write permissions"
-
 msgid ""
 "- å•ä¸ªä½œå“ï¼Œä¸»é¡µä½œå“ï¼Œç‚¹èµä½œå“ï¼Œæ”¶è—ä½œå“ï¼Œåˆè¾‘ä½œå“ï¼Œå›¾æ–‡ï¼Œæ–‡æ¡ˆï¼Œå°é¢ï¼Œç›´æ’­ï¼Œ"
 "åŸå£°ã€‚"
 msgstr ""
 "- one video, user post, liked post, collect post, mix post, note, desc, "
 "cover, live, original soundã€‚"
 
@@ -59,65 +53,62 @@
 msgid "- è·å–å¾®åš"
 msgstr "- Get Weibo"
 
 msgid "- è·å–ç½‘æ˜“äº‘éŸ³ä¹ä½œå“"
 msgstr "- Get music from NetEase Cloud Music"
 
 msgid ""
-"- è®°å½•appçš„debugåˆ°/logsä¸‹ï¼Œå¦‚é‡BUGæäº¤Issueæ—¶è¯·é™„å¸¦è¯¥æ–‡ä»¶å¹¶[red]åˆ é™¤ä¸ªäººæ•æ„Ÿ"
-"ä¿¡æ¯[/red]"
+"- è®°å½•appçš„è°ƒè¯•æ—¥å¿—åˆ°/logsä¸‹ï¼Œå¦‚é‡BUGæäº¤Issueæ—¶è¯·é™„å¸¦è¯¥æ–‡ä»¶å¹¶[red]åˆ é™¤ä¸ªäººæ•"
+"æ„Ÿä¿¡æ¯[/red]"
 msgstr ""
-"- Record the app's debug to /logs, in case of a bug when submitting an "
-"Issue, please attach the file and [red]delete personal sensitive "
-"information[/red]"
+"- Record the app's debug logs to /logs, such as bugs submit Issue when the "
+"attached file and [red]delete personal sensitive information[/red]."
 
-msgid "401 ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–ttwid"
-msgstr "Unauthorized request,Unable to get ttwid"
+msgid "0: [bold]å…¨éƒ¨ä¸‹è½½[/bold]"
+msgstr "0: [bold]All downloads[/bold]"
 
-msgid "404 æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
-msgstr "API endpoint not found"
+msgid "APIå†…å®¹è¯·æ±‚å¤±è´¥ï¼Œè¯·æ›´æ¢æ–°cookieåå†è¯•"
+msgstr ""
+"API content request failed, please replace the new cookie and try again"
 
-msgid "APIæœåŠ¡ä¸å¯ç”¨ã€‚ç±»å: {0}"
+msgid "APIæœåŠ¡ä¸å¯ç”¨ã€‚ç±»åï¼š{0}"
 msgstr "API service is not available. Class name: {0}"
 
-msgid "APIé”™è¯¯ç ï¼š{0}ã€‚ç±»å: {1}"
-msgstr "API error code: {0}. Class name: {1}"
-
-msgid "BaseDownloader è¯·æ±‚å¤´headers:{0}"
-msgstr "BaseDownloader è¯·æ±‚å¤´ headers:{0}"
-
 msgid "CLIå‚æ•°ï¼š{0}"
 msgstr "CLI parameters: {0}"
 
+msgid "HTTPçŠ¶æ€ç é”™è¯¯ï¼š"
+msgstr "HTTP status code error:"
+
 msgid "HTTPçŠ¶æ€é”™è¯¯, å°è¯•GETè¯·æ±‚å¤±è´¥: {0}, é”™è¯¯è¯¦æƒ…: {1}"
 msgstr "HTTP status error, Failed GET request attempt: {0}, Error details: {1}"
 
-msgid "HTTPçŠ¶æ€é”™è¯¯: {0}, URL: {1}, å°è¯•æ¬¡æ•°: {2}"
-msgstr "HTTP status error: {0}, URL: {1}, attempt: {2}"
-
 msgid "HTTPçŠ¶æ€é”™è¯¯: {0}, çŠ¶æ€ç : {1}"
 msgstr "HTTP status error: {0}, status code: {1}"
 
+msgid "HTTPçŠ¶æ€é”™è¯¯ï¼š{0}, URLï¼š{1}, å°è¯•æ¬¡æ•°ï¼š{2}"
+msgstr "HTTP Status Error: {0}, URL: {1}, Attempts: {2}"
+
 msgid "HTTPé”™è¯¯: {0}"
 msgstr "HTTP error: {0}"
 
 msgid "Hello, World!"
 msgstr "Hello, World!"
 
-msgid "SSOæ£€æŸ¥æ‰«ç çŠ¶æ€æ¥å£åœ°å€:"
-msgstr "SSO Check Sweep Status Interface Address:"
+msgid "SSOæ£€æŸ¥æ‰«ç çŠ¶æ€æ¥å£åœ°å€ï¼š{0}"
+msgstr "SSO check sweep status interface address: {0}"
 
-msgid "SSOæ£€æŸ¥ç™»å½•çŠ¶æ€æ¥å£åœ°å€:"
-msgstr "SSO Check Login Status interface address:"
+msgid "SSOæ£€æŸ¥ç™»å½•çŠ¶æ€æ¥å£åœ°å€ï¼š{0}"
+msgstr "SSO check login status interface address: {0}"
 
 msgid "SSOç™»å½•å¤±è´¥ï¼Œè¯·é‡è¯•ï¼"
 msgstr "SSO login failed, please try againï¼"
 
-msgid "SSOè·å–äºŒç»´ç æ¥å£åœ°å€:"
-msgstr "SSO get QR code interface address:"
+msgid "SSOè·å–äºŒç»´ç æ¥å£åœ°å€ï¼š{0}"
+msgstr "SSO get QR code interface address: {0}"
 
 msgid "TSæ–‡ä»¶ä¸‹è½½å¤±è´¥: {0}"
 msgstr "TS file download failed: {0}"
 
 msgid "TSæ–‡ä»¶ä¸‹è½½è¶…æ—¶: {0}"
 msgstr "TS file download timed out: {0}"
 
@@ -126,20 +117,29 @@
 
 msgid "[  {0}  ]:"
 msgstr "[  {0}  ]:"
 
 msgid "[  ä¸¢å¤±  ]:"
 msgstr "[  Loss  ]"
 
+msgid "[  ä¸¢å¤±  ]ï¼šæ‰€æœ‰é“¾æ¥éƒ½æ— æ³•ä¸‹è½½"
+msgstr "[ Missing ]: All links are unavailable for downloading"
+
 msgid "[  å¤±è´¥  ]:"
 msgstr "[  Fails  ]"
 
+msgid "[  å¤±è´¥  ]ï¼š"
+msgstr "[  Failure  ]"
+
 msgid "[  å®Œæˆ  ]:"
 msgstr "[  Done  ]"
 
+msgid "[  å®Œæˆ  ]ï¼š"
+msgstr "[  Done  ]"
+
 msgid "[  ç™»å½•  ]:äºŒç»´ç è¿‡æœŸï¼Œé‡æ–°è·å–ï¼"
 msgstr "[  Login  ]:QR code expired, re-fetchï¼"
 
 msgid "[  ç™»å½•  ]:æ‰«æäºŒç»´ç æˆåŠŸï¼"
 msgstr "[  Login  ]:Successful scanning of QR codeï¼"
 
 msgid "[  ç™»å½•  ]:æ‰«ç ç¯å¢ƒå¼‚å¸¸ï¼Œè¯·å‰å¾€appéªŒè¯ï¼"
@@ -155,27 +155,36 @@
 
 msgid "[  ç™»å½•  ]:è®¿é—®é¢‘ç¹ï¼Œè¯·æ£€æŸ¥å‚æ•°ï¼"
 msgstr "[  Login  ]:Access is frequent, check the parametersï¼"
 
 msgid "[  è·³è¿‡  ]:"
 msgstr "[  Skips  ]"
 
+msgid "[bold yellow]è¯·è¾“å…¥å¸Œæœ›ä¸‹è½½çš„åˆè¾‘åºå·ï¼š[/bold yellow]"
+msgstr ""
+"[bold yellow]Please enter the serial number of the compilation you wish to "
+"download:[/bold yellow]"
+
+msgid "[bold yellow]è¯·è¾“å…¥å¸Œæœ›ä¸‹è½½çš„æ”¶è—å¤¹åºå·ï¼š[/bold yellow]"
+msgstr ""
+"[bold yellow]Please enter the serial number of the favorite you would like "
+"to download:[/bold yellow]"
+
 msgid "`{0}` ä¸­çš„ `{1}` ä¸ç¬¦åˆå‘½åæ¨¡å¼"
 msgstr "`{1}` in `{0}` does not conform to naming patterns"
 
 msgid "bilibili æˆ– bili"
 msgstr "bilibili or bili"
 
 msgid ""
-"cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å– f2 -d dy --"
-"helpï¼Œå¦‚æ‰«ç ç™»å½•è¯·ä¿ç•™åŒå¼•å·cookie: ï¼Œå†ä½¿ç”¨--sso-loginå‘½ä»¤ã€‚"
+"cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å–ã€‚å¦‚ `--auto-"
+"cookie edge`"
 msgstr ""
-"cookie cannot be empty. Please provide valid cookie parameters, or "
-"automatically get f2 -d dy --help from your browser, e.g., to scan for login "
-"please keep the double quotes cookie: and then use the --sso-login commandã€‚"
+"the cookie cannot be empty. Please provide a valid cookie parameter, or get "
+"it automatically from the browser. For example, `--auto-cookie edge`"
 
 msgid "douyin æˆ– dy"
 msgstr "douyin or dy"
 
 msgid "f2 è¯·æ±‚ Content-Length æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {0}, é”™è¯¯è¯¦æƒ…: {1}"
 msgstr ""
 "f2 Unknown error occurred while requesting Content-Length: {0}, error "
@@ -189,61 +198,59 @@
 
 msgid "m3u8æ–‡ä»¶æˆ–tsæ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯èƒ½ç›´æ’­ç»“æŸ"
 msgstr "m3u8 file or ts file not found, possibly the end of the live"
 
 msgid "m3u8æ–‡ä»¶è§£æå¤±è´¥: {0}"
 msgstr "failed to parse m3u8 file: {0}"
 
-msgid ""
-"msToken: è¯·æ£€æŸ¥å¹¶æ›´æ–° f2 ä¸­ conf.yaml é…ç½®æ–‡ä»¶ä¸­çš„ msTokenï¼Œä»¥åŒ¹é… douyin æ–°"
-"è§„åˆ™ã€‚"
-msgstr ""
-"msToken: Please check and update the msToken in the conf.yaml configuration "
-"file in f2 to match the new douyin ruleã€‚"
-
-msgid ""
-"msToken: è¯·æ£€æŸ¥å¹¶æ›´æ–° f2 ä¸­ conf.yaml é…ç½®æ–‡ä»¶ä¸­çš„ msTokenï¼Œä»¥åŒ¹é… tiktok æ–°"
-"è§„åˆ™ã€‚"
-msgstr ""
-"msToken: Please check and update the msToken in the conf.yaml configuration "
-"file in f2 to match the new tiktok rulesã€‚"
+msgid "msToken APIé”™è¯¯ï¼š{0}"
+msgstr "msToken API error: {0}"
 
 msgid "neteasy_music æˆ– nem"
 msgstr "neteasy_music or nem"
 
-msgid "odin_tt: æ£€æŸ¥æ²¡æœ‰é€šè¿‡, è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„odin_tt"
-msgstr "odin_tt: Check failed, please update the odin_tt in the conf file"
-
 msgid "tiktok æˆ– tk"
 msgstr "tiktok or tk"
 
 msgid "ttwid: æ£€æŸ¥æ²¡æœ‰é€šè¿‡, è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„ttwid"
 msgstr "ttwid: Check failed, please update the ttwid in the conf file"
 
+msgid "ttwidæ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
+msgstr "ttwid can't find API endpoints"
+
 msgid "twitch æˆ– tv"
 msgstr "twitch or tv"
 
 msgid "twitter æˆ– x"
 msgstr "twitter or x"
 
 msgid "weibo æˆ– wb"
 msgstr "weibo or wb"
 
 msgid "youtube æˆ– ytb"
 msgstr "youtube or ytb"
 
+msgid "{0} å†…å®¹ä¸ç¬¦åˆè¦æ±‚"
+msgstr "{0} Content does not meet requirements"
+
+msgid "{0} åœ¨æœåŠ¡å™¨ä¸Šçš„æ€»å†…å®¹é•¿åº¦ä¸ºï¼š{1} å­—èŠ‚"
+msgstr "{0} Total content length on the server: {1} bytes"
+
+msgid "{0} å·²å­˜åœ¨ï¼Œå°†è¦†ç›–"
+msgstr "{0} already exists, will be overwritten"
+
 msgid "{0} åº”ç”¨é…ç½®æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼Œä¿å­˜è‡³ {1}"
 msgstr ""
 "{0} Application configuration file generated successfully, saved to {1}"
 
 msgid "{0} åº”ç”¨é…ç½®æœªæ‰¾åˆ°"
 msgstr "{0} Application configuration not found"
 
-msgid "{0} è¯¥ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½"
-msgstr "{0} This work has been blocked from being downloaded"
+msgid "{0} æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
+msgstr "{0} Unable to find API endpoint"
 
 msgid "{0} è¯¥ä½œå“æ²¡æœ‰åŠ¨æ€å°é¢"
 msgstr "{0} There is no dynamic cover for this work"
 
 msgid "{0} è¯¥ä½œå“æ²¡æœ‰å°é¢"
 msgstr "{0} There is no cover for this work"
 
@@ -255,16 +262,21 @@
 
 msgid "{0} è¯¥å›¾é›†æ²¡æœ‰å›¾ç‰‡é“¾æ¥ï¼Œæ— æ³•ä¸‹è½½"
 msgstr "{0} The atlas has no image link and cannot be downloaded"
 
 msgid "{0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“"
 msgstr "{0} Page not found"
 
-msgid "{0}åœ¨æœåŠ¡å™¨ä¸Šçš„æ€»å†…å®¹é•¿åº¦ä¸ºï¼š{1} å­—èŠ‚"
-msgstr "The total content length of {0} on the server is: {1} bytes"
+msgid "{0}: {1} (åŒ…å« {2} ä¸ªä½œå“ï¼Œæ”¶è—å¤¹ID {3})"
+msgstr "{0}: {1} (contains {2} entries, Favorite ID {3})"
+
+msgid "{0}ï¼š{1} (åŒ…å« {2} ä¸ªä½œå“[ä»¥ç½‘é¡µå®é™…æ•°é‡ä¸ºå‡†]ï¼Œæ”¶è—å¤¹ID {3})"
+msgstr ""
+"{0}:{1} (contains {2} entries [based on actual number of pages], Favorite ID "
+"{3})"
 
 msgid "â³"
 msgstr "â³"
 
 msgid "âš "
 msgstr "âš "
 
@@ -277,311 +289,393 @@
 msgid ""
 "ä¸‹è½½æ—¥æœŸåŒºé—´å‘å¸ƒçš„ä½œå“ï¼Œæ ¼å¼ï¼š2022-01-01|2023-01-01ï¼Œ'all' ä¸ºä¸‹è½½æ‰€æœ‰ä½œå“"
 msgstr ""
 "Download works released in the date range, format: 2022-01-01|2023-01-01, "
 "'all' is to download all works"
 
 msgid ""
-"ä¸‹è½½æ¨¡å¼ï¼šä¸»é¡µä½œå“(post), ç‚¹èµä½œå“(like), æ”¶è—ä½œå“(collect), åˆè¾‘(mix), ç›´æ’­"
-"(live), æ¨èä½œå“(feed), æœç´¢ä½œå“(search)"
-msgstr "Download Mode: post, like, collect, mix, live, feed, search"
-
-msgid ""
 "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post), ç‚¹èµä½œå“(like), æ”¶è—ä½œå“(collect), "
 "åˆè¾‘æ’­æ”¾åˆ—è¡¨(mix)"
 msgstr "Download modes: one, post, like, collect, mix"
 
 msgid ""
-"ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“(collect)ï¼Œ"
-"åˆè¾‘(mix)ï¼Œç›´æ’­(live)"
-msgstr "Download Mode: One, Post, Like, Collect, Mix, Live"
+"ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“"
+"(collection)ï¼Œæ”¶è—å¤¹ä½œå“(collects)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
+msgstr "Download Mode: One, Post, Like, Collection, Favorites, Mix, Live"
+
+msgid ""
+"ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“"
+"(collection)ï¼Œæ”¶è—å¤¹ä½œå“(collects)ï¼Œæ”¶è—éŸ³ä¹(music)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
+msgstr ""
+"Download mode: single work (one), home page work (post), like works (like), "
+"collection (collection), favorite works (collects), collection of music "
+"(music), compilation (mix), live (live)"
 
 msgid "ä¸å­˜åœ¨è¯¥æ¨¡å¼: {0}"
 msgstr "This mode does not exist: {0}"
 
-msgid "ä¸æ”¯æŒçš„æµè§ˆå™¨é€‰é¡¹, è¾“å…¥f2 dy --helpæŸ¥çœ‹æ›´å¤šå¸®åŠ©!"
-msgstr "Unsupported browser options, type f2 dy --help for more help!"
-
 msgid "ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶"
 msgstr "Cannot initialize and update configuration files at the same time"
 
 msgid "ä¸´æ—¶æ–‡ä»¶å·²å®Œå…¨ä¸‹è½½"
 msgstr "Temporary file has been fully downloaded"
 
 msgid "ä¸»æ’­æ˜µç§°: {0} å¼€æ’­æ—¶é—´: {1} ç›´æ’­æµæ¸…æ™°åº¦: {2}"
 msgstr "Nickname: {0} Start Time: {1} Streaming Clarity: {2}"
 
 msgid "ä¸»é…ç½®å‚æ•°ï¼š{0}"
 msgstr "Main configuration parameters: {0}"
 
-msgid "ä¸»é…ç½®è·¯å¾„ï¼š {0}"
+msgid "ä¸»é…ç½®è·¯å¾„ï¼š{0}"
 msgstr "Main configuration path: {0}"
 
-msgid "ä¸»é¡µä½œå“æ¥å£åœ°å€:"
-msgstr "Post interface address:"
+msgid "ä¸»é¡µä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Home page work interface address: {0}"
+
+msgid "ä¸»é¡µå–œæ¬¢ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "HomeLike WorksInterface Address: {0}"
+
+msgid "ä¸»é¡µæ”¶è—ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Home Favorite Works Interface Address: {0}"
+
+msgid "ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20"
+msgstr ""
+"The number of works that can be fetched from the interface per page is not "
+"recommended to be more than 20"
 
 msgid "ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20ã€‚"
 msgstr ""
 "The number of works that can be fetched from the interface per page is not "
 "recommended to exceed 20ã€‚"
 
 msgid ""
 "ä»£ç†æœåŠ¡å™¨ï¼Œæœ€å¤š 2 ä¸ªå‚æ•°ï¼Œhttpä¸httpsã€‚ç©ºæ ¼åŒºåˆ† 2 ä¸ªå‚æ•° http://x.x.x.x "
 "https://x.x.x.x"
 msgstr ""
 "Proxy server, up to 2 parameters, http and https. 2 parameters distinguished "
 "by space http://x.x.x.x https://x.x.x.x"
 
+msgid "ä½œå“ID: {0} ä½œå“æ–‡æ¡ˆ: {1} ä½œè€…: {2}"
+msgstr "Work ID: {0} Work Text: {1} Author: {2}"
+
+msgid "ä½œå“IDï¼š{0} ä½œå“æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}"
+msgstr "Work ID: {0} Work Text: {1} Author: {2}"
+
+msgid "ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„"
+msgstr "Where to save your work, supports absolute and relative paths"
+
 msgid "ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„ã€‚"
 msgstr "Work save location, support absolute and relative pathã€‚"
 
-msgid "ä½œå“ä¿å­˜ä½ç½®ï¼Œé»˜è®¤ä¸º 'Download'"
-msgstr "Where to save your work, default is 'Download'"
-
 msgid "ä½œå“å‘å¸ƒæ—¶é—´ä¸åœ¨æŒ‡å®šåŒºé—´å†…ï¼š{0}"
 msgstr "The work is not published within the specified interval: {0}"
 
 msgid "ä½œå“å‘å¸ƒæ—¶é—´åœ¨æŒ‡å®šåŒºé—´å†…ï¼šä½œå“id {0} å‘å¸ƒæ—¶é—´ {1}"
 msgstr ""
 "The posting time of the work is within the specified interval: work id {0} "
 "posting time {1}"
 
-msgid "ä½œå“è¯„è®ºæ¥å£åœ°å€:"
-msgstr "Post comment interface address:"
+msgid "ä½œå“åˆé›†IDï¼š{0} ä½œå“åˆé›†æ ‡é¢˜ï¼š{1}"
+msgstr "Collection ID: {0} Collection Title: {1}"
 
-msgid "ä½œå“è¯¦æƒ…æ¥å£åœ°å€:"
-msgstr "Post details interface address:"
+msgid "ä½œå“è¯„è®ºæ¥å£åœ°å€ï¼š{0}"
+msgstr "Work comment interface address: {0}"
+
+msgid "ä½œå“è¯¦æƒ…æ¥å£åœ°å€ï¼š{0}"
+msgstr "Work details interface address: {0}"
 
 msgid "ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–[yellow]cookie[/yellow]ï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"
 msgstr ""
 "Use SSO sweep login to get [yellow]cookie[/yellow], save LF master profile"
 
-msgid "ä½¿ç”¨å‘½ä»¤è¡Œé€‰é¡¹æ›´æ–°é…ç½®æ–‡ä»¶"
-msgstr "Use the command line option to update the configuration file"
+msgid "ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–cookieï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"
+msgstr ""
+"Use SSO sweep login to get cookies and save the low-frequency master "
+"configuration file"
 
 msgid "ä½¿ç”¨å‘½ä»¤è¡Œé€‰é¡¹æ›´æ–°é…ç½®æ–‡ä»¶ã€‚éœ€è¦å…ˆä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªé…ç½®æ–‡ä»¶è·¯å¾„"
 msgstr ""
 "Use the command line option to update the configuration file. You need to "
 "provide a configuration file path first with the '-c' option"
 
-msgid "ä¾‹ï¼š f2 dy -h æ¥è·å–douyinçš„å‘½ä»¤å¸®åŠ©"
-msgstr "Example: f2 dy -h to get help with douyin commands"
+msgid "ä¾‹ï¼šf2 -d DEBUG dy æ—¥å¿—çº§åˆ«ä¸ºè°ƒè¯•è¿è¡Œ"
+msgstr "Example: f2 -d DEBUG dy Log level is debug run"
 
-msgid "å…¨å±€ä½œå“æ–‡ä»¶å‘½åæ–¹å¼"
-msgstr "Global video file naming convention"
+msgid "ä¾‹ï¼šf2 dy -h/--help è·å–douyinçš„å‘½ä»¤å¸®åŠ©"
+msgstr "Example: f2 dy -h/--help Get help for commands in douyin"
 
 msgid "å…¨å±€ä½œå“æ–‡ä»¶å‘½åæ–¹å¼ï¼Œå‰å¾€æ–‡æ¡£æŸ¥çœ‹æ›´å¤šå¸®åŠ©"
 msgstr "Global file naming convention, go to the documentation for more help"
 
-msgid "å…³æ³¨ä½œå“æ¥å£åœ°å€:"
-msgstr "Follow the works interface address:"
-
-msgid "å…³æ³¨ç”¨æˆ·ç›´æ’­æ¥å£åœ°å€:"
-msgstr "Follow user live interface address:"
-
-msgid "å†…å®¹é•¿åº¦ä¸º0ï¼Œè·³è¿‡ä¸‹è½½"
-msgstr "Content length is 0, skipping download"
+msgid "å…³æ³¨ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Follow the work interface address: {0}"
 
-msgid "åˆå§‹åŒ–é…ç½®æ–‡ä»¶"
-msgstr "Initializing configuration files"
+msgid "å…³æ³¨ç”¨æˆ·ç›´æ’­æ¥å£åœ°å€ï¼š{0}"
+msgstr "Follow user live interface address: {0}"
 
 msgid "åˆå§‹åŒ–é…ç½®æ–‡ä»¶ã€‚ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶"
 msgstr ""
 "Initialize the configuration file. It is not possible to initialize and "
 "update the configuration file at the same time"
 
-msgid "å•ä¸ªè§†é¢‘æ•°æ®: {0}"
-msgstr "Single video data: {0}"
+msgid "å•ä¸ªä½œå“æ•°æ®ï¼š{0}"
+msgstr "Individual work data: {0}"
 
 msgid "åŸå£°"
 msgstr "Music"
 
+msgid "å‚æ•°"
+msgstr "parameters"
+
 msgid "å‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹"
 msgstr "Arguments must be of type list"
 
 msgid "å‚æ•°å¿…é¡»æ˜¯å­—å…¸ç±»å‹"
 msgstr "Arguments must be of dictionary type"
 
 msgid "å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"
 msgstr "Arguments must be of string type"
 
+msgid "å‚æ•°éªŒè¯å¤±è´¥ï¼Œè¯·æ›´æ–° F2 é…ç½®æ–‡ä»¶ä¸­çš„ {0}ï¼Œä»¥åŒ¹é… {1} æ–°è§„åˆ™"
+msgstr ""
+"Parameter validation failed, update {0} in the F2 configuration file to "
+"match {1} new rule"
+
+msgid "å¦ä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶æˆ–å—å¼‚æ­¥è°ƒåº¦å½±å“ï¼Œè¯¥ä»»åŠ¡éœ€è¦é‡æ–°ä¸‹è½½"
+msgstr ""
+"Another program is using this file or is affected by asynchronous "
+"scheduling, the task needs to be re-downloaded"
+
 msgid "åˆè¾‘: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
 msgstr "Mix: {0} All works have been captured"
 
-msgid "åˆè¾‘ä½œå“æ¥å£åœ°å€:"
-msgstr "Mix interface address:"
+msgid "åˆè¾‘ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Interface address for compilation works: {0}"
 
-msgid "åˆè¾‘åˆ—è¡¨æ¥å£åœ°å€:"
-msgstr "Playlist interface address:"
+msgid "åˆè¾‘åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}"
+msgstr "Compilation list interface address: {0}"
 
 msgid "åˆé›†: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
 msgstr "Mix: {0} All works have been collected"
 
-msgid "åˆé›†ä½œå“æ¥å£åœ°å€:"
-msgstr "Mix interface address:"
+msgid "åˆé›†ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "The interface address for the collection of works: {0}"
 
 msgid "å“åº”çŠ¶æ€ç : {0}"
 msgstr "Status code: {0}"
 
-msgid "å–œæ¬¢ä½œå“æ¥å£åœ°å€:"
-msgstr "Like interface address:"
+msgid "å–œæ¬¢ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Favorite works interface address: {0}"
 
 msgid "å›¾é›†"
 msgstr "IMG"
 
 msgid "åœ¨ {0} åº”ç”¨é‡Œæ²¡æœ‰æ‰¾åˆ°å¸®åŠ©æ–‡ä»¶"
 msgstr "Help file not found in {0} application"
 
+msgid "å¤„ç†HTTPé”™è¯¯æ—¶é‡åˆ°æ„å¤–æƒ…å†µï¼š{0}"
+msgstr "Unexpected conditions encountered while handling HTTP errors: {0}"
+
 msgid "å­åˆ†åŒº: {0} ä¸»æ’­æ˜µç§°: {1}"
 msgstr "Subpartition: {0} Anchor Nickname: {1}"
 
-msgid "å®šä½ä¸Šä¸€æ¬¡ä½œå“æ¥å£åœ°å€:"
-msgstr "Locate the last work interface address:"
+msgid "å®šä½ä¸Šä¸€æ¬¡ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Locate the last work interface address: {0}"
 
 msgid "å°é¢"
 msgstr "Cover"
 
+msgid "å°è¯•åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ï¼š{0}"
+msgstr "Attempt to delete temporary file failed: {0}"
+
 msgid "å·²å–æ¶ˆæ›´æ–°é…ç½®æ–‡ä»¶!"
 msgstr "Updating profiles has been canceled!"
 
 msgid "å¼€å§‹æ‰§è¡Œä¸‹è½½ä»»åŠ¡ï¼Œæœ¬æ¬¡å…±æœ‰ {0} ä¸ªä»»åŠ¡"
 msgstr "Started the download task, there are {0} tasks this time"
 
-msgid "å¼€å§‹çˆ¬å–åˆé›†: {0} çš„è§†é¢‘"
-msgstr "Start crawling the videos of the mix: {0}"
+msgid "å¼€å§‹çˆ¬å–ä½œå“ï¼š{0}"
+msgstr "Start crawling for entries: {0}"
+
+msgid "å¼€å§‹çˆ¬å–åˆé›†: {0} çš„ä½œå“"
+msgstr "Start crawling the collection: {0}'s work"
 
 msgid "å¼€å§‹çˆ¬å–æˆ¿é—´å·: {0} çš„æ•°æ®"
 msgstr "Start crawling for room number: {0}"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} feedçš„è§†é¢‘"
-msgstr "Start crawling videos from user: {0} feed"
+msgid "å¼€å§‹çˆ¬å–æ”¶è—å¤¹ï¼š{0} çš„ä½œå“"
+msgstr "Start crawling favorites: {0}'s entries"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} feedçš„ä½œå“"
+msgstr "Start crawling user: {0} feed entries"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} åˆé›†çš„ä½œå“"
+msgstr "Start crawling the User: {0} collection"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—å¤¹"
+msgstr "Start crawling user favorites"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„ä½œå“"
+msgstr "Start crawling user favorites"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„éŸ³ä¹ä½œå“"
+msgstr "Start crawling the user's music collection"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} å‘å¸ƒçš„è§†é¢‘"
-msgstr "Start crawling videos posted by user: {0}"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} å‘å¸ƒçš„ä½œå“"
+msgstr "Start crawling User: {0} Postings"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} åˆé›†çš„è§†é¢‘"
-msgstr "Start crawling user: {0} mix videos"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} å–œæ¬¢çš„ä½œå“"
+msgstr "Start Crawling User: {0} Likes"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} å–œæ¬¢çš„è§†é¢‘"
-msgstr "Start crawling user: {0} like video"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} æ”¶è—çš„ä½œå“"
+msgstr "Start crawling User: {0} Favorites"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} æ”¶è—çš„è§†é¢‘"
-msgstr "Start crawling user: {0} collect videos"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} ç‚¹èµçš„ä½œå“"
+msgstr "Start crawling for entries liked by user:{0}"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} ç‚¹èµçš„è§†é¢‘"
-msgstr "Start crawling user: {0} like videos"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„ä½œå“åˆé›†åˆ—è¡¨"
+msgstr "Start crawling the collection list of user:{0}'s works"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} çš„è§†é¢‘åˆé›†åˆ—è¡¨"
-msgstr "Start crawling the video play list of user: {0}"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„å…³æ³¨ç”¨æˆ·"
+msgstr "Users: {0} All concerned users captured"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„è§†é¢‘"
-msgstr "Start crawling user collect videos"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„ç²‰ä¸"
+msgstr "Start crawling the followers of user:{0}"
 
 msgid "å¼€å§‹çˆ¬å–ç›´æ’­: {0} çš„æ•°æ®"
 msgstr "Start crawling live: {0}"
 
 msgid "å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ"
 msgstr "Start crawling page {0}"
 
-msgid "å¼€å§‹çˆ¬å–è§†é¢‘: {0}"
-msgstr "Start crawling video: {0}"
+msgid "å¼‚æ­¥çš„ä»»åŠ¡æ•°"
+msgstr "Number of asynchronous tasks"
 
 msgid "å¼‚æ­¥çš„ä»»åŠ¡æ•°ã€‚"
 msgstr "The number of asynchronous tasksã€‚"
 
-msgid "å¼‚æ­¥çš„ä»»åŠ¡æ•°ï¼Œé»˜è®¤ä¸º 10"
-msgstr "The number of asynchronous tasks, default is 10"
+msgid "å½“å‰ {0} ç›´æ’­å·²ç»“æŸ"
+msgstr "Currently {0} live broadcast is closed"
 
 msgid "å½“å‰è¯·æ±‚çš„cursor: {0}"
 msgstr "Currently requested cursor: {0}"
 
+msgid "å½“å‰è¯·æ±‚çš„cursorï¼š{0}"
+msgstr "Currently requested cursor: {0}"
+
 msgid "å½“å‰è¯·æ±‚çš„max_cursor: {0}"
 msgstr "max_cursor of the current request: {0}"
 
+msgid "å½“å‰è¯·æ±‚çš„max_cursorï¼š{0}"
+msgstr "Max_cursor of the current request: {0}"
+
+msgid "å½“å‰è¯·æ±‚çš„max_cursorï¼š{0}ï¼Œ max_countsï¼š{1}"
+msgstr "max_cursor of the current request: {0}, max_counts: {1}"
+
+msgid "å½“å‰è¯·æ±‚çš„offsetï¼š{0}"
+msgstr "Current request offset: {0}"
+
+msgid "å½“å‰è¯·æ±‚çš„offsetï¼š{0} max_timeï¼š{1}"
+msgstr "Offset of current request: {0} max_time: {1}"
+
 msgid "æ‰¾åˆ°äº†æœªä¸‹è½½å®Œçš„æ–‡ä»¶ {0}, å¤§å°ä¸º {1} å­—èŠ‚"
 msgstr "Found an unfinished file {0}, size is {1} bytes"
 
 msgid "æŠ–éŸ³æ— æ°´å°è§£æ"
 msgstr "Douyin de-watermark"
 
 msgid "æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}, è¯·æ£€æŸ¥é‡è¯•"
 msgstr "Interface status code exception {0}, please check and retry"
 
+msgid "æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}ï¼Œè¯·æ£€æŸ¥é‡è¯•"
+msgstr "Interface status code exception {0}, please check and retry"
+
 msgid "æ¥å£çŠ¶æ€ç å¼‚å¸¸, è¯·æ£€æŸ¥é‡è¯•"
 msgstr "Interface status code is abnormal, please check and retry"
 
-msgid "æ”¶è—ä½œå“æ¥å£åœ°å€:"
-msgstr "Collect interface address:"
+msgid "æè¿°"
+msgstr "descriptions"
 
-msgid "æ–‡ä»¶åŒºå—ä¸‹è½½å¤±è´¥: {0}"
+msgid "æ”¶è—ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Favorite Works Interface Address: {0}"
+
+msgid "æ”¶è—å¤¹IDï¼š{0} æ”¶è—å¤¹æ ‡é¢˜ï¼š{1}"
+msgstr "Favorite ID: {0} Favorite Title: {1}"
+
+msgid "æ”¶è—å¤¹ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Favorite Works interface address: {0}"
+
+msgid "æ”¶è—å¤¹æ¥å£åœ°å€ï¼š{0}"
+msgstr "Favorites interface address: {0}"
+
+msgid "æ”¶è—å¤¹ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•ï¼Œå…±çˆ¬å– {1} ä¸ªä½œå“"
+msgstr ""
+"Favorites: {0} All entries have been collected, {1} entries were crawled"
+
+msgid "æ–‡ä»¶åŒºå—ä¸‹è½½å¤±è´¥ï¼š{0}"
 msgstr "File block download failed: {0}"
 
-msgid "æ–‡ä»¶åŒºå—ä¸‹è½½è¶…æ—¶: {0}"
-msgstr "File block download timed out: {0}"
+msgid "æ–‡ä»¶åŒºå—ä¸‹è½½è¶…æ—¶ï¼š{0}"
+msgstr "File block download timeout: {0}"
 
 msgid "æ–‡ä»¶åæ¨¡æ¿å­—æ®µ {0} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥"
 msgstr "The filename template field {0} does not exist, check the"
 
 msgid "æ–‡æ¡ˆ"
 msgstr "Desc"
 
 msgid "æ— æ•ˆå“åº”ç±»å‹ã€‚å“åº”ç±»å‹: {0}"
 msgstr "Invalid response type. Response Type: {0}"
 
 msgid "æ— æ³•ä» {0} æµè§ˆå™¨ä¸­è·å–cookie"
 msgstr "Unable to get cookie from {0} browser"
 
-msgid "æ— æ³•ä»{0}æµè§ˆå™¨ä¸­è·å–cookie"
-msgstr "Unable to get cookies from {0} browser"
-
-msgid "æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
-msgstr "API endpoint not found"
-
 msgid "æ— æ³•è§£æä½œå“å‘å¸ƒæ—¶é—´ï¼š{0}"
 msgstr "Unable to parse work Published: {0}"
 
 msgid "æ— æ³•è¯»å–è¯¥TSæ–‡ä»¶å­—èŠ‚é•¿åº¦ï¼Œå°†ä½¿ç”¨é»˜è®¤400kbå—å¤§å°å¤„ç†æ•°æ®"
 msgstr ""
 "Unable to read this TS file byte length, will use default 400kb block size "
 "to process data"
 
 msgid "æ—¥æœŸåŒºé—´å‚æ•°æ ¼å¼é”™è¯¯ï¼Œè¯·æŸ¥é˜…æ–‡æ¡£åé‡è¯•"
 msgstr ""
 "The date range parameter is formatted incorrectly, please consult the "
 "documentation and try again"
 
+msgid "æ˜¯å¦ä¿å­˜åŸå£°æ­Œè¯"
+msgstr "Whether to save the original lyrics"
+
+msgid "æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°"
+msgstr "Whether to save video soundtrack"
+
 msgid "æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°ã€‚å¯é€‰ï¼š'yes'ã€'no'"
 msgstr "Whether to save the original sound of the video. Optional: 'yes', 'no'"
 
-msgid "æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°ï¼Œé»˜è®¤ä¸º 'yes'"
-msgstr "Whether to save the original sound of the video, default is 'yes'"
+msgid "æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢"
+msgstr "Whether to save the video cover"
 
 msgid "æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢ã€‚å¯é€‰ï¼š'yes'ã€'no'"
 msgstr "Whether to save the video cover. Optional: 'yes', 'no'"
 
-msgid "æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢ï¼Œé»˜è®¤ä¸º 'yes'"
-msgstr "Whether to save the video cover, default is 'yes'"
+msgid "æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆ"
+msgstr "Whether to save video desc"
 
 msgid "æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆã€‚å¯é€‰ï¼š'yes'ã€'no'"
 msgstr "Whether to save the video text. Optional: 'yes', 'no'"
 
-msgid "æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆï¼Œé»˜è®¤ä¸º 'yes'"
-msgstr "Whether or not to save the video copy, default is 'yes'"
+msgid "æ˜¯å¦ä¿å­˜è§†é¢‘æ­Œè¯"
+msgstr "Whether to save video lyrics"
+
+msgid "æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹"
+msgstr "Whether to save your video in a separate folder"
 
 msgid "æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ã€‚å¯é€‰ï¼š'yes'ã€'no'"
 msgstr "Whether to save the work to a separate folder. Optional: 'yes', 'no'"
 
-msgid "æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ï¼Œé»˜è®¤ä¸º 'yes'"
-msgstr "Whether or not to save the work to a separate folder, default is 'yes'"
-
-msgid "æ˜¯å¦è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieï¼Œä»¥åŠä»å“ªä¸ªæµè§ˆå™¨è·å–"
-msgstr ""
-"Whether cookies are automatically fetched from browsers, and from which "
-"browsers"
-
 msgid "æ˜¯å¦è¦ä½¿ç”¨å‘½ä»¤è¡Œçš„å‚æ•°æ›´æ–°é…ç½®æ–‡ä»¶ï¼Ÿ"
 msgstr ""
 "Should I update the configuration file using parameters from the command "
 "lineï¼Ÿ"
 
 msgid "æ˜¾ç¤ºå¯Œæ–‡æœ¬å¸®åŠ©"
 msgstr "Show Rich Text Help"
@@ -593,290 +687,369 @@
 msgstr "Display language. Default is 'zh_CN'. Optional: 'zh_CN', 'en_US'"
 
 msgid "æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ã€‚å¯é€‰ï¼š'zh_CN'ã€'en_US'ã€‚ä¸æ”¯æŒé…ç½®æ–‡ä»¶ä¿®æ”¹ã€‚"
 msgstr ""
 "Display language. Default is 'zh_CN'. Optional: 'zh_CN', 'en_US'. "
 "Configuration file modification is not supportedã€‚"
 
+msgid "æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ï¼Œå¯é€‰ï¼š'zh_CN'ã€'en_US'ï¼Œä¸æ”¯æŒé…ç½®æ–‡ä»¶ä¿®æ”¹"
+msgstr ""
+"Display language. Default is 'zh_CN', optional: 'zh_CN', 'en_US', does not "
+"support configuration file modification"
+
 msgid ""
 "æ›´åŠ è¯¦ç»†çš„å‚æ•°è¯´æ˜è¯·ç‚¹å‡»[link=https://johnserf-seed.github.io/f2/site-config."
 "html][dark_violet]å‰å¾€æ–‡æ¡£[/dark_violet][/]æŸ¥çœ‹"
 msgstr ""
 "For a more detailed description of the parameters, please click "
 "[link=https://johnserf-seed.github.io/f2/site-config.html][dark_violet]Go to "
 "Documentation[/dark_violet][/]View"
 
-msgid "æœ€å¤§ä½œå“ä¸‹è½½æ•° é»˜è®¤ä¸º 0ï¼Œè¡¨ç¤ºæ— é™åˆ¶"
-msgstr ""
-"Maximum number of artwork downloads Default is 0, which means no limitation"
-
 msgid "æœ€å¤§ä½œå“ä¸‹è½½æ•°ã€‚0 è¡¨ç¤ºæ— é™åˆ¶"
 msgstr "Maximum number of downloads. 0 means unlimited"
 
 msgid "æœ€å¤§æ•°é‡: {0} æ¯æ¬¡è¯·æ±‚æ•°é‡: {1}"
 msgstr "Maximum number: {0} Number per request: {1}"
 
-msgid "æœ‹å‹ä½œå“æ¥å£åœ°å€:"
-msgstr "Friend's work interface address:"
+msgid "æœ€å¤§æ•°é‡ï¼š{0} æ¯æ¬¡è¯·æ±‚æ•°é‡ï¼š{1}"
+msgstr "Maximum number: {0} Number per request: {1}"
 
-msgid "æœªåœ¨å“åº”ä¸­æ‰¾åˆ°aweme_id"
-msgstr "No aweme_id found in the address of the response"
+msgid "æœ‹å‹ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Friend Works interface address: {0}"
 
-msgid "æœªåœ¨å“åº”ä¸­æ‰¾åˆ°unique_id"
-msgstr "Unique_id not found in response"
+msgid "æœªåœ¨å“åº”ä¸­æ‰¾åˆ° {0}"
+msgstr "Not found in response {0}"
 
-msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°aweme_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºä½œå“é¡µ"
+msgid "æœªåœ¨å“åº”ä¸­æ‰¾åˆ° {0}ï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µã€‚ç±»å: {1}"
 msgstr ""
-"Aweme_id not found in the response address, check if the link is a post page"
+"Did not find {0} in the response, check if the link is to the user's home "
+"page. Class name: {1}"
 
-msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_uid, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»å: {0}"
+msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°aweme_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºä½œå“é¡µ"
 msgstr ""
-"No sec_uid found in the response, check if the link is to the user's "
-"homepage class name: {0}"
+"Not found aweme_id in the address of the response, check if the link is a "
+"works page"
 
-msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_user_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»å: {0}"
+msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_user_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»åï¼š{0}"
 msgstr ""
-"Not found sec_user_id in the response, check if the link is to the user's "
-"homepage class name: {0}"
+"Not found sec_user_id in the address of the response, check if the link is "
+"to the user's homepage class name: {0}"
 
-msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°webcast_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç›´æ’­é¡µ"
-msgstr "Webcast_id not found in response address, check if link is a live page"
+msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°webcast_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç›´æ’­é¡µ"
+msgstr ""
+"Webcast_id not found in the address of the response, check if the link is a "
+"live page"
 
-msgid "æœªæ‰¾åˆ°APIç«¯ç‚¹ã€‚ç±»å: {0}"
+msgid "æœªæ‰¾åˆ°APIç«¯ç‚¹ã€‚ç±»åï¼š{0}"
 msgstr "API endpoint not found. Class name: {0}"
 
 msgid "æœªæ‰¾åˆ°m3u8æ–‡ä»¶çš„segments, å°è¯•è·å–åµŒå¥—çš„m3u8æ–‡ä»¶"
 msgstr "No segments found in m3u8 file, trying to get the nested m3u8 file"
 
 msgid "æœªæ‰¾åˆ°åµŒå¥—m3u8æ–‡ä»¶çš„segments, å¯èƒ½ç›´æ’­ç»“æŸæˆ–è¯¥ä¸»æ’­æ— æ³•ä½¿ç”¨m3u8æ–¹æ³•è§£æ"
 msgstr ""
 "No segments found in nested m3u8 file, possibly the end of the live or the "
 "anchor cannot use the m3u8 method to parse"
 
-msgid "æœªæˆæƒçš„è¯·æ±‚ã€‚ç±»å: {0}"
+msgid "æœªæˆæƒçš„è¯·æ±‚ã€‚ç±»åï¼š{0}"
 msgstr "Unauthorized request. Class name: {0}"
 
-msgid "æ ¹æ®ä½œå“å‘å¸ƒæ—¥æœŸåŒºé—´ä¸‹è½½ä½œå“ï¼Œé»˜è®¤ä¸º '0'"
-msgstr ""
-"Download works according to the work release date interval, default is '0'"
-
 msgid ""
 "æ ¹æ®æ¨¡å¼æä¾›ç›¸åº”çš„é“¾æ¥ã€‚ä¾‹å¦‚ï¼šä¸»é¡µã€ç‚¹èµã€æ”¶è—ä½œå“å¡«å…¥ä¸»é¡µé“¾æ¥ï¼Œå•ä½œå“å¡«å…¥ä½œ"
 "å“é“¾æ¥ï¼Œåˆè¾‘ä¸ç›´æ’­åŒä¸Š"
 msgstr ""
 "Provide the appropriate link according to the mode. For example: homepage, "
 "likes and favorites fill in the homepage link, single works fill in the "
 "works link, compilations and live streams are the same as above"
 
 msgid "æ¬¢è¿æäº¤PRé€‚é…æ›´å¤šç½‘ç«™"
 msgstr "Welcome to submit PR to adapt more websites"
 
-msgid "æ¯é¡µä½œå“æ•°ï¼Œé»˜è®¤ä¸º 20ä¸ªä½œå“/é¡µ"
-msgstr "The default number of entries per page is 20 entries per page"
+msgid "æ­Œè¯"
+msgstr "LYRIC"
+
+msgid "æ­Œè¯æ•°æ®å­—æ®µé”™è¯¯ï¼š{0}"
+msgstr "Lyrics data field error: {0}"
+
+msgid "æ­Œè¯æ•°æ®ç±»å‹é”™è¯¯ï¼š{0}"
+msgstr "Lyrics data type error: {0}"
 
 msgid "æ²¡æœ‰æ‰¾åˆ° {0} åº”ç”¨"
 msgstr "No {0} applications found"
 
 msgid "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä½œå“"
 msgstr "No eligible entries found"
 
-msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å–{0}ä¸ªè§†é¢‘"
-msgstr "End of crawl, total {0} videos crawled"
+msgid "çˆ¬å–äº† {0} ä¸ªå…³æ³¨ç”¨æˆ·"
+msgstr "Crawled {0} followers"
+
+msgid "çˆ¬å–äº† {0} ä¸ªç²‰ä¸ç”¨æˆ·"
+msgstr "Crawled {0} followers"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±æ‰¾åˆ° {0} ä¸ªæ”¶è—å¤¹"
+msgstr "End of crawl, total {0} favorites found"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªä½œå“"
+msgstr "End of crawl, total {0} entries crawled"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªåˆé›†ä½œå“"
+msgstr "End of crawl, total {0} collections crawled"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªæ”¶è—ä½œå“"
+msgstr "End of crawl, total {0} favorites crawled"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªæ”¶è—å¤¹"
+msgstr "End of crawl, total {0} favorites crawled"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªç‚¹èµä½œå“"
+msgstr "End of crawl, total {0} liked entries"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªç”¨æˆ·"
+msgstr "End of crawl, total {0} users crawled"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªéŸ³ä¹ä½œå“"
+msgstr "End of crawl, total {0} music entries crawled"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªé¦–é¡µæ¨èä½œå“"
+msgstr "End of crawl, total {0} homepage referrals crawled"
+
+msgid "çŠ¶æ€"
+msgstr "statuses"
 
 msgid "ç”ŸæˆX-Boguså¤±è´¥: {0})"
 msgstr "Generating X-Bogus failed: {0})"
 
+msgid "ç”Ÿæˆæ­Œè¯æ–‡ä»¶å¤±è´¥ï¼š{0}ï¼Œè¯·æ£€æŸ¥æ­Œè¯ `data` å†…å®¹"
+msgstr ""
+"Failed to generate lyrics file: {0}, please check lyrics `data` content"
+
 msgid "ç”Ÿæˆè™šå‡çš„msToken"
 msgstr "Generate a fake msToken"
 
 msgid "ç”¨æˆ·: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
 msgstr "User: {0} All works have been captured"
 
-msgid "ç”¨æˆ·: {0} æ²¡æœ‰è§†é¢‘åˆé›†"
-msgstr "Users: {0} No Play list"
+msgid "ç”¨æˆ·IDï¼š{0} ç”¨æˆ·æ˜µç§°ï¼š{1} ç”¨æˆ·ä½œå“æ•°ï¼š{2}"
+msgstr "User ID: {0} User Nickname: {1} Number of User Works: {2}"
+
+msgid "ç”¨æˆ·IDï¼š{0} ç”¨æˆ·æ˜µç§°ï¼š{1} ç”¨æˆ·ä½œå“æ•°ï¼š{2} é¢å¤–å†…å®¹ï¼š{3}"
+msgstr "User ID: {0} User Nickname: {1} Number of User Works: {2} Extras: {3}"
+
+msgid "ç”¨æˆ·ä¿¡æ¯æ¥å£åœ°å€ï¼š{0}"
+msgstr "User information interface address: {0}"
+
+msgid "ç”¨æˆ·å…³æ³¨åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}"
+msgstr "User Follow List interface address: {0}"
+
+msgid "ç”¨æˆ·æ”¶è—çš„ä½œå“é‡‡é›†å®Œæ¯•"
+msgstr "The collection of the user's favorite works is finished"
+
+msgid "ç”¨æˆ·æ”¶è—çš„éŸ³ä¹ä½œå“é‡‡é›†å®Œæ¯•"
+msgstr "The user's collection of music pieces is captured"
+
+msgid "ç”¨æˆ·æ²¡æœ‰ä½œå“åˆè¾‘"
+msgstr "Users do not have a collection of works"
 
-msgid "ç”¨æˆ·ä¿¡æ¯æ¥å£åœ°å€:"
-msgstr "User detail interface address:"
+msgid "ç”¨æˆ·ç²‰ä¸åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}"
+msgstr "User fan list interface address: {0}"
 
-msgid "ç”¨æˆ·æ”¶è—çš„è§†é¢‘é‡‡é›†å®Œæ¯•"
-msgstr "User's collect videos are captured"
+msgid "ç”¨æˆ·ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
+msgstr "User: {0} All works are captured"
 
-msgid "ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–msToken"
-msgstr "Unauthorized request,Unable to get msToken"
+msgid "ç”¨æˆ·ï¼š{0} æ‰€æœ‰å…³æ³¨ç”¨æˆ·é‡‡é›†å®Œæ¯•"
+msgstr "Users: {0} All concerned users captured"
 
-msgid "ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–ttwid"
-msgstr "Due to some error, the ttwid could not be retrieved"
+msgid "ç”¨æˆ·ï¼š{0} æ‰€æœ‰ç²‰ä¸é‡‡é›†å®Œæ¯•"
+msgstr "User: {0} All fans captured"
+
+msgid "ç”¨æˆ·ï¼š{0} æ²¡æœ‰ä½œå“åˆé›†"
+msgstr "Users: {0} No collection of works"
 
 msgid ""
 "ç™»å½•åçš„[yellow]cookie[/yellow]ï¼Œå¦‚æœä½¿ç”¨æœªç™»å½•çš„[yellow]cookie[/yellow]ï¼Œåˆ™"
 "æ— æ³•æŒä¹…ç¨³å®šä¸‹è½½ä½œå“"
 msgstr ""
 "Logged in [yellow]cookie[/yellow], if you use a non-logged in "
 "[yellow]cookie[/yellow], you will not be able to download the work in a "
 "persistent and stable manner"
 
-msgid "ç™»å½•åçš„cookie"
-msgstr "Cookie after login"
-
 msgid "ç™»å½•åçš„cookieï¼Œå¦‚æœä½¿ç”¨æœªç™»å½•çš„cookieï¼Œåˆ™æ— æ³•æŒä¹…ç¨³å®šä¸‹è½½ä½œå“"
 msgstr ""
 "Logged in cookies, if you use a cookie that is not logged in, you will not "
 "be able to download the work in a persistent and stable manner"
 
 msgid "ç›´æ’­"
 msgstr "LIVE"
 
 msgid "ç›´æ’­ID: {0} ç›´æ’­æ ‡é¢˜: {1} ç›´æ’­çŠ¶æ€: {2} è§‚çœ‹äººæ•°: {3}"
 msgstr "Live ID: {0} Live Title: {1} Live Status: {2} Viewers: {3}"
 
 msgid "ç›´æ’­ä¿¡æ¯çˆ¬å–ç»“æŸ"
 msgstr "End of live feed crawling"
 
-msgid "ç›´æ’­å·²ç»“æŸ"
-msgstr "The live has ended"
+msgid "ç›´æ’­æ¥å£åœ°å€ï¼ˆroom_idï¼‰ï¼š{0}"
+msgstr "Live streaming interface address (room_id): {0}"
 
-msgid "ç›´æ’­æ¥å£åœ°å€:"
-msgstr "Live Streaming address:"
+msgid "ç›´æ’­æ¥å£åœ°å€ï¼š{0}"
+msgstr "Live streaming interface address: {0}"
 
-msgid "ç›´æ’­æ¥å£åœ°å€ï¼ˆroom_idï¼‰:"
-msgstr "Live streaming interface address (room_id):"
-
-msgid "ç›¸å…³æ¨èä½œå“æ¥å£åœ°å€:"
-msgstr "Related address:"
+msgid "ç›¸å…³æ¨èä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Related recommended works interface address: {0}"
 
 msgid "ç¬¬ {0} æ¬¡å“åº”å†…å®¹ä¸ºç©º, çŠ¶æ€ç : {1}, URL:{2}"
 msgstr "The {0} th response is empty, status code: {1}, URL:{2}"
 
+msgid "ç¬¬ {0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“"
+msgstr "Page {0} No work found"
+
+msgid "ç­‰å¾… {0} ç§’åç»§ç»­"
+msgstr "Wait {0} seconds and continue"
+
 msgid "ç­›é€‰æ—¥æœŸåŒºé—´ï¼š{0} è‡³ {1}"
 msgstr "Filter Date Range: {0} to {1}"
 
+msgid "ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°"
+msgstr "Number of concurrent connections for network requests"
+
 msgid "ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°ã€‚"
 msgstr "The number of concurrent connections for network requestsã€‚"
 
-msgid "ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°ï¼Œé»˜è®¤ä¸º 5"
-msgstr "Number of concurrent connections for network requests, default is 5"
+msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´"
+msgstr "Network request timeout"
 
 msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ã€‚"
 msgstr "Network request timeout timeã€‚"
 
-msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤ä¸º 10"
-msgstr "Network request timeout, default is 10"
+msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°"
+msgstr "Number of network request timeout retries"
 
 msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°ã€‚"
 msgstr "The number of network request timeout retriesã€‚"
 
-msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°ï¼Œé»˜è®¤ä¸º 5"
-msgstr "Network request timeout retries, default is 5"
-
 msgid ""
-"è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€"
-"operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
+"è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
 msgstr ""
-"Automatically get [yellow]cookies[/yellow] from browsers. Options: chrome, "
-"firefox, edge, opera. be sure to close the selected browser before using "
-"this command"
+"Automatically get [yellow]cookies[/yellow] from browsers, make sure to close "
+"the selected browser before using this command"
 
-msgid ""
-"è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·"
-"ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
+msgid "è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
 msgstr ""
-"Automatically get cookies from browsers. options: chrome, firefox, edge, "
-"opera. make sure you close the selected browser before using this command"
+"Automatically get cookies from browsers, make sure to close the selected "
+"browser before using this command"
 
-msgid "è‡ªåŠ¨è·å–Cookieå¤±è´¥: {0}"
-msgstr "handler auto cookie error: {0}"
+msgid "è‡ªåŠ¨è·å–Cookieå¤±è´¥ï¼š{0}"
+msgstr "Failed to get cookie automatically: {0}"
 
 msgid "è‡ªå®šä¹‰é…ç½®å‚æ•°ï¼š{0}"
 msgstr "Customized configuration parameters: {0}"
 
-msgid "è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š {0}"
+msgid "è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š{0}"
 msgstr "Custom configuration path: {0}"
 
 msgid "è‡³å°‘æä¾› secUid æˆ– uniqueId ä¸­çš„ä¸€ä¸ªå‚æ•°"
 msgstr "Provide at least one of secUid or uniqueId as a parameter"
 
-msgid "è·å–aweme_idå¤±è´¥, {0}"
-msgstr "Failed to get aweme_id, {0}"
+msgid "è‡³å°‘æä¾› user_id æˆ– sec_user_id ä¸­çš„ä¸€ä¸ªå‚æ•°"
+msgstr "Provide at least one of user_id or sec_user_id"
 
-msgid "è·å–sec_uidå¤±è´¥, {0}"
-msgstr "Failed to get sec_uid, {0}"
-
-msgid "è·å–unique_idå¤±è´¥, {0}"
-msgstr "Failed to get unique_id, {0}"
+msgid "è·å– {0} å¤±è´¥ï¼Œ{1}"
+msgstr "Get {0} Failed, {1}"
 
 msgid "è·å–æ•°æ®å¤±è´¥ã€‚çŠ¶æ€ç : {0}"
 msgstr "Failed to get data. Status code: {0}"
 
 msgid "è·å–ç«¯ç‚¹æ•°æ®å¤±è´¥, æ¬¡æ•°è¾¾åˆ°ä¸Šé™"
 msgstr "Failed to get endpoint data, number of times reached the upper limit"
 
 msgid "è¦æ›´æ–°é…ç½®, é¦–å…ˆéœ€è¦ä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªè‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„"
 msgstr ""
 "To update the configuration, you first need to provide a custom "
 "configuration file path using the '-c' option"
 
+msgid "è¦æ›´æ–°é…ç½®ï¼Œé¦–å…ˆéœ€è¦ä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªè‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„"
+msgstr ""
+"To update the configuration, you first need to provide a custom "
+"configuration file path using the '-c' option"
+
 msgid "è§†é¢‘"
 msgstr "Video"
 
-msgid "è§†é¢‘ID: {0} è§†é¢‘æ–‡æ¡ˆ: {1} ä½œè€…: {2}"
+msgid "è§†é¢‘IDï¼š{0} è§†é¢‘æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}"
 msgstr "Video ID: {0} Video Copy: {1} Author: {2}"
 
-msgid "è§†é¢‘åˆé›†ID: {0} è§†é¢‘åˆé›†æ ‡é¢˜: {1}"
-msgstr "Video Mix ID: {0} Video Mix Title: {1}"
-
 msgid "è§£æ {0} æ¥å£ JSON å¤±è´¥ï¼š {1}"
 msgstr "Parsing {0} interface JSON failed: {1}"
 
+msgid "è¯¥ {0} ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½"
+msgstr "The {0} work has been blocked from download"
+
 msgid "è¯¥é“¾æ¥è¿”å›çš„æ˜¯room_idï¼Œè¯·ä½¿ç”¨`fetch_user_live_videos_by_room_id`æ¥å£"
 msgstr ""
 "This link returns the room_id, use the `fetch_user_live_videos_by_room_id` "
 "interface"
 
-msgid "è¯­è¨€è®¾ç½®ï¼Œé»˜è®¤ä¸º 'zh_CN'"
-msgstr "Language setting, default is 'zh_CN'"
+msgid "è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•ï¼Œå¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ï¼"
+msgstr ""
+"Please close all open browsers and retry, and that you have the proper "
+"permissions to access the browser!"
 
-msgid "è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•, å¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ !"
+msgid ""
+"è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸"
+"è¯¦ç»†ä¿¡æ¯ï¼š{3}"
 msgstr ""
-"Please close all open browsers and try again, and you have the proper "
-"permissions to access the browser !"
+"Request for endpoint failed, please check current network environment. Link: "
+"{0}, Agent: {1}, Exception Class Name: {2}, Exception Details: {3}"
 
 msgid "è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}"
 msgstr "The input URL List is not legal. Class name: {0}"
 
 msgid "è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}"
 msgstr "The input URL is not legal. Class name: {0}"
 
-msgid "è¿æ¥åˆ°APIæ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥URLæˆ–ç½‘ç»œæƒ…å†µã€‚ç±»å: {0}"
-msgstr ""
-"An error occurred while connecting to the API, please check the URL or "
-"network conditions. Class name: {0}"
-
 msgid "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
 msgstr ""
 "Failed to connect to endpoint, check network environment or Agent: {0} "
 "Agent: {1} Class name: {2}"
 
 msgid "è¿æ¥è¶…æ—¶é”™è¯¯: {0}"
 msgstr "Connection timeout error: {0}"
 
+msgid "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"
+msgstr "Configuration file does not exist"
+
 msgid "é…ç½®æ–‡ä»¶å·²æ›´æ–°!"
 msgstr "Configuration files have been updated!"
 
 msgid "é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œ[red]æœ€ä½ä¼˜å…ˆ[/red]"
 msgstr "Path to the configuration file, [red]lowest priority[/red]"
 
 msgid "é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œæœ€ä½ä¼˜å…ˆ"
 msgstr "Path to configuration file, highest priority"
 
-msgid "é™¤äº†å•ä¸ªä½œå“å¤–ï¼Œå…¶ä»–URLéƒ½éœ€è¦ç”¨æˆ·ä¸»é¡µURL"
-msgstr "User homepage URLs are required for all URLs except one video"
+msgid "é…ç½®æ–‡ä»¶è·¯å¾„æ— å†™æƒé™"
+msgstr "Configuration file does not exist"
+
+msgid "é“¾æ¥ {0} å†…å®¹é•¿åº¦ä¸º0ï¼Œå°è¯•ä¸‹ä¸€ä¸ªé“¾æ¥æ˜¯å¦å¯ç”¨"
+msgstr "link {0} content length 0, try next link if available"
+
+msgid "é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} "
+msgstr "Link: {0}, status code {1}: {2} "
+
+msgid "éŸ³ä¹"
+msgstr "SONG"
+
+msgid "éŸ³ä¹IDï¼š{0} éŸ³ä¹æ ‡é¢˜ï¼š{1} ä½œè€…ï¼š{2}"
+msgstr "Music ID: {0} Music Title: {1} Author: {2}"
+
+msgid "éŸ³ä¹æ”¶è—æ¥å£åœ°å€ï¼š{0}"
+msgstr "Music Collection interface address: {0}"
 
 msgid "é¡µé¢ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯ç”±äºåŒºåŸŸé™åˆ¶ï¼ˆä»£ç†ï¼‰é€ æˆçš„ã€‚ç±»å: {0}"
 msgstr ""
 "The page is not available, probably due to a regional restriction (proxy). "
 "Class name: {0}"
 
-msgid "é¦–é¡µæ¨èä½œå“æ¥å£åœ°å€:"
-msgstr "Home Feed interface address:"
+msgid "é¦–é¡µæ¨èä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "Home recommended works interface address: {0}"
 
-msgid "é¦–é¡µæ¨èæ¥å£åœ°å€:"
-msgstr "Home feed interface address:"
+msgid "é¦–é¡µæ¨èæ¥å£åœ°å€ï¼š{0}"
+msgstr "Home Recommended Interface Address: {0}"
```

### Comparing `f2-0.0.1.4/f2/languages/zh_CN/LC_MESSAGES/zh_CN.mo` & `f2-0.0.1.5/f2/languages/zh_CN/LC_MESSAGES/zh_CN.mo`

 * *Files 21% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: f2-translate\n"
 "Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"
-"PO-Revision-Date: 2024-02-15 23:12+0800\n"
+"PO-Revision-Date: 2024-04-05 00:25+0800\n"
 "Last-Translator: JohnserfSeed <johnserf-seed@foxmail.com>\n"
 "Language-Team: Chinese Simplified\n"
 "Language: zh_CN\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
@@ -14,20 +14,14 @@
 "X-Generator: Poedit 3.3.2\n"
 "X-Crowdin-Project: f2-translate\n"
 "X-Crowdin-Project-ID: 631650\n"
 "X-Crowdin-Language: zh-CN\n"
 "X-Crowdin-File: messages.pot\n"
 "X-Crowdin-File-ID: 2\n"
 
-msgid "'{0}' é…ç½®æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨"
-msgstr "'{0}' é…ç½®æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨"
-
-msgid "'{0}' é…ç½®æ–‡ä»¶è·¯å¾„æ— å†™æƒé™"
-msgstr "'{0}' é…ç½®æ–‡ä»¶è·¯å¾„æ— å†™æƒé™"
-
 msgid ""
 "- å•ä¸ªä½œå“ï¼Œä¸»é¡µä½œå“ï¼Œç‚¹èµä½œå“ï¼Œæ”¶è—ä½œå“ï¼Œåˆè¾‘ä½œå“ï¼Œå›¾æ–‡ï¼Œæ–‡æ¡ˆï¼Œå°é¢ï¼Œç›´æ’­ï¼Œ"
 "åŸå£°ã€‚"
 msgstr ""
 "- å•ä¸ªä½œå“ï¼Œä¸»é¡µä½œå“ï¼Œç‚¹èµä½œå“ï¼Œæ”¶è—ä½œå“ï¼Œåˆè¾‘ä½œå“ï¼Œå›¾æ–‡ï¼Œæ–‡æ¡ˆï¼Œå°é¢ï¼Œç›´æ’­ï¼Œ"
 "åŸå£°ã€‚"
 
@@ -59,64 +53,61 @@
 msgid "- è·å–å¾®åš"
 msgstr "- è·å–å¾®åš"
 
 msgid "- è·å–ç½‘æ˜“äº‘éŸ³ä¹ä½œå“"
 msgstr "- è·å–ç½‘æ˜“äº‘éŸ³ä¹ä½œå“"
 
 msgid ""
-"- è®°å½•appçš„debugåˆ°/logsä¸‹ï¼Œå¦‚é‡BUGæäº¤Issueæ—¶è¯·é™„å¸¦è¯¥æ–‡ä»¶å¹¶[red]åˆ é™¤ä¸ªäººæ•æ„Ÿ"
-"ä¿¡æ¯[/red]"
+"- è®°å½•appçš„è°ƒè¯•æ—¥å¿—åˆ°/logsä¸‹ï¼Œå¦‚é‡BUGæäº¤Issueæ—¶è¯·é™„å¸¦è¯¥æ–‡ä»¶å¹¶[red]åˆ é™¤ä¸ªäººæ•"
+"æ„Ÿä¿¡æ¯[/red]"
 msgstr ""
-"- è®°å½•appçš„debugåˆ°/logsä¸‹ï¼Œå¦‚é‡BUGæäº¤Issueæ—¶è¯·é™„å¸¦è¯¥æ–‡ä»¶å¹¶[red]åˆ é™¤ä¸ªäººæ•æ„Ÿ"
-"ä¿¡æ¯[/red]"
-
-msgid "401 ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–ttwid"
-msgstr "401 ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–ttwid"
-
-msgid "404 æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
-msgstr "404 æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
+"- è®°å½•appçš„è°ƒè¯•æ—¥å¿—åˆ°/logsä¸‹ï¼Œå¦‚é‡BUGæäº¤Issueæ—¶è¯·é™„å¸¦è¯¥æ–‡ä»¶å¹¶[red]åˆ é™¤ä¸ªäººæ•"
+"æ„Ÿä¿¡æ¯[/red]"
 
-msgid "APIæœåŠ¡ä¸å¯ç”¨ã€‚ç±»å: {0}"
-msgstr "APIæœåŠ¡ä¸å¯ç”¨ã€‚ç±»å: {0}"
+msgid "0: [bold]å…¨éƒ¨ä¸‹è½½[/bold]"
+msgstr "0: [bold]å…¨éƒ¨ä¸‹è½½[/bold]"
 
-msgid "APIé”™è¯¯ç ï¼š{0}ã€‚ç±»å: {1}"
-msgstr "APIé”™è¯¯ç ï¼š{0}ã€‚ç±»å: {1}"
+msgid "APIå†…å®¹è¯·æ±‚å¤±è´¥ï¼Œè¯·æ›´æ¢æ–°cookieåå†è¯•"
+msgstr "APIå†…å®¹è¯·æ±‚å¤±è´¥ï¼Œè¯·æ›´æ¢æ–°cookieåå†è¯•"
 
-msgid "BaseDownloader è¯·æ±‚å¤´headers:{0}"
-msgstr "BaseDownloader è¯·æ±‚å¤´headers:{0}"
+msgid "APIæœåŠ¡ä¸å¯ç”¨ã€‚ç±»åï¼š{0}"
+msgstr "APIæœåŠ¡ä¸å¯ç”¨ã€‚ç±»åï¼š{0}"
 
 msgid "CLIå‚æ•°ï¼š{0}"
 msgstr "CLIå‚æ•°ï¼š{0}"
 
+msgid "HTTPçŠ¶æ€ç é”™è¯¯ï¼š"
+msgstr "HTTPçŠ¶æ€ç é”™è¯¯ï¼š"
+
 msgid "HTTPçŠ¶æ€é”™è¯¯, å°è¯•GETè¯·æ±‚å¤±è´¥: {0}, é”™è¯¯è¯¦æƒ…: {1}"
 msgstr "HTTPçŠ¶æ€é”™è¯¯, å°è¯•GETè¯·æ±‚å¤±è´¥: {0}, é”™è¯¯è¯¦æƒ…: {1}"
 
-msgid "HTTPçŠ¶æ€é”™è¯¯: {0}, URL: {1}, å°è¯•æ¬¡æ•°: {2}"
-msgstr "HTTPçŠ¶æ€é”™è¯¯: {0}, URL: {1}, å°è¯•æ¬¡æ•°: {2}"
-
 msgid "HTTPçŠ¶æ€é”™è¯¯: {0}, çŠ¶æ€ç : {1}"
 msgstr "HTTPçŠ¶æ€é”™è¯¯: {0}, çŠ¶æ€ç : {1}"
 
+msgid "HTTPçŠ¶æ€é”™è¯¯ï¼š{0}, URLï¼š{1}, å°è¯•æ¬¡æ•°ï¼š{2}"
+msgstr "HTTPçŠ¶æ€é”™è¯¯ï¼š{0}, URLï¼š{1}, å°è¯•æ¬¡æ•°ï¼š{2}"
+
 msgid "HTTPé”™è¯¯: {0}"
 msgstr "HTTPé”™è¯¯: {0}"
 
 msgid "Hello, World!"
 msgstr "ä½ å¥½ï¼Œä¸–ç•Œï¼"
 
-msgid "SSOæ£€æŸ¥æ‰«ç çŠ¶æ€æ¥å£åœ°å€:"
-msgstr "SSOæ£€æŸ¥æ‰«ç çŠ¶æ€æ¥å£åœ°å€:"
+msgid "SSOæ£€æŸ¥æ‰«ç çŠ¶æ€æ¥å£åœ°å€ï¼š{0}"
+msgstr "SSOæ£€æŸ¥æ‰«ç çŠ¶æ€æ¥å£åœ°å€ï¼š{0}"
 
-msgid "SSOæ£€æŸ¥ç™»å½•çŠ¶æ€æ¥å£åœ°å€:"
-msgstr "SSOæ£€æŸ¥ç™»å½•çŠ¶æ€æ¥å£åœ°å€:"
+msgid "SSOæ£€æŸ¥ç™»å½•çŠ¶æ€æ¥å£åœ°å€ï¼š{0}"
+msgstr "SSOæ£€æŸ¥ç™»å½•çŠ¶æ€æ¥å£åœ°å€ï¼š{0}"
 
 msgid "SSOç™»å½•å¤±è´¥ï¼Œè¯·é‡è¯•ï¼"
 msgstr "SSOç™»å½•å¤±è´¥ï¼Œè¯·é‡è¯•ï¼"
 
-msgid "SSOè·å–äºŒç»´ç æ¥å£åœ°å€:"
-msgstr "SSOè·å–äºŒç»´ç æ¥å£åœ°å€:"
+msgid "SSOè·å–äºŒç»´ç æ¥å£åœ°å€ï¼š{0}"
+msgstr "SSOè·å–äºŒç»´ç æ¥å£åœ°å€ï¼š{0}"
 
 msgid "TSæ–‡ä»¶ä¸‹è½½å¤±è´¥: {0}"
 msgstr "TSæ–‡ä»¶ä¸‹è½½å¤±è´¥: {0}"
 
 msgid "TSæ–‡ä»¶ä¸‹è½½è¶…æ—¶: {0}"
 msgstr "TSæ–‡ä»¶ä¸‹è½½è¶…æ—¶: {0}"
 
@@ -125,20 +116,29 @@
 
 msgid "[  {0}  ]:"
 msgstr "[  {0}  ]:"
 
 msgid "[  ä¸¢å¤±  ]:"
 msgstr "[  ä¸¢å¤±  ]:"
 
+msgid "[  ä¸¢å¤±  ]ï¼šæ‰€æœ‰é“¾æ¥éƒ½æ— æ³•ä¸‹è½½"
+msgstr "[  ä¸¢å¤±  ]ï¼šæ‰€æœ‰é“¾æ¥éƒ½æ— æ³•ä¸‹è½½"
+
 msgid "[  å¤±è´¥  ]:"
 msgstr "[  å¤±è´¥  ]:"
 
+msgid "[  å¤±è´¥  ]ï¼š"
+msgstr "[  å¤±è´¥  ]ï¼š"
+
 msgid "[  å®Œæˆ  ]:"
 msgstr "[  å®Œæˆ  ]:"
 
+msgid "[  å®Œæˆ  ]ï¼š"
+msgstr "[  å®Œæˆ  ]ï¼š"
+
 msgid "[  ç™»å½•  ]:äºŒç»´ç è¿‡æœŸï¼Œé‡æ–°è·å–ï¼"
 msgstr "[  ç™»å½•  ]:äºŒç»´ç è¿‡æœŸï¼Œé‡æ–°è·å–ï¼"
 
 msgid "[  ç™»å½•  ]:æ‰«æäºŒç»´ç æˆåŠŸï¼"
 msgstr "[  ç™»å½•  ]:æ‰«æäºŒç»´ç æˆåŠŸï¼"
 
 msgid "[  ç™»å½•  ]:æ‰«ç ç¯å¢ƒå¼‚å¸¸ï¼Œè¯·å‰å¾€appéªŒè¯ï¼"
@@ -152,26 +152,32 @@
 
 msgid "[  ç™»å½•  ]:è®¿é—®é¢‘ç¹ï¼Œè¯·æ£€æŸ¥å‚æ•°ï¼"
 msgstr "[  ç™»å½•  ]:è®¿é—®é¢‘ç¹ï¼Œè¯·æ£€æŸ¥å‚æ•°ï¼"
 
 msgid "[  è·³è¿‡  ]:"
 msgstr "[  è·³è¿‡  ]:"
 
+msgid "[bold yellow]è¯·è¾“å…¥å¸Œæœ›ä¸‹è½½çš„åˆè¾‘åºå·ï¼š[/bold yellow]"
+msgstr "[bold yellow]è¯·è¾“å…¥å¸Œæœ›ä¸‹è½½çš„åˆè¾‘åºå·ï¼š[/bold yellow]"
+
+msgid "[bold yellow]è¯·è¾“å…¥å¸Œæœ›ä¸‹è½½çš„æ”¶è—å¤¹åºå·ï¼š[/bold yellow]"
+msgstr "[bold yellow]è¯·è¾“å…¥å¸Œæœ›ä¸‹è½½çš„æ”¶è—å¤¹åºå·ï¼š[/bold yellow]"
+
 msgid "`{0}` ä¸­çš„ `{1}` ä¸ç¬¦åˆå‘½åæ¨¡å¼"
 msgstr "`{0}` ä¸­çš„ `{1}` ä¸ç¬¦åˆå‘½åæ¨¡å¼"
 
 msgid "bilibili æˆ– bili"
 msgstr "bilibili æˆ– bili"
 
 msgid ""
-"cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å– f2 -d dy --"
-"helpï¼Œå¦‚æ‰«ç ç™»å½•è¯·ä¿ç•™åŒå¼•å·cookie: ï¼Œå†ä½¿ç”¨--sso-loginå‘½ä»¤ã€‚"
+"cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å–ã€‚å¦‚ `--auto-"
+"cookie edge`"
 msgstr ""
-"cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å– f2 -d dy --"
-"helpï¼Œå¦‚æ‰«ç ç™»å½•è¯·ä¿ç•™åŒå¼•å·cookie: ï¼Œå†ä½¿ç”¨--sso-loginå‘½ä»¤ã€‚"
+"cookieä¸èƒ½ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆçš„ cookie å‚æ•°ï¼Œæˆ–è‡ªåŠ¨ä»æµè§ˆå™¨è·å–ã€‚å¦‚ `--auto-"
+"cookie edge`"
 
 msgid "douyin æˆ– dy"
 msgstr "douyin æˆ– dy"
 
 msgid "f2 è¯·æ±‚ Content-Length æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {0}, é”™è¯¯è¯¦æƒ…: {1}"
 msgstr "f2 è¯·æ±‚ Content-Length æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {0}, é”™è¯¯è¯¦æƒ…: {1}"
 
@@ -183,60 +189,58 @@
 
 msgid "m3u8æ–‡ä»¶æˆ–tsæ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯èƒ½ç›´æ’­ç»“æŸ"
 msgstr "m3u8æ–‡ä»¶æˆ–tsæ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯èƒ½ç›´æ’­ç»“æŸ"
 
 msgid "m3u8æ–‡ä»¶è§£æå¤±è´¥: {0}"
 msgstr "m3u8æ–‡ä»¶è§£æå¤±è´¥: {0}"
 
-msgid ""
-"msToken: è¯·æ£€æŸ¥å¹¶æ›´æ–° f2 ä¸­ conf.yaml é…ç½®æ–‡ä»¶ä¸­çš„ msTokenï¼Œä»¥åŒ¹é… douyin æ–°"
-"è§„åˆ™ã€‚"
-msgstr ""
-"msToken: è¯·æ£€æŸ¥å¹¶æ›´æ–° f2 ä¸­ conf.yaml é…ç½®æ–‡ä»¶ä¸­çš„ msTokenï¼Œä»¥åŒ¹é… douyin æ–°"
-"è§„åˆ™ã€‚"
-
-msgid ""
-"msToken: è¯·æ£€æŸ¥å¹¶æ›´æ–° f2 ä¸­ conf.yaml é…ç½®æ–‡ä»¶ä¸­çš„ msTokenï¼Œä»¥åŒ¹é… tiktok æ–°"
-"è§„åˆ™ã€‚"
-msgstr ""
-"msToken: è¯·æ£€æŸ¥å¹¶æ›´æ–° f2 ä¸­ conf.yaml é…ç½®æ–‡ä»¶ä¸­çš„ msTokenï¼Œä»¥åŒ¹é… tiktok æ–°"
-"è§„åˆ™ã€‚"
+msgid "msToken APIé”™è¯¯ï¼š{0}"
+msgstr "msToken APIé”™è¯¯ï¼š{0}"
 
 msgid "neteasy_music æˆ– nem"
 msgstr "neteasy_music æˆ– nem"
 
-msgid "odin_tt: æ£€æŸ¥æ²¡æœ‰é€šè¿‡, è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„odin_tt"
-msgstr "odin_tt: æ£€æŸ¥æ²¡æœ‰é€šè¿‡, è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„odin_tt"
-
 msgid "tiktok æˆ– tk"
 msgstr "tiktok æˆ– tk"
 
 msgid "ttwid: æ£€æŸ¥æ²¡æœ‰é€šè¿‡, è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„ttwid"
 msgstr "ttwid: æ£€æŸ¥æ²¡æœ‰é€šè¿‡, è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„ttwid"
 
+msgid "ttwidæ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
+msgstr "ttwidæ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
+
 msgid "twitch æˆ– tv"
 msgstr "twitch æˆ– tv"
 
 msgid "twitter æˆ– x"
 msgstr "twitter æˆ– x"
 
 msgid "weibo æˆ– wb"
 msgstr "weibo æˆ– wb"
 
 msgid "youtube æˆ– ytb"
 msgstr "youtube æˆ– ytb"
 
+msgid "{0} å†…å®¹ä¸ç¬¦åˆè¦æ±‚"
+msgstr "{0} å†…å®¹ä¸ç¬¦åˆè¦æ±‚"
+
+msgid "{0} åœ¨æœåŠ¡å™¨ä¸Šçš„æ€»å†…å®¹é•¿åº¦ä¸ºï¼š{1} å­—èŠ‚"
+msgstr "{0} åœ¨æœåŠ¡å™¨ä¸Šçš„æ€»å†…å®¹é•¿åº¦ä¸ºï¼š{1} å­—èŠ‚"
+
+msgid "{0} å·²å­˜åœ¨ï¼Œå°†è¦†ç›–"
+msgstr "{0} å·²å­˜åœ¨ï¼Œå°†è¦†ç›–"
+
 msgid "{0} åº”ç”¨é…ç½®æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼Œä¿å­˜è‡³ {1}"
 msgstr "{0} åº”ç”¨é…ç½®æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼Œä¿å­˜è‡³ {1}"
 
 msgid "{0} åº”ç”¨é…ç½®æœªæ‰¾åˆ°"
 msgstr "{0} åº”ç”¨é…ç½®æœªæ‰¾åˆ°"
 
-msgid "{0} è¯¥ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½"
-msgstr "{0} è¯¥ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½"
+msgid "{0} æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
+msgstr "{0} æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
 
 msgid "{0} è¯¥ä½œå“æ²¡æœ‰åŠ¨æ€å°é¢"
 msgstr "{0} è¯¥ä½œå“æ²¡æœ‰åŠ¨æ€å°é¢"
 
 msgid "{0} è¯¥ä½œå“æ²¡æœ‰å°é¢"
 msgstr "{0} è¯¥ä½œå“æ²¡æœ‰å°é¢"
 
@@ -248,16 +252,19 @@
 
 msgid "{0} è¯¥å›¾é›†æ²¡æœ‰å›¾ç‰‡é“¾æ¥ï¼Œæ— æ³•ä¸‹è½½"
 msgstr "{0} è¯¥å›¾é›†æ²¡æœ‰å›¾ç‰‡é“¾æ¥ï¼Œæ— æ³•ä¸‹è½½"
 
 msgid "{0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“"
 msgstr "{0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“"
 
-msgid "{0}åœ¨æœåŠ¡å™¨ä¸Šçš„æ€»å†…å®¹é•¿åº¦ä¸ºï¼š{1} å­—èŠ‚"
-msgstr "{0}åœ¨æœåŠ¡å™¨ä¸Šçš„æ€»å†…å®¹é•¿åº¦ä¸ºï¼š{1} å­—èŠ‚"
+msgid "{0}: {1} (åŒ…å« {2} ä¸ªä½œå“ï¼Œæ”¶è—å¤¹ID {3})"
+msgstr "{0}: {1} (åŒ…å« {2} ä¸ªä½œå“ï¼Œæ”¶è—å¤¹ID {3})"
+
+msgid "{0}ï¼š{1} (åŒ…å« {2} ä¸ªä½œå“[ä»¥ç½‘é¡µå®é™…æ•°é‡ä¸ºå‡†]ï¼Œæ”¶è—å¤¹ID {3})"
+msgstr "{0}ï¼š{1} (åŒ…å« {2} ä¸ªä½œå“[ä»¥ç½‘é¡µå®é™…æ•°é‡ä¸ºå‡†]ï¼Œæ”¶è—å¤¹ID {3})"
 
 msgid "â³"
 msgstr "â³"
 
 msgid "âš "
 msgstr "âš "
 
@@ -269,302 +276,374 @@
 
 msgid ""
 "ä¸‹è½½æ—¥æœŸåŒºé—´å‘å¸ƒçš„ä½œå“ï¼Œæ ¼å¼ï¼š2022-01-01|2023-01-01ï¼Œ'all' ä¸ºä¸‹è½½æ‰€æœ‰ä½œå“"
 msgstr ""
 "ä¸‹è½½æ—¥æœŸåŒºé—´å‘å¸ƒçš„ä½œå“ï¼Œæ ¼å¼ï¼š2022-01-01|2023-01-01ï¼Œ'all' ä¸ºä¸‹è½½æ‰€æœ‰ä½œå“"
 
 msgid ""
-"ä¸‹è½½æ¨¡å¼ï¼šä¸»é¡µä½œå“(post), ç‚¹èµä½œå“(like), æ”¶è—ä½œå“(collect), åˆè¾‘(mix), ç›´æ’­"
-"(live), æ¨èä½œå“(feed), æœç´¢ä½œå“(search)"
-msgstr ""
-"ä¸‹è½½æ¨¡å¼ï¼šä¸»é¡µä½œå“(post), ç‚¹èµä½œå“(like), æ”¶è—ä½œå“(collect), åˆè¾‘(mix), ç›´æ’­"
-"(live), æ¨èä½œå“(feed), æœç´¢ä½œå“(search)"
-
-msgid ""
 "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post), ç‚¹èµä½œå“(like), æ”¶è—ä½œå“(collect), "
 "åˆè¾‘æ’­æ”¾åˆ—è¡¨(mix)"
 msgstr ""
 "ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post), ç‚¹èµä½œå“(like), æ”¶è—ä½œå“(collect), "
 "åˆè¾‘æ’­æ”¾åˆ—è¡¨(mix)"
 
 msgid ""
-"ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“(collect)ï¼Œ"
-"åˆè¾‘(mix)ï¼Œç›´æ’­(live)"
+"ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“"
+"(collection)ï¼Œæ”¶è—å¤¹ä½œå“(collects)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
+msgstr ""
+"ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“"
+"(collection)ï¼Œæ”¶è—å¤¹ä½œå“(collects)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
+
+msgid ""
+"ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“"
+"(collection)ï¼Œæ”¶è—å¤¹ä½œå“(collects)ï¼Œæ”¶è—éŸ³ä¹(music)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
 msgstr ""
-"ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“(collect)ï¼Œ"
-"åˆè¾‘(mix)ï¼Œç›´æ’­(live)"
+"ä¸‹è½½æ¨¡å¼ï¼šå•ä¸ªä½œå“(one)ï¼Œä¸»é¡µä½œå“(post)ï¼Œç‚¹èµä½œå“(like)ï¼Œæ”¶è—ä½œå“"
+"(collection)ï¼Œæ”¶è—å¤¹ä½œå“(collects)ï¼Œæ”¶è—éŸ³ä¹(music)ï¼Œåˆè¾‘(mix)ï¼Œç›´æ’­(live)"
 
 msgid "ä¸å­˜åœ¨è¯¥æ¨¡å¼: {0}"
 msgstr "ä¸å­˜åœ¨è¯¥æ¨¡å¼: {0}"
 
-msgid "ä¸æ”¯æŒçš„æµè§ˆå™¨é€‰é¡¹, è¾“å…¥f2 dy --helpæŸ¥çœ‹æ›´å¤šå¸®åŠ©!"
-msgstr "ä¸æ”¯æŒçš„æµè§ˆå™¨é€‰é¡¹, è¾“å…¥f2 dy --helpæŸ¥çœ‹æ›´å¤šå¸®åŠ©!"
-
 msgid "ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶"
 msgstr "ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶"
 
 msgid "ä¸´æ—¶æ–‡ä»¶å·²å®Œå…¨ä¸‹è½½"
 msgstr "ä¸´æ—¶æ–‡ä»¶å·²å®Œå…¨ä¸‹è½½"
 
 msgid "ä¸»æ’­æ˜µç§°: {0} å¼€æ’­æ—¶é—´: {1} ç›´æ’­æµæ¸…æ™°åº¦: {2}"
 msgstr "ä¸»æ’­æ˜µç§°: {0} å¼€æ’­æ—¶é—´: {1} ç›´æ’­æµæ¸…æ™°åº¦: {2}"
 
 msgid "ä¸»é…ç½®å‚æ•°ï¼š{0}"
 msgstr "ä¸»é…ç½®å‚æ•°ï¼š{0}"
 
-msgid "ä¸»é…ç½®è·¯å¾„ï¼š {0}"
-msgstr "ä¸»é…ç½®è·¯å¾„ï¼š {0}"
+msgid "ä¸»é…ç½®è·¯å¾„ï¼š{0}"
+msgstr "ä¸»é…ç½®è·¯å¾„ï¼š{0}"
+
+msgid "ä¸»é¡µä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "ä¸»é¡µä½œå“æ¥å£åœ°å€ï¼š{0}"
+
+msgid "ä¸»é¡µå–œæ¬¢ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "ä¸»é¡µå–œæ¬¢ä½œå“æ¥å£åœ°å€ï¼š{0}"
+
+msgid "ä¸»é¡µæ”¶è—ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "ä¸»é¡µæ”¶è—ä½œå“æ¥å£åœ°å€ï¼š{0}"
 
-msgid "ä¸»é¡µä½œå“æ¥å£åœ°å€:"
-msgstr "ä¸»é¡µä½œå“æ¥å£åœ°å€:"
+msgid "ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20"
+msgstr "ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20"
 
 msgid "ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20ã€‚"
 msgstr "ä»æ¥å£æ¯é¡µå¯è·å–ä½œå“æ•°ï¼Œä¸å»ºè®®è¶…è¿‡20ã€‚"
 
 msgid ""
 "ä»£ç†æœåŠ¡å™¨ï¼Œæœ€å¤š 2 ä¸ªå‚æ•°ï¼Œhttpä¸httpsã€‚ç©ºæ ¼åŒºåˆ† 2 ä¸ªå‚æ•° http://x.x.x.x "
 "https://x.x.x.x"
 msgstr ""
 "ä»£ç†æœåŠ¡å™¨ï¼Œæœ€å¤š 2 ä¸ªå‚æ•°ï¼Œhttpä¸httpsã€‚ç©ºæ ¼åŒºåˆ† 2 ä¸ªå‚æ•° http://x.x.x.x "
 "https://x.x.x.x"
 
+msgid "ä½œå“ID: {0} ä½œå“æ–‡æ¡ˆ: {1} ä½œè€…: {2}"
+msgstr "ä½œå“ID: {0} ä½œå“æ–‡æ¡ˆ: {1} ä½œè€…: {2}"
+
+msgid "ä½œå“IDï¼š{0} ä½œå“æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}"
+msgstr "ä½œå“IDï¼š{0} ä½œå“æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}"
+
+msgid "ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„"
+msgstr "ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„"
+
 msgid "ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„ã€‚"
 msgstr "ä½œå“ä¿å­˜ä½ç½®ï¼Œæ”¯æŒç»å¯¹ä¸ç›¸å¯¹è·¯å¾„ã€‚"
 
-msgid "ä½œå“ä¿å­˜ä½ç½®ï¼Œé»˜è®¤ä¸º 'Download'"
-msgstr "ä½œå“ä¿å­˜ä½ç½®ï¼Œé»˜è®¤ä¸º 'Download'"
-
 msgid "ä½œå“å‘å¸ƒæ—¶é—´ä¸åœ¨æŒ‡å®šåŒºé—´å†…ï¼š{0}"
 msgstr "ä½œå“å‘å¸ƒæ—¶é—´ä¸åœ¨æŒ‡å®šåŒºé—´å†…ï¼š{0}"
 
 msgid "ä½œå“å‘å¸ƒæ—¶é—´åœ¨æŒ‡å®šåŒºé—´å†…ï¼šä½œå“id {0} å‘å¸ƒæ—¶é—´ {1}"
 msgstr "ä½œå“å‘å¸ƒæ—¶é—´åœ¨æŒ‡å®šåŒºé—´å†…ï¼šä½œå“id {0} å‘å¸ƒæ—¶é—´ {1}"
 
-msgid "ä½œå“è¯„è®ºæ¥å£åœ°å€:"
-msgstr "ä½œå“è¯„è®ºæ¥å£åœ°å€:"
+msgid "ä½œå“åˆé›†IDï¼š{0} ä½œå“åˆé›†æ ‡é¢˜ï¼š{1}"
+msgstr "ä½œå“åˆé›†IDï¼š{0} ä½œå“åˆé›†æ ‡é¢˜ï¼š{1}"
+
+msgid "ä½œå“è¯„è®ºæ¥å£åœ°å€ï¼š{0}"
+msgstr "ä½œå“è¯„è®ºæ¥å£åœ°å€ï¼š{0}"
 
-msgid "ä½œå“è¯¦æƒ…æ¥å£åœ°å€:"
-msgstr "ä½œå“è¯¦æƒ…æ¥å£åœ°å€:"
+msgid "ä½œå“è¯¦æƒ…æ¥å£åœ°å€ï¼š{0}"
+msgstr "ä½œå“è¯¦æƒ…æ¥å£åœ°å€ï¼š{0}"
 
 msgid "ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–[yellow]cookie[/yellow]ï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"
 msgstr "ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–[yellow]cookie[/yellow]ï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"
 
-msgid "ä½¿ç”¨å‘½ä»¤è¡Œé€‰é¡¹æ›´æ–°é…ç½®æ–‡ä»¶"
-msgstr "ä½¿ç”¨å‘½ä»¤è¡Œé€‰é¡¹æ›´æ–°é…ç½®æ–‡ä»¶"
+msgid "ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–cookieï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"
+msgstr "ä½¿ç”¨SSOæ‰«ç ç™»å½•è·å–cookieï¼Œä¿å­˜ä½é¢‘ä¸»é…ç½®æ–‡ä»¶"
 
 msgid "ä½¿ç”¨å‘½ä»¤è¡Œé€‰é¡¹æ›´æ–°é…ç½®æ–‡ä»¶ã€‚éœ€è¦å…ˆä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªé…ç½®æ–‡ä»¶è·¯å¾„"
 msgstr "ä½¿ç”¨å‘½ä»¤è¡Œé€‰é¡¹æ›´æ–°é…ç½®æ–‡ä»¶ã€‚éœ€è¦å…ˆä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªé…ç½®æ–‡ä»¶è·¯å¾„"
 
-msgid "ä¾‹ï¼š f2 dy -h æ¥è·å–douyinçš„å‘½ä»¤å¸®åŠ©"
-msgstr "ä¾‹ï¼š f2 dy -h æ¥è·å–douyinçš„å‘½ä»¤å¸®åŠ©"
+msgid "ä¾‹ï¼šf2 -d DEBUG dy æ—¥å¿—çº§åˆ«ä¸ºè°ƒè¯•è¿è¡Œ"
+msgstr "ä¾‹ï¼šf2 -d DEBUG dy æ—¥å¿—çº§åˆ«ä¸ºè°ƒè¯•è¿è¡Œ"
 
-msgid "å…¨å±€ä½œå“æ–‡ä»¶å‘½åæ–¹å¼"
-msgstr "å…¨å±€ä½œå“æ–‡ä»¶å‘½åæ–¹å¼"
+msgid "ä¾‹ï¼šf2 dy -h/--help è·å–douyinçš„å‘½ä»¤å¸®åŠ©"
+msgstr "ä¾‹ï¼šf2 dy -h/--help è·å–douyinçš„å‘½ä»¤å¸®åŠ©"
 
 msgid "å…¨å±€ä½œå“æ–‡ä»¶å‘½åæ–¹å¼ï¼Œå‰å¾€æ–‡æ¡£æŸ¥çœ‹æ›´å¤šå¸®åŠ©"
 msgstr "å…¨å±€ä½œå“æ–‡ä»¶å‘½åæ–¹å¼ï¼Œå‰å¾€æ–‡æ¡£æŸ¥çœ‹æ›´å¤šå¸®åŠ©"
 
-msgid "å…³æ³¨ä½œå“æ¥å£åœ°å€:"
-msgstr "å…³æ³¨ä½œå“æ¥å£åœ°å€:"
-
-msgid "å…³æ³¨ç”¨æˆ·ç›´æ’­æ¥å£åœ°å€:"
-msgstr "å…³æ³¨ç”¨æˆ·ç›´æ’­æ¥å£åœ°å€:"
-
-msgid "å†…å®¹é•¿åº¦ä¸º0ï¼Œè·³è¿‡ä¸‹è½½"
-msgstr "å†…å®¹é•¿åº¦ä¸º0ï¼Œè·³è¿‡ä¸‹è½½"
+msgid "å…³æ³¨ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "å…³æ³¨ä½œå“æ¥å£åœ°å€ï¼š{0}"
 
-msgid "åˆå§‹åŒ–é…ç½®æ–‡ä»¶"
-msgstr "åˆå§‹åŒ–é…ç½®æ–‡ä»¶"
+msgid "å…³æ³¨ç”¨æˆ·ç›´æ’­æ¥å£åœ°å€ï¼š{0}"
+msgstr "å…³æ³¨ç”¨æˆ·ç›´æ’­æ¥å£åœ°å€ï¼š{0}"
 
 msgid "åˆå§‹åŒ–é…ç½®æ–‡ä»¶ã€‚ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶"
 msgstr "åˆå§‹åŒ–é…ç½®æ–‡ä»¶ã€‚ä¸èƒ½åŒæ—¶åˆå§‹åŒ–å’Œæ›´æ–°é…ç½®æ–‡ä»¶"
 
-msgid "å•ä¸ªè§†é¢‘æ•°æ®: {0}"
-msgstr "å•ä¸ªè§†é¢‘æ•°æ®: {0}"
+msgid "å•ä¸ªä½œå“æ•°æ®ï¼š{0}"
+msgstr "å•ä¸ªä½œå“æ•°æ®ï¼š{0}"
 
 msgid "åŸå£°"
 msgstr "åŸå£°"
 
+msgid "å‚æ•°"
+msgstr "å‚æ•°"
+
 msgid "å‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹"
 msgstr "å‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹"
 
 msgid "å‚æ•°å¿…é¡»æ˜¯å­—å…¸ç±»å‹"
 msgstr "å‚æ•°å¿…é¡»æ˜¯å­—å…¸ç±»å‹"
 
 msgid "å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"
 msgstr "å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"
 
+msgid "å‚æ•°éªŒè¯å¤±è´¥ï¼Œè¯·æ›´æ–° F2 é…ç½®æ–‡ä»¶ä¸­çš„ {0}ï¼Œä»¥åŒ¹é… {1} æ–°è§„åˆ™"
+msgstr "å‚æ•°éªŒè¯å¤±è´¥ï¼Œè¯·æ›´æ–° F2 é…ç½®æ–‡ä»¶ä¸­çš„ {0}ï¼Œä»¥åŒ¹é… {1} æ–°è§„åˆ™"
+
+msgid "å¦ä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶æˆ–å—å¼‚æ­¥è°ƒåº¦å½±å“ï¼Œè¯¥ä»»åŠ¡éœ€è¦é‡æ–°ä¸‹è½½"
+msgstr "å¦ä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶æˆ–å—å¼‚æ­¥è°ƒåº¦å½±å“ï¼Œè¯¥ä»»åŠ¡éœ€è¦é‡æ–°ä¸‹è½½"
+
 msgid "åˆè¾‘: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
 msgstr "åˆè¾‘: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
 
-msgid "åˆè¾‘ä½œå“æ¥å£åœ°å€:"
-msgstr "åˆè¾‘ä½œå“æ¥å£åœ°å€:"
+msgid "åˆè¾‘ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "åˆè¾‘ä½œå“æ¥å£åœ°å€ï¼š{0}"
 
-msgid "åˆè¾‘åˆ—è¡¨æ¥å£åœ°å€:"
-msgstr "åˆè¾‘åˆ—è¡¨æ¥å£åœ°å€:"
+msgid "åˆè¾‘åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}"
+msgstr "åˆè¾‘åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}"
 
 msgid "åˆé›†: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
 msgstr "åˆé›†: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
 
-msgid "åˆé›†ä½œå“æ¥å£åœ°å€:"
-msgstr "åˆé›†ä½œå“æ¥å£åœ°å€:"
+msgid "åˆé›†ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "åˆé›†ä½œå“æ¥å£åœ°å€ï¼š{0}"
 
 msgid "å“åº”çŠ¶æ€ç : {0}"
 msgstr "å“åº”çŠ¶æ€ç : {0}"
 
-msgid "å–œæ¬¢ä½œå“æ¥å£åœ°å€:"
-msgstr "å–œæ¬¢ä½œå“æ¥å£åœ°å€:"
+msgid "å–œæ¬¢ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "å–œæ¬¢ä½œå“æ¥å£åœ°å€ï¼š{0}"
 
 msgid "å›¾é›†"
 msgstr "å›¾é›†"
 
 msgid "åœ¨ {0} åº”ç”¨é‡Œæ²¡æœ‰æ‰¾åˆ°å¸®åŠ©æ–‡ä»¶"
 msgstr "åœ¨ {0} åº”ç”¨é‡Œæ²¡æœ‰æ‰¾åˆ°å¸®åŠ©æ–‡ä»¶"
 
+msgid "å¤„ç†HTTPé”™è¯¯æ—¶é‡åˆ°æ„å¤–æƒ…å†µï¼š{0}"
+msgstr "å¤„ç†HTTPé”™è¯¯æ—¶é‡åˆ°æ„å¤–æƒ…å†µï¼š{0}"
+
 msgid "å­åˆ†åŒº: {0} ä¸»æ’­æ˜µç§°: {1}"
 msgstr "å­åˆ†åŒº: {0} ä¸»æ’­æ˜µç§°: {1}"
 
-msgid "å®šä½ä¸Šä¸€æ¬¡ä½œå“æ¥å£åœ°å€:"
-msgstr "å®šä½ä¸Šä¸€æ¬¡ä½œå“æ¥å£åœ°å€:"
+msgid "å®šä½ä¸Šä¸€æ¬¡ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "å®šä½ä¸Šä¸€æ¬¡ä½œå“æ¥å£åœ°å€ï¼š{0}"
 
 msgid "å°é¢"
 msgstr "å°é¢"
 
+msgid "å°è¯•åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ï¼š{0}"
+msgstr "å°è¯•åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ï¼š{0}"
+
 msgid "å·²å–æ¶ˆæ›´æ–°é…ç½®æ–‡ä»¶!"
 msgstr "å·²å–æ¶ˆæ›´æ–°é…ç½®æ–‡ä»¶!"
 
 msgid "å¼€å§‹æ‰§è¡Œä¸‹è½½ä»»åŠ¡ï¼Œæœ¬æ¬¡å…±æœ‰ {0} ä¸ªä»»åŠ¡"
 msgstr "å¼€å§‹æ‰§è¡Œä¸‹è½½ä»»åŠ¡ï¼Œæœ¬æ¬¡å…±æœ‰ {0} ä¸ªä»»åŠ¡"
 
-msgid "å¼€å§‹çˆ¬å–åˆé›†: {0} çš„è§†é¢‘"
-msgstr "å¼€å§‹çˆ¬å–åˆé›†: {0} çš„è§†é¢‘"
+msgid "å¼€å§‹çˆ¬å–ä½œå“ï¼š{0}"
+msgstr "å¼€å§‹çˆ¬å–ä½œå“ï¼š{0}"
+
+msgid "å¼€å§‹çˆ¬å–åˆé›†: {0} çš„ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–åˆé›†: {0} çš„ä½œå“"
 
 msgid "å¼€å§‹çˆ¬å–æˆ¿é—´å·: {0} çš„æ•°æ®"
 msgstr "å¼€å§‹çˆ¬å–æˆ¿é—´å·: {0} çš„æ•°æ®"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} feedçš„è§†é¢‘"
-msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} feedçš„è§†é¢‘"
+msgid "å¼€å§‹çˆ¬å–æ”¶è—å¤¹ï¼š{0} çš„ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–æ”¶è—å¤¹ï¼š{0} çš„ä½œå“"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} feedçš„ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} feedçš„ä½œå“"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} åˆé›†çš„ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} åˆé›†çš„ä½œå“"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—å¤¹"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—å¤¹"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„ä½œå“"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} å‘å¸ƒçš„è§†é¢‘"
-msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} å‘å¸ƒçš„è§†é¢‘"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„éŸ³ä¹ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„éŸ³ä¹ä½œå“"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} åˆé›†çš„è§†é¢‘"
-msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} åˆé›†çš„è§†é¢‘"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} å‘å¸ƒçš„ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} å‘å¸ƒçš„ä½œå“"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} å–œæ¬¢çš„è§†é¢‘"
-msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} å–œæ¬¢çš„è§†é¢‘"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} å–œæ¬¢çš„ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} å–œæ¬¢çš„ä½œå“"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} æ”¶è—çš„è§†é¢‘"
-msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} æ”¶è—çš„è§†é¢‘"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} æ”¶è—çš„ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} æ”¶è—çš„ä½œå“"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} ç‚¹èµçš„è§†é¢‘"
-msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} ç‚¹èµçš„è§†é¢‘"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} ç‚¹èµçš„ä½œå“"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} ç‚¹èµçš„ä½œå“"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} çš„è§†é¢‘åˆé›†åˆ—è¡¨"
-msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·: {0} çš„è§†é¢‘åˆé›†åˆ—è¡¨"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„ä½œå“åˆé›†åˆ—è¡¨"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„ä½œå“åˆé›†åˆ—è¡¨"
 
-msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„è§†é¢‘"
-msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·æ”¶è—çš„è§†é¢‘"
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„å…³æ³¨ç”¨æˆ·"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„å…³æ³¨ç”¨æˆ·"
+
+msgid "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„ç²‰ä¸"
+msgstr "å¼€å§‹çˆ¬å–ç”¨æˆ·ï¼š{0} çš„ç²‰ä¸"
 
 msgid "å¼€å§‹çˆ¬å–ç›´æ’­: {0} çš„æ•°æ®"
 msgstr "å¼€å§‹çˆ¬å–ç›´æ’­: {0} çš„æ•°æ®"
 
 msgid "å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ"
 msgstr "å¼€å§‹çˆ¬å–ç¬¬ {0} é¡µ"
 
-msgid "å¼€å§‹çˆ¬å–è§†é¢‘: {0}"
-msgstr "å¼€å§‹çˆ¬å–è§†é¢‘: {0}"
+msgid "å¼‚æ­¥çš„ä»»åŠ¡æ•°"
+msgstr "å¼‚æ­¥çš„ä»»åŠ¡æ•°"
 
 msgid "å¼‚æ­¥çš„ä»»åŠ¡æ•°ã€‚"
 msgstr "å¼‚æ­¥çš„ä»»åŠ¡æ•°ã€‚"
 
-msgid "å¼‚æ­¥çš„ä»»åŠ¡æ•°ï¼Œé»˜è®¤ä¸º 10"
-msgstr "å¼‚æ­¥çš„ä»»åŠ¡æ•°ï¼Œé»˜è®¤ä¸º 10"
+msgid "å½“å‰ {0} ç›´æ’­å·²ç»“æŸ"
+msgstr "å½“å‰ {0} ç›´æ’­å·²ç»“æŸ"
 
 msgid "å½“å‰è¯·æ±‚çš„cursor: {0}"
 msgstr "å½“å‰è¯·æ±‚çš„cursor: {0}"
 
+msgid "å½“å‰è¯·æ±‚çš„cursorï¼š{0}"
+msgstr "å½“å‰è¯·æ±‚çš„cursorï¼š{0}"
+
 msgid "å½“å‰è¯·æ±‚çš„max_cursor: {0}"
 msgstr "å½“å‰è¯·æ±‚çš„max_cursor: {0}"
 
+msgid "å½“å‰è¯·æ±‚çš„max_cursorï¼š{0}"
+msgstr "å½“å‰è¯·æ±‚çš„max_cursorï¼š{0}"
+
+msgid "å½“å‰è¯·æ±‚çš„max_cursorï¼š{0}ï¼Œ max_countsï¼š{1}"
+msgstr "å½“å‰è¯·æ±‚çš„max_cursorï¼š{0}ï¼Œ max_countsï¼š{1}"
+
+msgid "å½“å‰è¯·æ±‚çš„offsetï¼š{0}"
+msgstr "å½“å‰è¯·æ±‚çš„offsetï¼š{0}"
+
+msgid "å½“å‰è¯·æ±‚çš„offsetï¼š{0} max_timeï¼š{1}"
+msgstr "å½“å‰è¯·æ±‚çš„offsetï¼š{0} max_timeï¼š{1}"
+
 msgid "æ‰¾åˆ°äº†æœªä¸‹è½½å®Œçš„æ–‡ä»¶ {0}, å¤§å°ä¸º {1} å­—èŠ‚"
 msgstr "æ‰¾åˆ°äº†æœªä¸‹è½½å®Œçš„æ–‡ä»¶ {0}, å¤§å°ä¸º {1} å­—èŠ‚"
 
 msgid "æŠ–éŸ³æ— æ°´å°è§£æ"
 msgstr "æŠ–éŸ³æ— æ°´å°è§£æ"
 
 msgid "æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}, è¯·æ£€æŸ¥é‡è¯•"
 msgstr "æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}, è¯·æ£€æŸ¥é‡è¯•"
 
+msgid "æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}ï¼Œè¯·æ£€æŸ¥é‡è¯•"
+msgstr "æ¥å£çŠ¶æ€ç å¼‚å¸¸ {0}ï¼Œè¯·æ£€æŸ¥é‡è¯•"
+
 msgid "æ¥å£çŠ¶æ€ç å¼‚å¸¸, è¯·æ£€æŸ¥é‡è¯•"
 msgstr "æ¥å£çŠ¶æ€ç å¼‚å¸¸, è¯·æ£€æŸ¥é‡è¯•"
 
-msgid "æ”¶è—ä½œå“æ¥å£åœ°å€:"
-msgstr "æ”¶è—ä½œå“æ¥å£åœ°å€:"
+msgid "æè¿°"
+msgstr "æè¿°"
 
-msgid "æ–‡ä»¶åŒºå—ä¸‹è½½å¤±è´¥: {0}"
-msgstr "æ–‡ä»¶åŒºå—ä¸‹è½½å¤±è´¥: {0}"
+msgid "æ”¶è—ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "æ”¶è—ä½œå“æ¥å£åœ°å€ï¼š{0}"
 
-msgid "æ–‡ä»¶åŒºå—ä¸‹è½½è¶…æ—¶: {0}"
-msgstr "æ–‡ä»¶åŒºå—ä¸‹è½½è¶…æ—¶: {0}"
+msgid "æ”¶è—å¤¹IDï¼š{0} æ”¶è—å¤¹æ ‡é¢˜ï¼š{1}"
+msgstr "æ”¶è—å¤¹IDï¼š{0} æ”¶è—å¤¹æ ‡é¢˜ï¼š{1}"
+
+msgid "æ”¶è—å¤¹ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "æ”¶è—å¤¹ä½œå“æ¥å£åœ°å€ï¼š{0}"
+
+msgid "æ”¶è—å¤¹æ¥å£åœ°å€ï¼š{0}"
+msgstr "æ”¶è—å¤¹æ¥å£åœ°å€ï¼š{0}"
+
+msgid "æ”¶è—å¤¹ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•ï¼Œå…±çˆ¬å– {1} ä¸ªä½œå“"
+msgstr "æ”¶è—å¤¹ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•ï¼Œå…±çˆ¬å– {1} ä¸ªä½œå“"
+
+msgid "æ–‡ä»¶åŒºå—ä¸‹è½½å¤±è´¥ï¼š{0}"
+msgstr "æ–‡ä»¶åŒºå—ä¸‹è½½å¤±è´¥ï¼š{0}"
+
+msgid "æ–‡ä»¶åŒºå—ä¸‹è½½è¶…æ—¶ï¼š{0}"
+msgstr "æ–‡ä»¶åŒºå—ä¸‹è½½è¶…æ—¶ï¼š{0}"
 
 msgid "æ–‡ä»¶åæ¨¡æ¿å­—æ®µ {0} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥"
 msgstr "æ–‡ä»¶åæ¨¡æ¿å­—æ®µ {0} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥"
 
 msgid "æ–‡æ¡ˆ"
 msgstr "æ–‡æ¡ˆ"
 
 msgid "æ— æ•ˆå“åº”ç±»å‹ã€‚å“åº”ç±»å‹: {0}"
 msgstr "æ— æ•ˆå“åº”ç±»å‹ã€‚å“åº”ç±»å‹: {0}"
 
 msgid "æ— æ³•ä» {0} æµè§ˆå™¨ä¸­è·å–cookie"
 msgstr "æ— æ³•ä» {0} æµè§ˆå™¨ä¸­è·å–cookie"
 
-msgid "æ— æ³•ä»{0}æµè§ˆå™¨ä¸­è·å–cookie"
-msgstr "æ— æ³•ä»{0}æµè§ˆå™¨ä¸­è·å–cookie"
-
-msgid "æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
-msgstr "æ— æ³•æ‰¾åˆ°APIç«¯ç‚¹"
-
 msgid "æ— æ³•è§£æä½œå“å‘å¸ƒæ—¶é—´ï¼š{0}"
 msgstr "æ— æ³•è§£æä½œå“å‘å¸ƒæ—¶é—´ï¼š{0}"
 
 msgid "æ— æ³•è¯»å–è¯¥TSæ–‡ä»¶å­—èŠ‚é•¿åº¦ï¼Œå°†ä½¿ç”¨é»˜è®¤400kbå—å¤§å°å¤„ç†æ•°æ®"
 msgstr "æ— æ³•è¯»å–è¯¥TSæ–‡ä»¶å­—èŠ‚é•¿åº¦ï¼Œå°†ä½¿ç”¨é»˜è®¤400kbå—å¤§å°å¤„ç†æ•°æ®"
 
 msgid "æ—¥æœŸåŒºé—´å‚æ•°æ ¼å¼é”™è¯¯ï¼Œè¯·æŸ¥é˜…æ–‡æ¡£åé‡è¯•"
 msgstr "æ—¥æœŸåŒºé—´å‚æ•°æ ¼å¼é”™è¯¯ï¼Œè¯·æŸ¥é˜…æ–‡æ¡£åé‡è¯•"
 
+msgid "æ˜¯å¦ä¿å­˜åŸå£°æ­Œè¯"
+msgstr "æ˜¯å¦ä¿å­˜åŸå£°æ­Œè¯"
+
+msgid "æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°"
+msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°"
+
 msgid "æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°ã€‚å¯é€‰ï¼š'yes'ã€'no'"
 msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°ã€‚å¯é€‰ï¼š'yes'ã€'no'"
 
-msgid "æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°ï¼Œé»˜è®¤ä¸º 'yes'"
-msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘åŸå£°ï¼Œé»˜è®¤ä¸º 'yes'"
+msgid "æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢"
+msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢"
 
 msgid "æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢ã€‚å¯é€‰ï¼š'yes'ã€'no'"
 msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢ã€‚å¯é€‰ï¼š'yes'ã€'no'"
 
-msgid "æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢ï¼Œé»˜è®¤ä¸º 'yes'"
-msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘å°é¢ï¼Œé»˜è®¤ä¸º 'yes'"
+msgid "æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆ"
+msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆ"
 
 msgid "æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆã€‚å¯é€‰ï¼š'yes'ã€'no'"
 msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆã€‚å¯é€‰ï¼š'yes'ã€'no'"
 
-msgid "æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆï¼Œé»˜è®¤ä¸º 'yes'"
-msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘æ–‡æ¡ˆï¼Œé»˜è®¤ä¸º 'yes'"
+msgid "æ˜¯å¦ä¿å­˜è§†é¢‘æ­Œè¯"
+msgstr "æ˜¯å¦ä¿å­˜è§†é¢‘æ­Œè¯"
+
+msgid "æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹"
+msgstr "æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹"
 
 msgid "æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ã€‚å¯é€‰ï¼š'yes'ã€'no'"
 msgstr "æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ã€‚å¯é€‰ï¼š'yes'ã€'no'"
 
-msgid "æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ï¼Œé»˜è®¤ä¸º 'yes'"
-msgstr "æ˜¯å¦å°†ä½œå“ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶å¤¹ï¼Œé»˜è®¤ä¸º 'yes'"
-
-msgid "æ˜¯å¦è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieï¼Œä»¥åŠä»å“ªä¸ªæµè§ˆå™¨è·å–"
-msgstr "æ˜¯å¦è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieï¼Œä»¥åŠä»å“ªä¸ªæµè§ˆå™¨è·å–"
-
 msgid "æ˜¯å¦è¦ä½¿ç”¨å‘½ä»¤è¡Œçš„å‚æ•°æ›´æ–°é…ç½®æ–‡ä»¶ï¼Ÿ"
 msgstr "æ˜¯å¦è¦ä½¿ç”¨å‘½ä»¤è¡Œçš„å‚æ•°æ›´æ–°é…ç½®æ–‡ä»¶ï¼Ÿ"
 
 msgid "æ˜¾ç¤ºå¯Œæ–‡æœ¬å¸®åŠ©"
 msgstr "æ˜¾ç¤ºå¯Œæ–‡æœ¬å¸®åŠ©"
 
 msgid "æ˜¾ç¤ºç»å…¸å¸®åŠ©ä¿¡æ¯"
@@ -572,263 +651,336 @@
 
 msgid "æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ã€‚å¯é€‰ï¼š'zh_CN'ã€'en_US'"
 msgstr "æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ã€‚å¯é€‰ï¼š'zh_CN'ã€'en_US'"
 
 msgid "æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ã€‚å¯é€‰ï¼š'zh_CN'ã€'en_US'ã€‚ä¸æ”¯æŒé…ç½®æ–‡ä»¶ä¿®æ”¹ã€‚"
 msgstr "æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ã€‚å¯é€‰ï¼š'zh_CN'ã€'en_US'ã€‚ä¸æ”¯æŒé…ç½®æ–‡ä»¶ä¿®æ”¹ã€‚"
 
+msgid "æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ï¼Œå¯é€‰ï¼š'zh_CN'ã€'en_US'ï¼Œä¸æ”¯æŒé…ç½®æ–‡ä»¶ä¿®æ”¹"
+msgstr "æ˜¾ç¤ºè¯­è¨€ã€‚é»˜è®¤ä¸º 'zh_CN'ï¼Œå¯é€‰ï¼š'zh_CN'ã€'en_US'ï¼Œä¸æ”¯æŒé…ç½®æ–‡ä»¶ä¿®æ”¹"
+
 msgid ""
 "æ›´åŠ è¯¦ç»†çš„å‚æ•°è¯´æ˜è¯·ç‚¹å‡»[link=https://johnserf-seed.github.io/f2/site-config."
 "html][dark_violet]å‰å¾€æ–‡æ¡£[/dark_violet][/]æŸ¥çœ‹"
 msgstr ""
 "æ›´åŠ è¯¦ç»†çš„å‚æ•°è¯´æ˜è¯·ç‚¹å‡»[link=https://johnserf-seed.github.io/f2/site-config."
 "html][dark_violet]å‰å¾€æ–‡æ¡£[/dark_violet][/]æŸ¥çœ‹"
 
-msgid "æœ€å¤§ä½œå“ä¸‹è½½æ•° é»˜è®¤ä¸º 0ï¼Œè¡¨ç¤ºæ— é™åˆ¶"
-msgstr "æœ€å¤§ä½œå“ä¸‹è½½æ•° é»˜è®¤ä¸º 0ï¼Œè¡¨ç¤ºæ— é™åˆ¶"
-
 msgid "æœ€å¤§ä½œå“ä¸‹è½½æ•°ã€‚0 è¡¨ç¤ºæ— é™åˆ¶"
 msgstr "æœ€å¤§ä½œå“ä¸‹è½½æ•°ã€‚0 è¡¨ç¤ºæ— é™åˆ¶"
 
 msgid "æœ€å¤§æ•°é‡: {0} æ¯æ¬¡è¯·æ±‚æ•°é‡: {1}"
 msgstr "æœ€å¤§æ•°é‡: {0} æ¯æ¬¡è¯·æ±‚æ•°é‡: {1}"
 
-msgid "æœ‹å‹ä½œå“æ¥å£åœ°å€:"
-msgstr "æœ‹å‹ä½œå“æ¥å£åœ°å€:"
+msgid "æœ€å¤§æ•°é‡ï¼š{0} æ¯æ¬¡è¯·æ±‚æ•°é‡ï¼š{1}"
+msgstr "æœ€å¤§æ•°é‡ï¼š{0} æ¯æ¬¡è¯·æ±‚æ•°é‡ï¼š{1}"
 
-msgid "æœªåœ¨å“åº”ä¸­æ‰¾åˆ°aweme_id"
-msgstr "æœªåœ¨å“åº”ä¸­æ‰¾åˆ°aweme_id"
+msgid "æœ‹å‹ä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "æœ‹å‹ä½œå“æ¥å£åœ°å€ï¼š{0}"
 
-msgid "æœªåœ¨å“åº”ä¸­æ‰¾åˆ°unique_id"
-msgstr "æœªåœ¨å“åº”ä¸­æ‰¾åˆ°unique_id"
+msgid "æœªåœ¨å“åº”ä¸­æ‰¾åˆ° {0}"
+msgstr "æœªåœ¨å“åº”ä¸­æ‰¾åˆ° {0}"
 
-msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°aweme_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºä½œå“é¡µ"
-msgstr "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°aweme_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºä½œå“é¡µ"
+msgid "æœªåœ¨å“åº”ä¸­æ‰¾åˆ° {0}ï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µã€‚ç±»å: {1}"
+msgstr "æœªåœ¨å“åº”ä¸­æ‰¾åˆ° {0}ï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µã€‚ç±»å: {1}"
 
-msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_uid, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»å: {0}"
-msgstr "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_uid, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»å: {0}"
+msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°aweme_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºä½œå“é¡µ"
+msgstr "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°aweme_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºä½œå“é¡µ"
 
-msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_user_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»å: {0}"
-msgstr "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_user_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»å: {0}"
+msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_user_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»åï¼š{0}"
+msgstr "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°sec_user_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç”¨æˆ·ä¸»é¡µç±»åï¼š{0}"
 
-msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°webcast_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç›´æ’­é¡µ"
-msgstr "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°webcast_id, æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç›´æ’­é¡µ"
+msgid "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°webcast_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç›´æ’­é¡µ"
+msgstr "æœªåœ¨å“åº”çš„åœ°å€ä¸­æ‰¾åˆ°webcast_idï¼Œæ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºç›´æ’­é¡µ"
 
-msgid "æœªæ‰¾åˆ°APIç«¯ç‚¹ã€‚ç±»å: {0}"
-msgstr "æœªæ‰¾åˆ°APIç«¯ç‚¹ã€‚ç±»å: {0}"
+msgid "æœªæ‰¾åˆ°APIç«¯ç‚¹ã€‚ç±»åï¼š{0}"
+msgstr "æœªæ‰¾åˆ°APIç«¯ç‚¹ã€‚ç±»åï¼š{0}"
 
 msgid "æœªæ‰¾åˆ°m3u8æ–‡ä»¶çš„segments, å°è¯•è·å–åµŒå¥—çš„m3u8æ–‡ä»¶"
 msgstr "æœªæ‰¾åˆ°m3u8æ–‡ä»¶çš„segments, å°è¯•è·å–åµŒå¥—çš„m3u8æ–‡ä»¶"
 
 msgid "æœªæ‰¾åˆ°åµŒå¥—m3u8æ–‡ä»¶çš„segments, å¯èƒ½ç›´æ’­ç»“æŸæˆ–è¯¥ä¸»æ’­æ— æ³•ä½¿ç”¨m3u8æ–¹æ³•è§£æ"
 msgstr "æœªæ‰¾åˆ°åµŒå¥—m3u8æ–‡ä»¶çš„segments, å¯èƒ½ç›´æ’­ç»“æŸæˆ–è¯¥ä¸»æ’­æ— æ³•ä½¿ç”¨m3u8æ–¹æ³•è§£æ"
 
-msgid "æœªæˆæƒçš„è¯·æ±‚ã€‚ç±»å: {0}"
-msgstr "æœªæˆæƒçš„è¯·æ±‚ã€‚ç±»å: {0}"
-
-msgid "æ ¹æ®ä½œå“å‘å¸ƒæ—¥æœŸåŒºé—´ä¸‹è½½ä½œå“ï¼Œé»˜è®¤ä¸º '0'"
-msgstr "æ ¹æ®ä½œå“å‘å¸ƒæ—¥æœŸåŒºé—´ä¸‹è½½ä½œå“ï¼Œé»˜è®¤ä¸º '0'"
+msgid "æœªæˆæƒçš„è¯·æ±‚ã€‚ç±»åï¼š{0}"
+msgstr "æœªæˆæƒçš„è¯·æ±‚ã€‚ç±»åï¼š{0}"
 
 msgid ""
 "æ ¹æ®æ¨¡å¼æä¾›ç›¸åº”çš„é“¾æ¥ã€‚ä¾‹å¦‚ï¼šä¸»é¡µã€ç‚¹èµã€æ”¶è—ä½œå“å¡«å…¥ä¸»é¡µé“¾æ¥ï¼Œå•ä½œå“å¡«å…¥ä½œ"
 "å“é“¾æ¥ï¼Œåˆè¾‘ä¸ç›´æ’­åŒä¸Š"
 msgstr ""
 "æ ¹æ®æ¨¡å¼æä¾›ç›¸åº”çš„é“¾æ¥ã€‚ä¾‹å¦‚ï¼šä¸»é¡µã€ç‚¹èµã€æ”¶è—ä½œå“å¡«å…¥ä¸»é¡µé“¾æ¥ï¼Œå•ä½œå“å¡«å…¥ä½œ"
 "å“é“¾æ¥ï¼Œåˆè¾‘ä¸ç›´æ’­åŒä¸Š"
 
 msgid "æ¬¢è¿æäº¤PRé€‚é…æ›´å¤šç½‘ç«™"
 msgstr "æ¬¢è¿æäº¤PRé€‚é…æ›´å¤šç½‘ç«™"
 
-msgid "æ¯é¡µä½œå“æ•°ï¼Œé»˜è®¤ä¸º 20ä¸ªä½œå“/é¡µ"
-msgstr "æ¯é¡µä½œå“æ•°ï¼Œé»˜è®¤ä¸º 20ä¸ªä½œå“/é¡µ"
+msgid "æ­Œè¯"
+msgstr "æ­Œè¯"
+
+msgid "æ­Œè¯æ•°æ®å­—æ®µé”™è¯¯ï¼š{0}"
+msgstr "æ­Œè¯æ•°æ®å­—æ®µé”™è¯¯ï¼š{0}"
+
+msgid "æ­Œè¯æ•°æ®ç±»å‹é”™è¯¯ï¼š{0}"
+msgstr "æ­Œè¯æ•°æ®ç±»å‹é”™è¯¯ï¼š{0}"
 
 msgid "æ²¡æœ‰æ‰¾åˆ° {0} åº”ç”¨"
 msgstr "æ²¡æœ‰æ‰¾åˆ° {0} åº”ç”¨"
 
 msgid "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä½œå“"
 msgstr "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä½œå“"
 
-msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å–{0}ä¸ªè§†é¢‘"
-msgstr "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å–{0}ä¸ªè§†é¢‘"
+msgid "çˆ¬å–äº† {0} ä¸ªå…³æ³¨ç”¨æˆ·"
+msgstr "çˆ¬å–äº† {0} ä¸ªå…³æ³¨ç”¨æˆ·"
+
+msgid "çˆ¬å–äº† {0} ä¸ªç²‰ä¸ç”¨æˆ·"
+msgstr "çˆ¬å–äº† {0} ä¸ªç²‰ä¸ç”¨æˆ·"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±æ‰¾åˆ° {0} ä¸ªæ”¶è—å¤¹"
+msgstr "çˆ¬å–ç»“æŸï¼Œå…±æ‰¾åˆ° {0} ä¸ªæ”¶è—å¤¹"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªä½œå“"
+msgstr "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªä½œå“"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªåˆé›†ä½œå“"
+msgstr "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªåˆé›†ä½œå“"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªæ”¶è—ä½œå“"
+msgstr "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªæ”¶è—ä½œå“"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªæ”¶è—å¤¹"
+msgstr "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªæ”¶è—å¤¹"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªç‚¹èµä½œå“"
+msgstr "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªç‚¹èµä½œå“"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªç”¨æˆ·"
+msgstr "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªç”¨æˆ·"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªéŸ³ä¹ä½œå“"
+msgstr "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªéŸ³ä¹ä½œå“"
+
+msgid "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªé¦–é¡µæ¨èä½œå“"
+msgstr "çˆ¬å–ç»“æŸï¼Œå…±çˆ¬å– {0} ä¸ªé¦–é¡µæ¨èä½œå“"
+
+msgid "çŠ¶æ€"
+msgstr "çŠ¶æ€"
 
 msgid "ç”ŸæˆX-Boguså¤±è´¥: {0})"
 msgstr "ç”ŸæˆX-Boguså¤±è´¥: {0})"
 
+msgid "ç”Ÿæˆæ­Œè¯æ–‡ä»¶å¤±è´¥ï¼š{0}ï¼Œè¯·æ£€æŸ¥æ­Œè¯ `data` å†…å®¹"
+msgstr "ç”Ÿæˆæ­Œè¯æ–‡ä»¶å¤±è´¥ï¼š{0}ï¼Œè¯·æ£€æŸ¥æ­Œè¯ `data` å†…å®¹"
+
 msgid "ç”Ÿæˆè™šå‡çš„msToken"
 msgstr "ç”Ÿæˆè™šå‡çš„msToken"
 
 msgid "ç”¨æˆ·: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
 msgstr "ç”¨æˆ·: {0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
 
-msgid "ç”¨æˆ·: {0} æ²¡æœ‰è§†é¢‘åˆé›†"
-msgstr "ç”¨æˆ·: {0} æ²¡æœ‰è§†é¢‘åˆé›†"
+msgid "ç”¨æˆ·IDï¼š{0} ç”¨æˆ·æ˜µç§°ï¼š{1} ç”¨æˆ·ä½œå“æ•°ï¼š{2}"
+msgstr "ç”¨æˆ·IDï¼š{0} ç”¨æˆ·æ˜µç§°ï¼š{1} ç”¨æˆ·ä½œå“æ•°ï¼š{2}"
 
-msgid "ç”¨æˆ·ä¿¡æ¯æ¥å£åœ°å€:"
-msgstr "ç”¨æˆ·ä¿¡æ¯æ¥å£åœ°å€:"
+msgid "ç”¨æˆ·IDï¼š{0} ç”¨æˆ·æ˜µç§°ï¼š{1} ç”¨æˆ·ä½œå“æ•°ï¼š{2} é¢å¤–å†…å®¹ï¼š{3}"
+msgstr "ç”¨æˆ·IDï¼š{0} ç”¨æˆ·æ˜µç§°ï¼š{1} ç”¨æˆ·ä½œå“æ•°ï¼š{2} é¢å¤–å†…å®¹ï¼š{3}"
 
-msgid "ç”¨æˆ·æ”¶è—çš„è§†é¢‘é‡‡é›†å®Œæ¯•"
-msgstr "ç”¨æˆ·æ”¶è—çš„è§†é¢‘é‡‡é›†å®Œæ¯•"
+msgid "ç”¨æˆ·ä¿¡æ¯æ¥å£åœ°å€ï¼š{0}"
+msgstr "ç”¨æˆ·ä¿¡æ¯æ¥å£åœ°å€ï¼š{0}"
 
-msgid "ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–msToken"
-msgstr "ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–msToken"
+msgid "ç”¨æˆ·å…³æ³¨åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}"
+msgstr "ç”¨æˆ·å…³æ³¨åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}"
 
-msgid "ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–ttwid"
-msgstr "ç”±äºæŸäº›é”™è¯¯, æ— æ³•è·å–ttwid"
+msgid "ç”¨æˆ·æ”¶è—çš„ä½œå“é‡‡é›†å®Œæ¯•"
+msgstr "ç”¨æˆ·æ”¶è—çš„ä½œå“é‡‡é›†å®Œæ¯•"
+
+msgid "ç”¨æˆ·æ”¶è—çš„éŸ³ä¹ä½œå“é‡‡é›†å®Œæ¯•"
+msgstr "ç”¨æˆ·æ”¶è—çš„éŸ³ä¹ä½œå“é‡‡é›†å®Œæ¯•"
+
+msgid "ç”¨æˆ·æ²¡æœ‰ä½œå“åˆè¾‘"
+msgstr "ç”¨æˆ·æ²¡æœ‰ä½œå“åˆè¾‘"
+
+msgid "ç”¨æˆ·ç²‰ä¸åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}"
+msgstr "ç”¨æˆ·ç²‰ä¸åˆ—è¡¨æ¥å£åœ°å€ï¼š{0}"
+
+msgid "ç”¨æˆ·ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
+msgstr "ç”¨æˆ·ï¼š{0} æ‰€æœ‰ä½œå“é‡‡é›†å®Œæ¯•"
+
+msgid "ç”¨æˆ·ï¼š{0} æ‰€æœ‰å…³æ³¨ç”¨æˆ·é‡‡é›†å®Œæ¯•"
+msgstr "ç”¨æˆ·ï¼š{0} æ‰€æœ‰å…³æ³¨ç”¨æˆ·é‡‡é›†å®Œæ¯•"
+
+msgid "ç”¨æˆ·ï¼š{0} æ‰€æœ‰ç²‰ä¸é‡‡é›†å®Œæ¯•"
+msgstr "ç”¨æˆ·ï¼š{0} æ‰€æœ‰ç²‰ä¸é‡‡é›†å®Œæ¯•"
+
+msgid "ç”¨æˆ·ï¼š{0} æ²¡æœ‰ä½œå“åˆé›†"
+msgstr "ç”¨æˆ·ï¼š{0} æ²¡æœ‰ä½œå“åˆé›†"
 
 msgid ""
 "ç™»å½•åçš„[yellow]cookie[/yellow]ï¼Œå¦‚æœä½¿ç”¨æœªç™»å½•çš„[yellow]cookie[/yellow]ï¼Œåˆ™"
 "æ— æ³•æŒä¹…ç¨³å®šä¸‹è½½ä½œå“"
 msgstr ""
 "ç™»å½•åçš„[yellow]cookie[/yellow]ï¼Œå¦‚æœä½¿ç”¨æœªç™»å½•çš„[yellow]cookie[/yellow]ï¼Œåˆ™"
 "æ— æ³•æŒä¹…ç¨³å®šä¸‹è½½ä½œå“"
 
-msgid "ç™»å½•åçš„cookie"
-msgstr "ç™»å½•åçš„cookie"
-
 msgid "ç™»å½•åçš„cookieï¼Œå¦‚æœä½¿ç”¨æœªç™»å½•çš„cookieï¼Œåˆ™æ— æ³•æŒä¹…ç¨³å®šä¸‹è½½ä½œå“"
 msgstr "ç™»å½•åçš„cookieï¼Œå¦‚æœä½¿ç”¨æœªç™»å½•çš„cookieï¼Œåˆ™æ— æ³•æŒä¹…ç¨³å®šä¸‹è½½ä½œå“"
 
 msgid "ç›´æ’­"
 msgstr "ç›´æ’­"
 
 msgid "ç›´æ’­ID: {0} ç›´æ’­æ ‡é¢˜: {1} ç›´æ’­çŠ¶æ€: {2} è§‚çœ‹äººæ•°: {3}"
 msgstr "ç›´æ’­ID: {0} ç›´æ’­æ ‡é¢˜: {1} ç›´æ’­çŠ¶æ€: {2} è§‚çœ‹äººæ•°: {3}"
 
 msgid "ç›´æ’­ä¿¡æ¯çˆ¬å–ç»“æŸ"
 msgstr "ç›´æ’­ä¿¡æ¯çˆ¬å–ç»“æŸ"
 
-msgid "ç›´æ’­å·²ç»“æŸ"
-msgstr "ç›´æ’­å·²ç»“æŸ"
-
-msgid "ç›´æ’­æ¥å£åœ°å€:"
-msgstr "ç›´æ’­æ¥å£åœ°å€:"
+msgid "ç›´æ’­æ¥å£åœ°å€ï¼ˆroom_idï¼‰ï¼š{0}"
+msgstr "ç›´æ’­æ¥å£åœ°å€ï¼ˆroom_idï¼‰ï¼š{0}"
 
-msgid "ç›´æ’­æ¥å£åœ°å€ï¼ˆroom_idï¼‰:"
-msgstr "ç›´æ’­æ¥å£åœ°å€ï¼ˆroom_idï¼‰:"
+msgid "ç›´æ’­æ¥å£åœ°å€ï¼š{0}"
+msgstr "ç›´æ’­æ¥å£åœ°å€ï¼š{0}"
 
-msgid "ç›¸å…³æ¨èä½œå“æ¥å£åœ°å€:"
-msgstr "ç›¸å…³æ¨èä½œå“æ¥å£åœ°å€:"
+msgid "ç›¸å…³æ¨èä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "ç›¸å…³æ¨èä½œå“æ¥å£åœ°å€ï¼š{0}"
 
 msgid "ç¬¬ {0} æ¬¡å“åº”å†…å®¹ä¸ºç©º, çŠ¶æ€ç : {1}, URL:{2}"
 msgstr "ç¬¬ {0} æ¬¡å“åº”å†…å®¹ä¸ºç©º, çŠ¶æ€ç : {1}, URL:{2}"
 
+msgid "ç¬¬ {0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“"
+msgstr "ç¬¬ {0} é¡µæ²¡æœ‰æ‰¾åˆ°ä½œå“"
+
+msgid "ç­‰å¾… {0} ç§’åç»§ç»­"
+msgstr "ç­‰å¾… {0} ç§’åç»§ç»­"
+
 msgid "ç­›é€‰æ—¥æœŸåŒºé—´ï¼š{0} è‡³ {1}"
 msgstr "ç­›é€‰æ—¥æœŸåŒºé—´ï¼š{0} è‡³ {1}"
 
+msgid "ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°"
+msgstr "ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°"
+
 msgid "ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°ã€‚"
 msgstr "ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°ã€‚"
 
-msgid "ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°ï¼Œé»˜è®¤ä¸º 5"
-msgstr "ç½‘ç»œè¯·æ±‚å¹¶å‘è¿æ¥æ•°ï¼Œé»˜è®¤ä¸º 5"
+msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´"
+msgstr "ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´"
 
 msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ã€‚"
 msgstr "ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ã€‚"
 
-msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤ä¸º 10"
-msgstr "ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤ä¸º 10"
+msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°"
+msgstr "ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°"
 
 msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°ã€‚"
 msgstr "ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°ã€‚"
 
-msgid "ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°ï¼Œé»˜è®¤ä¸º 5"
-msgstr "ç½‘ç»œè¯·æ±‚è¶…æ—¶é‡è¯•æ•°ï¼Œé»˜è®¤ä¸º 5"
-
 msgid ""
-"è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€"
-"operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
+"è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
 msgstr ""
-"è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€"
-"operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
+"è‡ªåŠ¨ä»æµè§ˆå™¨è·å–[yellow]cookie[/yellow]ï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
 
-msgid ""
-"è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·"
-"ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
-msgstr ""
-"è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieã€‚å¯é€‰é¡¹ï¼šchromeã€firefoxã€edgeã€operaã€‚ä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·"
-"ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
+msgid "è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
+msgstr "è‡ªåŠ¨ä»æµè§ˆå™¨è·å–cookieï¼Œä½¿ç”¨è¯¥å‘½ä»¤å‰è¯·ç¡®ä¿å…³é—­æ‰€é€‰çš„æµè§ˆå™¨"
 
-msgid "è‡ªåŠ¨è·å–Cookieå¤±è´¥: {0}"
-msgstr "è‡ªåŠ¨è·å–Cookieå¤±è´¥: {0}"
+msgid "è‡ªåŠ¨è·å–Cookieå¤±è´¥ï¼š{0}"
+msgstr "è‡ªåŠ¨è·å–Cookieå¤±è´¥ï¼š{0}"
 
 msgid "è‡ªå®šä¹‰é…ç½®å‚æ•°ï¼š{0}"
 msgstr "è‡ªå®šä¹‰é…ç½®å‚æ•°ï¼š{0}"
 
-msgid "è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š {0}"
-msgstr "è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š {0}"
+msgid "è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š{0}"
+msgstr "è‡ªå®šä¹‰é…ç½®è·¯å¾„ï¼š{0}"
 
 msgid "è‡³å°‘æä¾› secUid æˆ– uniqueId ä¸­çš„ä¸€ä¸ªå‚æ•°"
 msgstr "è‡³å°‘æä¾› secUid æˆ– uniqueId ä¸­çš„ä¸€ä¸ªå‚æ•°"
 
-msgid "è·å–aweme_idå¤±è´¥, {0}"
-msgstr "è·å–aweme_idå¤±è´¥, {0}"
-
-msgid "è·å–sec_uidå¤±è´¥, {0}"
-msgstr "è·å–sec_uidå¤±è´¥, {0}"
+msgid "è‡³å°‘æä¾› user_id æˆ– sec_user_id ä¸­çš„ä¸€ä¸ªå‚æ•°"
+msgstr "è‡³å°‘æä¾› user_id æˆ– sec_user_id ä¸­çš„ä¸€ä¸ªå‚æ•°"
 
-msgid "è·å–unique_idå¤±è´¥, {0}"
-msgstr "è·å–unique_idå¤±è´¥, {0}"
+msgid "è·å– {0} å¤±è´¥ï¼Œ{1}"
+msgstr "è·å– {0} å¤±è´¥ï¼Œ{1}"
 
 msgid "è·å–æ•°æ®å¤±è´¥ã€‚çŠ¶æ€ç : {0}"
 msgstr "è·å–æ•°æ®å¤±è´¥ã€‚çŠ¶æ€ç : {0}"
 
 msgid "è·å–ç«¯ç‚¹æ•°æ®å¤±è´¥, æ¬¡æ•°è¾¾åˆ°ä¸Šé™"
 msgstr "è·å–ç«¯ç‚¹æ•°æ®å¤±è´¥, æ¬¡æ•°è¾¾åˆ°ä¸Šé™"
 
 msgid "è¦æ›´æ–°é…ç½®, é¦–å…ˆéœ€è¦ä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªè‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„"
 msgstr "è¦æ›´æ–°é…ç½®, é¦–å…ˆéœ€è¦ä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªè‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„"
 
+msgid "è¦æ›´æ–°é…ç½®ï¼Œé¦–å…ˆéœ€è¦ä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªè‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„"
+msgstr "è¦æ›´æ–°é…ç½®ï¼Œé¦–å…ˆéœ€è¦ä½¿ç”¨'-c'é€‰é¡¹æä¾›ä¸€ä¸ªè‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„"
+
 msgid "è§†é¢‘"
 msgstr "è§†é¢‘"
 
-msgid "è§†é¢‘ID: {0} è§†é¢‘æ–‡æ¡ˆ: {1} ä½œè€…: {2}"
-msgstr "è§†é¢‘ID: {0} è§†é¢‘æ–‡æ¡ˆ: {1} ä½œè€…: {2}"
-
-msgid "è§†é¢‘åˆé›†ID: {0} è§†é¢‘åˆé›†æ ‡é¢˜: {1}"
-msgstr "è§†é¢‘åˆé›†ID: {0} è§†é¢‘åˆé›†æ ‡é¢˜: {1}"
+msgid "è§†é¢‘IDï¼š{0} è§†é¢‘æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}"
+msgstr "è§†é¢‘IDï¼š{0} è§†é¢‘æ–‡æ¡ˆï¼š{1} ä½œè€…ï¼š{2}"
 
 msgid "è§£æ {0} æ¥å£ JSON å¤±è´¥ï¼š {1}"
 msgstr "è§£æ {0} æ¥å£ JSON å¤±è´¥ï¼š {1}"
 
+msgid "è¯¥ {0} ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½"
+msgstr "è¯¥ {0} ä½œå“å·²è¢«å±è”½ï¼Œæ— æ³•ä¸‹è½½"
+
 msgid "è¯¥é“¾æ¥è¿”å›çš„æ˜¯room_idï¼Œè¯·ä½¿ç”¨`fetch_user_live_videos_by_room_id`æ¥å£"
 msgstr "è¯¥é“¾æ¥è¿”å›çš„æ˜¯room_idï¼Œè¯·ä½¿ç”¨`fetch_user_live_videos_by_room_id`æ¥å£"
 
-msgid "è¯­è¨€è®¾ç½®ï¼Œé»˜è®¤ä¸º 'zh_CN'"
-msgstr "è¯­è¨€è®¾ç½®ï¼Œé»˜è®¤ä¸º 'zh_CN'"
+msgid "è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•ï¼Œå¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ï¼"
+msgstr "è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•ï¼Œå¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ï¼"
 
-msgid "è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•, å¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ !"
-msgstr "è¯·å…³é—­æ‰€æœ‰å·²æ‰“å¼€çš„æµè§ˆå™¨é‡è¯•, å¹¶ä¸”ä½ æœ‰é€‚å½“çš„æƒé™è®¿é—®æµè§ˆå™¨ !"
+msgid ""
+"è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸"
+"è¯¦ç»†ä¿¡æ¯ï¼š{3}"
+msgstr ""
+"è¯·æ±‚ç«¯ç‚¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥å½“å‰ç½‘ç»œç¯å¢ƒã€‚ é“¾æ¥ï¼š{0}ï¼Œä»£ç†ï¼š{1}ï¼Œå¼‚å¸¸ç±»åï¼š{2}ï¼Œå¼‚å¸¸"
+"è¯¦ç»†ä¿¡æ¯ï¼š{3}"
 
 msgid "è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}"
 msgstr "è¾“å…¥çš„URL Listä¸åˆæ³•ã€‚ç±»åï¼š{0}"
 
 msgid "è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}"
 msgstr "è¾“å…¥çš„URLä¸åˆæ³•ã€‚ç±»åï¼š{0}"
 
-msgid "è¿æ¥åˆ°APIæ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥URLæˆ–ç½‘ç»œæƒ…å†µã€‚ç±»å: {0}"
-msgstr "è¿æ¥åˆ°APIæ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥URLæˆ–ç½‘ç»œæƒ…å†µã€‚ç±»å: {0}"
-
 msgid "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
 msgstr "è¿æ¥ç«¯ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–ä»£ç†ï¼š{0} ä»£ç†ï¼š{1} ç±»åï¼š{2}"
 
 msgid "è¿æ¥è¶…æ—¶é”™è¯¯: {0}"
 msgstr "è¿æ¥è¶…æ—¶é”™è¯¯: {0}"
 
+msgid "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"
+msgstr "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"
+
 msgid "é…ç½®æ–‡ä»¶å·²æ›´æ–°!"
 msgstr "é…ç½®æ–‡ä»¶å·²æ›´æ–°!"
 
 msgid "é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œ[red]æœ€ä½ä¼˜å…ˆ[/red]"
 msgstr "é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œ[red]æœ€ä½ä¼˜å…ˆ[/red]"
 
 msgid "é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œæœ€ä½ä¼˜å…ˆ"
 msgstr "é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œæœ€ä½ä¼˜å…ˆ"
 
-msgid "é™¤äº†å•ä¸ªä½œå“å¤–ï¼Œå…¶ä»–URLéƒ½éœ€è¦ç”¨æˆ·ä¸»é¡µURL"
-msgstr "é™¤äº†å•ä¸ªä½œå“å¤–ï¼Œå…¶ä»–URLéƒ½éœ€è¦ç”¨æˆ·ä¸»é¡µURL"
+msgid "é…ç½®æ–‡ä»¶è·¯å¾„æ— å†™æƒé™"
+msgstr "é…ç½®æ–‡ä»¶è·¯å¾„æ— å†™æƒé™"
+
+msgid "é“¾æ¥ {0} å†…å®¹é•¿åº¦ä¸º0ï¼Œå°è¯•ä¸‹ä¸€ä¸ªé“¾æ¥æ˜¯å¦å¯ç”¨"
+msgstr "é“¾æ¥ {0} å†…å®¹é•¿åº¦ä¸º0ï¼Œå°è¯•ä¸‹ä¸€ä¸ªé“¾æ¥æ˜¯å¦å¯ç”¨"
+
+msgid "é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} "
+msgstr "é“¾æ¥ï¼š{0}ï¼ŒçŠ¶æ€ç  {1}ï¼š{2} "
+
+msgid "éŸ³ä¹"
+msgstr "éŸ³ä¹"
+
+msgid "éŸ³ä¹IDï¼š{0} éŸ³ä¹æ ‡é¢˜ï¼š{1} ä½œè€…ï¼š{2}"
+msgstr "éŸ³ä¹IDï¼š{0} éŸ³ä¹æ ‡é¢˜ï¼š{1} ä½œè€…ï¼š{2}"
+
+msgid "éŸ³ä¹æ”¶è—æ¥å£åœ°å€ï¼š{0}"
+msgstr "éŸ³ä¹æ”¶è—æ¥å£åœ°å€ï¼š{0}"
 
 msgid "é¡µé¢ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯ç”±äºåŒºåŸŸé™åˆ¶ï¼ˆä»£ç†ï¼‰é€ æˆçš„ã€‚ç±»å: {0}"
 msgstr "é¡µé¢ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯ç”±äºåŒºåŸŸé™åˆ¶ï¼ˆä»£ç†ï¼‰é€ æˆçš„ã€‚ç±»å: {0}"
 
-msgid "é¦–é¡µæ¨èä½œå“æ¥å£åœ°å€:"
-msgstr "é¦–é¡µæ¨èä½œå“æ¥å£åœ°å€:"
+msgid "é¦–é¡µæ¨èä½œå“æ¥å£åœ°å€ï¼š{0}"
+msgstr "é¦–é¡µæ¨èä½œå“æ¥å£åœ°å€ï¼š{0}"
 
-msgid "é¦–é¡µæ¨èæ¥å£åœ°å€:"
-msgstr "é¦–é¡µæ¨èæ¥å£åœ°å€:"
+msgid "é¦–é¡µæ¨èæ¥å£åœ°å€ï¼š{0}"
+msgstr "é¦–é¡µæ¨èæ¥å£åœ°å€ï¼š{0}"
```

### Comparing `f2-0.0.1.4/f2/log/logger.py` & `f2-0.0.1.5/f2/log/logger.py`

 * *Files 2% similar despite different names*

```diff
@@ -64,15 +64,17 @@
             files_to_delete = all_logs
         else:
             files_to_delete = all_logs[:-keep_last_n]
         for log_file in files_to_delete:
             try:
                 log_file.unlink()
             except PermissionError:
-                self.logger.warning(f"æ— æ³•åˆ é™¤æ—¥å¿—æ–‡ä»¶ {log_file}, å®ƒæ­£è¢«å¦ä¸€ä¸ªè¿›ç¨‹ä½¿ç”¨")
+                self.logger.warning(
+                    f"æ— æ³•åˆ é™¤æ—¥å¿—æ–‡ä»¶ {log_file}, å®ƒæ­£è¢«å¦ä¸€ä¸ªè¿›ç¨‹ä½¿ç”¨"
+                )
 
     def shutdown(self):
         for handler in self.logger.handlers:
             handler.close()
             self.logger.removeHandler(handler)
         self.logger.handlers.clear()
         time.sleep(1)  # ç¡®ä¿æ–‡ä»¶è¢«é‡Šæ”¾
```

### Comparing `f2-0.0.1.4/f2/utils/_dl.py` & `f2-0.0.1.5/f2/utils/_dl.py`

 * *Files 5% similar despite different names*

```diff
@@ -21,21 +21,31 @@
         int: Content-Lengthçš„å€¼ï¼Œå¦‚æœè·å–å¤±è´¥åˆ™è¿”å›0 (Value of Content-Length, or 0 if retrieval fails)
     """
     async with httpx.AsyncClient(
         timeout=10.0, transport=httpx.AsyncHTTPTransport(retries=5), proxies=proxies
     ) as client:
         try:
             response = await client.head(url, headers=headers, follow_redirects=True)
+            # å½“headè¯·æ±‚è¢«ç¦æ­¢æ—¶ï¼Œé‡Šæ”¾statuså¼‚å¸¸è¢«æ•è· (When head requests are forbidden, release status exceptions are caught)
             response.raise_for_status()
+
+            if (
+                response.headers.get("Content-Length") != None
+                and int(response.headers.get("Content-Length")) == 0
+            ):
+                # å¦‚æœheadè¯·æ±‚æ— æ³•è·å–Content-Length, åˆ™ä½¿ç”¨GETè¯·æ±‚å†æ¬¡å°è¯•è·å–
+                response = await client.get(url, headers=headers, follow_redirects=True)
+                response.raise_for_status()
+
         except httpx.ConnectTimeout:
             # è¿æ¥è¶…æ—¶é”™è¯¯å¤„ç† (Handling connection timeout errors)
             logger.error(_("è¿æ¥è¶…æ—¶é”™è¯¯: {0}".format(url)))
-            logger.error("==========================")
+            logger.error("===================================")
             logger.error(f"headers:{headers}, proxies:{proxies}")
-            logger.error("==========================")
+            logger.error("===================================")
             return 0
         # å¯¹HTTPçŠ¶æ€é”™è¯¯è¿›è¡Œå¤„ç† (Handling HTTP status errors)
         except httpx.HTTPStatusError as exc:
             # HEADæˆ–è¯·æ±‚ä¸è¢«å…è®¸ (HEAD or request not allowed)
             if exc.response.status_code in [405, 403, 401, 302]:
                 try:
                     # ä½¿ç”¨GETè¯·æ±‚å°è¯•å†æ¬¡è·å–Content-Length
```

### Comparing `f2-0.0.1.4/f2/utils/_signal.py` & `f2-0.0.1.5/f2/utils/_signal.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/utils/_singleton.py` & `f2-0.0.1.5/f2/utils/_singleton.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/f2/utils/conf_manager.py` & `f2-0.0.1.5/f2/utils/conf_manager.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 # path: f2/utils/conf_manager.py
 
 import f2
-import time
 import yaml
 import click
 
 from pathlib import Path
 from f2.exceptions.file_exceptions import (
     FileNotFound,
     FilePermissionError,
@@ -23,22 +22,18 @@
         else:
             self.filepath = Path(get_resource_path(filepath))
         self.config = self.load_config()
 
     def load_config(self) -> dict:
         """ä»æ–‡ä»¶ä¸­åŠ è½½é…ç½® (Load the conf from the file)"""
 
-        try:
-            if not self.filepath.exists():
-                raise FileNotFound(_("'{0}' é…ç½®æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨").format(self.filepath))
-            return yaml.safe_load(self.filepath.read_text(encoding="utf-8")) or {}
-        except FileNotFound as e:
-            e.display_error()
-            time.sleep(2)
-            exit(0)
+        if not self.filepath.exists():
+            raise FileNotFound(_("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"), self.filepath)
+
+        return yaml.safe_load(self.filepath.read_text(encoding="utf-8")) or {}
 
     def get_config(self, app_name: str, default=None) -> dict:
         """
         ä»é…ç½®ä¸­è·å–ç»™å®šé”®çš„å€¼ (Get the value of the given key from the conf)
 
         Args:
             app_name: str: åº”ç”¨åç§° (app name)
@@ -54,17 +49,15 @@
         """å°†é…ç½®ä¿å­˜åˆ°æ–‡ä»¶ (Save the conf to the file)
         Args:
             config: dict: é…ç½®å­—å…¸ (conf dict)
         """
         try:
             self.filepath.write_text(yaml.dump(config), encoding="utf-8")
         except PermissionError:
-            raise FilePermissionError(
-                _("'{0}' é…ç½®æ–‡ä»¶è·¯å¾„æ— å†™æƒé™").format(self.filepath)
-            )
+            raise FilePermissionError(_("é…ç½®æ–‡ä»¶è·¯å¾„æ— å†™æƒé™"), self.filepath)
 
     def backup_config(self):
         """åœ¨è¿›è¡Œæ›´æ”¹å‰å¤‡ä»½é…ç½®æ–‡ä»¶ (Backup the conf file before making changes)"""
         # å¦‚æœå·²ç»æ˜¯å¤‡ä»½æ–‡ä»¶ï¼Œç›´æ¥è¿”å› (If it is already a backup file, return directly)
         if self.filepath.suffix == ".bak":
             return
```

### Comparing `f2-0.0.1.4/f2/utils/json_filter.py` & `f2-0.0.1.5/f2/utils/json_filter.py`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/.gitignore` & `f2-0.0.1.5/.gitignore`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/LICENSE` & `f2-0.0.1.5/LICENSE`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/README.md` & `f2-0.0.1.5/README.md`

 * *Files identical despite different names*

### Comparing `f2-0.0.1.4/pyproject.toml` & `f2-0.0.1.5/pyproject.toml`

 * *Files 1% similar despite different names*

```diff
@@ -23,15 +23,15 @@
     "Intended Audience :: Developers",
     "Intended Audience :: Customer Service",
     "License :: OSI Approved :: Apache Software License"
 ]
 
 dependencies = [
     "click==8.1.7",
-    "rich==13.6.0",
+    "rich==13.7.1",
     "httpx==0.25.0",
     "aiofiles==22.1.0",
     "aiosqlite==0.19.0",
     "pyyaml==6.0.1",
     "jsonpath-ng==1.6.0",
     "importlib_resources==6.1.0",
     "m3u8==3.6.0",
```

### Comparing `f2-0.0.1.4/PKG-INFO` & `f2-0.0.1.5/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-Metadata-Version: 2.1
+Metadata-Version: 2.3
 Name: f2
-Version: 0.0.1.4
+Version: 0.0.1.5
 Summary: ğŸš€Asynchronous based full-platform download tool
 Project-URL: Homepage, https://github.com/Johnserf-Seed/f2
 Project-URL: Documentation, https://johnserf-seed.github.io/f2/
 Project-URL: Chat, https://discord.gg//3PhtPmgHf8
 Project-URL: Source Code, https://github.com/Johnserf-Seed/f2
 Project-URL: Issue Tracker, https://github.com/Johnserf-Seed/f2/issues
 Author-email: Johnserf-Seed <johnserf-seed@foxmail.com>
@@ -28,15 +28,15 @@
 Requires-Dist: jsonpath-ng==1.6.0
 Requires-Dist: m3u8==3.6.0
 Requires-Dist: pydantic==1.10.12
 Requires-Dist: pytest-asyncio==0.21.1
 Requires-Dist: pytest==7.4.2
 Requires-Dist: pyyaml==6.0.1
 Requires-Dist: qrcode==7.4.2
-Requires-Dist: rich==13.6.0
+Requires-Dist: rich==13.7.1
 Description-Content-Type: text/markdown
 
 
 <p align="center">
   <img src="https://github.com/Johnserf-Seed/f2/raw/main/docs/public/f2-logo-with-shadow-svg@0.5x.svg" alt="Logo">
 </p>
```

